program(1.0)
[buildInfo = dict<tensor<string, []>, tensor<string, []>>({{"coremlc-component-MIL", "3304.5.2"}, {"coremlc-version", "3304.6.2"}})]
{
    func main<ios17>(tensor<int32, [1]> cache_length, tensor<fp16, [1, 448]> decoder_key_padding_mask, tensor<fp16, [1, 1280, 1, 1500]> encoder_output_embeds, tensor<int32, [1]> input_ids, tensor<fp16, [1, 40960, 1, 448]> key_cache, tensor<fp16, [1, 448]> kv_cache_update_mask, tensor<fp16, [1, 40960, 1, 448]> value_cache) {
            tensor<int32, []> var_80_axis_0 = const()[name = tensor<string, []>("op_80_axis_0"), val = tensor<int32, []>(0)];
            tensor<int32, []> var_80_batch_dims_0 = const()[name = tensor<string, []>("op_80_batch_dims_0"), val = tensor<int32, []>(0)];
            tensor<bool, []> var_80_validate_indices_0 = const()[name = tensor<string, []>("op_80_validate_indices_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [51866, 1280]> embed_tokens_weight_to_fp16 = const()[name = tensor<string, []>("embed_tokens_weight_to_fp16"), val = tensor<fp16, [51866, 1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(64)))];
            tensor<fp16, [1, 1280]> var_80_cast_fp16 = gather(axis = var_80_axis_0, batch_dims = var_80_batch_dims_0, indices = input_ids, validate_indices = var_80_validate_indices_0, x = embed_tokens_weight_to_fp16)[name = tensor<string, []>("op_80_cast_fp16")];
            tensor<int32, []> var_84_axis_0 = const()[name = tensor<string, []>("op_84_axis_0"), val = tensor<int32, []>(0)];
            tensor<int32, []> var_84_batch_dims_0 = const()[name = tensor<string, []>("op_84_batch_dims_0"), val = tensor<int32, []>(0)];
            tensor<bool, []> var_84_validate_indices_0 = const()[name = tensor<string, []>("op_84_validate_indices_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [448, 1280]> embed_positions_weight_to_fp16 = const()[name = tensor<string, []>("embed_positions_weight_to_fp16"), val = tensor<fp16, [448, 1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(132777088)))];
            tensor<string, []> cache_length_to_int16_dtype_0 = const()[name = tensor<string, []>("cache_length_to_int16_dtype_0"), val = tensor<string, []>("int16")];
            tensor<int16, [1]> cast_0 = cast(dtype = cache_length_to_int16_dtype_0, x = cache_length)[name = tensor<string, []>("cast_0")];
            tensor<fp16, [1, 1280]> var_84_cast_fp16_cast_int16 = gather(axis = var_84_axis_0, batch_dims = var_84_batch_dims_0, indices = cast_0, validate_indices = var_84_validate_indices_0, x = embed_positions_weight_to_fp16)[name = tensor<string, []>("op_84_cast_fp16_cast_int16")];
            tensor<fp16, [1, 1280]> hidden_states_1_cast_fp16 = add(x = var_80_cast_fp16, y = var_84_cast_fp16_cast_int16)[name = tensor<string, []>("hidden_states_1_cast_fp16")];
            tensor<int32, [1]> var_98_axes_0 = const()[name = tensor<string, []>("op_98_axes_0"), val = tensor<int32, [1]>([2])];
            tensor<fp16, [1, 1280, 1]> var_98_cast_fp16 = expand_dims(axes = var_98_axes_0, x = hidden_states_1_cast_fp16)[name = tensor<string, []>("op_98_cast_fp16")];
            tensor<int32, [1]> inputs_1_axes_0 = const()[name = tensor<string, []>("inputs_1_axes_0"), val = tensor<int32, [1]>([3])];
            tensor<fp16, [1, 1280, 1, 1]> inputs_1_cast_fp16 = expand_dims(axes = inputs_1_axes_0, x = var_98_cast_fp16)[name = tensor<string, []>("inputs_1_cast_fp16")];
            tensor<int32, [32]> tile_0 = const()[name = tensor<string, []>("tile_0"), val = tensor<int32, [32]>([1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280])];
            tensor<int32, []> var_103_axis_0 = const()[name = tensor<string, []>("op_103_axis_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_0, tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_1, tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_2, tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_3, tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_4, tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_5, tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_6, tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_7, tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_8, tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_9, tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_10, tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_11, tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_12, tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_13, tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_14, tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_15, tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_16, tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_17, tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_18, tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_19, tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_20, tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_21, tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_22, tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_23, tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_24, tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_25, tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_26, tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_27, tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_28, tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_29, tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_30, tensor<fp16, [1, 1280, 1, 448]> var_103_cast_fp16_31 = split(axis = var_103_axis_0, split_sizes = tile_0, x = key_cache)[name = tensor<string, []>("op_103_cast_fp16")];
            tensor<int32, [32]> tile_1 = const()[name = tensor<string, []>("tile_1"), val = tensor<int32, [32]>([1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280, 1280])];
            tensor<int32, []> var_138_axis_0 = const()[name = tensor<string, []>("op_138_axis_0"), val = tensor<int32, []>(1)];
            tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_0, tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_1, tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_2, tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_3, tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_4, tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_5, tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_6, tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_7, tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_8, tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_9, tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_10, tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_11, tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_12, tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_13, tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_14, tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_15, tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_16, tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_17, tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_18, tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_19, tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_20, tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_21, tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_22, tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_23, tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_24, tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_25, tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_26, tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_27, tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_28, tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_29, tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_30, tensor<fp16, [1, 1280, 1, 448]> var_138_cast_fp16_31 = split(axis = var_138_axis_0, split_sizes = tile_1, x = value_cache)[name = tensor<string, []>("op_138_cast_fp16")];
            tensor<int32, []> var_176 = const()[name = tensor<string, []>("op_176"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_183 = const()[name = tensor<string, []>("op_183"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_184 = const()[name = tensor<string, []>("op_184"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_196 = const()[name = tensor<string, []>("op_196"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_1_cast_fp16 = reduce_mean(axes = var_196, keep_dims = var_184, x = inputs_1_cast_fp16)[name = tensor<string, []>("channels_mean_1_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_1_cast_fp16 = sub(x = inputs_1_cast_fp16, y = channels_mean_1_cast_fp16)[name = tensor<string, []>("zero_mean_1_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_1_cast_fp16 = mul(x = zero_mean_1_cast_fp16, y = zero_mean_1_cast_fp16)[name = tensor<string, []>("zero_mean_sq_1_cast_fp16")];
            tensor<int32, [1]> var_200 = const()[name = tensor<string, []>("op_200"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_201_cast_fp16 = reduce_mean(axes = var_200, keep_dims = var_184, x = zero_mean_sq_1_cast_fp16)[name = tensor<string, []>("op_201_cast_fp16")];
            tensor<fp16, []> var_202_to_fp16 = const()[name = tensor<string, []>("op_202_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_203_cast_fp16 = add(x = var_201_cast_fp16, y = var_202_to_fp16)[name = tensor<string, []>("op_203_cast_fp16")];
            tensor<fp32, []> denom_1_epsilon_0 = const()[name = tensor<string, []>("denom_1_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_1_cast_fp16 = rsqrt(epsilon = denom_1_epsilon_0, x = var_203_cast_fp16)[name = tensor<string, []>("denom_1_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_1_cast_fp16 = mul(x = zero_mean_1_cast_fp16, y = denom_1_cast_fp16)[name = tensor<string, []>("out_1_cast_fp16")];
            tensor<fp16, [1280]> obj_1_mean_0_to_fp16 = const()[name = tensor<string, []>("obj_1_mean_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(133924032)))];
            tensor<fp16, [1280]> obj_1_variance_0_to_fp16 = const()[name = tensor<string, []>("obj_1_variance_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(133926656)))];
            tensor<fp16, [1280]> obj_1_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_1_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(133929280)))];
            tensor<fp16, [1280]> obj_1_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_1_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(133931904)))];
            tensor<fp16, []> obj_1_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_1_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_1_cast_fp16 = batch_norm(beta = obj_1_beta_0_to_fp16, epsilon = obj_1_epsilon_0_to_fp16, gamma = obj_1_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_1_cast_fp16)[name = tensor<string, []>("obj_1_cast_fp16")];
            tensor<int32, [2]> var_221 = const()[name = tensor<string, []>("op_221"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_223 = const()[name = tensor<string, []>("op_223"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_1_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_1_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_1_pad_0 = const()[name = tensor<string, []>("pretrained_out_1_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_0_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(133934528))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(134753792))), name = tensor<string, []>("layers_0_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_0_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_0_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(134753920)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_1_cast_fp16 = conv(bias = layers_0_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_223, groups = var_183, pad = pretrained_out_1_pad_0, pad_type = pretrained_out_1_pad_type_0, strides = var_221, weight = layers_0_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_1_cast_fp16)[name = tensor<string, []>("pretrained_out_1_cast_fp16")];
            tensor<int32, [2]> var_227 = const()[name = tensor<string, []>("op_227"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_229 = const()[name = tensor<string, []>("op_229"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_1_pad_type_0 = const()[name = tensor<string, []>("input_1_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_1_pad_0 = const()[name = tensor<string, []>("input_1_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_0_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_0_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(134756544)))];
            tensor<fp16, [1, 16, 1, 1]> input_1_cast_fp16 = conv(dilations = var_229, groups = var_183, pad = input_1_pad_0, pad_type = input_1_pad_type_0, strides = var_227, weight = layers_0_self_attn_q_proj_loraA_weight_to_fp16, x = obj_1_cast_fp16)[name = tensor<string, []>("input_1_cast_fp16")];
            tensor<int32, [2]> var_233 = const()[name = tensor<string, []>("op_233"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_235 = const()[name = tensor<string, []>("op_235"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1_pad_type_0 = const()[name = tensor<string, []>("lora_out_1_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1_pad_0 = const()[name = tensor<string, []>("lora_out_1_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_3_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_3_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(134797568)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_3_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_235, groups = var_183, pad = lora_out_1_pad_0, pad_type = lora_out_1_pad_type_0, strides = var_233, weight = lora_out_3_weight_0_to_fp16, x = input_1_cast_fp16)[name = tensor<string, []>("lora_out_3_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_1_cast_fp16 = add(x = pretrained_out_1_cast_fp16, y = lora_out_3_cast_fp16)[name = tensor<string, []>("query_1_cast_fp16")];
            tensor<int32, [2]> var_245 = const()[name = tensor<string, []>("op_245"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_247 = const()[name = tensor<string, []>("op_247"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_3_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_3_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_3_pad_0 = const()[name = tensor<string, []>("pretrained_out_3_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_0_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(134838592))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(135657856))), name = tensor<string, []>("layers_0_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_3_cast_fp16 = conv(dilations = var_247, groups = var_183, pad = pretrained_out_3_pad_0, pad_type = pretrained_out_3_pad_type_0, strides = var_245, weight = layers_0_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_1_cast_fp16)[name = tensor<string, []>("pretrained_out_3_cast_fp16")];
            tensor<int32, [2]> var_251 = const()[name = tensor<string, []>("op_251"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_253 = const()[name = tensor<string, []>("op_253"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_3_pad_type_0 = const()[name = tensor<string, []>("input_3_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_3_pad_0 = const()[name = tensor<string, []>("input_3_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_0_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_0_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(135657984)))];
            tensor<fp16, [1, 16, 1, 1]> input_3_cast_fp16 = conv(dilations = var_253, groups = var_183, pad = input_3_pad_0, pad_type = input_3_pad_type_0, strides = var_251, weight = layers_0_self_attn_k_proj_loraA_weight_to_fp16, x = obj_1_cast_fp16)[name = tensor<string, []>("input_3_cast_fp16")];
            tensor<int32, [2]> var_257 = const()[name = tensor<string, []>("op_257"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_259 = const()[name = tensor<string, []>("op_259"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_5_pad_type_0 = const()[name = tensor<string, []>("lora_out_5_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_5_pad_0 = const()[name = tensor<string, []>("lora_out_5_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_7_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_7_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(135699008)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_7_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_259, groups = var_183, pad = lora_out_5_pad_0, pad_type = lora_out_5_pad_type_0, strides = var_257, weight = lora_out_7_weight_0_to_fp16, x = input_3_cast_fp16)[name = tensor<string, []>("lora_out_7_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_1_cast_fp16 = add(x = pretrained_out_3_cast_fp16, y = lora_out_7_cast_fp16)[name = tensor<string, []>("current_key_1_cast_fp16")];
            tensor<int32, [2]> var_270 = const()[name = tensor<string, []>("op_270"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_272 = const()[name = tensor<string, []>("op_272"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_5_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_5_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_5_pad_0 = const()[name = tensor<string, []>("pretrained_out_5_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_0_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(135740032))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(136559296))), name = tensor<string, []>("layers_0_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_0_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_0_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(136559424)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_5_cast_fp16 = conv(bias = layers_0_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_272, groups = var_183, pad = pretrained_out_5_pad_0, pad_type = pretrained_out_5_pad_type_0, strides = var_270, weight = layers_0_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_1_cast_fp16)[name = tensor<string, []>("pretrained_out_5_cast_fp16")];
            tensor<int32, [2]> var_276 = const()[name = tensor<string, []>("op_276"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_278 = const()[name = tensor<string, []>("op_278"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_5_pad_type_0 = const()[name = tensor<string, []>("input_5_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_5_pad_0 = const()[name = tensor<string, []>("input_5_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_0_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_0_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(136562048)))];
            tensor<fp16, [1, 16, 1, 1]> input_5_cast_fp16 = conv(dilations = var_278, groups = var_183, pad = input_5_pad_0, pad_type = input_5_pad_type_0, strides = var_276, weight = layers_0_self_attn_v_proj_loraA_weight_to_fp16, x = obj_1_cast_fp16)[name = tensor<string, []>("input_5_cast_fp16")];
            tensor<int32, [2]> var_282 = const()[name = tensor<string, []>("op_282"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_284 = const()[name = tensor<string, []>("op_284"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_9_pad_type_0 = const()[name = tensor<string, []>("lora_out_9_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_9_pad_0 = const()[name = tensor<string, []>("lora_out_9_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_11_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_11_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(136603072)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_11_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_284, groups = var_183, pad = lora_out_9_pad_0, pad_type = lora_out_9_pad_type_0, strides = var_282, weight = lora_out_11_weight_0_to_fp16, x = input_5_cast_fp16)[name = tensor<string, []>("lora_out_11_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_1_cast_fp16 = add(x = pretrained_out_5_cast_fp16, y = lora_out_11_cast_fp16)[name = tensor<string, []>("current_value_1_cast_fp16")];
            tensor<int32, [1]> var_291_axes_0 = const()[name = tensor<string, []>("op_291_axes_0"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 448]> var_291_cast_fp16 = expand_dims(axes = var_291_axes_0, x = kv_cache_update_mask)[name = tensor<string, []>("op_291_cast_fp16")];
            tensor<int32, [1]> var_292_axes_0 = const()[name = tensor<string, []>("op_292_axes_0"), val = tensor<int32, [1]>([2])];
            tensor<fp16, [1, 1, 1, 448]> var_292_cast_fp16 = expand_dims(axes = var_292_axes_0, x = var_291_cast_fp16)[name = tensor<string, []>("op_292_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_294_cast_fp16 = mul(x = current_key_1_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_294_cast_fp16")];
            tensor<fp16, []> var_177_to_fp16 = const()[name = tensor<string, []>("op_177_to_fp16"), val = tensor<fp16, []>(0x1p+0)];
            tensor<fp16, [1, 1, 1, 448]> var_295_cast_fp16 = sub(x = var_177_to_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_295_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_296_cast_fp16 = mul(x = var_103_cast_fp16_0, y = var_295_cast_fp16)[name = tensor<string, []>("op_296_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_1_cast_fp16 = add(x = var_294_cast_fp16, y = var_296_cast_fp16)[name = tensor<string, []>("key_1_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_298_cast_fp16 = mul(x = current_value_1_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_298_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_300_cast_fp16 = mul(x = var_138_cast_fp16_0, y = var_295_cast_fp16)[name = tensor<string, []>("op_300_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_1_cast_fp16 = add(x = var_298_cast_fp16, y = var_300_cast_fp16)[name = tensor<string, []>("value_1_cast_fp16")];
            tensor<int32, [4]> var_303 = const()[name = tensor<string, []>("op_303"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_304_cast_fp16 = reshape(shape = var_303, x = query_1_cast_fp16)[name = tensor<string, []>("op_304_cast_fp16")];
            tensor<fp16, []> var_305_to_fp16 = const()[name = tensor<string, []>("op_305_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_306_cast_fp16 = mul(x = var_304_cast_fp16, y = var_305_to_fp16)[name = tensor<string, []>("op_306_cast_fp16")];
            tensor<int32, [4]> var_307 = const()[name = tensor<string, []>("op_307"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_308_cast_fp16 = reshape(shape = var_307, x = key_1_cast_fp16)[name = tensor<string, []>("op_308_cast_fp16")];
            tensor<bool, []> mh_w_1_transpose_x_0 = const()[name = tensor<string, []>("mh_w_1_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_1_transpose_y_0 = const()[name = tensor<string, []>("mh_w_1_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_1_cast_fp16 = matmul(transpose_x = mh_w_1_transpose_x_0, transpose_y = mh_w_1_transpose_y_0, x = var_306_cast_fp16, y = var_308_cast_fp16)[name = tensor<string, []>("mh_w_1_cast_fp16")];
            tensor<int32, [1]> var_312_axes_0 = const()[name = tensor<string, []>("op_312_axes_0"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 448]> var_312_cast_fp16 = expand_dims(axes = var_312_axes_0, x = decoder_key_padding_mask)[name = tensor<string, []>("op_312_cast_fp16")];
            tensor<int32, [1]> var_313_axes_0 = const()[name = tensor<string, []>("op_313_axes_0"), val = tensor<int32, [1]>([2])];
            tensor<fp16, [1, 1, 1, 448]> var_313_cast_fp16 = expand_dims(axes = var_313_axes_0, x = var_312_cast_fp16)[name = tensor<string, []>("op_313_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_3_cast_fp16 = add(x = mh_w_1_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_3_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_316_cast_fp16 = softmax(axis = var_176, x = mh_w_3_cast_fp16)[name = tensor<string, []>("op_316_cast_fp16")];
            tensor<int32, [4]> var_317 = const()[name = tensor<string, []>("op_317"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_318_cast_fp16 = reshape(shape = var_317, x = value_1_cast_fp16)[name = tensor<string, []>("op_318_cast_fp16")];
            tensor<bool, []> attn_1_transpose_x_0 = const()[name = tensor<string, []>("attn_1_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_1_transpose_y_0 = const()[name = tensor<string, []>("attn_1_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_1_cast_fp16 = matmul(transpose_x = attn_1_transpose_x_0, transpose_y = attn_1_transpose_y_0, x = var_318_cast_fp16, y = var_316_cast_fp16)[name = tensor<string, []>("attn_1_cast_fp16")];
            tensor<int32, [4]> var_321 = const()[name = tensor<string, []>("op_321"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_7_cast_fp16 = reshape(shape = var_321, x = attn_1_cast_fp16)[name = tensor<string, []>("input_7_cast_fp16")];
            tensor<int32, [2]> var_328 = const()[name = tensor<string, []>("op_328"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_330 = const()[name = tensor<string, []>("op_330"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_7_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_7_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_7_pad_0 = const()[name = tensor<string, []>("pretrained_out_7_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_0_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(136644096))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(137463360))), name = tensor<string, []>("layers_0_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_0_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_0_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(137463488)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_7_cast_fp16 = conv(bias = layers_0_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_330, groups = var_183, pad = pretrained_out_7_pad_0, pad_type = pretrained_out_7_pad_type_0, strides = var_328, weight = layers_0_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_7_cast_fp16)[name = tensor<string, []>("pretrained_out_7_cast_fp16")];
            tensor<int32, [2]> var_334 = const()[name = tensor<string, []>("op_334"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_336 = const()[name = tensor<string, []>("op_336"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_9_pad_type_0 = const()[name = tensor<string, []>("input_9_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_9_pad_0 = const()[name = tensor<string, []>("input_9_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_0_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_0_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(137466112)))];
            tensor<fp16, [1, 16, 1, 1]> input_9_cast_fp16 = conv(dilations = var_336, groups = var_183, pad = input_9_pad_0, pad_type = input_9_pad_type_0, strides = var_334, weight = layers_0_self_attn_o_proj_loraA_weight_to_fp16, x = input_7_cast_fp16)[name = tensor<string, []>("input_9_cast_fp16")];
            tensor<int32, [2]> var_340 = const()[name = tensor<string, []>("op_340"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_342 = const()[name = tensor<string, []>("op_342"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_13_pad_type_0 = const()[name = tensor<string, []>("lora_out_13_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_13_pad_0 = const()[name = tensor<string, []>("lora_out_13_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_15_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_15_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(137507136)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_15_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_342, groups = var_183, pad = lora_out_13_pad_0, pad_type = lora_out_13_pad_type_0, strides = var_340, weight = lora_out_15_weight_0_to_fp16, x = input_9_cast_fp16)[name = tensor<string, []>("lora_out_15_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_7_cast_fp16 = add(x = pretrained_out_7_cast_fp16, y = lora_out_15_cast_fp16)[name = tensor<string, []>("obj_7_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_3_cast_fp16 = add(x = inputs_1_cast_fp16, y = obj_7_cast_fp16)[name = tensor<string, []>("inputs_3_cast_fp16")];
            tensor<int32, [1]> var_355 = const()[name = tensor<string, []>("op_355"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_3_cast_fp16 = reduce_mean(axes = var_355, keep_dims = var_184, x = inputs_3_cast_fp16)[name = tensor<string, []>("channels_mean_3_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_3_cast_fp16 = sub(x = inputs_3_cast_fp16, y = channels_mean_3_cast_fp16)[name = tensor<string, []>("zero_mean_3_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_3_cast_fp16 = mul(x = zero_mean_3_cast_fp16, y = zero_mean_3_cast_fp16)[name = tensor<string, []>("zero_mean_sq_3_cast_fp16")];
            tensor<int32, [1]> var_359 = const()[name = tensor<string, []>("op_359"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_360_cast_fp16 = reduce_mean(axes = var_359, keep_dims = var_184, x = zero_mean_sq_3_cast_fp16)[name = tensor<string, []>("op_360_cast_fp16")];
            tensor<fp16, []> var_361_to_fp16 = const()[name = tensor<string, []>("op_361_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_362_cast_fp16 = add(x = var_360_cast_fp16, y = var_361_to_fp16)[name = tensor<string, []>("op_362_cast_fp16")];
            tensor<fp32, []> denom_3_epsilon_0 = const()[name = tensor<string, []>("denom_3_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_3_cast_fp16 = rsqrt(epsilon = denom_3_epsilon_0, x = var_362_cast_fp16)[name = tensor<string, []>("denom_3_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_3_cast_fp16 = mul(x = zero_mean_3_cast_fp16, y = denom_3_cast_fp16)[name = tensor<string, []>("out_3_cast_fp16")];
            tensor<fp16, [1280]> obj_9_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_9_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(137548160)))];
            tensor<fp16, [1280]> obj_9_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_9_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(137550784)))];
            tensor<fp16, []> obj_9_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_9_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_9_cast_fp16 = batch_norm(beta = obj_9_beta_0_to_fp16, epsilon = obj_9_epsilon_0_to_fp16, gamma = obj_9_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_3_cast_fp16)[name = tensor<string, []>("obj_9_cast_fp16")];
            tensor<int32, [2]> var_380 = const()[name = tensor<string, []>("op_380"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_382 = const()[name = tensor<string, []>("op_382"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_9_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_9_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_9_pad_0 = const()[name = tensor<string, []>("pretrained_out_9_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_0_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(137553408))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(138372672))), name = tensor<string, []>("layers_0_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_0_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_0_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(138372800)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_9_cast_fp16 = conv(bias = layers_0_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_382, groups = var_183, pad = pretrained_out_9_pad_0, pad_type = pretrained_out_9_pad_type_0, strides = var_380, weight = layers_0_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_9_cast_fp16)[name = tensor<string, []>("pretrained_out_9_cast_fp16")];
            tensor<int32, [2]> var_386 = const()[name = tensor<string, []>("op_386"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_388 = const()[name = tensor<string, []>("op_388"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_11_pad_type_0 = const()[name = tensor<string, []>("input_11_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_11_pad_0 = const()[name = tensor<string, []>("input_11_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_0_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_0_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(138375424)))];
            tensor<fp16, [1, 16, 1, 1]> input_11_cast_fp16 = conv(dilations = var_388, groups = var_183, pad = input_11_pad_0, pad_type = input_11_pad_type_0, strides = var_386, weight = layers_0_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_9_cast_fp16)[name = tensor<string, []>("input_11_cast_fp16")];
            tensor<int32, [2]> var_392 = const()[name = tensor<string, []>("op_392"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_394 = const()[name = tensor<string, []>("op_394"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_17_pad_type_0 = const()[name = tensor<string, []>("lora_out_17_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_17_pad_0 = const()[name = tensor<string, []>("lora_out_17_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_19_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_19_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(138416448)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_19_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_394, groups = var_183, pad = lora_out_17_pad_0, pad_type = lora_out_17_pad_type_0, strides = var_392, weight = lora_out_19_weight_0_to_fp16, x = input_11_cast_fp16)[name = tensor<string, []>("lora_out_19_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_3_cast_fp16 = add(x = pretrained_out_9_cast_fp16, y = lora_out_19_cast_fp16)[name = tensor<string, []>("query_3_cast_fp16")];
            tensor<int32, [2]> var_404 = const()[name = tensor<string, []>("op_404"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_406 = const()[name = tensor<string, []>("op_406"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_11_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_11_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_11_pad_0 = const()[name = tensor<string, []>("pretrained_out_11_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_0_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(138457472))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(139276736))), name = tensor<string, []>("layers_0_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_11_cast_fp16 = conv(dilations = var_406, groups = var_183, pad = pretrained_out_11_pad_0, pad_type = pretrained_out_11_pad_type_0, strides = var_404, weight = layers_0_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_11_cast_fp16")];
            tensor<int32, [2]> var_410 = const()[name = tensor<string, []>("op_410"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_412 = const()[name = tensor<string, []>("op_412"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_13_pad_type_0 = const()[name = tensor<string, []>("input_13_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_13_pad_0 = const()[name = tensor<string, []>("input_13_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_0_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_0_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(139276864)))];
            tensor<fp16, [1, 16, 1, 1500]> input_13_cast_fp16 = conv(dilations = var_412, groups = var_183, pad = input_13_pad_0, pad_type = input_13_pad_type_0, strides = var_410, weight = layers_0_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_13_cast_fp16")];
            tensor<int32, [2]> var_416 = const()[name = tensor<string, []>("op_416"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_418 = const()[name = tensor<string, []>("op_418"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_21_pad_type_0 = const()[name = tensor<string, []>("lora_out_21_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_21_pad_0 = const()[name = tensor<string, []>("lora_out_21_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_23_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_23_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(139317888)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_23_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_418, groups = var_183, pad = lora_out_21_pad_0, pad_type = lora_out_21_pad_type_0, strides = var_416, weight = lora_out_23_weight_0_to_fp16, x = input_13_cast_fp16)[name = tensor<string, []>("lora_out_23_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_3_cast_fp16 = add(x = pretrained_out_11_cast_fp16, y = lora_out_23_cast_fp16)[name = tensor<string, []>("key_3_cast_fp16")];
            tensor<int32, [2]> var_429 = const()[name = tensor<string, []>("op_429"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_431 = const()[name = tensor<string, []>("op_431"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_13_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_13_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_13_pad_0 = const()[name = tensor<string, []>("pretrained_out_13_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_0_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(139358912))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(140178176))), name = tensor<string, []>("layers_0_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_0_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_0_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(140178304)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_13_cast_fp16 = conv(bias = layers_0_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_431, groups = var_183, pad = pretrained_out_13_pad_0, pad_type = pretrained_out_13_pad_type_0, strides = var_429, weight = layers_0_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_13_cast_fp16")];
            tensor<int32, [2]> var_435 = const()[name = tensor<string, []>("op_435"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_437 = const()[name = tensor<string, []>("op_437"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_15_pad_type_0 = const()[name = tensor<string, []>("input_15_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_15_pad_0 = const()[name = tensor<string, []>("input_15_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_0_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_0_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(140180928)))];
            tensor<fp16, [1, 16, 1, 1500]> input_15_cast_fp16 = conv(dilations = var_437, groups = var_183, pad = input_15_pad_0, pad_type = input_15_pad_type_0, strides = var_435, weight = layers_0_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_15_cast_fp16")];
            tensor<int32, [2]> var_441 = const()[name = tensor<string, []>("op_441"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_443 = const()[name = tensor<string, []>("op_443"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_25_pad_type_0 = const()[name = tensor<string, []>("lora_out_25_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_25_pad_0 = const()[name = tensor<string, []>("lora_out_25_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_27_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_27_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(140221952)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_27_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_443, groups = var_183, pad = lora_out_25_pad_0, pad_type = lora_out_25_pad_type_0, strides = var_441, weight = lora_out_27_weight_0_to_fp16, x = input_15_cast_fp16)[name = tensor<string, []>("lora_out_27_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_3_cast_fp16 = add(x = pretrained_out_13_cast_fp16, y = lora_out_27_cast_fp16)[name = tensor<string, []>("value_3_cast_fp16")];
            tensor<int32, [4]> var_450 = const()[name = tensor<string, []>("op_450"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_451_cast_fp16 = reshape(shape = var_450, x = query_3_cast_fp16)[name = tensor<string, []>("op_451_cast_fp16")];
            tensor<fp16, []> var_452_to_fp16 = const()[name = tensor<string, []>("op_452_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_453_cast_fp16 = mul(x = var_451_cast_fp16, y = var_452_to_fp16)[name = tensor<string, []>("op_453_cast_fp16")];
            tensor<int32, [4]> var_454 = const()[name = tensor<string, []>("op_454"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_455_cast_fp16 = reshape(shape = var_454, x = key_3_cast_fp16)[name = tensor<string, []>("op_455_cast_fp16")];
            tensor<bool, []> mh_w_5_transpose_x_0 = const()[name = tensor<string, []>("mh_w_5_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_5_transpose_y_0 = const()[name = tensor<string, []>("mh_w_5_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_5_cast_fp16 = matmul(transpose_x = mh_w_5_transpose_x_0, transpose_y = mh_w_5_transpose_y_0, x = var_453_cast_fp16, y = var_455_cast_fp16)[name = tensor<string, []>("mh_w_5_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_13_cast_fp16 = softmax(axis = var_176, x = mh_w_5_cast_fp16)[name = tensor<string, []>("obj_13_cast_fp16")];
            tensor<int32, [4]> var_459 = const()[name = tensor<string, []>("op_459"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_460_cast_fp16 = reshape(shape = var_459, x = value_3_cast_fp16)[name = tensor<string, []>("op_460_cast_fp16")];
            tensor<bool, []> attn_3_transpose_x_0 = const()[name = tensor<string, []>("attn_3_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_3_transpose_y_0 = const()[name = tensor<string, []>("attn_3_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_3_cast_fp16 = matmul(transpose_x = attn_3_transpose_x_0, transpose_y = attn_3_transpose_y_0, x = var_460_cast_fp16, y = obj_13_cast_fp16)[name = tensor<string, []>("attn_3_cast_fp16")];
            tensor<int32, [4]> var_463 = const()[name = tensor<string, []>("op_463"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_17_cast_fp16 = reshape(shape = var_463, x = attn_3_cast_fp16)[name = tensor<string, []>("input_17_cast_fp16")];
            tensor<int32, [2]> var_470 = const()[name = tensor<string, []>("op_470"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_472 = const()[name = tensor<string, []>("op_472"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_15_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_15_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_15_pad_0 = const()[name = tensor<string, []>("pretrained_out_15_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_0_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(140262976))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(141082240))), name = tensor<string, []>("layers_0_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_0_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_0_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(141082368)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_15_cast_fp16 = conv(bias = layers_0_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_472, groups = var_183, pad = pretrained_out_15_pad_0, pad_type = pretrained_out_15_pad_type_0, strides = var_470, weight = layers_0_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_17_cast_fp16)[name = tensor<string, []>("pretrained_out_15_cast_fp16")];
            tensor<int32, [2]> var_476 = const()[name = tensor<string, []>("op_476"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_478 = const()[name = tensor<string, []>("op_478"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_19_pad_type_0 = const()[name = tensor<string, []>("input_19_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_19_pad_0 = const()[name = tensor<string, []>("input_19_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_0_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_0_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(141084992)))];
            tensor<fp16, [1, 16, 1, 1]> input_19_cast_fp16 = conv(dilations = var_478, groups = var_183, pad = input_19_pad_0, pad_type = input_19_pad_type_0, strides = var_476, weight = layers_0_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_17_cast_fp16)[name = tensor<string, []>("input_19_cast_fp16")];
            tensor<int32, [2]> var_482 = const()[name = tensor<string, []>("op_482"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_484 = const()[name = tensor<string, []>("op_484"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_29_pad_type_0 = const()[name = tensor<string, []>("lora_out_29_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_29_pad_0 = const()[name = tensor<string, []>("lora_out_29_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_31_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_31_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(141126016)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_31_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_484, groups = var_183, pad = lora_out_29_pad_0, pad_type = lora_out_29_pad_type_0, strides = var_482, weight = lora_out_31_weight_0_to_fp16, x = input_19_cast_fp16)[name = tensor<string, []>("lora_out_31_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_11_cast_fp16 = add(x = pretrained_out_15_cast_fp16, y = lora_out_31_cast_fp16)[name = tensor<string, []>("obj_11_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_5_cast_fp16 = add(x = inputs_3_cast_fp16, y = obj_11_cast_fp16)[name = tensor<string, []>("inputs_5_cast_fp16")];
            tensor<int32, [1]> var_493 = const()[name = tensor<string, []>("op_493"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_5_cast_fp16 = reduce_mean(axes = var_493, keep_dims = var_184, x = inputs_5_cast_fp16)[name = tensor<string, []>("channels_mean_5_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_5_cast_fp16 = sub(x = inputs_5_cast_fp16, y = channels_mean_5_cast_fp16)[name = tensor<string, []>("zero_mean_5_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_5_cast_fp16 = mul(x = zero_mean_5_cast_fp16, y = zero_mean_5_cast_fp16)[name = tensor<string, []>("zero_mean_sq_5_cast_fp16")];
            tensor<int32, [1]> var_497 = const()[name = tensor<string, []>("op_497"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_498_cast_fp16 = reduce_mean(axes = var_497, keep_dims = var_184, x = zero_mean_sq_5_cast_fp16)[name = tensor<string, []>("op_498_cast_fp16")];
            tensor<fp16, []> var_499_to_fp16 = const()[name = tensor<string, []>("op_499_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_500_cast_fp16 = add(x = var_498_cast_fp16, y = var_499_to_fp16)[name = tensor<string, []>("op_500_cast_fp16")];
            tensor<fp32, []> denom_5_epsilon_0 = const()[name = tensor<string, []>("denom_5_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_5_cast_fp16 = rsqrt(epsilon = denom_5_epsilon_0, x = var_500_cast_fp16)[name = tensor<string, []>("denom_5_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_5_cast_fp16 = mul(x = zero_mean_5_cast_fp16, y = denom_5_cast_fp16)[name = tensor<string, []>("out_5_cast_fp16")];
            tensor<fp16, [1280]> input_21_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_21_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(141167040)))];
            tensor<fp16, [1280]> input_21_beta_0_to_fp16 = const()[name = tensor<string, []>("input_21_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(141169664)))];
            tensor<fp16, []> input_21_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_21_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_21_cast_fp16 = batch_norm(beta = input_21_beta_0_to_fp16, epsilon = input_21_epsilon_0_to_fp16, gamma = input_21_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_5_cast_fp16)[name = tensor<string, []>("input_21_cast_fp16")];
            tensor<int32, [2]> var_514 = const()[name = tensor<string, []>("op_514"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_516 = const()[name = tensor<string, []>("op_516"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_17_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_17_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_17_pad_0 = const()[name = tensor<string, []>("pretrained_out_17_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_0_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(141172288))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(144449152))), name = tensor<string, []>("layers_0_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_0_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_0_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(144449280)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_17_cast_fp16 = conv(bias = layers_0_fc1_pretrained_bias_to_fp16, dilations = var_516, groups = var_183, pad = pretrained_out_17_pad_0, pad_type = pretrained_out_17_pad_type_0, strides = var_514, weight = layers_0_fc1_pretrained_weight_to_fp16_palettized, x = input_21_cast_fp16)[name = tensor<string, []>("pretrained_out_17_cast_fp16")];
            tensor<int32, [2]> var_520 = const()[name = tensor<string, []>("op_520"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_522 = const()[name = tensor<string, []>("op_522"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_23_pad_type_0 = const()[name = tensor<string, []>("input_23_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_23_pad_0 = const()[name = tensor<string, []>("input_23_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_0_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_0_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(144459584)))];
            tensor<fp16, [1, 16, 1, 1]> input_23_cast_fp16 = conv(dilations = var_522, groups = var_183, pad = input_23_pad_0, pad_type = input_23_pad_type_0, strides = var_520, weight = layers_0_fc1_loraA_weight_to_fp16, x = input_21_cast_fp16)[name = tensor<string, []>("input_23_cast_fp16")];
            tensor<int32, [2]> var_526 = const()[name = tensor<string, []>("op_526"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_528 = const()[name = tensor<string, []>("op_528"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_33_pad_type_0 = const()[name = tensor<string, []>("lora_out_33_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_33_pad_0 = const()[name = tensor<string, []>("lora_out_33_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_35_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_35_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(144500608)))];
            tensor<fp16, [5120]> lora_out_35_bias_0_to_fp16 = const()[name = tensor<string, []>("lora_out_35_bias_0_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(144664512)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_35_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_528, groups = var_183, pad = lora_out_33_pad_0, pad_type = lora_out_33_pad_type_0, strides = var_526, weight = lora_out_35_weight_0_to_fp16, x = input_23_cast_fp16)[name = tensor<string, []>("lora_out_35_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_25_cast_fp16 = add(x = pretrained_out_17_cast_fp16, y = lora_out_35_cast_fp16)[name = tensor<string, []>("input_25_cast_fp16")];
            tensor<string, []> input_27_mode_0 = const()[name = tensor<string, []>("input_27_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_27_cast_fp16 = gelu(mode = input_27_mode_0, x = input_25_cast_fp16)[name = tensor<string, []>("input_27_cast_fp16")];
            tensor<int32, [2]> var_540 = const()[name = tensor<string, []>("op_540"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_542 = const()[name = tensor<string, []>("op_542"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_19_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_19_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_19_pad_0 = const()[name = tensor<string, []>("pretrained_out_19_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_0_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(144674816))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(147951680))), name = tensor<string, []>("layers_0_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_0_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_0_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(147951808)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_19_cast_fp16 = conv(bias = layers_0_fc2_pretrained_bias_to_fp16, dilations = var_542, groups = var_183, pad = pretrained_out_19_pad_0, pad_type = pretrained_out_19_pad_type_0, strides = var_540, weight = layers_0_fc2_pretrained_weight_to_fp16_palettized, x = input_27_cast_fp16)[name = tensor<string, []>("pretrained_out_19_cast_fp16")];
            tensor<int32, [2]> var_546 = const()[name = tensor<string, []>("op_546"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_548 = const()[name = tensor<string, []>("op_548"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_29_pad_type_0 = const()[name = tensor<string, []>("input_29_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_29_pad_0 = const()[name = tensor<string, []>("input_29_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_0_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_0_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(147954432)))];
            tensor<fp16, [1, 16, 1, 1]> input_29_cast_fp16 = conv(dilations = var_548, groups = var_183, pad = input_29_pad_0, pad_type = input_29_pad_type_0, strides = var_546, weight = layers_0_fc2_loraA_weight_to_fp16, x = input_27_cast_fp16)[name = tensor<string, []>("input_29_cast_fp16")];
            tensor<int32, [2]> var_552 = const()[name = tensor<string, []>("op_552"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_554 = const()[name = tensor<string, []>("op_554"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_37_pad_type_0 = const()[name = tensor<string, []>("lora_out_37_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_37_pad_0 = const()[name = tensor<string, []>("lora_out_37_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_39_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_39_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(148118336)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_39_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_554, groups = var_183, pad = lora_out_37_pad_0, pad_type = lora_out_37_pad_type_0, strides = var_552, weight = lora_out_39_weight_0_to_fp16, x = input_29_cast_fp16)[name = tensor<string, []>("lora_out_39_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_3_cast_fp16 = add(x = pretrained_out_19_cast_fp16, y = lora_out_39_cast_fp16)[name = tensor<string, []>("hidden_states_3_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_7_cast_fp16 = add(x = inputs_5_cast_fp16, y = hidden_states_3_cast_fp16)[name = tensor<string, []>("inputs_7_cast_fp16")];
            tensor<int32, []> var_570 = const()[name = tensor<string, []>("op_570"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_577 = const()[name = tensor<string, []>("op_577"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_578 = const()[name = tensor<string, []>("op_578"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_590 = const()[name = tensor<string, []>("op_590"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_7_cast_fp16 = reduce_mean(axes = var_590, keep_dims = var_578, x = inputs_7_cast_fp16)[name = tensor<string, []>("channels_mean_7_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_7_cast_fp16 = sub(x = inputs_7_cast_fp16, y = channels_mean_7_cast_fp16)[name = tensor<string, []>("zero_mean_7_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_7_cast_fp16 = mul(x = zero_mean_7_cast_fp16, y = zero_mean_7_cast_fp16)[name = tensor<string, []>("zero_mean_sq_7_cast_fp16")];
            tensor<int32, [1]> var_594 = const()[name = tensor<string, []>("op_594"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_595_cast_fp16 = reduce_mean(axes = var_594, keep_dims = var_578, x = zero_mean_sq_7_cast_fp16)[name = tensor<string, []>("op_595_cast_fp16")];
            tensor<fp16, []> var_596_to_fp16 = const()[name = tensor<string, []>("op_596_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_597_cast_fp16 = add(x = var_595_cast_fp16, y = var_596_to_fp16)[name = tensor<string, []>("op_597_cast_fp16")];
            tensor<fp32, []> denom_7_epsilon_0 = const()[name = tensor<string, []>("denom_7_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_7_cast_fp16 = rsqrt(epsilon = denom_7_epsilon_0, x = var_597_cast_fp16)[name = tensor<string, []>("denom_7_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_7_cast_fp16 = mul(x = zero_mean_7_cast_fp16, y = denom_7_cast_fp16)[name = tensor<string, []>("out_7_cast_fp16")];
            tensor<fp16, [1280]> obj_15_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_15_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(148159360)))];
            tensor<fp16, [1280]> obj_15_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_15_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(148161984)))];
            tensor<fp16, []> obj_15_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_15_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_15_cast_fp16 = batch_norm(beta = obj_15_beta_0_to_fp16, epsilon = obj_15_epsilon_0_to_fp16, gamma = obj_15_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_7_cast_fp16)[name = tensor<string, []>("obj_15_cast_fp16")];
            tensor<int32, [2]> var_615 = const()[name = tensor<string, []>("op_615"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_617 = const()[name = tensor<string, []>("op_617"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_21_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_21_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_21_pad_0 = const()[name = tensor<string, []>("pretrained_out_21_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_1_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(148164608))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(148983872))), name = tensor<string, []>("layers_1_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_1_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_1_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(148984000)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_21_cast_fp16 = conv(bias = layers_1_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_617, groups = var_577, pad = pretrained_out_21_pad_0, pad_type = pretrained_out_21_pad_type_0, strides = var_615, weight = layers_1_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_15_cast_fp16)[name = tensor<string, []>("pretrained_out_21_cast_fp16")];
            tensor<int32, [2]> var_621 = const()[name = tensor<string, []>("op_621"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_623 = const()[name = tensor<string, []>("op_623"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_31_pad_type_0 = const()[name = tensor<string, []>("input_31_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_31_pad_0 = const()[name = tensor<string, []>("input_31_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_1_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_1_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(148986624)))];
            tensor<fp16, [1, 16, 1, 1]> input_31_cast_fp16 = conv(dilations = var_623, groups = var_577, pad = input_31_pad_0, pad_type = input_31_pad_type_0, strides = var_621, weight = layers_1_self_attn_q_proj_loraA_weight_to_fp16, x = obj_15_cast_fp16)[name = tensor<string, []>("input_31_cast_fp16")];
            tensor<int32, [2]> var_627 = const()[name = tensor<string, []>("op_627"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_629 = const()[name = tensor<string, []>("op_629"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_41_pad_type_0 = const()[name = tensor<string, []>("lora_out_41_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_41_pad_0 = const()[name = tensor<string, []>("lora_out_41_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_43_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_43_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(149027648)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_43_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_629, groups = var_577, pad = lora_out_41_pad_0, pad_type = lora_out_41_pad_type_0, strides = var_627, weight = lora_out_43_weight_0_to_fp16, x = input_31_cast_fp16)[name = tensor<string, []>("lora_out_43_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_5_cast_fp16 = add(x = pretrained_out_21_cast_fp16, y = lora_out_43_cast_fp16)[name = tensor<string, []>("query_5_cast_fp16")];
            tensor<int32, [2]> var_639 = const()[name = tensor<string, []>("op_639"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_641 = const()[name = tensor<string, []>("op_641"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_23_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_23_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_23_pad_0 = const()[name = tensor<string, []>("pretrained_out_23_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_1_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(149068672))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(149887936))), name = tensor<string, []>("layers_1_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_23_cast_fp16 = conv(dilations = var_641, groups = var_577, pad = pretrained_out_23_pad_0, pad_type = pretrained_out_23_pad_type_0, strides = var_639, weight = layers_1_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_15_cast_fp16)[name = tensor<string, []>("pretrained_out_23_cast_fp16")];
            tensor<int32, [2]> var_645 = const()[name = tensor<string, []>("op_645"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_647 = const()[name = tensor<string, []>("op_647"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_33_pad_type_0 = const()[name = tensor<string, []>("input_33_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_33_pad_0 = const()[name = tensor<string, []>("input_33_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_1_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_1_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(149888064)))];
            tensor<fp16, [1, 16, 1, 1]> input_33_cast_fp16 = conv(dilations = var_647, groups = var_577, pad = input_33_pad_0, pad_type = input_33_pad_type_0, strides = var_645, weight = layers_1_self_attn_k_proj_loraA_weight_to_fp16, x = obj_15_cast_fp16)[name = tensor<string, []>("input_33_cast_fp16")];
            tensor<int32, [2]> var_651 = const()[name = tensor<string, []>("op_651"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_653 = const()[name = tensor<string, []>("op_653"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_45_pad_type_0 = const()[name = tensor<string, []>("lora_out_45_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_45_pad_0 = const()[name = tensor<string, []>("lora_out_45_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_47_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_47_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(149929088)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_47_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_653, groups = var_577, pad = lora_out_45_pad_0, pad_type = lora_out_45_pad_type_0, strides = var_651, weight = lora_out_47_weight_0_to_fp16, x = input_33_cast_fp16)[name = tensor<string, []>("lora_out_47_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_3_cast_fp16 = add(x = pretrained_out_23_cast_fp16, y = lora_out_47_cast_fp16)[name = tensor<string, []>("current_key_3_cast_fp16")];
            tensor<int32, [2]> var_664 = const()[name = tensor<string, []>("op_664"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_666 = const()[name = tensor<string, []>("op_666"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_25_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_25_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_25_pad_0 = const()[name = tensor<string, []>("pretrained_out_25_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_1_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(149970112))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(150789376))), name = tensor<string, []>("layers_1_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_1_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_1_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(150789504)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_25_cast_fp16 = conv(bias = layers_1_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_666, groups = var_577, pad = pretrained_out_25_pad_0, pad_type = pretrained_out_25_pad_type_0, strides = var_664, weight = layers_1_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_15_cast_fp16)[name = tensor<string, []>("pretrained_out_25_cast_fp16")];
            tensor<int32, [2]> var_670 = const()[name = tensor<string, []>("op_670"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_672 = const()[name = tensor<string, []>("op_672"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_35_pad_type_0 = const()[name = tensor<string, []>("input_35_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_35_pad_0 = const()[name = tensor<string, []>("input_35_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_1_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_1_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(150792128)))];
            tensor<fp16, [1, 16, 1, 1]> input_35_cast_fp16 = conv(dilations = var_672, groups = var_577, pad = input_35_pad_0, pad_type = input_35_pad_type_0, strides = var_670, weight = layers_1_self_attn_v_proj_loraA_weight_to_fp16, x = obj_15_cast_fp16)[name = tensor<string, []>("input_35_cast_fp16")];
            tensor<int32, [2]> var_676 = const()[name = tensor<string, []>("op_676"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_678 = const()[name = tensor<string, []>("op_678"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_49_pad_type_0 = const()[name = tensor<string, []>("lora_out_49_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_49_pad_0 = const()[name = tensor<string, []>("lora_out_49_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_51_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_51_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(150833152)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_51_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_678, groups = var_577, pad = lora_out_49_pad_0, pad_type = lora_out_49_pad_type_0, strides = var_676, weight = lora_out_51_weight_0_to_fp16, x = input_35_cast_fp16)[name = tensor<string, []>("lora_out_51_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_3_cast_fp16 = add(x = pretrained_out_25_cast_fp16, y = lora_out_51_cast_fp16)[name = tensor<string, []>("current_value_3_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_688_cast_fp16 = mul(x = current_key_3_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_688_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_690_cast_fp16 = mul(x = var_103_cast_fp16_1, y = var_295_cast_fp16)[name = tensor<string, []>("op_690_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_5_cast_fp16 = add(x = var_688_cast_fp16, y = var_690_cast_fp16)[name = tensor<string, []>("key_5_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_692_cast_fp16 = mul(x = current_value_3_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_692_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_694_cast_fp16 = mul(x = var_138_cast_fp16_1, y = var_295_cast_fp16)[name = tensor<string, []>("op_694_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_5_cast_fp16 = add(x = var_692_cast_fp16, y = var_694_cast_fp16)[name = tensor<string, []>("value_5_cast_fp16")];
            tensor<int32, [4]> var_697 = const()[name = tensor<string, []>("op_697"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_698_cast_fp16 = reshape(shape = var_697, x = query_5_cast_fp16)[name = tensor<string, []>("op_698_cast_fp16")];
            tensor<fp16, []> var_699_to_fp16 = const()[name = tensor<string, []>("op_699_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_700_cast_fp16 = mul(x = var_698_cast_fp16, y = var_699_to_fp16)[name = tensor<string, []>("op_700_cast_fp16")];
            tensor<int32, [4]> var_701 = const()[name = tensor<string, []>("op_701"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_702_cast_fp16 = reshape(shape = var_701, x = key_5_cast_fp16)[name = tensor<string, []>("op_702_cast_fp16")];
            tensor<bool, []> mh_w_7_transpose_x_0 = const()[name = tensor<string, []>("mh_w_7_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_7_transpose_y_0 = const()[name = tensor<string, []>("mh_w_7_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_7_cast_fp16 = matmul(transpose_x = mh_w_7_transpose_x_0, transpose_y = mh_w_7_transpose_y_0, x = var_700_cast_fp16, y = var_702_cast_fp16)[name = tensor<string, []>("mh_w_7_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_9_cast_fp16 = add(x = mh_w_7_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_9_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_710_cast_fp16 = softmax(axis = var_570, x = mh_w_9_cast_fp16)[name = tensor<string, []>("op_710_cast_fp16")];
            tensor<int32, [4]> var_711 = const()[name = tensor<string, []>("op_711"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_712_cast_fp16 = reshape(shape = var_711, x = value_5_cast_fp16)[name = tensor<string, []>("op_712_cast_fp16")];
            tensor<bool, []> attn_5_transpose_x_0 = const()[name = tensor<string, []>("attn_5_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_5_transpose_y_0 = const()[name = tensor<string, []>("attn_5_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_5_cast_fp16 = matmul(transpose_x = attn_5_transpose_x_0, transpose_y = attn_5_transpose_y_0, x = var_712_cast_fp16, y = var_710_cast_fp16)[name = tensor<string, []>("attn_5_cast_fp16")];
            tensor<int32, [4]> var_715 = const()[name = tensor<string, []>("op_715"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_37_cast_fp16 = reshape(shape = var_715, x = attn_5_cast_fp16)[name = tensor<string, []>("input_37_cast_fp16")];
            tensor<int32, [2]> var_722 = const()[name = tensor<string, []>("op_722"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_724 = const()[name = tensor<string, []>("op_724"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_27_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_27_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_27_pad_0 = const()[name = tensor<string, []>("pretrained_out_27_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_1_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(150874176))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(151693440))), name = tensor<string, []>("layers_1_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_1_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_1_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(151693568)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_27_cast_fp16 = conv(bias = layers_1_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_724, groups = var_577, pad = pretrained_out_27_pad_0, pad_type = pretrained_out_27_pad_type_0, strides = var_722, weight = layers_1_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_37_cast_fp16)[name = tensor<string, []>("pretrained_out_27_cast_fp16")];
            tensor<int32, [2]> var_728 = const()[name = tensor<string, []>("op_728"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_730 = const()[name = tensor<string, []>("op_730"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_39_pad_type_0 = const()[name = tensor<string, []>("input_39_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_39_pad_0 = const()[name = tensor<string, []>("input_39_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_1_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_1_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(151696192)))];
            tensor<fp16, [1, 16, 1, 1]> input_39_cast_fp16 = conv(dilations = var_730, groups = var_577, pad = input_39_pad_0, pad_type = input_39_pad_type_0, strides = var_728, weight = layers_1_self_attn_o_proj_loraA_weight_to_fp16, x = input_37_cast_fp16)[name = tensor<string, []>("input_39_cast_fp16")];
            tensor<int32, [2]> var_734 = const()[name = tensor<string, []>("op_734"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_736 = const()[name = tensor<string, []>("op_736"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_53_pad_type_0 = const()[name = tensor<string, []>("lora_out_53_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_53_pad_0 = const()[name = tensor<string, []>("lora_out_53_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_55_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_55_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(151737216)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_55_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_736, groups = var_577, pad = lora_out_53_pad_0, pad_type = lora_out_53_pad_type_0, strides = var_734, weight = lora_out_55_weight_0_to_fp16, x = input_39_cast_fp16)[name = tensor<string, []>("lora_out_55_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_21_cast_fp16 = add(x = pretrained_out_27_cast_fp16, y = lora_out_55_cast_fp16)[name = tensor<string, []>("obj_21_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_9_cast_fp16 = add(x = inputs_7_cast_fp16, y = obj_21_cast_fp16)[name = tensor<string, []>("inputs_9_cast_fp16")];
            tensor<int32, [1]> var_749 = const()[name = tensor<string, []>("op_749"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_9_cast_fp16 = reduce_mean(axes = var_749, keep_dims = var_578, x = inputs_9_cast_fp16)[name = tensor<string, []>("channels_mean_9_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_9_cast_fp16 = sub(x = inputs_9_cast_fp16, y = channels_mean_9_cast_fp16)[name = tensor<string, []>("zero_mean_9_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_9_cast_fp16 = mul(x = zero_mean_9_cast_fp16, y = zero_mean_9_cast_fp16)[name = tensor<string, []>("zero_mean_sq_9_cast_fp16")];
            tensor<int32, [1]> var_753 = const()[name = tensor<string, []>("op_753"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_754_cast_fp16 = reduce_mean(axes = var_753, keep_dims = var_578, x = zero_mean_sq_9_cast_fp16)[name = tensor<string, []>("op_754_cast_fp16")];
            tensor<fp16, []> var_755_to_fp16 = const()[name = tensor<string, []>("op_755_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_756_cast_fp16 = add(x = var_754_cast_fp16, y = var_755_to_fp16)[name = tensor<string, []>("op_756_cast_fp16")];
            tensor<fp32, []> denom_9_epsilon_0 = const()[name = tensor<string, []>("denom_9_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_9_cast_fp16 = rsqrt(epsilon = denom_9_epsilon_0, x = var_756_cast_fp16)[name = tensor<string, []>("denom_9_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_9_cast_fp16 = mul(x = zero_mean_9_cast_fp16, y = denom_9_cast_fp16)[name = tensor<string, []>("out_9_cast_fp16")];
            tensor<fp16, [1280]> obj_23_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_23_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(151778240)))];
            tensor<fp16, [1280]> obj_23_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_23_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(151780864)))];
            tensor<fp16, []> obj_23_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_23_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_23_cast_fp16 = batch_norm(beta = obj_23_beta_0_to_fp16, epsilon = obj_23_epsilon_0_to_fp16, gamma = obj_23_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_9_cast_fp16)[name = tensor<string, []>("obj_23_cast_fp16")];
            tensor<int32, [2]> var_774 = const()[name = tensor<string, []>("op_774"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_776 = const()[name = tensor<string, []>("op_776"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_29_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_29_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_29_pad_0 = const()[name = tensor<string, []>("pretrained_out_29_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_1_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(151783488))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(152602752))), name = tensor<string, []>("layers_1_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_1_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_1_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(152602880)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_29_cast_fp16 = conv(bias = layers_1_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_776, groups = var_577, pad = pretrained_out_29_pad_0, pad_type = pretrained_out_29_pad_type_0, strides = var_774, weight = layers_1_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_23_cast_fp16)[name = tensor<string, []>("pretrained_out_29_cast_fp16")];
            tensor<int32, [2]> var_780 = const()[name = tensor<string, []>("op_780"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_782 = const()[name = tensor<string, []>("op_782"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_41_pad_type_0 = const()[name = tensor<string, []>("input_41_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_41_pad_0 = const()[name = tensor<string, []>("input_41_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_1_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_1_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(152605504)))];
            tensor<fp16, [1, 16, 1, 1]> input_41_cast_fp16 = conv(dilations = var_782, groups = var_577, pad = input_41_pad_0, pad_type = input_41_pad_type_0, strides = var_780, weight = layers_1_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_23_cast_fp16)[name = tensor<string, []>("input_41_cast_fp16")];
            tensor<int32, [2]> var_786 = const()[name = tensor<string, []>("op_786"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_788 = const()[name = tensor<string, []>("op_788"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_57_pad_type_0 = const()[name = tensor<string, []>("lora_out_57_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_57_pad_0 = const()[name = tensor<string, []>("lora_out_57_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_59_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_59_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(152646528)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_59_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_788, groups = var_577, pad = lora_out_57_pad_0, pad_type = lora_out_57_pad_type_0, strides = var_786, weight = lora_out_59_weight_0_to_fp16, x = input_41_cast_fp16)[name = tensor<string, []>("lora_out_59_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_7_cast_fp16 = add(x = pretrained_out_29_cast_fp16, y = lora_out_59_cast_fp16)[name = tensor<string, []>("query_7_cast_fp16")];
            tensor<int32, [2]> var_798 = const()[name = tensor<string, []>("op_798"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_800 = const()[name = tensor<string, []>("op_800"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_31_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_31_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_31_pad_0 = const()[name = tensor<string, []>("pretrained_out_31_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_1_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(152687552))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(153506816))), name = tensor<string, []>("layers_1_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_31_cast_fp16 = conv(dilations = var_800, groups = var_577, pad = pretrained_out_31_pad_0, pad_type = pretrained_out_31_pad_type_0, strides = var_798, weight = layers_1_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_31_cast_fp16")];
            tensor<int32, [2]> var_804 = const()[name = tensor<string, []>("op_804"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_806 = const()[name = tensor<string, []>("op_806"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_43_pad_type_0 = const()[name = tensor<string, []>("input_43_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_43_pad_0 = const()[name = tensor<string, []>("input_43_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_1_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_1_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(153506944)))];
            tensor<fp16, [1, 16, 1, 1500]> input_43_cast_fp16 = conv(dilations = var_806, groups = var_577, pad = input_43_pad_0, pad_type = input_43_pad_type_0, strides = var_804, weight = layers_1_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_43_cast_fp16")];
            tensor<int32, [2]> var_810 = const()[name = tensor<string, []>("op_810"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_812 = const()[name = tensor<string, []>("op_812"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_61_pad_type_0 = const()[name = tensor<string, []>("lora_out_61_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_61_pad_0 = const()[name = tensor<string, []>("lora_out_61_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_63_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_63_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(153547968)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_63_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_812, groups = var_577, pad = lora_out_61_pad_0, pad_type = lora_out_61_pad_type_0, strides = var_810, weight = lora_out_63_weight_0_to_fp16, x = input_43_cast_fp16)[name = tensor<string, []>("lora_out_63_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_7_cast_fp16 = add(x = pretrained_out_31_cast_fp16, y = lora_out_63_cast_fp16)[name = tensor<string, []>("key_7_cast_fp16")];
            tensor<int32, [2]> var_823 = const()[name = tensor<string, []>("op_823"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_825 = const()[name = tensor<string, []>("op_825"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_33_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_33_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_33_pad_0 = const()[name = tensor<string, []>("pretrained_out_33_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_1_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(153588992))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(154408256))), name = tensor<string, []>("layers_1_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_1_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_1_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(154408384)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_33_cast_fp16 = conv(bias = layers_1_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_825, groups = var_577, pad = pretrained_out_33_pad_0, pad_type = pretrained_out_33_pad_type_0, strides = var_823, weight = layers_1_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_33_cast_fp16")];
            tensor<int32, [2]> var_829 = const()[name = tensor<string, []>("op_829"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_831 = const()[name = tensor<string, []>("op_831"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_45_pad_type_0 = const()[name = tensor<string, []>("input_45_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_45_pad_0 = const()[name = tensor<string, []>("input_45_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_1_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_1_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(154411008)))];
            tensor<fp16, [1, 16, 1, 1500]> input_45_cast_fp16 = conv(dilations = var_831, groups = var_577, pad = input_45_pad_0, pad_type = input_45_pad_type_0, strides = var_829, weight = layers_1_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_45_cast_fp16")];
            tensor<int32, [2]> var_835 = const()[name = tensor<string, []>("op_835"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_837 = const()[name = tensor<string, []>("op_837"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_65_pad_type_0 = const()[name = tensor<string, []>("lora_out_65_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_65_pad_0 = const()[name = tensor<string, []>("lora_out_65_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_67_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_67_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(154452032)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_67_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_837, groups = var_577, pad = lora_out_65_pad_0, pad_type = lora_out_65_pad_type_0, strides = var_835, weight = lora_out_67_weight_0_to_fp16, x = input_45_cast_fp16)[name = tensor<string, []>("lora_out_67_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_7_cast_fp16 = add(x = pretrained_out_33_cast_fp16, y = lora_out_67_cast_fp16)[name = tensor<string, []>("value_7_cast_fp16")];
            tensor<int32, [4]> var_844 = const()[name = tensor<string, []>("op_844"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_845_cast_fp16 = reshape(shape = var_844, x = query_7_cast_fp16)[name = tensor<string, []>("op_845_cast_fp16")];
            tensor<fp16, []> var_846_to_fp16 = const()[name = tensor<string, []>("op_846_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_847_cast_fp16 = mul(x = var_845_cast_fp16, y = var_846_to_fp16)[name = tensor<string, []>("op_847_cast_fp16")];
            tensor<int32, [4]> var_848 = const()[name = tensor<string, []>("op_848"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_849_cast_fp16 = reshape(shape = var_848, x = key_7_cast_fp16)[name = tensor<string, []>("op_849_cast_fp16")];
            tensor<bool, []> mh_w_11_transpose_x_0 = const()[name = tensor<string, []>("mh_w_11_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_11_transpose_y_0 = const()[name = tensor<string, []>("mh_w_11_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_11_cast_fp16 = matmul(transpose_x = mh_w_11_transpose_x_0, transpose_y = mh_w_11_transpose_y_0, x = var_847_cast_fp16, y = var_849_cast_fp16)[name = tensor<string, []>("mh_w_11_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_27_cast_fp16 = softmax(axis = var_570, x = mh_w_11_cast_fp16)[name = tensor<string, []>("obj_27_cast_fp16")];
            tensor<int32, [4]> var_853 = const()[name = tensor<string, []>("op_853"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_854_cast_fp16 = reshape(shape = var_853, x = value_7_cast_fp16)[name = tensor<string, []>("op_854_cast_fp16")];
            tensor<bool, []> attn_7_transpose_x_0 = const()[name = tensor<string, []>("attn_7_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_7_transpose_y_0 = const()[name = tensor<string, []>("attn_7_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_7_cast_fp16 = matmul(transpose_x = attn_7_transpose_x_0, transpose_y = attn_7_transpose_y_0, x = var_854_cast_fp16, y = obj_27_cast_fp16)[name = tensor<string, []>("attn_7_cast_fp16")];
            tensor<int32, [4]> var_857 = const()[name = tensor<string, []>("op_857"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_47_cast_fp16 = reshape(shape = var_857, x = attn_7_cast_fp16)[name = tensor<string, []>("input_47_cast_fp16")];
            tensor<int32, [2]> var_864 = const()[name = tensor<string, []>("op_864"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_866 = const()[name = tensor<string, []>("op_866"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_35_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_35_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_35_pad_0 = const()[name = tensor<string, []>("pretrained_out_35_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_1_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(154493056))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(155312320))), name = tensor<string, []>("layers_1_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_1_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_1_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(155312448)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_35_cast_fp16 = conv(bias = layers_1_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_866, groups = var_577, pad = pretrained_out_35_pad_0, pad_type = pretrained_out_35_pad_type_0, strides = var_864, weight = layers_1_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_47_cast_fp16)[name = tensor<string, []>("pretrained_out_35_cast_fp16")];
            tensor<int32, [2]> var_870 = const()[name = tensor<string, []>("op_870"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_872 = const()[name = tensor<string, []>("op_872"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_49_pad_type_0 = const()[name = tensor<string, []>("input_49_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_49_pad_0 = const()[name = tensor<string, []>("input_49_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_1_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_1_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(155315072)))];
            tensor<fp16, [1, 16, 1, 1]> input_49_cast_fp16 = conv(dilations = var_872, groups = var_577, pad = input_49_pad_0, pad_type = input_49_pad_type_0, strides = var_870, weight = layers_1_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_47_cast_fp16)[name = tensor<string, []>("input_49_cast_fp16")];
            tensor<int32, [2]> var_876 = const()[name = tensor<string, []>("op_876"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_878 = const()[name = tensor<string, []>("op_878"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_69_pad_type_0 = const()[name = tensor<string, []>("lora_out_69_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_69_pad_0 = const()[name = tensor<string, []>("lora_out_69_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_71_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_71_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(155356096)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_71_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_878, groups = var_577, pad = lora_out_69_pad_0, pad_type = lora_out_69_pad_type_0, strides = var_876, weight = lora_out_71_weight_0_to_fp16, x = input_49_cast_fp16)[name = tensor<string, []>("lora_out_71_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_25_cast_fp16 = add(x = pretrained_out_35_cast_fp16, y = lora_out_71_cast_fp16)[name = tensor<string, []>("obj_25_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_11_cast_fp16 = add(x = inputs_9_cast_fp16, y = obj_25_cast_fp16)[name = tensor<string, []>("inputs_11_cast_fp16")];
            tensor<int32, [1]> var_887 = const()[name = tensor<string, []>("op_887"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_11_cast_fp16 = reduce_mean(axes = var_887, keep_dims = var_578, x = inputs_11_cast_fp16)[name = tensor<string, []>("channels_mean_11_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_11_cast_fp16 = sub(x = inputs_11_cast_fp16, y = channels_mean_11_cast_fp16)[name = tensor<string, []>("zero_mean_11_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_11_cast_fp16 = mul(x = zero_mean_11_cast_fp16, y = zero_mean_11_cast_fp16)[name = tensor<string, []>("zero_mean_sq_11_cast_fp16")];
            tensor<int32, [1]> var_891 = const()[name = tensor<string, []>("op_891"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_892_cast_fp16 = reduce_mean(axes = var_891, keep_dims = var_578, x = zero_mean_sq_11_cast_fp16)[name = tensor<string, []>("op_892_cast_fp16")];
            tensor<fp16, []> var_893_to_fp16 = const()[name = tensor<string, []>("op_893_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_894_cast_fp16 = add(x = var_892_cast_fp16, y = var_893_to_fp16)[name = tensor<string, []>("op_894_cast_fp16")];
            tensor<fp32, []> denom_11_epsilon_0 = const()[name = tensor<string, []>("denom_11_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_11_cast_fp16 = rsqrt(epsilon = denom_11_epsilon_0, x = var_894_cast_fp16)[name = tensor<string, []>("denom_11_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_11_cast_fp16 = mul(x = zero_mean_11_cast_fp16, y = denom_11_cast_fp16)[name = tensor<string, []>("out_11_cast_fp16")];
            tensor<fp16, [1280]> input_51_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_51_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(155397120)))];
            tensor<fp16, [1280]> input_51_beta_0_to_fp16 = const()[name = tensor<string, []>("input_51_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(155399744)))];
            tensor<fp16, []> input_51_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_51_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_51_cast_fp16 = batch_norm(beta = input_51_beta_0_to_fp16, epsilon = input_51_epsilon_0_to_fp16, gamma = input_51_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_11_cast_fp16)[name = tensor<string, []>("input_51_cast_fp16")];
            tensor<int32, [2]> var_908 = const()[name = tensor<string, []>("op_908"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_910 = const()[name = tensor<string, []>("op_910"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_37_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_37_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_37_pad_0 = const()[name = tensor<string, []>("pretrained_out_37_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_1_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(155402368))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(158679232))), name = tensor<string, []>("layers_1_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_1_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_1_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(158679360)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_37_cast_fp16 = conv(bias = layers_1_fc1_pretrained_bias_to_fp16, dilations = var_910, groups = var_577, pad = pretrained_out_37_pad_0, pad_type = pretrained_out_37_pad_type_0, strides = var_908, weight = layers_1_fc1_pretrained_weight_to_fp16_palettized, x = input_51_cast_fp16)[name = tensor<string, []>("pretrained_out_37_cast_fp16")];
            tensor<int32, [2]> var_914 = const()[name = tensor<string, []>("op_914"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_916 = const()[name = tensor<string, []>("op_916"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_53_pad_type_0 = const()[name = tensor<string, []>("input_53_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_53_pad_0 = const()[name = tensor<string, []>("input_53_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_1_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_1_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(158689664)))];
            tensor<fp16, [1, 16, 1, 1]> input_53_cast_fp16 = conv(dilations = var_916, groups = var_577, pad = input_53_pad_0, pad_type = input_53_pad_type_0, strides = var_914, weight = layers_1_fc1_loraA_weight_to_fp16, x = input_51_cast_fp16)[name = tensor<string, []>("input_53_cast_fp16")];
            tensor<int32, [2]> var_920 = const()[name = tensor<string, []>("op_920"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_922 = const()[name = tensor<string, []>("op_922"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_73_pad_type_0 = const()[name = tensor<string, []>("lora_out_73_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_73_pad_0 = const()[name = tensor<string, []>("lora_out_73_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_75_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_75_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(158730688)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_75_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_922, groups = var_577, pad = lora_out_73_pad_0, pad_type = lora_out_73_pad_type_0, strides = var_920, weight = lora_out_75_weight_0_to_fp16, x = input_53_cast_fp16)[name = tensor<string, []>("lora_out_75_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_55_cast_fp16 = add(x = pretrained_out_37_cast_fp16, y = lora_out_75_cast_fp16)[name = tensor<string, []>("input_55_cast_fp16")];
            tensor<string, []> input_57_mode_0 = const()[name = tensor<string, []>("input_57_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_57_cast_fp16 = gelu(mode = input_57_mode_0, x = input_55_cast_fp16)[name = tensor<string, []>("input_57_cast_fp16")];
            tensor<int32, [2]> var_934 = const()[name = tensor<string, []>("op_934"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_936 = const()[name = tensor<string, []>("op_936"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_39_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_39_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_39_pad_0 = const()[name = tensor<string, []>("pretrained_out_39_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_1_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(158894592))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(162171456))), name = tensor<string, []>("layers_1_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_1_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_1_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(162171584)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_39_cast_fp16 = conv(bias = layers_1_fc2_pretrained_bias_to_fp16, dilations = var_936, groups = var_577, pad = pretrained_out_39_pad_0, pad_type = pretrained_out_39_pad_type_0, strides = var_934, weight = layers_1_fc2_pretrained_weight_to_fp16_palettized, x = input_57_cast_fp16)[name = tensor<string, []>("pretrained_out_39_cast_fp16")];
            tensor<int32, [2]> var_940 = const()[name = tensor<string, []>("op_940"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_942 = const()[name = tensor<string, []>("op_942"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_59_pad_type_0 = const()[name = tensor<string, []>("input_59_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_59_pad_0 = const()[name = tensor<string, []>("input_59_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_1_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_1_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(162174208)))];
            tensor<fp16, [1, 16, 1, 1]> input_59_cast_fp16 = conv(dilations = var_942, groups = var_577, pad = input_59_pad_0, pad_type = input_59_pad_type_0, strides = var_940, weight = layers_1_fc2_loraA_weight_to_fp16, x = input_57_cast_fp16)[name = tensor<string, []>("input_59_cast_fp16")];
            tensor<int32, [2]> var_946 = const()[name = tensor<string, []>("op_946"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_948 = const()[name = tensor<string, []>("op_948"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_77_pad_type_0 = const()[name = tensor<string, []>("lora_out_77_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_77_pad_0 = const()[name = tensor<string, []>("lora_out_77_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_79_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_79_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(162338112)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_79_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_948, groups = var_577, pad = lora_out_77_pad_0, pad_type = lora_out_77_pad_type_0, strides = var_946, weight = lora_out_79_weight_0_to_fp16, x = input_59_cast_fp16)[name = tensor<string, []>("lora_out_79_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_5_cast_fp16 = add(x = pretrained_out_39_cast_fp16, y = lora_out_79_cast_fp16)[name = tensor<string, []>("hidden_states_5_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_13_cast_fp16 = add(x = inputs_11_cast_fp16, y = hidden_states_5_cast_fp16)[name = tensor<string, []>("inputs_13_cast_fp16")];
            tensor<int32, []> var_964 = const()[name = tensor<string, []>("op_964"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_971 = const()[name = tensor<string, []>("op_971"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_972 = const()[name = tensor<string, []>("op_972"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_984 = const()[name = tensor<string, []>("op_984"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_13_cast_fp16 = reduce_mean(axes = var_984, keep_dims = var_972, x = inputs_13_cast_fp16)[name = tensor<string, []>("channels_mean_13_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_13_cast_fp16 = sub(x = inputs_13_cast_fp16, y = channels_mean_13_cast_fp16)[name = tensor<string, []>("zero_mean_13_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_13_cast_fp16 = mul(x = zero_mean_13_cast_fp16, y = zero_mean_13_cast_fp16)[name = tensor<string, []>("zero_mean_sq_13_cast_fp16")];
            tensor<int32, [1]> var_988 = const()[name = tensor<string, []>("op_988"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_989_cast_fp16 = reduce_mean(axes = var_988, keep_dims = var_972, x = zero_mean_sq_13_cast_fp16)[name = tensor<string, []>("op_989_cast_fp16")];
            tensor<fp16, []> var_990_to_fp16 = const()[name = tensor<string, []>("op_990_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_991_cast_fp16 = add(x = var_989_cast_fp16, y = var_990_to_fp16)[name = tensor<string, []>("op_991_cast_fp16")];
            tensor<fp32, []> denom_13_epsilon_0 = const()[name = tensor<string, []>("denom_13_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_13_cast_fp16 = rsqrt(epsilon = denom_13_epsilon_0, x = var_991_cast_fp16)[name = tensor<string, []>("denom_13_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_13_cast_fp16 = mul(x = zero_mean_13_cast_fp16, y = denom_13_cast_fp16)[name = tensor<string, []>("out_13_cast_fp16")];
            tensor<fp16, [1280]> obj_29_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_29_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(162379136)))];
            tensor<fp16, [1280]> obj_29_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_29_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(162381760)))];
            tensor<fp16, []> obj_29_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_29_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_29_cast_fp16 = batch_norm(beta = obj_29_beta_0_to_fp16, epsilon = obj_29_epsilon_0_to_fp16, gamma = obj_29_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_13_cast_fp16)[name = tensor<string, []>("obj_29_cast_fp16")];
            tensor<int32, [2]> var_1009 = const()[name = tensor<string, []>("op_1009"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1011 = const()[name = tensor<string, []>("op_1011"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_41_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_41_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_41_pad_0 = const()[name = tensor<string, []>("pretrained_out_41_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_2_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(162384384))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(163203648))), name = tensor<string, []>("layers_2_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_2_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_2_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(163203776)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_41_cast_fp16 = conv(bias = layers_2_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_1011, groups = var_971, pad = pretrained_out_41_pad_0, pad_type = pretrained_out_41_pad_type_0, strides = var_1009, weight = layers_2_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_29_cast_fp16)[name = tensor<string, []>("pretrained_out_41_cast_fp16")];
            tensor<int32, [2]> var_1015 = const()[name = tensor<string, []>("op_1015"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1017 = const()[name = tensor<string, []>("op_1017"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_61_pad_type_0 = const()[name = tensor<string, []>("input_61_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_61_pad_0 = const()[name = tensor<string, []>("input_61_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_2_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_2_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(163206400)))];
            tensor<fp16, [1, 16, 1, 1]> input_61_cast_fp16 = conv(dilations = var_1017, groups = var_971, pad = input_61_pad_0, pad_type = input_61_pad_type_0, strides = var_1015, weight = layers_2_self_attn_q_proj_loraA_weight_to_fp16, x = obj_29_cast_fp16)[name = tensor<string, []>("input_61_cast_fp16")];
            tensor<int32, [2]> var_1021 = const()[name = tensor<string, []>("op_1021"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1023 = const()[name = tensor<string, []>("op_1023"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_81_pad_type_0 = const()[name = tensor<string, []>("lora_out_81_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_81_pad_0 = const()[name = tensor<string, []>("lora_out_81_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_83_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_83_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(163247424)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_83_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_1023, groups = var_971, pad = lora_out_81_pad_0, pad_type = lora_out_81_pad_type_0, strides = var_1021, weight = lora_out_83_weight_0_to_fp16, x = input_61_cast_fp16)[name = tensor<string, []>("lora_out_83_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_9_cast_fp16 = add(x = pretrained_out_41_cast_fp16, y = lora_out_83_cast_fp16)[name = tensor<string, []>("query_9_cast_fp16")];
            tensor<int32, [2]> var_1033 = const()[name = tensor<string, []>("op_1033"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1035 = const()[name = tensor<string, []>("op_1035"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_43_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_43_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_43_pad_0 = const()[name = tensor<string, []>("pretrained_out_43_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_2_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(163288448))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(164107712))), name = tensor<string, []>("layers_2_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_43_cast_fp16 = conv(dilations = var_1035, groups = var_971, pad = pretrained_out_43_pad_0, pad_type = pretrained_out_43_pad_type_0, strides = var_1033, weight = layers_2_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_29_cast_fp16)[name = tensor<string, []>("pretrained_out_43_cast_fp16")];
            tensor<int32, [2]> var_1039 = const()[name = tensor<string, []>("op_1039"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1041 = const()[name = tensor<string, []>("op_1041"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_63_pad_type_0 = const()[name = tensor<string, []>("input_63_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_63_pad_0 = const()[name = tensor<string, []>("input_63_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_2_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_2_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(164107840)))];
            tensor<fp16, [1, 16, 1, 1]> input_63_cast_fp16 = conv(dilations = var_1041, groups = var_971, pad = input_63_pad_0, pad_type = input_63_pad_type_0, strides = var_1039, weight = layers_2_self_attn_k_proj_loraA_weight_to_fp16, x = obj_29_cast_fp16)[name = tensor<string, []>("input_63_cast_fp16")];
            tensor<int32, [2]> var_1045 = const()[name = tensor<string, []>("op_1045"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1047 = const()[name = tensor<string, []>("op_1047"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_85_pad_type_0 = const()[name = tensor<string, []>("lora_out_85_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_85_pad_0 = const()[name = tensor<string, []>("lora_out_85_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_87_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_87_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(164148864)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_87_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_1047, groups = var_971, pad = lora_out_85_pad_0, pad_type = lora_out_85_pad_type_0, strides = var_1045, weight = lora_out_87_weight_0_to_fp16, x = input_63_cast_fp16)[name = tensor<string, []>("lora_out_87_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_5_cast_fp16 = add(x = pretrained_out_43_cast_fp16, y = lora_out_87_cast_fp16)[name = tensor<string, []>("current_key_5_cast_fp16")];
            tensor<int32, [2]> var_1058 = const()[name = tensor<string, []>("op_1058"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1060 = const()[name = tensor<string, []>("op_1060"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_45_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_45_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_45_pad_0 = const()[name = tensor<string, []>("pretrained_out_45_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_2_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(164189888))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(165009152))), name = tensor<string, []>("layers_2_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_2_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_2_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(165009280)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_45_cast_fp16 = conv(bias = layers_2_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_1060, groups = var_971, pad = pretrained_out_45_pad_0, pad_type = pretrained_out_45_pad_type_0, strides = var_1058, weight = layers_2_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_29_cast_fp16)[name = tensor<string, []>("pretrained_out_45_cast_fp16")];
            tensor<int32, [2]> var_1064 = const()[name = tensor<string, []>("op_1064"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1066 = const()[name = tensor<string, []>("op_1066"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_65_pad_type_0 = const()[name = tensor<string, []>("input_65_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_65_pad_0 = const()[name = tensor<string, []>("input_65_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_2_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_2_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(165011904)))];
            tensor<fp16, [1, 16, 1, 1]> input_65_cast_fp16 = conv(dilations = var_1066, groups = var_971, pad = input_65_pad_0, pad_type = input_65_pad_type_0, strides = var_1064, weight = layers_2_self_attn_v_proj_loraA_weight_to_fp16, x = obj_29_cast_fp16)[name = tensor<string, []>("input_65_cast_fp16")];
            tensor<int32, [2]> var_1070 = const()[name = tensor<string, []>("op_1070"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1072 = const()[name = tensor<string, []>("op_1072"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_89_pad_type_0 = const()[name = tensor<string, []>("lora_out_89_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_89_pad_0 = const()[name = tensor<string, []>("lora_out_89_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_91_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_91_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(165052928)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_91_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_1072, groups = var_971, pad = lora_out_89_pad_0, pad_type = lora_out_89_pad_type_0, strides = var_1070, weight = lora_out_91_weight_0_to_fp16, x = input_65_cast_fp16)[name = tensor<string, []>("lora_out_91_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_5_cast_fp16 = add(x = pretrained_out_45_cast_fp16, y = lora_out_91_cast_fp16)[name = tensor<string, []>("current_value_5_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_1082_cast_fp16 = mul(x = current_key_5_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_1082_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_1084_cast_fp16 = mul(x = var_103_cast_fp16_2, y = var_295_cast_fp16)[name = tensor<string, []>("op_1084_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_9_cast_fp16 = add(x = var_1082_cast_fp16, y = var_1084_cast_fp16)[name = tensor<string, []>("key_9_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_1086_cast_fp16 = mul(x = current_value_5_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_1086_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_1088_cast_fp16 = mul(x = var_138_cast_fp16_2, y = var_295_cast_fp16)[name = tensor<string, []>("op_1088_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_9_cast_fp16 = add(x = var_1086_cast_fp16, y = var_1088_cast_fp16)[name = tensor<string, []>("value_9_cast_fp16")];
            tensor<int32, [4]> var_1091 = const()[name = tensor<string, []>("op_1091"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_1092_cast_fp16 = reshape(shape = var_1091, x = query_9_cast_fp16)[name = tensor<string, []>("op_1092_cast_fp16")];
            tensor<fp16, []> var_1093_to_fp16 = const()[name = tensor<string, []>("op_1093_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_1094_cast_fp16 = mul(x = var_1092_cast_fp16, y = var_1093_to_fp16)[name = tensor<string, []>("op_1094_cast_fp16")];
            tensor<int32, [4]> var_1095 = const()[name = tensor<string, []>("op_1095"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_1096_cast_fp16 = reshape(shape = var_1095, x = key_9_cast_fp16)[name = tensor<string, []>("op_1096_cast_fp16")];
            tensor<bool, []> mh_w_13_transpose_x_0 = const()[name = tensor<string, []>("mh_w_13_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_13_transpose_y_0 = const()[name = tensor<string, []>("mh_w_13_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_13_cast_fp16 = matmul(transpose_x = mh_w_13_transpose_x_0, transpose_y = mh_w_13_transpose_y_0, x = var_1094_cast_fp16, y = var_1096_cast_fp16)[name = tensor<string, []>("mh_w_13_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_15_cast_fp16 = add(x = mh_w_13_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_15_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_1104_cast_fp16 = softmax(axis = var_964, x = mh_w_15_cast_fp16)[name = tensor<string, []>("op_1104_cast_fp16")];
            tensor<int32, [4]> var_1105 = const()[name = tensor<string, []>("op_1105"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_1106_cast_fp16 = reshape(shape = var_1105, x = value_9_cast_fp16)[name = tensor<string, []>("op_1106_cast_fp16")];
            tensor<bool, []> attn_9_transpose_x_0 = const()[name = tensor<string, []>("attn_9_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_9_transpose_y_0 = const()[name = tensor<string, []>("attn_9_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_9_cast_fp16 = matmul(transpose_x = attn_9_transpose_x_0, transpose_y = attn_9_transpose_y_0, x = var_1106_cast_fp16, y = var_1104_cast_fp16)[name = tensor<string, []>("attn_9_cast_fp16")];
            tensor<int32, [4]> var_1109 = const()[name = tensor<string, []>("op_1109"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_67_cast_fp16 = reshape(shape = var_1109, x = attn_9_cast_fp16)[name = tensor<string, []>("input_67_cast_fp16")];
            tensor<int32, [2]> var_1116 = const()[name = tensor<string, []>("op_1116"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1118 = const()[name = tensor<string, []>("op_1118"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_47_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_47_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_47_pad_0 = const()[name = tensor<string, []>("pretrained_out_47_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_2_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(165093952))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(165913216))), name = tensor<string, []>("layers_2_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_2_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_2_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(165913344)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_47_cast_fp16 = conv(bias = layers_2_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_1118, groups = var_971, pad = pretrained_out_47_pad_0, pad_type = pretrained_out_47_pad_type_0, strides = var_1116, weight = layers_2_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_67_cast_fp16)[name = tensor<string, []>("pretrained_out_47_cast_fp16")];
            tensor<int32, [2]> var_1122 = const()[name = tensor<string, []>("op_1122"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1124 = const()[name = tensor<string, []>("op_1124"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_69_pad_type_0 = const()[name = tensor<string, []>("input_69_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_69_pad_0 = const()[name = tensor<string, []>("input_69_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_2_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_2_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(165915968)))];
            tensor<fp16, [1, 16, 1, 1]> input_69_cast_fp16 = conv(dilations = var_1124, groups = var_971, pad = input_69_pad_0, pad_type = input_69_pad_type_0, strides = var_1122, weight = layers_2_self_attn_o_proj_loraA_weight_to_fp16, x = input_67_cast_fp16)[name = tensor<string, []>("input_69_cast_fp16")];
            tensor<int32, [2]> var_1128 = const()[name = tensor<string, []>("op_1128"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1130 = const()[name = tensor<string, []>("op_1130"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_93_pad_type_0 = const()[name = tensor<string, []>("lora_out_93_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_93_pad_0 = const()[name = tensor<string, []>("lora_out_93_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_95_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_95_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(165956992)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_95_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_1130, groups = var_971, pad = lora_out_93_pad_0, pad_type = lora_out_93_pad_type_0, strides = var_1128, weight = lora_out_95_weight_0_to_fp16, x = input_69_cast_fp16)[name = tensor<string, []>("lora_out_95_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_35_cast_fp16 = add(x = pretrained_out_47_cast_fp16, y = lora_out_95_cast_fp16)[name = tensor<string, []>("obj_35_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_15_cast_fp16 = add(x = inputs_13_cast_fp16, y = obj_35_cast_fp16)[name = tensor<string, []>("inputs_15_cast_fp16")];
            tensor<int32, [1]> var_1143 = const()[name = tensor<string, []>("op_1143"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_15_cast_fp16 = reduce_mean(axes = var_1143, keep_dims = var_972, x = inputs_15_cast_fp16)[name = tensor<string, []>("channels_mean_15_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_15_cast_fp16 = sub(x = inputs_15_cast_fp16, y = channels_mean_15_cast_fp16)[name = tensor<string, []>("zero_mean_15_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_15_cast_fp16 = mul(x = zero_mean_15_cast_fp16, y = zero_mean_15_cast_fp16)[name = tensor<string, []>("zero_mean_sq_15_cast_fp16")];
            tensor<int32, [1]> var_1147 = const()[name = tensor<string, []>("op_1147"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_1148_cast_fp16 = reduce_mean(axes = var_1147, keep_dims = var_972, x = zero_mean_sq_15_cast_fp16)[name = tensor<string, []>("op_1148_cast_fp16")];
            tensor<fp16, []> var_1149_to_fp16 = const()[name = tensor<string, []>("op_1149_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_1150_cast_fp16 = add(x = var_1148_cast_fp16, y = var_1149_to_fp16)[name = tensor<string, []>("op_1150_cast_fp16")];
            tensor<fp32, []> denom_15_epsilon_0 = const()[name = tensor<string, []>("denom_15_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_15_cast_fp16 = rsqrt(epsilon = denom_15_epsilon_0, x = var_1150_cast_fp16)[name = tensor<string, []>("denom_15_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_15_cast_fp16 = mul(x = zero_mean_15_cast_fp16, y = denom_15_cast_fp16)[name = tensor<string, []>("out_15_cast_fp16")];
            tensor<fp16, [1280]> obj_37_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_37_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(165998016)))];
            tensor<fp16, [1280]> obj_37_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_37_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(166000640)))];
            tensor<fp16, []> obj_37_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_37_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_37_cast_fp16 = batch_norm(beta = obj_37_beta_0_to_fp16, epsilon = obj_37_epsilon_0_to_fp16, gamma = obj_37_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_15_cast_fp16)[name = tensor<string, []>("obj_37_cast_fp16")];
            tensor<int32, [2]> var_1168 = const()[name = tensor<string, []>("op_1168"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1170 = const()[name = tensor<string, []>("op_1170"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_49_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_49_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_49_pad_0 = const()[name = tensor<string, []>("pretrained_out_49_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_2_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(166003264))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(166822528))), name = tensor<string, []>("layers_2_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_2_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_2_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(166822656)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_49_cast_fp16 = conv(bias = layers_2_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_1170, groups = var_971, pad = pretrained_out_49_pad_0, pad_type = pretrained_out_49_pad_type_0, strides = var_1168, weight = layers_2_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_37_cast_fp16)[name = tensor<string, []>("pretrained_out_49_cast_fp16")];
            tensor<int32, [2]> var_1174 = const()[name = tensor<string, []>("op_1174"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1176 = const()[name = tensor<string, []>("op_1176"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_71_pad_type_0 = const()[name = tensor<string, []>("input_71_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_71_pad_0 = const()[name = tensor<string, []>("input_71_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_2_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_2_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(166825280)))];
            tensor<fp16, [1, 16, 1, 1]> input_71_cast_fp16 = conv(dilations = var_1176, groups = var_971, pad = input_71_pad_0, pad_type = input_71_pad_type_0, strides = var_1174, weight = layers_2_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_37_cast_fp16)[name = tensor<string, []>("input_71_cast_fp16")];
            tensor<int32, [2]> var_1180 = const()[name = tensor<string, []>("op_1180"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1182 = const()[name = tensor<string, []>("op_1182"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_97_pad_type_0 = const()[name = tensor<string, []>("lora_out_97_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_97_pad_0 = const()[name = tensor<string, []>("lora_out_97_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_99_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_99_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(166866304)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_99_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_1182, groups = var_971, pad = lora_out_97_pad_0, pad_type = lora_out_97_pad_type_0, strides = var_1180, weight = lora_out_99_weight_0_to_fp16, x = input_71_cast_fp16)[name = tensor<string, []>("lora_out_99_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_11_cast_fp16 = add(x = pretrained_out_49_cast_fp16, y = lora_out_99_cast_fp16)[name = tensor<string, []>("query_11_cast_fp16")];
            tensor<int32, [2]> var_1192 = const()[name = tensor<string, []>("op_1192"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1194 = const()[name = tensor<string, []>("op_1194"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_51_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_51_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_51_pad_0 = const()[name = tensor<string, []>("pretrained_out_51_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_2_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(166907328))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(167726592))), name = tensor<string, []>("layers_2_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_51_cast_fp16 = conv(dilations = var_1194, groups = var_971, pad = pretrained_out_51_pad_0, pad_type = pretrained_out_51_pad_type_0, strides = var_1192, weight = layers_2_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_51_cast_fp16")];
            tensor<int32, [2]> var_1198 = const()[name = tensor<string, []>("op_1198"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1200 = const()[name = tensor<string, []>("op_1200"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_73_pad_type_0 = const()[name = tensor<string, []>("input_73_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_73_pad_0 = const()[name = tensor<string, []>("input_73_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_2_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_2_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(167726720)))];
            tensor<fp16, [1, 16, 1, 1500]> input_73_cast_fp16 = conv(dilations = var_1200, groups = var_971, pad = input_73_pad_0, pad_type = input_73_pad_type_0, strides = var_1198, weight = layers_2_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_73_cast_fp16")];
            tensor<int32, [2]> var_1204 = const()[name = tensor<string, []>("op_1204"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1206 = const()[name = tensor<string, []>("op_1206"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_101_pad_type_0 = const()[name = tensor<string, []>("lora_out_101_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_101_pad_0 = const()[name = tensor<string, []>("lora_out_101_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_103_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_103_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(167767744)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_103_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_1206, groups = var_971, pad = lora_out_101_pad_0, pad_type = lora_out_101_pad_type_0, strides = var_1204, weight = lora_out_103_weight_0_to_fp16, x = input_73_cast_fp16)[name = tensor<string, []>("lora_out_103_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_11_cast_fp16 = add(x = pretrained_out_51_cast_fp16, y = lora_out_103_cast_fp16)[name = tensor<string, []>("key_11_cast_fp16")];
            tensor<int32, [2]> var_1217 = const()[name = tensor<string, []>("op_1217"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1219 = const()[name = tensor<string, []>("op_1219"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_53_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_53_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_53_pad_0 = const()[name = tensor<string, []>("pretrained_out_53_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_2_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(167808768))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(168628032))), name = tensor<string, []>("layers_2_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_2_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_2_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(168628160)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_53_cast_fp16 = conv(bias = layers_2_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_1219, groups = var_971, pad = pretrained_out_53_pad_0, pad_type = pretrained_out_53_pad_type_0, strides = var_1217, weight = layers_2_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_53_cast_fp16")];
            tensor<int32, [2]> var_1223 = const()[name = tensor<string, []>("op_1223"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1225 = const()[name = tensor<string, []>("op_1225"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_75_pad_type_0 = const()[name = tensor<string, []>("input_75_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_75_pad_0 = const()[name = tensor<string, []>("input_75_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_2_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_2_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(168630784)))];
            tensor<fp16, [1, 16, 1, 1500]> input_75_cast_fp16 = conv(dilations = var_1225, groups = var_971, pad = input_75_pad_0, pad_type = input_75_pad_type_0, strides = var_1223, weight = layers_2_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_75_cast_fp16")];
            tensor<int32, [2]> var_1229 = const()[name = tensor<string, []>("op_1229"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1231 = const()[name = tensor<string, []>("op_1231"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_105_pad_type_0 = const()[name = tensor<string, []>("lora_out_105_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_105_pad_0 = const()[name = tensor<string, []>("lora_out_105_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_107_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_107_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(168671808)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_107_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_1231, groups = var_971, pad = lora_out_105_pad_0, pad_type = lora_out_105_pad_type_0, strides = var_1229, weight = lora_out_107_weight_0_to_fp16, x = input_75_cast_fp16)[name = tensor<string, []>("lora_out_107_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_11_cast_fp16 = add(x = pretrained_out_53_cast_fp16, y = lora_out_107_cast_fp16)[name = tensor<string, []>("value_11_cast_fp16")];
            tensor<int32, [4]> var_1238 = const()[name = tensor<string, []>("op_1238"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_1239_cast_fp16 = reshape(shape = var_1238, x = query_11_cast_fp16)[name = tensor<string, []>("op_1239_cast_fp16")];
            tensor<fp16, []> var_1240_to_fp16 = const()[name = tensor<string, []>("op_1240_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_1241_cast_fp16 = mul(x = var_1239_cast_fp16, y = var_1240_to_fp16)[name = tensor<string, []>("op_1241_cast_fp16")];
            tensor<int32, [4]> var_1242 = const()[name = tensor<string, []>("op_1242"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_1243_cast_fp16 = reshape(shape = var_1242, x = key_11_cast_fp16)[name = tensor<string, []>("op_1243_cast_fp16")];
            tensor<bool, []> mh_w_17_transpose_x_0 = const()[name = tensor<string, []>("mh_w_17_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_17_transpose_y_0 = const()[name = tensor<string, []>("mh_w_17_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_17_cast_fp16 = matmul(transpose_x = mh_w_17_transpose_x_0, transpose_y = mh_w_17_transpose_y_0, x = var_1241_cast_fp16, y = var_1243_cast_fp16)[name = tensor<string, []>("mh_w_17_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_41_cast_fp16 = softmax(axis = var_964, x = mh_w_17_cast_fp16)[name = tensor<string, []>("obj_41_cast_fp16")];
            tensor<int32, [4]> var_1247 = const()[name = tensor<string, []>("op_1247"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_1248_cast_fp16 = reshape(shape = var_1247, x = value_11_cast_fp16)[name = tensor<string, []>("op_1248_cast_fp16")];
            tensor<bool, []> attn_11_transpose_x_0 = const()[name = tensor<string, []>("attn_11_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_11_transpose_y_0 = const()[name = tensor<string, []>("attn_11_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_11_cast_fp16 = matmul(transpose_x = attn_11_transpose_x_0, transpose_y = attn_11_transpose_y_0, x = var_1248_cast_fp16, y = obj_41_cast_fp16)[name = tensor<string, []>("attn_11_cast_fp16")];
            tensor<int32, [4]> var_1251 = const()[name = tensor<string, []>("op_1251"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_77_cast_fp16 = reshape(shape = var_1251, x = attn_11_cast_fp16)[name = tensor<string, []>("input_77_cast_fp16")];
            tensor<int32, [2]> var_1258 = const()[name = tensor<string, []>("op_1258"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1260 = const()[name = tensor<string, []>("op_1260"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_55_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_55_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_55_pad_0 = const()[name = tensor<string, []>("pretrained_out_55_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_2_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(168712832))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(169532096))), name = tensor<string, []>("layers_2_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_2_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_2_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(169532224)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_55_cast_fp16 = conv(bias = layers_2_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_1260, groups = var_971, pad = pretrained_out_55_pad_0, pad_type = pretrained_out_55_pad_type_0, strides = var_1258, weight = layers_2_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_77_cast_fp16)[name = tensor<string, []>("pretrained_out_55_cast_fp16")];
            tensor<int32, [2]> var_1264 = const()[name = tensor<string, []>("op_1264"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1266 = const()[name = tensor<string, []>("op_1266"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_79_pad_type_0 = const()[name = tensor<string, []>("input_79_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_79_pad_0 = const()[name = tensor<string, []>("input_79_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_2_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_2_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(169534848)))];
            tensor<fp16, [1, 16, 1, 1]> input_79_cast_fp16 = conv(dilations = var_1266, groups = var_971, pad = input_79_pad_0, pad_type = input_79_pad_type_0, strides = var_1264, weight = layers_2_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_77_cast_fp16)[name = tensor<string, []>("input_79_cast_fp16")];
            tensor<int32, [2]> var_1270 = const()[name = tensor<string, []>("op_1270"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1272 = const()[name = tensor<string, []>("op_1272"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_109_pad_type_0 = const()[name = tensor<string, []>("lora_out_109_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_109_pad_0 = const()[name = tensor<string, []>("lora_out_109_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_111_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_111_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(169575872)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_111_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_1272, groups = var_971, pad = lora_out_109_pad_0, pad_type = lora_out_109_pad_type_0, strides = var_1270, weight = lora_out_111_weight_0_to_fp16, x = input_79_cast_fp16)[name = tensor<string, []>("lora_out_111_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_39_cast_fp16 = add(x = pretrained_out_55_cast_fp16, y = lora_out_111_cast_fp16)[name = tensor<string, []>("obj_39_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_17_cast_fp16 = add(x = inputs_15_cast_fp16, y = obj_39_cast_fp16)[name = tensor<string, []>("inputs_17_cast_fp16")];
            tensor<int32, [1]> var_1281 = const()[name = tensor<string, []>("op_1281"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_17_cast_fp16 = reduce_mean(axes = var_1281, keep_dims = var_972, x = inputs_17_cast_fp16)[name = tensor<string, []>("channels_mean_17_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_17_cast_fp16 = sub(x = inputs_17_cast_fp16, y = channels_mean_17_cast_fp16)[name = tensor<string, []>("zero_mean_17_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_17_cast_fp16 = mul(x = zero_mean_17_cast_fp16, y = zero_mean_17_cast_fp16)[name = tensor<string, []>("zero_mean_sq_17_cast_fp16")];
            tensor<int32, [1]> var_1285 = const()[name = tensor<string, []>("op_1285"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_1286_cast_fp16 = reduce_mean(axes = var_1285, keep_dims = var_972, x = zero_mean_sq_17_cast_fp16)[name = tensor<string, []>("op_1286_cast_fp16")];
            tensor<fp16, []> var_1287_to_fp16 = const()[name = tensor<string, []>("op_1287_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_1288_cast_fp16 = add(x = var_1286_cast_fp16, y = var_1287_to_fp16)[name = tensor<string, []>("op_1288_cast_fp16")];
            tensor<fp32, []> denom_17_epsilon_0 = const()[name = tensor<string, []>("denom_17_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_17_cast_fp16 = rsqrt(epsilon = denom_17_epsilon_0, x = var_1288_cast_fp16)[name = tensor<string, []>("denom_17_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_17_cast_fp16 = mul(x = zero_mean_17_cast_fp16, y = denom_17_cast_fp16)[name = tensor<string, []>("out_17_cast_fp16")];
            tensor<fp16, [1280]> input_81_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_81_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(169616896)))];
            tensor<fp16, [1280]> input_81_beta_0_to_fp16 = const()[name = tensor<string, []>("input_81_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(169619520)))];
            tensor<fp16, []> input_81_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_81_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_81_cast_fp16 = batch_norm(beta = input_81_beta_0_to_fp16, epsilon = input_81_epsilon_0_to_fp16, gamma = input_81_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_17_cast_fp16)[name = tensor<string, []>("input_81_cast_fp16")];
            tensor<int32, [2]> var_1302 = const()[name = tensor<string, []>("op_1302"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1304 = const()[name = tensor<string, []>("op_1304"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_57_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_57_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_57_pad_0 = const()[name = tensor<string, []>("pretrained_out_57_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_2_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(169622144))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(172899008))), name = tensor<string, []>("layers_2_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_2_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_2_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(172899136)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_57_cast_fp16 = conv(bias = layers_2_fc1_pretrained_bias_to_fp16, dilations = var_1304, groups = var_971, pad = pretrained_out_57_pad_0, pad_type = pretrained_out_57_pad_type_0, strides = var_1302, weight = layers_2_fc1_pretrained_weight_to_fp16_palettized, x = input_81_cast_fp16)[name = tensor<string, []>("pretrained_out_57_cast_fp16")];
            tensor<int32, [2]> var_1308 = const()[name = tensor<string, []>("op_1308"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1310 = const()[name = tensor<string, []>("op_1310"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_83_pad_type_0 = const()[name = tensor<string, []>("input_83_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_83_pad_0 = const()[name = tensor<string, []>("input_83_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_2_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_2_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(172909440)))];
            tensor<fp16, [1, 16, 1, 1]> input_83_cast_fp16 = conv(dilations = var_1310, groups = var_971, pad = input_83_pad_0, pad_type = input_83_pad_type_0, strides = var_1308, weight = layers_2_fc1_loraA_weight_to_fp16, x = input_81_cast_fp16)[name = tensor<string, []>("input_83_cast_fp16")];
            tensor<int32, [2]> var_1314 = const()[name = tensor<string, []>("op_1314"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1316 = const()[name = tensor<string, []>("op_1316"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_113_pad_type_0 = const()[name = tensor<string, []>("lora_out_113_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_113_pad_0 = const()[name = tensor<string, []>("lora_out_113_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_115_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_115_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(172950464)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_115_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_1316, groups = var_971, pad = lora_out_113_pad_0, pad_type = lora_out_113_pad_type_0, strides = var_1314, weight = lora_out_115_weight_0_to_fp16, x = input_83_cast_fp16)[name = tensor<string, []>("lora_out_115_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_85_cast_fp16 = add(x = pretrained_out_57_cast_fp16, y = lora_out_115_cast_fp16)[name = tensor<string, []>("input_85_cast_fp16")];
            tensor<string, []> input_87_mode_0 = const()[name = tensor<string, []>("input_87_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_87_cast_fp16 = gelu(mode = input_87_mode_0, x = input_85_cast_fp16)[name = tensor<string, []>("input_87_cast_fp16")];
            tensor<int32, [2]> var_1328 = const()[name = tensor<string, []>("op_1328"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1330 = const()[name = tensor<string, []>("op_1330"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_59_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_59_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_59_pad_0 = const()[name = tensor<string, []>("pretrained_out_59_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_2_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(173114368))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(176391232))), name = tensor<string, []>("layers_2_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_2_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_2_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(176391360)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_59_cast_fp16 = conv(bias = layers_2_fc2_pretrained_bias_to_fp16, dilations = var_1330, groups = var_971, pad = pretrained_out_59_pad_0, pad_type = pretrained_out_59_pad_type_0, strides = var_1328, weight = layers_2_fc2_pretrained_weight_to_fp16_palettized, x = input_87_cast_fp16)[name = tensor<string, []>("pretrained_out_59_cast_fp16")];
            tensor<int32, [2]> var_1334 = const()[name = tensor<string, []>("op_1334"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1336 = const()[name = tensor<string, []>("op_1336"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_89_pad_type_0 = const()[name = tensor<string, []>("input_89_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_89_pad_0 = const()[name = tensor<string, []>("input_89_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_2_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_2_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(176393984)))];
            tensor<fp16, [1, 16, 1, 1]> input_89_cast_fp16 = conv(dilations = var_1336, groups = var_971, pad = input_89_pad_0, pad_type = input_89_pad_type_0, strides = var_1334, weight = layers_2_fc2_loraA_weight_to_fp16, x = input_87_cast_fp16)[name = tensor<string, []>("input_89_cast_fp16")];
            tensor<int32, [2]> var_1340 = const()[name = tensor<string, []>("op_1340"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1342 = const()[name = tensor<string, []>("op_1342"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_117_pad_type_0 = const()[name = tensor<string, []>("lora_out_117_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_117_pad_0 = const()[name = tensor<string, []>("lora_out_117_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_119_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_119_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(176557888)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_119_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_1342, groups = var_971, pad = lora_out_117_pad_0, pad_type = lora_out_117_pad_type_0, strides = var_1340, weight = lora_out_119_weight_0_to_fp16, x = input_89_cast_fp16)[name = tensor<string, []>("lora_out_119_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_7_cast_fp16 = add(x = pretrained_out_59_cast_fp16, y = lora_out_119_cast_fp16)[name = tensor<string, []>("hidden_states_7_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_19_cast_fp16 = add(x = inputs_17_cast_fp16, y = hidden_states_7_cast_fp16)[name = tensor<string, []>("inputs_19_cast_fp16")];
            tensor<int32, []> var_1358 = const()[name = tensor<string, []>("op_1358"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_1365 = const()[name = tensor<string, []>("op_1365"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_1366 = const()[name = tensor<string, []>("op_1366"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_1378 = const()[name = tensor<string, []>("op_1378"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_19_cast_fp16 = reduce_mean(axes = var_1378, keep_dims = var_1366, x = inputs_19_cast_fp16)[name = tensor<string, []>("channels_mean_19_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_19_cast_fp16 = sub(x = inputs_19_cast_fp16, y = channels_mean_19_cast_fp16)[name = tensor<string, []>("zero_mean_19_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_19_cast_fp16 = mul(x = zero_mean_19_cast_fp16, y = zero_mean_19_cast_fp16)[name = tensor<string, []>("zero_mean_sq_19_cast_fp16")];
            tensor<int32, [1]> var_1382 = const()[name = tensor<string, []>("op_1382"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_1383_cast_fp16 = reduce_mean(axes = var_1382, keep_dims = var_1366, x = zero_mean_sq_19_cast_fp16)[name = tensor<string, []>("op_1383_cast_fp16")];
            tensor<fp16, []> var_1384_to_fp16 = const()[name = tensor<string, []>("op_1384_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_1385_cast_fp16 = add(x = var_1383_cast_fp16, y = var_1384_to_fp16)[name = tensor<string, []>("op_1385_cast_fp16")];
            tensor<fp32, []> denom_19_epsilon_0 = const()[name = tensor<string, []>("denom_19_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_19_cast_fp16 = rsqrt(epsilon = denom_19_epsilon_0, x = var_1385_cast_fp16)[name = tensor<string, []>("denom_19_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_19_cast_fp16 = mul(x = zero_mean_19_cast_fp16, y = denom_19_cast_fp16)[name = tensor<string, []>("out_19_cast_fp16")];
            tensor<fp16, [1280]> obj_43_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_43_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(176598912)))];
            tensor<fp16, [1280]> obj_43_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_43_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(176601536)))];
            tensor<fp16, []> obj_43_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_43_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_43_cast_fp16 = batch_norm(beta = obj_43_beta_0_to_fp16, epsilon = obj_43_epsilon_0_to_fp16, gamma = obj_43_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_19_cast_fp16)[name = tensor<string, []>("obj_43_cast_fp16")];
            tensor<int32, [2]> var_1403 = const()[name = tensor<string, []>("op_1403"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1405 = const()[name = tensor<string, []>("op_1405"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_61_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_61_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_61_pad_0 = const()[name = tensor<string, []>("pretrained_out_61_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_3_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(176604160))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(177423424))), name = tensor<string, []>("layers_3_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_3_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_3_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(177423552)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_61_cast_fp16 = conv(bias = layers_3_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_1405, groups = var_1365, pad = pretrained_out_61_pad_0, pad_type = pretrained_out_61_pad_type_0, strides = var_1403, weight = layers_3_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_43_cast_fp16)[name = tensor<string, []>("pretrained_out_61_cast_fp16")];
            tensor<int32, [2]> var_1409 = const()[name = tensor<string, []>("op_1409"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1411 = const()[name = tensor<string, []>("op_1411"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_91_pad_type_0 = const()[name = tensor<string, []>("input_91_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_91_pad_0 = const()[name = tensor<string, []>("input_91_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_3_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_3_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(177426176)))];
            tensor<fp16, [1, 16, 1, 1]> input_91_cast_fp16 = conv(dilations = var_1411, groups = var_1365, pad = input_91_pad_0, pad_type = input_91_pad_type_0, strides = var_1409, weight = layers_3_self_attn_q_proj_loraA_weight_to_fp16, x = obj_43_cast_fp16)[name = tensor<string, []>("input_91_cast_fp16")];
            tensor<int32, [2]> var_1415 = const()[name = tensor<string, []>("op_1415"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1417 = const()[name = tensor<string, []>("op_1417"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_121_pad_type_0 = const()[name = tensor<string, []>("lora_out_121_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_121_pad_0 = const()[name = tensor<string, []>("lora_out_121_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_123_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_123_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(177467200)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_123_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_1417, groups = var_1365, pad = lora_out_121_pad_0, pad_type = lora_out_121_pad_type_0, strides = var_1415, weight = lora_out_123_weight_0_to_fp16, x = input_91_cast_fp16)[name = tensor<string, []>("lora_out_123_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_13_cast_fp16 = add(x = pretrained_out_61_cast_fp16, y = lora_out_123_cast_fp16)[name = tensor<string, []>("query_13_cast_fp16")];
            tensor<int32, [2]> var_1427 = const()[name = tensor<string, []>("op_1427"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1429 = const()[name = tensor<string, []>("op_1429"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_63_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_63_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_63_pad_0 = const()[name = tensor<string, []>("pretrained_out_63_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_3_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(177508224))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(178327488))), name = tensor<string, []>("layers_3_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_63_cast_fp16 = conv(dilations = var_1429, groups = var_1365, pad = pretrained_out_63_pad_0, pad_type = pretrained_out_63_pad_type_0, strides = var_1427, weight = layers_3_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_43_cast_fp16)[name = tensor<string, []>("pretrained_out_63_cast_fp16")];
            tensor<int32, [2]> var_1433 = const()[name = tensor<string, []>("op_1433"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1435 = const()[name = tensor<string, []>("op_1435"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_93_pad_type_0 = const()[name = tensor<string, []>("input_93_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_93_pad_0 = const()[name = tensor<string, []>("input_93_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_3_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_3_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(178327616)))];
            tensor<fp16, [1, 16, 1, 1]> input_93_cast_fp16 = conv(dilations = var_1435, groups = var_1365, pad = input_93_pad_0, pad_type = input_93_pad_type_0, strides = var_1433, weight = layers_3_self_attn_k_proj_loraA_weight_to_fp16, x = obj_43_cast_fp16)[name = tensor<string, []>("input_93_cast_fp16")];
            tensor<int32, [2]> var_1439 = const()[name = tensor<string, []>("op_1439"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1441 = const()[name = tensor<string, []>("op_1441"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_125_pad_type_0 = const()[name = tensor<string, []>("lora_out_125_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_125_pad_0 = const()[name = tensor<string, []>("lora_out_125_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_127_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_127_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(178368640)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_127_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_1441, groups = var_1365, pad = lora_out_125_pad_0, pad_type = lora_out_125_pad_type_0, strides = var_1439, weight = lora_out_127_weight_0_to_fp16, x = input_93_cast_fp16)[name = tensor<string, []>("lora_out_127_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_7_cast_fp16 = add(x = pretrained_out_63_cast_fp16, y = lora_out_127_cast_fp16)[name = tensor<string, []>("current_key_7_cast_fp16")];
            tensor<int32, [2]> var_1452 = const()[name = tensor<string, []>("op_1452"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1454 = const()[name = tensor<string, []>("op_1454"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_65_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_65_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_65_pad_0 = const()[name = tensor<string, []>("pretrained_out_65_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_3_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(178409664))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(179228928))), name = tensor<string, []>("layers_3_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_3_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_3_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(179229056)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_65_cast_fp16 = conv(bias = layers_3_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_1454, groups = var_1365, pad = pretrained_out_65_pad_0, pad_type = pretrained_out_65_pad_type_0, strides = var_1452, weight = layers_3_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_43_cast_fp16)[name = tensor<string, []>("pretrained_out_65_cast_fp16")];
            tensor<int32, [2]> var_1458 = const()[name = tensor<string, []>("op_1458"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1460 = const()[name = tensor<string, []>("op_1460"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_95_pad_type_0 = const()[name = tensor<string, []>("input_95_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_95_pad_0 = const()[name = tensor<string, []>("input_95_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_3_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_3_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(179231680)))];
            tensor<fp16, [1, 16, 1, 1]> input_95_cast_fp16 = conv(dilations = var_1460, groups = var_1365, pad = input_95_pad_0, pad_type = input_95_pad_type_0, strides = var_1458, weight = layers_3_self_attn_v_proj_loraA_weight_to_fp16, x = obj_43_cast_fp16)[name = tensor<string, []>("input_95_cast_fp16")];
            tensor<int32, [2]> var_1464 = const()[name = tensor<string, []>("op_1464"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1466 = const()[name = tensor<string, []>("op_1466"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_129_pad_type_0 = const()[name = tensor<string, []>("lora_out_129_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_129_pad_0 = const()[name = tensor<string, []>("lora_out_129_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_131_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_131_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(179272704)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_131_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_1466, groups = var_1365, pad = lora_out_129_pad_0, pad_type = lora_out_129_pad_type_0, strides = var_1464, weight = lora_out_131_weight_0_to_fp16, x = input_95_cast_fp16)[name = tensor<string, []>("lora_out_131_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_7_cast_fp16 = add(x = pretrained_out_65_cast_fp16, y = lora_out_131_cast_fp16)[name = tensor<string, []>("current_value_7_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_1476_cast_fp16 = mul(x = current_key_7_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_1476_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_1478_cast_fp16 = mul(x = var_103_cast_fp16_3, y = var_295_cast_fp16)[name = tensor<string, []>("op_1478_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_13_cast_fp16 = add(x = var_1476_cast_fp16, y = var_1478_cast_fp16)[name = tensor<string, []>("key_13_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_1480_cast_fp16 = mul(x = current_value_7_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_1480_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_1482_cast_fp16 = mul(x = var_138_cast_fp16_3, y = var_295_cast_fp16)[name = tensor<string, []>("op_1482_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_13_cast_fp16 = add(x = var_1480_cast_fp16, y = var_1482_cast_fp16)[name = tensor<string, []>("value_13_cast_fp16")];
            tensor<int32, [4]> var_1485 = const()[name = tensor<string, []>("op_1485"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_1486_cast_fp16 = reshape(shape = var_1485, x = query_13_cast_fp16)[name = tensor<string, []>("op_1486_cast_fp16")];
            tensor<fp16, []> var_1487_to_fp16 = const()[name = tensor<string, []>("op_1487_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_1488_cast_fp16 = mul(x = var_1486_cast_fp16, y = var_1487_to_fp16)[name = tensor<string, []>("op_1488_cast_fp16")];
            tensor<int32, [4]> var_1489 = const()[name = tensor<string, []>("op_1489"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_1490_cast_fp16 = reshape(shape = var_1489, x = key_13_cast_fp16)[name = tensor<string, []>("op_1490_cast_fp16")];
            tensor<bool, []> mh_w_19_transpose_x_0 = const()[name = tensor<string, []>("mh_w_19_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_19_transpose_y_0 = const()[name = tensor<string, []>("mh_w_19_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_19_cast_fp16 = matmul(transpose_x = mh_w_19_transpose_x_0, transpose_y = mh_w_19_transpose_y_0, x = var_1488_cast_fp16, y = var_1490_cast_fp16)[name = tensor<string, []>("mh_w_19_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_21_cast_fp16 = add(x = mh_w_19_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_21_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_1498_cast_fp16 = softmax(axis = var_1358, x = mh_w_21_cast_fp16)[name = tensor<string, []>("op_1498_cast_fp16")];
            tensor<int32, [4]> var_1499 = const()[name = tensor<string, []>("op_1499"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_1500_cast_fp16 = reshape(shape = var_1499, x = value_13_cast_fp16)[name = tensor<string, []>("op_1500_cast_fp16")];
            tensor<bool, []> attn_13_transpose_x_0 = const()[name = tensor<string, []>("attn_13_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_13_transpose_y_0 = const()[name = tensor<string, []>("attn_13_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_13_cast_fp16 = matmul(transpose_x = attn_13_transpose_x_0, transpose_y = attn_13_transpose_y_0, x = var_1500_cast_fp16, y = var_1498_cast_fp16)[name = tensor<string, []>("attn_13_cast_fp16")];
            tensor<int32, [4]> var_1503 = const()[name = tensor<string, []>("op_1503"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_97_cast_fp16 = reshape(shape = var_1503, x = attn_13_cast_fp16)[name = tensor<string, []>("input_97_cast_fp16")];
            tensor<int32, [2]> var_1510 = const()[name = tensor<string, []>("op_1510"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1512 = const()[name = tensor<string, []>("op_1512"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_67_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_67_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_67_pad_0 = const()[name = tensor<string, []>("pretrained_out_67_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_3_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(179313728))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(180132992))), name = tensor<string, []>("layers_3_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_3_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_3_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(180133120)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_67_cast_fp16 = conv(bias = layers_3_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_1512, groups = var_1365, pad = pretrained_out_67_pad_0, pad_type = pretrained_out_67_pad_type_0, strides = var_1510, weight = layers_3_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_97_cast_fp16)[name = tensor<string, []>("pretrained_out_67_cast_fp16")];
            tensor<int32, [2]> var_1516 = const()[name = tensor<string, []>("op_1516"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1518 = const()[name = tensor<string, []>("op_1518"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_99_pad_type_0 = const()[name = tensor<string, []>("input_99_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_99_pad_0 = const()[name = tensor<string, []>("input_99_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_3_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_3_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(180135744)))];
            tensor<fp16, [1, 16, 1, 1]> input_99_cast_fp16 = conv(dilations = var_1518, groups = var_1365, pad = input_99_pad_0, pad_type = input_99_pad_type_0, strides = var_1516, weight = layers_3_self_attn_o_proj_loraA_weight_to_fp16, x = input_97_cast_fp16)[name = tensor<string, []>("input_99_cast_fp16")];
            tensor<int32, [2]> var_1522 = const()[name = tensor<string, []>("op_1522"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1524 = const()[name = tensor<string, []>("op_1524"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_133_pad_type_0 = const()[name = tensor<string, []>("lora_out_133_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_133_pad_0 = const()[name = tensor<string, []>("lora_out_133_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_135_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_135_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(180176768)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_135_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_1524, groups = var_1365, pad = lora_out_133_pad_0, pad_type = lora_out_133_pad_type_0, strides = var_1522, weight = lora_out_135_weight_0_to_fp16, x = input_99_cast_fp16)[name = tensor<string, []>("lora_out_135_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_49_cast_fp16 = add(x = pretrained_out_67_cast_fp16, y = lora_out_135_cast_fp16)[name = tensor<string, []>("obj_49_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_21_cast_fp16 = add(x = inputs_19_cast_fp16, y = obj_49_cast_fp16)[name = tensor<string, []>("inputs_21_cast_fp16")];
            tensor<int32, [1]> var_1537 = const()[name = tensor<string, []>("op_1537"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_21_cast_fp16 = reduce_mean(axes = var_1537, keep_dims = var_1366, x = inputs_21_cast_fp16)[name = tensor<string, []>("channels_mean_21_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_21_cast_fp16 = sub(x = inputs_21_cast_fp16, y = channels_mean_21_cast_fp16)[name = tensor<string, []>("zero_mean_21_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_21_cast_fp16 = mul(x = zero_mean_21_cast_fp16, y = zero_mean_21_cast_fp16)[name = tensor<string, []>("zero_mean_sq_21_cast_fp16")];
            tensor<int32, [1]> var_1541 = const()[name = tensor<string, []>("op_1541"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_1542_cast_fp16 = reduce_mean(axes = var_1541, keep_dims = var_1366, x = zero_mean_sq_21_cast_fp16)[name = tensor<string, []>("op_1542_cast_fp16")];
            tensor<fp16, []> var_1543_to_fp16 = const()[name = tensor<string, []>("op_1543_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_1544_cast_fp16 = add(x = var_1542_cast_fp16, y = var_1543_to_fp16)[name = tensor<string, []>("op_1544_cast_fp16")];
            tensor<fp32, []> denom_21_epsilon_0 = const()[name = tensor<string, []>("denom_21_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_21_cast_fp16 = rsqrt(epsilon = denom_21_epsilon_0, x = var_1544_cast_fp16)[name = tensor<string, []>("denom_21_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_21_cast_fp16 = mul(x = zero_mean_21_cast_fp16, y = denom_21_cast_fp16)[name = tensor<string, []>("out_21_cast_fp16")];
            tensor<fp16, [1280]> obj_51_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_51_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(180217792)))];
            tensor<fp16, [1280]> obj_51_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_51_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(180220416)))];
            tensor<fp16, []> obj_51_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_51_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_51_cast_fp16 = batch_norm(beta = obj_51_beta_0_to_fp16, epsilon = obj_51_epsilon_0_to_fp16, gamma = obj_51_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_21_cast_fp16)[name = tensor<string, []>("obj_51_cast_fp16")];
            tensor<int32, [2]> var_1562 = const()[name = tensor<string, []>("op_1562"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1564 = const()[name = tensor<string, []>("op_1564"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_69_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_69_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_69_pad_0 = const()[name = tensor<string, []>("pretrained_out_69_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_3_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(180223040))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(181042304))), name = tensor<string, []>("layers_3_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_3_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_3_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(181042432)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_69_cast_fp16 = conv(bias = layers_3_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_1564, groups = var_1365, pad = pretrained_out_69_pad_0, pad_type = pretrained_out_69_pad_type_0, strides = var_1562, weight = layers_3_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_51_cast_fp16)[name = tensor<string, []>("pretrained_out_69_cast_fp16")];
            tensor<int32, [2]> var_1568 = const()[name = tensor<string, []>("op_1568"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1570 = const()[name = tensor<string, []>("op_1570"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_101_pad_type_0 = const()[name = tensor<string, []>("input_101_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_101_pad_0 = const()[name = tensor<string, []>("input_101_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_3_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_3_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(181045056)))];
            tensor<fp16, [1, 16, 1, 1]> input_101_cast_fp16 = conv(dilations = var_1570, groups = var_1365, pad = input_101_pad_0, pad_type = input_101_pad_type_0, strides = var_1568, weight = layers_3_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_51_cast_fp16)[name = tensor<string, []>("input_101_cast_fp16")];
            tensor<int32, [2]> var_1574 = const()[name = tensor<string, []>("op_1574"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1576 = const()[name = tensor<string, []>("op_1576"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_137_pad_type_0 = const()[name = tensor<string, []>("lora_out_137_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_137_pad_0 = const()[name = tensor<string, []>("lora_out_137_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_139_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_139_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(181086080)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_139_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_1576, groups = var_1365, pad = lora_out_137_pad_0, pad_type = lora_out_137_pad_type_0, strides = var_1574, weight = lora_out_139_weight_0_to_fp16, x = input_101_cast_fp16)[name = tensor<string, []>("lora_out_139_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_15_cast_fp16 = add(x = pretrained_out_69_cast_fp16, y = lora_out_139_cast_fp16)[name = tensor<string, []>("query_15_cast_fp16")];
            tensor<int32, [2]> var_1586 = const()[name = tensor<string, []>("op_1586"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1588 = const()[name = tensor<string, []>("op_1588"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_71_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_71_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_71_pad_0 = const()[name = tensor<string, []>("pretrained_out_71_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_3_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(181127104))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(181946368))), name = tensor<string, []>("layers_3_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_71_cast_fp16 = conv(dilations = var_1588, groups = var_1365, pad = pretrained_out_71_pad_0, pad_type = pretrained_out_71_pad_type_0, strides = var_1586, weight = layers_3_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_71_cast_fp16")];
            tensor<int32, [2]> var_1592 = const()[name = tensor<string, []>("op_1592"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1594 = const()[name = tensor<string, []>("op_1594"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_103_pad_type_0 = const()[name = tensor<string, []>("input_103_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_103_pad_0 = const()[name = tensor<string, []>("input_103_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_3_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_3_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(181946496)))];
            tensor<fp16, [1, 16, 1, 1500]> input_103_cast_fp16 = conv(dilations = var_1594, groups = var_1365, pad = input_103_pad_0, pad_type = input_103_pad_type_0, strides = var_1592, weight = layers_3_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_103_cast_fp16")];
            tensor<int32, [2]> var_1598 = const()[name = tensor<string, []>("op_1598"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1600 = const()[name = tensor<string, []>("op_1600"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_141_pad_type_0 = const()[name = tensor<string, []>("lora_out_141_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_141_pad_0 = const()[name = tensor<string, []>("lora_out_141_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_143_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_143_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(181987520)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_143_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_1600, groups = var_1365, pad = lora_out_141_pad_0, pad_type = lora_out_141_pad_type_0, strides = var_1598, weight = lora_out_143_weight_0_to_fp16, x = input_103_cast_fp16)[name = tensor<string, []>("lora_out_143_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_15_cast_fp16 = add(x = pretrained_out_71_cast_fp16, y = lora_out_143_cast_fp16)[name = tensor<string, []>("key_15_cast_fp16")];
            tensor<int32, [2]> var_1611 = const()[name = tensor<string, []>("op_1611"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1613 = const()[name = tensor<string, []>("op_1613"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_73_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_73_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_73_pad_0 = const()[name = tensor<string, []>("pretrained_out_73_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_3_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(182028544))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(182847808))), name = tensor<string, []>("layers_3_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_3_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_3_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(182847936)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_73_cast_fp16 = conv(bias = layers_3_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_1613, groups = var_1365, pad = pretrained_out_73_pad_0, pad_type = pretrained_out_73_pad_type_0, strides = var_1611, weight = layers_3_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_73_cast_fp16")];
            tensor<int32, [2]> var_1617 = const()[name = tensor<string, []>("op_1617"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1619 = const()[name = tensor<string, []>("op_1619"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_105_pad_type_0 = const()[name = tensor<string, []>("input_105_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_105_pad_0 = const()[name = tensor<string, []>("input_105_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_3_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_3_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(182850560)))];
            tensor<fp16, [1, 16, 1, 1500]> input_105_cast_fp16 = conv(dilations = var_1619, groups = var_1365, pad = input_105_pad_0, pad_type = input_105_pad_type_0, strides = var_1617, weight = layers_3_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_105_cast_fp16")];
            tensor<int32, [2]> var_1623 = const()[name = tensor<string, []>("op_1623"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1625 = const()[name = tensor<string, []>("op_1625"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_145_pad_type_0 = const()[name = tensor<string, []>("lora_out_145_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_145_pad_0 = const()[name = tensor<string, []>("lora_out_145_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_147_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_147_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(182891584)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_147_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_1625, groups = var_1365, pad = lora_out_145_pad_0, pad_type = lora_out_145_pad_type_0, strides = var_1623, weight = lora_out_147_weight_0_to_fp16, x = input_105_cast_fp16)[name = tensor<string, []>("lora_out_147_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_15_cast_fp16 = add(x = pretrained_out_73_cast_fp16, y = lora_out_147_cast_fp16)[name = tensor<string, []>("value_15_cast_fp16")];
            tensor<int32, [4]> var_1632 = const()[name = tensor<string, []>("op_1632"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_1633_cast_fp16 = reshape(shape = var_1632, x = query_15_cast_fp16)[name = tensor<string, []>("op_1633_cast_fp16")];
            tensor<fp16, []> var_1634_to_fp16 = const()[name = tensor<string, []>("op_1634_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_1635_cast_fp16 = mul(x = var_1633_cast_fp16, y = var_1634_to_fp16)[name = tensor<string, []>("op_1635_cast_fp16")];
            tensor<int32, [4]> var_1636 = const()[name = tensor<string, []>("op_1636"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_1637_cast_fp16 = reshape(shape = var_1636, x = key_15_cast_fp16)[name = tensor<string, []>("op_1637_cast_fp16")];
            tensor<bool, []> mh_w_23_transpose_x_0 = const()[name = tensor<string, []>("mh_w_23_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_23_transpose_y_0 = const()[name = tensor<string, []>("mh_w_23_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_23_cast_fp16 = matmul(transpose_x = mh_w_23_transpose_x_0, transpose_y = mh_w_23_transpose_y_0, x = var_1635_cast_fp16, y = var_1637_cast_fp16)[name = tensor<string, []>("mh_w_23_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_55_cast_fp16 = softmax(axis = var_1358, x = mh_w_23_cast_fp16)[name = tensor<string, []>("obj_55_cast_fp16")];
            tensor<int32, [4]> var_1641 = const()[name = tensor<string, []>("op_1641"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_1642_cast_fp16 = reshape(shape = var_1641, x = value_15_cast_fp16)[name = tensor<string, []>("op_1642_cast_fp16")];
            tensor<bool, []> attn_15_transpose_x_0 = const()[name = tensor<string, []>("attn_15_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_15_transpose_y_0 = const()[name = tensor<string, []>("attn_15_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_15_cast_fp16 = matmul(transpose_x = attn_15_transpose_x_0, transpose_y = attn_15_transpose_y_0, x = var_1642_cast_fp16, y = obj_55_cast_fp16)[name = tensor<string, []>("attn_15_cast_fp16")];
            tensor<int32, [4]> var_1645 = const()[name = tensor<string, []>("op_1645"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_107_cast_fp16 = reshape(shape = var_1645, x = attn_15_cast_fp16)[name = tensor<string, []>("input_107_cast_fp16")];
            tensor<int32, [2]> var_1652 = const()[name = tensor<string, []>("op_1652"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1654 = const()[name = tensor<string, []>("op_1654"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_75_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_75_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_75_pad_0 = const()[name = tensor<string, []>("pretrained_out_75_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_3_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(182932608))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(183751872))), name = tensor<string, []>("layers_3_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_3_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_3_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(183752000)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_75_cast_fp16 = conv(bias = layers_3_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_1654, groups = var_1365, pad = pretrained_out_75_pad_0, pad_type = pretrained_out_75_pad_type_0, strides = var_1652, weight = layers_3_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_107_cast_fp16)[name = tensor<string, []>("pretrained_out_75_cast_fp16")];
            tensor<int32, [2]> var_1658 = const()[name = tensor<string, []>("op_1658"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1660 = const()[name = tensor<string, []>("op_1660"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_109_pad_type_0 = const()[name = tensor<string, []>("input_109_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_109_pad_0 = const()[name = tensor<string, []>("input_109_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_3_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_3_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(183754624)))];
            tensor<fp16, [1, 16, 1, 1]> input_109_cast_fp16 = conv(dilations = var_1660, groups = var_1365, pad = input_109_pad_0, pad_type = input_109_pad_type_0, strides = var_1658, weight = layers_3_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_107_cast_fp16)[name = tensor<string, []>("input_109_cast_fp16")];
            tensor<int32, [2]> var_1664 = const()[name = tensor<string, []>("op_1664"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1666 = const()[name = tensor<string, []>("op_1666"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_149_pad_type_0 = const()[name = tensor<string, []>("lora_out_149_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_149_pad_0 = const()[name = tensor<string, []>("lora_out_149_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_151_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_151_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(183795648)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_151_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_1666, groups = var_1365, pad = lora_out_149_pad_0, pad_type = lora_out_149_pad_type_0, strides = var_1664, weight = lora_out_151_weight_0_to_fp16, x = input_109_cast_fp16)[name = tensor<string, []>("lora_out_151_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_53_cast_fp16 = add(x = pretrained_out_75_cast_fp16, y = lora_out_151_cast_fp16)[name = tensor<string, []>("obj_53_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_23_cast_fp16 = add(x = inputs_21_cast_fp16, y = obj_53_cast_fp16)[name = tensor<string, []>("inputs_23_cast_fp16")];
            tensor<int32, [1]> var_1675 = const()[name = tensor<string, []>("op_1675"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_23_cast_fp16 = reduce_mean(axes = var_1675, keep_dims = var_1366, x = inputs_23_cast_fp16)[name = tensor<string, []>("channels_mean_23_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_23_cast_fp16 = sub(x = inputs_23_cast_fp16, y = channels_mean_23_cast_fp16)[name = tensor<string, []>("zero_mean_23_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_23_cast_fp16 = mul(x = zero_mean_23_cast_fp16, y = zero_mean_23_cast_fp16)[name = tensor<string, []>("zero_mean_sq_23_cast_fp16")];
            tensor<int32, [1]> var_1679 = const()[name = tensor<string, []>("op_1679"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_1680_cast_fp16 = reduce_mean(axes = var_1679, keep_dims = var_1366, x = zero_mean_sq_23_cast_fp16)[name = tensor<string, []>("op_1680_cast_fp16")];
            tensor<fp16, []> var_1681_to_fp16 = const()[name = tensor<string, []>("op_1681_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_1682_cast_fp16 = add(x = var_1680_cast_fp16, y = var_1681_to_fp16)[name = tensor<string, []>("op_1682_cast_fp16")];
            tensor<fp32, []> denom_23_epsilon_0 = const()[name = tensor<string, []>("denom_23_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_23_cast_fp16 = rsqrt(epsilon = denom_23_epsilon_0, x = var_1682_cast_fp16)[name = tensor<string, []>("denom_23_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_23_cast_fp16 = mul(x = zero_mean_23_cast_fp16, y = denom_23_cast_fp16)[name = tensor<string, []>("out_23_cast_fp16")];
            tensor<fp16, [1280]> input_111_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_111_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(183836672)))];
            tensor<fp16, [1280]> input_111_beta_0_to_fp16 = const()[name = tensor<string, []>("input_111_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(183839296)))];
            tensor<fp16, []> input_111_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_111_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_111_cast_fp16 = batch_norm(beta = input_111_beta_0_to_fp16, epsilon = input_111_epsilon_0_to_fp16, gamma = input_111_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_23_cast_fp16)[name = tensor<string, []>("input_111_cast_fp16")];
            tensor<int32, [2]> var_1696 = const()[name = tensor<string, []>("op_1696"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1698 = const()[name = tensor<string, []>("op_1698"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_77_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_77_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_77_pad_0 = const()[name = tensor<string, []>("pretrained_out_77_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_3_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(183841920))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(187118784))), name = tensor<string, []>("layers_3_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_3_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_3_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(187118912)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_77_cast_fp16 = conv(bias = layers_3_fc1_pretrained_bias_to_fp16, dilations = var_1698, groups = var_1365, pad = pretrained_out_77_pad_0, pad_type = pretrained_out_77_pad_type_0, strides = var_1696, weight = layers_3_fc1_pretrained_weight_to_fp16_palettized, x = input_111_cast_fp16)[name = tensor<string, []>("pretrained_out_77_cast_fp16")];
            tensor<int32, [2]> var_1702 = const()[name = tensor<string, []>("op_1702"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1704 = const()[name = tensor<string, []>("op_1704"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_113_pad_type_0 = const()[name = tensor<string, []>("input_113_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_113_pad_0 = const()[name = tensor<string, []>("input_113_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_3_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_3_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(187129216)))];
            tensor<fp16, [1, 16, 1, 1]> input_113_cast_fp16 = conv(dilations = var_1704, groups = var_1365, pad = input_113_pad_0, pad_type = input_113_pad_type_0, strides = var_1702, weight = layers_3_fc1_loraA_weight_to_fp16, x = input_111_cast_fp16)[name = tensor<string, []>("input_113_cast_fp16")];
            tensor<int32, [2]> var_1708 = const()[name = tensor<string, []>("op_1708"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1710 = const()[name = tensor<string, []>("op_1710"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_153_pad_type_0 = const()[name = tensor<string, []>("lora_out_153_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_153_pad_0 = const()[name = tensor<string, []>("lora_out_153_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_155_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_155_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(187170240)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_155_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_1710, groups = var_1365, pad = lora_out_153_pad_0, pad_type = lora_out_153_pad_type_0, strides = var_1708, weight = lora_out_155_weight_0_to_fp16, x = input_113_cast_fp16)[name = tensor<string, []>("lora_out_155_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_115_cast_fp16 = add(x = pretrained_out_77_cast_fp16, y = lora_out_155_cast_fp16)[name = tensor<string, []>("input_115_cast_fp16")];
            tensor<string, []> input_117_mode_0 = const()[name = tensor<string, []>("input_117_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_117_cast_fp16 = gelu(mode = input_117_mode_0, x = input_115_cast_fp16)[name = tensor<string, []>("input_117_cast_fp16")];
            tensor<int32, [2]> var_1722 = const()[name = tensor<string, []>("op_1722"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1724 = const()[name = tensor<string, []>("op_1724"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_79_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_79_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_79_pad_0 = const()[name = tensor<string, []>("pretrained_out_79_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_3_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(187334144))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(190611008))), name = tensor<string, []>("layers_3_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_3_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_3_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(190611136)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_79_cast_fp16 = conv(bias = layers_3_fc2_pretrained_bias_to_fp16, dilations = var_1724, groups = var_1365, pad = pretrained_out_79_pad_0, pad_type = pretrained_out_79_pad_type_0, strides = var_1722, weight = layers_3_fc2_pretrained_weight_to_fp16_palettized, x = input_117_cast_fp16)[name = tensor<string, []>("pretrained_out_79_cast_fp16")];
            tensor<int32, [2]> var_1728 = const()[name = tensor<string, []>("op_1728"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1730 = const()[name = tensor<string, []>("op_1730"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_119_pad_type_0 = const()[name = tensor<string, []>("input_119_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_119_pad_0 = const()[name = tensor<string, []>("input_119_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_3_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_3_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(190613760)))];
            tensor<fp16, [1, 16, 1, 1]> input_119_cast_fp16 = conv(dilations = var_1730, groups = var_1365, pad = input_119_pad_0, pad_type = input_119_pad_type_0, strides = var_1728, weight = layers_3_fc2_loraA_weight_to_fp16, x = input_117_cast_fp16)[name = tensor<string, []>("input_119_cast_fp16")];
            tensor<int32, [2]> var_1734 = const()[name = tensor<string, []>("op_1734"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1736 = const()[name = tensor<string, []>("op_1736"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_157_pad_type_0 = const()[name = tensor<string, []>("lora_out_157_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_157_pad_0 = const()[name = tensor<string, []>("lora_out_157_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_159_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_159_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(190777664)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_159_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_1736, groups = var_1365, pad = lora_out_157_pad_0, pad_type = lora_out_157_pad_type_0, strides = var_1734, weight = lora_out_159_weight_0_to_fp16, x = input_119_cast_fp16)[name = tensor<string, []>("lora_out_159_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_9_cast_fp16 = add(x = pretrained_out_79_cast_fp16, y = lora_out_159_cast_fp16)[name = tensor<string, []>("hidden_states_9_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_25_cast_fp16 = add(x = inputs_23_cast_fp16, y = hidden_states_9_cast_fp16)[name = tensor<string, []>("inputs_25_cast_fp16")];
            tensor<int32, []> var_1752 = const()[name = tensor<string, []>("op_1752"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_1759 = const()[name = tensor<string, []>("op_1759"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_1760 = const()[name = tensor<string, []>("op_1760"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_1772 = const()[name = tensor<string, []>("op_1772"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_25_cast_fp16 = reduce_mean(axes = var_1772, keep_dims = var_1760, x = inputs_25_cast_fp16)[name = tensor<string, []>("channels_mean_25_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_25_cast_fp16 = sub(x = inputs_25_cast_fp16, y = channels_mean_25_cast_fp16)[name = tensor<string, []>("zero_mean_25_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_25_cast_fp16 = mul(x = zero_mean_25_cast_fp16, y = zero_mean_25_cast_fp16)[name = tensor<string, []>("zero_mean_sq_25_cast_fp16")];
            tensor<int32, [1]> var_1776 = const()[name = tensor<string, []>("op_1776"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_1777_cast_fp16 = reduce_mean(axes = var_1776, keep_dims = var_1760, x = zero_mean_sq_25_cast_fp16)[name = tensor<string, []>("op_1777_cast_fp16")];
            tensor<fp16, []> var_1778_to_fp16 = const()[name = tensor<string, []>("op_1778_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_1779_cast_fp16 = add(x = var_1777_cast_fp16, y = var_1778_to_fp16)[name = tensor<string, []>("op_1779_cast_fp16")];
            tensor<fp32, []> denom_25_epsilon_0 = const()[name = tensor<string, []>("denom_25_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_25_cast_fp16 = rsqrt(epsilon = denom_25_epsilon_0, x = var_1779_cast_fp16)[name = tensor<string, []>("denom_25_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_25_cast_fp16 = mul(x = zero_mean_25_cast_fp16, y = denom_25_cast_fp16)[name = tensor<string, []>("out_25_cast_fp16")];
            tensor<fp16, [1280]> obj_57_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_57_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(190818688)))];
            tensor<fp16, [1280]> obj_57_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_57_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(190821312)))];
            tensor<fp16, []> obj_57_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_57_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_57_cast_fp16 = batch_norm(beta = obj_57_beta_0_to_fp16, epsilon = obj_57_epsilon_0_to_fp16, gamma = obj_57_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_25_cast_fp16)[name = tensor<string, []>("obj_57_cast_fp16")];
            tensor<int32, [2]> var_1797 = const()[name = tensor<string, []>("op_1797"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1799 = const()[name = tensor<string, []>("op_1799"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_81_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_81_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_81_pad_0 = const()[name = tensor<string, []>("pretrained_out_81_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_4_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(190823936))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(191643200))), name = tensor<string, []>("layers_4_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_4_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_4_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(191643328)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_81_cast_fp16 = conv(bias = layers_4_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_1799, groups = var_1759, pad = pretrained_out_81_pad_0, pad_type = pretrained_out_81_pad_type_0, strides = var_1797, weight = layers_4_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_57_cast_fp16)[name = tensor<string, []>("pretrained_out_81_cast_fp16")];
            tensor<int32, [2]> var_1803 = const()[name = tensor<string, []>("op_1803"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1805 = const()[name = tensor<string, []>("op_1805"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_121_pad_type_0 = const()[name = tensor<string, []>("input_121_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_121_pad_0 = const()[name = tensor<string, []>("input_121_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_4_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_4_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(191645952)))];
            tensor<fp16, [1, 16, 1, 1]> input_121_cast_fp16 = conv(dilations = var_1805, groups = var_1759, pad = input_121_pad_0, pad_type = input_121_pad_type_0, strides = var_1803, weight = layers_4_self_attn_q_proj_loraA_weight_to_fp16, x = obj_57_cast_fp16)[name = tensor<string, []>("input_121_cast_fp16")];
            tensor<int32, [2]> var_1809 = const()[name = tensor<string, []>("op_1809"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1811 = const()[name = tensor<string, []>("op_1811"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_161_pad_type_0 = const()[name = tensor<string, []>("lora_out_161_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_161_pad_0 = const()[name = tensor<string, []>("lora_out_161_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_163_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_163_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(191686976)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_163_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_1811, groups = var_1759, pad = lora_out_161_pad_0, pad_type = lora_out_161_pad_type_0, strides = var_1809, weight = lora_out_163_weight_0_to_fp16, x = input_121_cast_fp16)[name = tensor<string, []>("lora_out_163_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_17_cast_fp16 = add(x = pretrained_out_81_cast_fp16, y = lora_out_163_cast_fp16)[name = tensor<string, []>("query_17_cast_fp16")];
            tensor<int32, [2]> var_1821 = const()[name = tensor<string, []>("op_1821"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1823 = const()[name = tensor<string, []>("op_1823"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_83_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_83_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_83_pad_0 = const()[name = tensor<string, []>("pretrained_out_83_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_4_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(191728000))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(192547264))), name = tensor<string, []>("layers_4_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_83_cast_fp16 = conv(dilations = var_1823, groups = var_1759, pad = pretrained_out_83_pad_0, pad_type = pretrained_out_83_pad_type_0, strides = var_1821, weight = layers_4_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_57_cast_fp16)[name = tensor<string, []>("pretrained_out_83_cast_fp16")];
            tensor<int32, [2]> var_1827 = const()[name = tensor<string, []>("op_1827"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1829 = const()[name = tensor<string, []>("op_1829"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_123_pad_type_0 = const()[name = tensor<string, []>("input_123_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_123_pad_0 = const()[name = tensor<string, []>("input_123_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_4_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_4_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(192547392)))];
            tensor<fp16, [1, 16, 1, 1]> input_123_cast_fp16 = conv(dilations = var_1829, groups = var_1759, pad = input_123_pad_0, pad_type = input_123_pad_type_0, strides = var_1827, weight = layers_4_self_attn_k_proj_loraA_weight_to_fp16, x = obj_57_cast_fp16)[name = tensor<string, []>("input_123_cast_fp16")];
            tensor<int32, [2]> var_1833 = const()[name = tensor<string, []>("op_1833"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1835 = const()[name = tensor<string, []>("op_1835"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_165_pad_type_0 = const()[name = tensor<string, []>("lora_out_165_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_165_pad_0 = const()[name = tensor<string, []>("lora_out_165_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_167_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_167_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(192588416)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_167_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_1835, groups = var_1759, pad = lora_out_165_pad_0, pad_type = lora_out_165_pad_type_0, strides = var_1833, weight = lora_out_167_weight_0_to_fp16, x = input_123_cast_fp16)[name = tensor<string, []>("lora_out_167_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_9_cast_fp16 = add(x = pretrained_out_83_cast_fp16, y = lora_out_167_cast_fp16)[name = tensor<string, []>("current_key_9_cast_fp16")];
            tensor<int32, [2]> var_1846 = const()[name = tensor<string, []>("op_1846"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1848 = const()[name = tensor<string, []>("op_1848"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_85_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_85_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_85_pad_0 = const()[name = tensor<string, []>("pretrained_out_85_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_4_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(192629440))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(193448704))), name = tensor<string, []>("layers_4_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_4_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_4_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(193448832)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_85_cast_fp16 = conv(bias = layers_4_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_1848, groups = var_1759, pad = pretrained_out_85_pad_0, pad_type = pretrained_out_85_pad_type_0, strides = var_1846, weight = layers_4_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_57_cast_fp16)[name = tensor<string, []>("pretrained_out_85_cast_fp16")];
            tensor<int32, [2]> var_1852 = const()[name = tensor<string, []>("op_1852"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1854 = const()[name = tensor<string, []>("op_1854"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_125_pad_type_0 = const()[name = tensor<string, []>("input_125_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_125_pad_0 = const()[name = tensor<string, []>("input_125_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_4_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_4_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(193451456)))];
            tensor<fp16, [1, 16, 1, 1]> input_125_cast_fp16 = conv(dilations = var_1854, groups = var_1759, pad = input_125_pad_0, pad_type = input_125_pad_type_0, strides = var_1852, weight = layers_4_self_attn_v_proj_loraA_weight_to_fp16, x = obj_57_cast_fp16)[name = tensor<string, []>("input_125_cast_fp16")];
            tensor<int32, [2]> var_1858 = const()[name = tensor<string, []>("op_1858"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1860 = const()[name = tensor<string, []>("op_1860"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_169_pad_type_0 = const()[name = tensor<string, []>("lora_out_169_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_169_pad_0 = const()[name = tensor<string, []>("lora_out_169_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_171_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_171_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(193492480)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_171_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_1860, groups = var_1759, pad = lora_out_169_pad_0, pad_type = lora_out_169_pad_type_0, strides = var_1858, weight = lora_out_171_weight_0_to_fp16, x = input_125_cast_fp16)[name = tensor<string, []>("lora_out_171_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_9_cast_fp16 = add(x = pretrained_out_85_cast_fp16, y = lora_out_171_cast_fp16)[name = tensor<string, []>("current_value_9_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_1870_cast_fp16 = mul(x = current_key_9_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_1870_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_1872_cast_fp16 = mul(x = var_103_cast_fp16_4, y = var_295_cast_fp16)[name = tensor<string, []>("op_1872_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_17_cast_fp16 = add(x = var_1870_cast_fp16, y = var_1872_cast_fp16)[name = tensor<string, []>("key_17_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_1874_cast_fp16 = mul(x = current_value_9_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_1874_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_1876_cast_fp16 = mul(x = var_138_cast_fp16_4, y = var_295_cast_fp16)[name = tensor<string, []>("op_1876_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_17_cast_fp16 = add(x = var_1874_cast_fp16, y = var_1876_cast_fp16)[name = tensor<string, []>("value_17_cast_fp16")];
            tensor<int32, [4]> var_1879 = const()[name = tensor<string, []>("op_1879"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_1880_cast_fp16 = reshape(shape = var_1879, x = query_17_cast_fp16)[name = tensor<string, []>("op_1880_cast_fp16")];
            tensor<fp16, []> var_1881_to_fp16 = const()[name = tensor<string, []>("op_1881_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_1882_cast_fp16 = mul(x = var_1880_cast_fp16, y = var_1881_to_fp16)[name = tensor<string, []>("op_1882_cast_fp16")];
            tensor<int32, [4]> var_1883 = const()[name = tensor<string, []>("op_1883"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_1884_cast_fp16 = reshape(shape = var_1883, x = key_17_cast_fp16)[name = tensor<string, []>("op_1884_cast_fp16")];
            tensor<bool, []> mh_w_25_transpose_x_0 = const()[name = tensor<string, []>("mh_w_25_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_25_transpose_y_0 = const()[name = tensor<string, []>("mh_w_25_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_25_cast_fp16 = matmul(transpose_x = mh_w_25_transpose_x_0, transpose_y = mh_w_25_transpose_y_0, x = var_1882_cast_fp16, y = var_1884_cast_fp16)[name = tensor<string, []>("mh_w_25_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_27_cast_fp16 = add(x = mh_w_25_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_27_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_1892_cast_fp16 = softmax(axis = var_1752, x = mh_w_27_cast_fp16)[name = tensor<string, []>("op_1892_cast_fp16")];
            tensor<int32, [4]> var_1893 = const()[name = tensor<string, []>("op_1893"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_1894_cast_fp16 = reshape(shape = var_1893, x = value_17_cast_fp16)[name = tensor<string, []>("op_1894_cast_fp16")];
            tensor<bool, []> attn_17_transpose_x_0 = const()[name = tensor<string, []>("attn_17_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_17_transpose_y_0 = const()[name = tensor<string, []>("attn_17_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_17_cast_fp16 = matmul(transpose_x = attn_17_transpose_x_0, transpose_y = attn_17_transpose_y_0, x = var_1894_cast_fp16, y = var_1892_cast_fp16)[name = tensor<string, []>("attn_17_cast_fp16")];
            tensor<int32, [4]> var_1897 = const()[name = tensor<string, []>("op_1897"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_127_cast_fp16 = reshape(shape = var_1897, x = attn_17_cast_fp16)[name = tensor<string, []>("input_127_cast_fp16")];
            tensor<int32, [2]> var_1904 = const()[name = tensor<string, []>("op_1904"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1906 = const()[name = tensor<string, []>("op_1906"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_87_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_87_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_87_pad_0 = const()[name = tensor<string, []>("pretrained_out_87_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_4_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(193533504))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(194352768))), name = tensor<string, []>("layers_4_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_4_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_4_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(194352896)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_87_cast_fp16 = conv(bias = layers_4_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_1906, groups = var_1759, pad = pretrained_out_87_pad_0, pad_type = pretrained_out_87_pad_type_0, strides = var_1904, weight = layers_4_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_127_cast_fp16)[name = tensor<string, []>("pretrained_out_87_cast_fp16")];
            tensor<int32, [2]> var_1910 = const()[name = tensor<string, []>("op_1910"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1912 = const()[name = tensor<string, []>("op_1912"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_129_pad_type_0 = const()[name = tensor<string, []>("input_129_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_129_pad_0 = const()[name = tensor<string, []>("input_129_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_4_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_4_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(194355520)))];
            tensor<fp16, [1, 16, 1, 1]> input_129_cast_fp16 = conv(dilations = var_1912, groups = var_1759, pad = input_129_pad_0, pad_type = input_129_pad_type_0, strides = var_1910, weight = layers_4_self_attn_o_proj_loraA_weight_to_fp16, x = input_127_cast_fp16)[name = tensor<string, []>("input_129_cast_fp16")];
            tensor<int32, [2]> var_1916 = const()[name = tensor<string, []>("op_1916"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1918 = const()[name = tensor<string, []>("op_1918"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_173_pad_type_0 = const()[name = tensor<string, []>("lora_out_173_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_173_pad_0 = const()[name = tensor<string, []>("lora_out_173_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_175_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_175_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(194396544)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_175_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_1918, groups = var_1759, pad = lora_out_173_pad_0, pad_type = lora_out_173_pad_type_0, strides = var_1916, weight = lora_out_175_weight_0_to_fp16, x = input_129_cast_fp16)[name = tensor<string, []>("lora_out_175_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_63_cast_fp16 = add(x = pretrained_out_87_cast_fp16, y = lora_out_175_cast_fp16)[name = tensor<string, []>("obj_63_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_27_cast_fp16 = add(x = inputs_25_cast_fp16, y = obj_63_cast_fp16)[name = tensor<string, []>("inputs_27_cast_fp16")];
            tensor<int32, [1]> var_1931 = const()[name = tensor<string, []>("op_1931"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_27_cast_fp16 = reduce_mean(axes = var_1931, keep_dims = var_1760, x = inputs_27_cast_fp16)[name = tensor<string, []>("channels_mean_27_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_27_cast_fp16 = sub(x = inputs_27_cast_fp16, y = channels_mean_27_cast_fp16)[name = tensor<string, []>("zero_mean_27_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_27_cast_fp16 = mul(x = zero_mean_27_cast_fp16, y = zero_mean_27_cast_fp16)[name = tensor<string, []>("zero_mean_sq_27_cast_fp16")];
            tensor<int32, [1]> var_1935 = const()[name = tensor<string, []>("op_1935"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_1936_cast_fp16 = reduce_mean(axes = var_1935, keep_dims = var_1760, x = zero_mean_sq_27_cast_fp16)[name = tensor<string, []>("op_1936_cast_fp16")];
            tensor<fp16, []> var_1937_to_fp16 = const()[name = tensor<string, []>("op_1937_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_1938_cast_fp16 = add(x = var_1936_cast_fp16, y = var_1937_to_fp16)[name = tensor<string, []>("op_1938_cast_fp16")];
            tensor<fp32, []> denom_27_epsilon_0 = const()[name = tensor<string, []>("denom_27_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_27_cast_fp16 = rsqrt(epsilon = denom_27_epsilon_0, x = var_1938_cast_fp16)[name = tensor<string, []>("denom_27_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_27_cast_fp16 = mul(x = zero_mean_27_cast_fp16, y = denom_27_cast_fp16)[name = tensor<string, []>("out_27_cast_fp16")];
            tensor<fp16, [1280]> obj_65_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_65_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(194437568)))];
            tensor<fp16, [1280]> obj_65_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_65_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(194440192)))];
            tensor<fp16, []> obj_65_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_65_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_65_cast_fp16 = batch_norm(beta = obj_65_beta_0_to_fp16, epsilon = obj_65_epsilon_0_to_fp16, gamma = obj_65_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_27_cast_fp16)[name = tensor<string, []>("obj_65_cast_fp16")];
            tensor<int32, [2]> var_1956 = const()[name = tensor<string, []>("op_1956"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1958 = const()[name = tensor<string, []>("op_1958"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_89_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_89_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_89_pad_0 = const()[name = tensor<string, []>("pretrained_out_89_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_4_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(194442816))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(195262080))), name = tensor<string, []>("layers_4_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_4_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_4_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(195262208)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_89_cast_fp16 = conv(bias = layers_4_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_1958, groups = var_1759, pad = pretrained_out_89_pad_0, pad_type = pretrained_out_89_pad_type_0, strides = var_1956, weight = layers_4_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_65_cast_fp16)[name = tensor<string, []>("pretrained_out_89_cast_fp16")];
            tensor<int32, [2]> var_1962 = const()[name = tensor<string, []>("op_1962"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1964 = const()[name = tensor<string, []>("op_1964"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_131_pad_type_0 = const()[name = tensor<string, []>("input_131_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_131_pad_0 = const()[name = tensor<string, []>("input_131_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_4_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_4_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(195264832)))];
            tensor<fp16, [1, 16, 1, 1]> input_131_cast_fp16 = conv(dilations = var_1964, groups = var_1759, pad = input_131_pad_0, pad_type = input_131_pad_type_0, strides = var_1962, weight = layers_4_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_65_cast_fp16)[name = tensor<string, []>("input_131_cast_fp16")];
            tensor<int32, [2]> var_1968 = const()[name = tensor<string, []>("op_1968"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1970 = const()[name = tensor<string, []>("op_1970"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_177_pad_type_0 = const()[name = tensor<string, []>("lora_out_177_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_177_pad_0 = const()[name = tensor<string, []>("lora_out_177_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_179_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_179_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(195305856)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_179_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_1970, groups = var_1759, pad = lora_out_177_pad_0, pad_type = lora_out_177_pad_type_0, strides = var_1968, weight = lora_out_179_weight_0_to_fp16, x = input_131_cast_fp16)[name = tensor<string, []>("lora_out_179_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_19_cast_fp16 = add(x = pretrained_out_89_cast_fp16, y = lora_out_179_cast_fp16)[name = tensor<string, []>("query_19_cast_fp16")];
            tensor<int32, [2]> var_1980 = const()[name = tensor<string, []>("op_1980"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1982 = const()[name = tensor<string, []>("op_1982"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_91_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_91_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_91_pad_0 = const()[name = tensor<string, []>("pretrained_out_91_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_4_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(195346880))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(196166144))), name = tensor<string, []>("layers_4_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_91_cast_fp16 = conv(dilations = var_1982, groups = var_1759, pad = pretrained_out_91_pad_0, pad_type = pretrained_out_91_pad_type_0, strides = var_1980, weight = layers_4_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_91_cast_fp16")];
            tensor<int32, [2]> var_1986 = const()[name = tensor<string, []>("op_1986"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1988 = const()[name = tensor<string, []>("op_1988"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_133_pad_type_0 = const()[name = tensor<string, []>("input_133_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_133_pad_0 = const()[name = tensor<string, []>("input_133_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_4_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_4_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(196166272)))];
            tensor<fp16, [1, 16, 1, 1500]> input_133_cast_fp16 = conv(dilations = var_1988, groups = var_1759, pad = input_133_pad_0, pad_type = input_133_pad_type_0, strides = var_1986, weight = layers_4_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_133_cast_fp16")];
            tensor<int32, [2]> var_1992 = const()[name = tensor<string, []>("op_1992"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_1994 = const()[name = tensor<string, []>("op_1994"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_181_pad_type_0 = const()[name = tensor<string, []>("lora_out_181_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_181_pad_0 = const()[name = tensor<string, []>("lora_out_181_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_183_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_183_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(196207296)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_183_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_1994, groups = var_1759, pad = lora_out_181_pad_0, pad_type = lora_out_181_pad_type_0, strides = var_1992, weight = lora_out_183_weight_0_to_fp16, x = input_133_cast_fp16)[name = tensor<string, []>("lora_out_183_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_19_cast_fp16 = add(x = pretrained_out_91_cast_fp16, y = lora_out_183_cast_fp16)[name = tensor<string, []>("key_19_cast_fp16")];
            tensor<int32, [2]> var_2005 = const()[name = tensor<string, []>("op_2005"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2007 = const()[name = tensor<string, []>("op_2007"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_93_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_93_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_93_pad_0 = const()[name = tensor<string, []>("pretrained_out_93_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_4_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(196248320))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(197067584))), name = tensor<string, []>("layers_4_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_4_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_4_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(197067712)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_93_cast_fp16 = conv(bias = layers_4_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_2007, groups = var_1759, pad = pretrained_out_93_pad_0, pad_type = pretrained_out_93_pad_type_0, strides = var_2005, weight = layers_4_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_93_cast_fp16")];
            tensor<int32, [2]> var_2011 = const()[name = tensor<string, []>("op_2011"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2013 = const()[name = tensor<string, []>("op_2013"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_135_pad_type_0 = const()[name = tensor<string, []>("input_135_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_135_pad_0 = const()[name = tensor<string, []>("input_135_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_4_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_4_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(197070336)))];
            tensor<fp16, [1, 16, 1, 1500]> input_135_cast_fp16 = conv(dilations = var_2013, groups = var_1759, pad = input_135_pad_0, pad_type = input_135_pad_type_0, strides = var_2011, weight = layers_4_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_135_cast_fp16")];
            tensor<int32, [2]> var_2017 = const()[name = tensor<string, []>("op_2017"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2019 = const()[name = tensor<string, []>("op_2019"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_185_pad_type_0 = const()[name = tensor<string, []>("lora_out_185_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_185_pad_0 = const()[name = tensor<string, []>("lora_out_185_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_187_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_187_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(197111360)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_187_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_2019, groups = var_1759, pad = lora_out_185_pad_0, pad_type = lora_out_185_pad_type_0, strides = var_2017, weight = lora_out_187_weight_0_to_fp16, x = input_135_cast_fp16)[name = tensor<string, []>("lora_out_187_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_19_cast_fp16 = add(x = pretrained_out_93_cast_fp16, y = lora_out_187_cast_fp16)[name = tensor<string, []>("value_19_cast_fp16")];
            tensor<int32, [4]> var_2026 = const()[name = tensor<string, []>("op_2026"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_2027_cast_fp16 = reshape(shape = var_2026, x = query_19_cast_fp16)[name = tensor<string, []>("op_2027_cast_fp16")];
            tensor<fp16, []> var_2028_to_fp16 = const()[name = tensor<string, []>("op_2028_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_2029_cast_fp16 = mul(x = var_2027_cast_fp16, y = var_2028_to_fp16)[name = tensor<string, []>("op_2029_cast_fp16")];
            tensor<int32, [4]> var_2030 = const()[name = tensor<string, []>("op_2030"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_2031_cast_fp16 = reshape(shape = var_2030, x = key_19_cast_fp16)[name = tensor<string, []>("op_2031_cast_fp16")];
            tensor<bool, []> mh_w_29_transpose_x_0 = const()[name = tensor<string, []>("mh_w_29_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_29_transpose_y_0 = const()[name = tensor<string, []>("mh_w_29_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_29_cast_fp16 = matmul(transpose_x = mh_w_29_transpose_x_0, transpose_y = mh_w_29_transpose_y_0, x = var_2029_cast_fp16, y = var_2031_cast_fp16)[name = tensor<string, []>("mh_w_29_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_69_cast_fp16 = softmax(axis = var_1752, x = mh_w_29_cast_fp16)[name = tensor<string, []>("obj_69_cast_fp16")];
            tensor<int32, [4]> var_2035 = const()[name = tensor<string, []>("op_2035"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_2036_cast_fp16 = reshape(shape = var_2035, x = value_19_cast_fp16)[name = tensor<string, []>("op_2036_cast_fp16")];
            tensor<bool, []> attn_19_transpose_x_0 = const()[name = tensor<string, []>("attn_19_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_19_transpose_y_0 = const()[name = tensor<string, []>("attn_19_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_19_cast_fp16 = matmul(transpose_x = attn_19_transpose_x_0, transpose_y = attn_19_transpose_y_0, x = var_2036_cast_fp16, y = obj_69_cast_fp16)[name = tensor<string, []>("attn_19_cast_fp16")];
            tensor<int32, [4]> var_2039 = const()[name = tensor<string, []>("op_2039"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_137_cast_fp16 = reshape(shape = var_2039, x = attn_19_cast_fp16)[name = tensor<string, []>("input_137_cast_fp16")];
            tensor<int32, [2]> var_2046 = const()[name = tensor<string, []>("op_2046"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2048 = const()[name = tensor<string, []>("op_2048"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_95_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_95_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_95_pad_0 = const()[name = tensor<string, []>("pretrained_out_95_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_4_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(197152384))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(197971648))), name = tensor<string, []>("layers_4_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_4_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_4_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(197971776)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_95_cast_fp16 = conv(bias = layers_4_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_2048, groups = var_1759, pad = pretrained_out_95_pad_0, pad_type = pretrained_out_95_pad_type_0, strides = var_2046, weight = layers_4_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_137_cast_fp16)[name = tensor<string, []>("pretrained_out_95_cast_fp16")];
            tensor<int32, [2]> var_2052 = const()[name = tensor<string, []>("op_2052"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2054 = const()[name = tensor<string, []>("op_2054"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_139_pad_type_0 = const()[name = tensor<string, []>("input_139_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_139_pad_0 = const()[name = tensor<string, []>("input_139_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_4_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_4_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(197974400)))];
            tensor<fp16, [1, 16, 1, 1]> input_139_cast_fp16 = conv(dilations = var_2054, groups = var_1759, pad = input_139_pad_0, pad_type = input_139_pad_type_0, strides = var_2052, weight = layers_4_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_137_cast_fp16)[name = tensor<string, []>("input_139_cast_fp16")];
            tensor<int32, [2]> var_2058 = const()[name = tensor<string, []>("op_2058"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2060 = const()[name = tensor<string, []>("op_2060"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_189_pad_type_0 = const()[name = tensor<string, []>("lora_out_189_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_189_pad_0 = const()[name = tensor<string, []>("lora_out_189_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_191_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_191_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(198015424)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_191_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_2060, groups = var_1759, pad = lora_out_189_pad_0, pad_type = lora_out_189_pad_type_0, strides = var_2058, weight = lora_out_191_weight_0_to_fp16, x = input_139_cast_fp16)[name = tensor<string, []>("lora_out_191_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_67_cast_fp16 = add(x = pretrained_out_95_cast_fp16, y = lora_out_191_cast_fp16)[name = tensor<string, []>("obj_67_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_29_cast_fp16 = add(x = inputs_27_cast_fp16, y = obj_67_cast_fp16)[name = tensor<string, []>("inputs_29_cast_fp16")];
            tensor<int32, [1]> var_2069 = const()[name = tensor<string, []>("op_2069"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_29_cast_fp16 = reduce_mean(axes = var_2069, keep_dims = var_1760, x = inputs_29_cast_fp16)[name = tensor<string, []>("channels_mean_29_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_29_cast_fp16 = sub(x = inputs_29_cast_fp16, y = channels_mean_29_cast_fp16)[name = tensor<string, []>("zero_mean_29_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_29_cast_fp16 = mul(x = zero_mean_29_cast_fp16, y = zero_mean_29_cast_fp16)[name = tensor<string, []>("zero_mean_sq_29_cast_fp16")];
            tensor<int32, [1]> var_2073 = const()[name = tensor<string, []>("op_2073"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_2074_cast_fp16 = reduce_mean(axes = var_2073, keep_dims = var_1760, x = zero_mean_sq_29_cast_fp16)[name = tensor<string, []>("op_2074_cast_fp16")];
            tensor<fp16, []> var_2075_to_fp16 = const()[name = tensor<string, []>("op_2075_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_2076_cast_fp16 = add(x = var_2074_cast_fp16, y = var_2075_to_fp16)[name = tensor<string, []>("op_2076_cast_fp16")];
            tensor<fp32, []> denom_29_epsilon_0 = const()[name = tensor<string, []>("denom_29_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_29_cast_fp16 = rsqrt(epsilon = denom_29_epsilon_0, x = var_2076_cast_fp16)[name = tensor<string, []>("denom_29_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_29_cast_fp16 = mul(x = zero_mean_29_cast_fp16, y = denom_29_cast_fp16)[name = tensor<string, []>("out_29_cast_fp16")];
            tensor<fp16, [1280]> input_141_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_141_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(198056448)))];
            tensor<fp16, [1280]> input_141_beta_0_to_fp16 = const()[name = tensor<string, []>("input_141_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(198059072)))];
            tensor<fp16, []> input_141_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_141_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_141_cast_fp16 = batch_norm(beta = input_141_beta_0_to_fp16, epsilon = input_141_epsilon_0_to_fp16, gamma = input_141_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_29_cast_fp16)[name = tensor<string, []>("input_141_cast_fp16")];
            tensor<int32, [2]> var_2090 = const()[name = tensor<string, []>("op_2090"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2092 = const()[name = tensor<string, []>("op_2092"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_97_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_97_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_97_pad_0 = const()[name = tensor<string, []>("pretrained_out_97_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_4_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(198061696))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(201338560))), name = tensor<string, []>("layers_4_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_4_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_4_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(201338688)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_97_cast_fp16 = conv(bias = layers_4_fc1_pretrained_bias_to_fp16, dilations = var_2092, groups = var_1759, pad = pretrained_out_97_pad_0, pad_type = pretrained_out_97_pad_type_0, strides = var_2090, weight = layers_4_fc1_pretrained_weight_to_fp16_palettized, x = input_141_cast_fp16)[name = tensor<string, []>("pretrained_out_97_cast_fp16")];
            tensor<int32, [2]> var_2096 = const()[name = tensor<string, []>("op_2096"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2098 = const()[name = tensor<string, []>("op_2098"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_143_pad_type_0 = const()[name = tensor<string, []>("input_143_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_143_pad_0 = const()[name = tensor<string, []>("input_143_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_4_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_4_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(201348992)))];
            tensor<fp16, [1, 16, 1, 1]> input_143_cast_fp16 = conv(dilations = var_2098, groups = var_1759, pad = input_143_pad_0, pad_type = input_143_pad_type_0, strides = var_2096, weight = layers_4_fc1_loraA_weight_to_fp16, x = input_141_cast_fp16)[name = tensor<string, []>("input_143_cast_fp16")];
            tensor<int32, [2]> var_2102 = const()[name = tensor<string, []>("op_2102"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2104 = const()[name = tensor<string, []>("op_2104"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_193_pad_type_0 = const()[name = tensor<string, []>("lora_out_193_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_193_pad_0 = const()[name = tensor<string, []>("lora_out_193_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_195_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_195_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(201390016)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_195_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_2104, groups = var_1759, pad = lora_out_193_pad_0, pad_type = lora_out_193_pad_type_0, strides = var_2102, weight = lora_out_195_weight_0_to_fp16, x = input_143_cast_fp16)[name = tensor<string, []>("lora_out_195_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_145_cast_fp16 = add(x = pretrained_out_97_cast_fp16, y = lora_out_195_cast_fp16)[name = tensor<string, []>("input_145_cast_fp16")];
            tensor<string, []> input_147_mode_0 = const()[name = tensor<string, []>("input_147_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_147_cast_fp16 = gelu(mode = input_147_mode_0, x = input_145_cast_fp16)[name = tensor<string, []>("input_147_cast_fp16")];
            tensor<int32, [2]> var_2116 = const()[name = tensor<string, []>("op_2116"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2118 = const()[name = tensor<string, []>("op_2118"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_99_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_99_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_99_pad_0 = const()[name = tensor<string, []>("pretrained_out_99_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_4_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(201553920))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(204830784))), name = tensor<string, []>("layers_4_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_4_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_4_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(204830912)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_99_cast_fp16 = conv(bias = layers_4_fc2_pretrained_bias_to_fp16, dilations = var_2118, groups = var_1759, pad = pretrained_out_99_pad_0, pad_type = pretrained_out_99_pad_type_0, strides = var_2116, weight = layers_4_fc2_pretrained_weight_to_fp16_palettized, x = input_147_cast_fp16)[name = tensor<string, []>("pretrained_out_99_cast_fp16")];
            tensor<int32, [2]> var_2122 = const()[name = tensor<string, []>("op_2122"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2124 = const()[name = tensor<string, []>("op_2124"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_149_pad_type_0 = const()[name = tensor<string, []>("input_149_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_149_pad_0 = const()[name = tensor<string, []>("input_149_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_4_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_4_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(204833536)))];
            tensor<fp16, [1, 16, 1, 1]> input_149_cast_fp16 = conv(dilations = var_2124, groups = var_1759, pad = input_149_pad_0, pad_type = input_149_pad_type_0, strides = var_2122, weight = layers_4_fc2_loraA_weight_to_fp16, x = input_147_cast_fp16)[name = tensor<string, []>("input_149_cast_fp16")];
            tensor<int32, [2]> var_2128 = const()[name = tensor<string, []>("op_2128"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2130 = const()[name = tensor<string, []>("op_2130"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_197_pad_type_0 = const()[name = tensor<string, []>("lora_out_197_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_197_pad_0 = const()[name = tensor<string, []>("lora_out_197_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_199_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_199_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(204997440)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_199_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_2130, groups = var_1759, pad = lora_out_197_pad_0, pad_type = lora_out_197_pad_type_0, strides = var_2128, weight = lora_out_199_weight_0_to_fp16, x = input_149_cast_fp16)[name = tensor<string, []>("lora_out_199_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_11_cast_fp16 = add(x = pretrained_out_99_cast_fp16, y = lora_out_199_cast_fp16)[name = tensor<string, []>("hidden_states_11_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_31_cast_fp16 = add(x = inputs_29_cast_fp16, y = hidden_states_11_cast_fp16)[name = tensor<string, []>("inputs_31_cast_fp16")];
            tensor<int32, []> var_2146 = const()[name = tensor<string, []>("op_2146"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_2153 = const()[name = tensor<string, []>("op_2153"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_2154 = const()[name = tensor<string, []>("op_2154"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_2166 = const()[name = tensor<string, []>("op_2166"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_31_cast_fp16 = reduce_mean(axes = var_2166, keep_dims = var_2154, x = inputs_31_cast_fp16)[name = tensor<string, []>("channels_mean_31_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_31_cast_fp16 = sub(x = inputs_31_cast_fp16, y = channels_mean_31_cast_fp16)[name = tensor<string, []>("zero_mean_31_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_31_cast_fp16 = mul(x = zero_mean_31_cast_fp16, y = zero_mean_31_cast_fp16)[name = tensor<string, []>("zero_mean_sq_31_cast_fp16")];
            tensor<int32, [1]> var_2170 = const()[name = tensor<string, []>("op_2170"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_2171_cast_fp16 = reduce_mean(axes = var_2170, keep_dims = var_2154, x = zero_mean_sq_31_cast_fp16)[name = tensor<string, []>("op_2171_cast_fp16")];
            tensor<fp16, []> var_2172_to_fp16 = const()[name = tensor<string, []>("op_2172_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_2173_cast_fp16 = add(x = var_2171_cast_fp16, y = var_2172_to_fp16)[name = tensor<string, []>("op_2173_cast_fp16")];
            tensor<fp32, []> denom_31_epsilon_0 = const()[name = tensor<string, []>("denom_31_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_31_cast_fp16 = rsqrt(epsilon = denom_31_epsilon_0, x = var_2173_cast_fp16)[name = tensor<string, []>("denom_31_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_31_cast_fp16 = mul(x = zero_mean_31_cast_fp16, y = denom_31_cast_fp16)[name = tensor<string, []>("out_31_cast_fp16")];
            tensor<fp16, [1280]> obj_71_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_71_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(205038464)))];
            tensor<fp16, [1280]> obj_71_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_71_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(205041088)))];
            tensor<fp16, []> obj_71_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_71_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_71_cast_fp16 = batch_norm(beta = obj_71_beta_0_to_fp16, epsilon = obj_71_epsilon_0_to_fp16, gamma = obj_71_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_31_cast_fp16)[name = tensor<string, []>("obj_71_cast_fp16")];
            tensor<int32, [2]> var_2191 = const()[name = tensor<string, []>("op_2191"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2193 = const()[name = tensor<string, []>("op_2193"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_101_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_101_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_101_pad_0 = const()[name = tensor<string, []>("pretrained_out_101_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_5_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(205043712))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(205862976))), name = tensor<string, []>("layers_5_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_5_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_5_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(205863104)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_101_cast_fp16 = conv(bias = layers_5_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_2193, groups = var_2153, pad = pretrained_out_101_pad_0, pad_type = pretrained_out_101_pad_type_0, strides = var_2191, weight = layers_5_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_71_cast_fp16)[name = tensor<string, []>("pretrained_out_101_cast_fp16")];
            tensor<int32, [2]> var_2197 = const()[name = tensor<string, []>("op_2197"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2199 = const()[name = tensor<string, []>("op_2199"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_151_pad_type_0 = const()[name = tensor<string, []>("input_151_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_151_pad_0 = const()[name = tensor<string, []>("input_151_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_5_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_5_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(205865728)))];
            tensor<fp16, [1, 16, 1, 1]> input_151_cast_fp16 = conv(dilations = var_2199, groups = var_2153, pad = input_151_pad_0, pad_type = input_151_pad_type_0, strides = var_2197, weight = layers_5_self_attn_q_proj_loraA_weight_to_fp16, x = obj_71_cast_fp16)[name = tensor<string, []>("input_151_cast_fp16")];
            tensor<int32, [2]> var_2203 = const()[name = tensor<string, []>("op_2203"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2205 = const()[name = tensor<string, []>("op_2205"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_201_pad_type_0 = const()[name = tensor<string, []>("lora_out_201_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_201_pad_0 = const()[name = tensor<string, []>("lora_out_201_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_203_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_203_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(205906752)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_203_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_2205, groups = var_2153, pad = lora_out_201_pad_0, pad_type = lora_out_201_pad_type_0, strides = var_2203, weight = lora_out_203_weight_0_to_fp16, x = input_151_cast_fp16)[name = tensor<string, []>("lora_out_203_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_21_cast_fp16 = add(x = pretrained_out_101_cast_fp16, y = lora_out_203_cast_fp16)[name = tensor<string, []>("query_21_cast_fp16")];
            tensor<int32, [2]> var_2215 = const()[name = tensor<string, []>("op_2215"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2217 = const()[name = tensor<string, []>("op_2217"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_103_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_103_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_103_pad_0 = const()[name = tensor<string, []>("pretrained_out_103_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_5_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(205947776))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(206767040))), name = tensor<string, []>("layers_5_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_103_cast_fp16 = conv(dilations = var_2217, groups = var_2153, pad = pretrained_out_103_pad_0, pad_type = pretrained_out_103_pad_type_0, strides = var_2215, weight = layers_5_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_71_cast_fp16)[name = tensor<string, []>("pretrained_out_103_cast_fp16")];
            tensor<int32, [2]> var_2221 = const()[name = tensor<string, []>("op_2221"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2223 = const()[name = tensor<string, []>("op_2223"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_153_pad_type_0 = const()[name = tensor<string, []>("input_153_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_153_pad_0 = const()[name = tensor<string, []>("input_153_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_5_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_5_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(206767168)))];
            tensor<fp16, [1, 16, 1, 1]> input_153_cast_fp16 = conv(dilations = var_2223, groups = var_2153, pad = input_153_pad_0, pad_type = input_153_pad_type_0, strides = var_2221, weight = layers_5_self_attn_k_proj_loraA_weight_to_fp16, x = obj_71_cast_fp16)[name = tensor<string, []>("input_153_cast_fp16")];
            tensor<int32, [2]> var_2227 = const()[name = tensor<string, []>("op_2227"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2229 = const()[name = tensor<string, []>("op_2229"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_205_pad_type_0 = const()[name = tensor<string, []>("lora_out_205_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_205_pad_0 = const()[name = tensor<string, []>("lora_out_205_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_207_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_207_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(206808192)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_207_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_2229, groups = var_2153, pad = lora_out_205_pad_0, pad_type = lora_out_205_pad_type_0, strides = var_2227, weight = lora_out_207_weight_0_to_fp16, x = input_153_cast_fp16)[name = tensor<string, []>("lora_out_207_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_11_cast_fp16 = add(x = pretrained_out_103_cast_fp16, y = lora_out_207_cast_fp16)[name = tensor<string, []>("current_key_11_cast_fp16")];
            tensor<int32, [2]> var_2240 = const()[name = tensor<string, []>("op_2240"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2242 = const()[name = tensor<string, []>("op_2242"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_105_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_105_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_105_pad_0 = const()[name = tensor<string, []>("pretrained_out_105_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_5_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(206849216))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(207668480))), name = tensor<string, []>("layers_5_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_5_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_5_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(207668608)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_105_cast_fp16 = conv(bias = layers_5_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_2242, groups = var_2153, pad = pretrained_out_105_pad_0, pad_type = pretrained_out_105_pad_type_0, strides = var_2240, weight = layers_5_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_71_cast_fp16)[name = tensor<string, []>("pretrained_out_105_cast_fp16")];
            tensor<int32, [2]> var_2246 = const()[name = tensor<string, []>("op_2246"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2248 = const()[name = tensor<string, []>("op_2248"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_155_pad_type_0 = const()[name = tensor<string, []>("input_155_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_155_pad_0 = const()[name = tensor<string, []>("input_155_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_5_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_5_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(207671232)))];
            tensor<fp16, [1, 16, 1, 1]> input_155_cast_fp16 = conv(dilations = var_2248, groups = var_2153, pad = input_155_pad_0, pad_type = input_155_pad_type_0, strides = var_2246, weight = layers_5_self_attn_v_proj_loraA_weight_to_fp16, x = obj_71_cast_fp16)[name = tensor<string, []>("input_155_cast_fp16")];
            tensor<int32, [2]> var_2252 = const()[name = tensor<string, []>("op_2252"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2254 = const()[name = tensor<string, []>("op_2254"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_209_pad_type_0 = const()[name = tensor<string, []>("lora_out_209_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_209_pad_0 = const()[name = tensor<string, []>("lora_out_209_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_211_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_211_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(207712256)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_211_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_2254, groups = var_2153, pad = lora_out_209_pad_0, pad_type = lora_out_209_pad_type_0, strides = var_2252, weight = lora_out_211_weight_0_to_fp16, x = input_155_cast_fp16)[name = tensor<string, []>("lora_out_211_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_11_cast_fp16 = add(x = pretrained_out_105_cast_fp16, y = lora_out_211_cast_fp16)[name = tensor<string, []>("current_value_11_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_2264_cast_fp16 = mul(x = current_key_11_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_2264_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_2266_cast_fp16 = mul(x = var_103_cast_fp16_5, y = var_295_cast_fp16)[name = tensor<string, []>("op_2266_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_21_cast_fp16 = add(x = var_2264_cast_fp16, y = var_2266_cast_fp16)[name = tensor<string, []>("key_21_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_2268_cast_fp16 = mul(x = current_value_11_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_2268_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_2270_cast_fp16 = mul(x = var_138_cast_fp16_5, y = var_295_cast_fp16)[name = tensor<string, []>("op_2270_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_21_cast_fp16 = add(x = var_2268_cast_fp16, y = var_2270_cast_fp16)[name = tensor<string, []>("value_21_cast_fp16")];
            tensor<int32, [4]> var_2273 = const()[name = tensor<string, []>("op_2273"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_2274_cast_fp16 = reshape(shape = var_2273, x = query_21_cast_fp16)[name = tensor<string, []>("op_2274_cast_fp16")];
            tensor<fp16, []> var_2275_to_fp16 = const()[name = tensor<string, []>("op_2275_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_2276_cast_fp16 = mul(x = var_2274_cast_fp16, y = var_2275_to_fp16)[name = tensor<string, []>("op_2276_cast_fp16")];
            tensor<int32, [4]> var_2277 = const()[name = tensor<string, []>("op_2277"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_2278_cast_fp16 = reshape(shape = var_2277, x = key_21_cast_fp16)[name = tensor<string, []>("op_2278_cast_fp16")];
            tensor<bool, []> mh_w_31_transpose_x_0 = const()[name = tensor<string, []>("mh_w_31_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_31_transpose_y_0 = const()[name = tensor<string, []>("mh_w_31_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_31_cast_fp16 = matmul(transpose_x = mh_w_31_transpose_x_0, transpose_y = mh_w_31_transpose_y_0, x = var_2276_cast_fp16, y = var_2278_cast_fp16)[name = tensor<string, []>("mh_w_31_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_33_cast_fp16 = add(x = mh_w_31_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_33_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_2286_cast_fp16 = softmax(axis = var_2146, x = mh_w_33_cast_fp16)[name = tensor<string, []>("op_2286_cast_fp16")];
            tensor<int32, [4]> var_2287 = const()[name = tensor<string, []>("op_2287"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_2288_cast_fp16 = reshape(shape = var_2287, x = value_21_cast_fp16)[name = tensor<string, []>("op_2288_cast_fp16")];
            tensor<bool, []> attn_21_transpose_x_0 = const()[name = tensor<string, []>("attn_21_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_21_transpose_y_0 = const()[name = tensor<string, []>("attn_21_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_21_cast_fp16 = matmul(transpose_x = attn_21_transpose_x_0, transpose_y = attn_21_transpose_y_0, x = var_2288_cast_fp16, y = var_2286_cast_fp16)[name = tensor<string, []>("attn_21_cast_fp16")];
            tensor<int32, [4]> var_2291 = const()[name = tensor<string, []>("op_2291"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_157_cast_fp16 = reshape(shape = var_2291, x = attn_21_cast_fp16)[name = tensor<string, []>("input_157_cast_fp16")];
            tensor<int32, [2]> var_2298 = const()[name = tensor<string, []>("op_2298"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2300 = const()[name = tensor<string, []>("op_2300"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_107_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_107_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_107_pad_0 = const()[name = tensor<string, []>("pretrained_out_107_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_5_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(207753280))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(208572544))), name = tensor<string, []>("layers_5_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_5_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_5_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(208572672)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_107_cast_fp16 = conv(bias = layers_5_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_2300, groups = var_2153, pad = pretrained_out_107_pad_0, pad_type = pretrained_out_107_pad_type_0, strides = var_2298, weight = layers_5_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_157_cast_fp16)[name = tensor<string, []>("pretrained_out_107_cast_fp16")];
            tensor<int32, [2]> var_2304 = const()[name = tensor<string, []>("op_2304"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2306 = const()[name = tensor<string, []>("op_2306"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_159_pad_type_0 = const()[name = tensor<string, []>("input_159_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_159_pad_0 = const()[name = tensor<string, []>("input_159_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_5_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_5_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(208575296)))];
            tensor<fp16, [1, 16, 1, 1]> input_159_cast_fp16 = conv(dilations = var_2306, groups = var_2153, pad = input_159_pad_0, pad_type = input_159_pad_type_0, strides = var_2304, weight = layers_5_self_attn_o_proj_loraA_weight_to_fp16, x = input_157_cast_fp16)[name = tensor<string, []>("input_159_cast_fp16")];
            tensor<int32, [2]> var_2310 = const()[name = tensor<string, []>("op_2310"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2312 = const()[name = tensor<string, []>("op_2312"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_213_pad_type_0 = const()[name = tensor<string, []>("lora_out_213_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_213_pad_0 = const()[name = tensor<string, []>("lora_out_213_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_215_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_215_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(208616320)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_215_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_2312, groups = var_2153, pad = lora_out_213_pad_0, pad_type = lora_out_213_pad_type_0, strides = var_2310, weight = lora_out_215_weight_0_to_fp16, x = input_159_cast_fp16)[name = tensor<string, []>("lora_out_215_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_77_cast_fp16 = add(x = pretrained_out_107_cast_fp16, y = lora_out_215_cast_fp16)[name = tensor<string, []>("obj_77_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_33_cast_fp16 = add(x = inputs_31_cast_fp16, y = obj_77_cast_fp16)[name = tensor<string, []>("inputs_33_cast_fp16")];
            tensor<int32, [1]> var_2325 = const()[name = tensor<string, []>("op_2325"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_33_cast_fp16 = reduce_mean(axes = var_2325, keep_dims = var_2154, x = inputs_33_cast_fp16)[name = tensor<string, []>("channels_mean_33_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_33_cast_fp16 = sub(x = inputs_33_cast_fp16, y = channels_mean_33_cast_fp16)[name = tensor<string, []>("zero_mean_33_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_33_cast_fp16 = mul(x = zero_mean_33_cast_fp16, y = zero_mean_33_cast_fp16)[name = tensor<string, []>("zero_mean_sq_33_cast_fp16")];
            tensor<int32, [1]> var_2329 = const()[name = tensor<string, []>("op_2329"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_2330_cast_fp16 = reduce_mean(axes = var_2329, keep_dims = var_2154, x = zero_mean_sq_33_cast_fp16)[name = tensor<string, []>("op_2330_cast_fp16")];
            tensor<fp16, []> var_2331_to_fp16 = const()[name = tensor<string, []>("op_2331_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_2332_cast_fp16 = add(x = var_2330_cast_fp16, y = var_2331_to_fp16)[name = tensor<string, []>("op_2332_cast_fp16")];
            tensor<fp32, []> denom_33_epsilon_0 = const()[name = tensor<string, []>("denom_33_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_33_cast_fp16 = rsqrt(epsilon = denom_33_epsilon_0, x = var_2332_cast_fp16)[name = tensor<string, []>("denom_33_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_33_cast_fp16 = mul(x = zero_mean_33_cast_fp16, y = denom_33_cast_fp16)[name = tensor<string, []>("out_33_cast_fp16")];
            tensor<fp16, [1280]> obj_79_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_79_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(208657344)))];
            tensor<fp16, [1280]> obj_79_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_79_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(208659968)))];
            tensor<fp16, []> obj_79_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_79_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_79_cast_fp16 = batch_norm(beta = obj_79_beta_0_to_fp16, epsilon = obj_79_epsilon_0_to_fp16, gamma = obj_79_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_33_cast_fp16)[name = tensor<string, []>("obj_79_cast_fp16")];
            tensor<int32, [2]> var_2350 = const()[name = tensor<string, []>("op_2350"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2352 = const()[name = tensor<string, []>("op_2352"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_109_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_109_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_109_pad_0 = const()[name = tensor<string, []>("pretrained_out_109_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_5_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(208662592))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(209481856))), name = tensor<string, []>("layers_5_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_5_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_5_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(209481984)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_109_cast_fp16 = conv(bias = layers_5_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_2352, groups = var_2153, pad = pretrained_out_109_pad_0, pad_type = pretrained_out_109_pad_type_0, strides = var_2350, weight = layers_5_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_79_cast_fp16)[name = tensor<string, []>("pretrained_out_109_cast_fp16")];
            tensor<int32, [2]> var_2356 = const()[name = tensor<string, []>("op_2356"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2358 = const()[name = tensor<string, []>("op_2358"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_161_pad_type_0 = const()[name = tensor<string, []>("input_161_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_161_pad_0 = const()[name = tensor<string, []>("input_161_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_5_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_5_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(209484608)))];
            tensor<fp16, [1, 16, 1, 1]> input_161_cast_fp16 = conv(dilations = var_2358, groups = var_2153, pad = input_161_pad_0, pad_type = input_161_pad_type_0, strides = var_2356, weight = layers_5_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_79_cast_fp16)[name = tensor<string, []>("input_161_cast_fp16")];
            tensor<int32, [2]> var_2362 = const()[name = tensor<string, []>("op_2362"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2364 = const()[name = tensor<string, []>("op_2364"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_217_pad_type_0 = const()[name = tensor<string, []>("lora_out_217_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_217_pad_0 = const()[name = tensor<string, []>("lora_out_217_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_219_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_219_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(209525632)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_219_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_2364, groups = var_2153, pad = lora_out_217_pad_0, pad_type = lora_out_217_pad_type_0, strides = var_2362, weight = lora_out_219_weight_0_to_fp16, x = input_161_cast_fp16)[name = tensor<string, []>("lora_out_219_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_23_cast_fp16 = add(x = pretrained_out_109_cast_fp16, y = lora_out_219_cast_fp16)[name = tensor<string, []>("query_23_cast_fp16")];
            tensor<int32, [2]> var_2374 = const()[name = tensor<string, []>("op_2374"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2376 = const()[name = tensor<string, []>("op_2376"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_111_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_111_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_111_pad_0 = const()[name = tensor<string, []>("pretrained_out_111_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_5_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(209566656))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(210385920))), name = tensor<string, []>("layers_5_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_111_cast_fp16 = conv(dilations = var_2376, groups = var_2153, pad = pretrained_out_111_pad_0, pad_type = pretrained_out_111_pad_type_0, strides = var_2374, weight = layers_5_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_111_cast_fp16")];
            tensor<int32, [2]> var_2380 = const()[name = tensor<string, []>("op_2380"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2382 = const()[name = tensor<string, []>("op_2382"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_163_pad_type_0 = const()[name = tensor<string, []>("input_163_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_163_pad_0 = const()[name = tensor<string, []>("input_163_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_5_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_5_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(210386048)))];
            tensor<fp16, [1, 16, 1, 1500]> input_163_cast_fp16 = conv(dilations = var_2382, groups = var_2153, pad = input_163_pad_0, pad_type = input_163_pad_type_0, strides = var_2380, weight = layers_5_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_163_cast_fp16")];
            tensor<int32, [2]> var_2386 = const()[name = tensor<string, []>("op_2386"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2388 = const()[name = tensor<string, []>("op_2388"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_221_pad_type_0 = const()[name = tensor<string, []>("lora_out_221_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_221_pad_0 = const()[name = tensor<string, []>("lora_out_221_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_223_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_223_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(210427072)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_223_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_2388, groups = var_2153, pad = lora_out_221_pad_0, pad_type = lora_out_221_pad_type_0, strides = var_2386, weight = lora_out_223_weight_0_to_fp16, x = input_163_cast_fp16)[name = tensor<string, []>("lora_out_223_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_23_cast_fp16 = add(x = pretrained_out_111_cast_fp16, y = lora_out_223_cast_fp16)[name = tensor<string, []>("key_23_cast_fp16")];
            tensor<int32, [2]> var_2399 = const()[name = tensor<string, []>("op_2399"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2401 = const()[name = tensor<string, []>("op_2401"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_113_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_113_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_113_pad_0 = const()[name = tensor<string, []>("pretrained_out_113_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_5_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(210468096))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(211287360))), name = tensor<string, []>("layers_5_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_5_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_5_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(211287488)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_113_cast_fp16 = conv(bias = layers_5_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_2401, groups = var_2153, pad = pretrained_out_113_pad_0, pad_type = pretrained_out_113_pad_type_0, strides = var_2399, weight = layers_5_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_113_cast_fp16")];
            tensor<int32, [2]> var_2405 = const()[name = tensor<string, []>("op_2405"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2407 = const()[name = tensor<string, []>("op_2407"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_165_pad_type_0 = const()[name = tensor<string, []>("input_165_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_165_pad_0 = const()[name = tensor<string, []>("input_165_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_5_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_5_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(211290112)))];
            tensor<fp16, [1, 16, 1, 1500]> input_165_cast_fp16 = conv(dilations = var_2407, groups = var_2153, pad = input_165_pad_0, pad_type = input_165_pad_type_0, strides = var_2405, weight = layers_5_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_165_cast_fp16")];
            tensor<int32, [2]> var_2411 = const()[name = tensor<string, []>("op_2411"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2413 = const()[name = tensor<string, []>("op_2413"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_225_pad_type_0 = const()[name = tensor<string, []>("lora_out_225_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_225_pad_0 = const()[name = tensor<string, []>("lora_out_225_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_227_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_227_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(211331136)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_227_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_2413, groups = var_2153, pad = lora_out_225_pad_0, pad_type = lora_out_225_pad_type_0, strides = var_2411, weight = lora_out_227_weight_0_to_fp16, x = input_165_cast_fp16)[name = tensor<string, []>("lora_out_227_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_23_cast_fp16 = add(x = pretrained_out_113_cast_fp16, y = lora_out_227_cast_fp16)[name = tensor<string, []>("value_23_cast_fp16")];
            tensor<int32, [4]> var_2420 = const()[name = tensor<string, []>("op_2420"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_2421_cast_fp16 = reshape(shape = var_2420, x = query_23_cast_fp16)[name = tensor<string, []>("op_2421_cast_fp16")];
            tensor<fp16, []> var_2422_to_fp16 = const()[name = tensor<string, []>("op_2422_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_2423_cast_fp16 = mul(x = var_2421_cast_fp16, y = var_2422_to_fp16)[name = tensor<string, []>("op_2423_cast_fp16")];
            tensor<int32, [4]> var_2424 = const()[name = tensor<string, []>("op_2424"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_2425_cast_fp16 = reshape(shape = var_2424, x = key_23_cast_fp16)[name = tensor<string, []>("op_2425_cast_fp16")];
            tensor<bool, []> mh_w_35_transpose_x_0 = const()[name = tensor<string, []>("mh_w_35_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_35_transpose_y_0 = const()[name = tensor<string, []>("mh_w_35_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_35_cast_fp16 = matmul(transpose_x = mh_w_35_transpose_x_0, transpose_y = mh_w_35_transpose_y_0, x = var_2423_cast_fp16, y = var_2425_cast_fp16)[name = tensor<string, []>("mh_w_35_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_83_cast_fp16 = softmax(axis = var_2146, x = mh_w_35_cast_fp16)[name = tensor<string, []>("obj_83_cast_fp16")];
            tensor<int32, [4]> var_2429 = const()[name = tensor<string, []>("op_2429"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_2430_cast_fp16 = reshape(shape = var_2429, x = value_23_cast_fp16)[name = tensor<string, []>("op_2430_cast_fp16")];
            tensor<bool, []> attn_23_transpose_x_0 = const()[name = tensor<string, []>("attn_23_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_23_transpose_y_0 = const()[name = tensor<string, []>("attn_23_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_23_cast_fp16 = matmul(transpose_x = attn_23_transpose_x_0, transpose_y = attn_23_transpose_y_0, x = var_2430_cast_fp16, y = obj_83_cast_fp16)[name = tensor<string, []>("attn_23_cast_fp16")];
            tensor<int32, [4]> var_2433 = const()[name = tensor<string, []>("op_2433"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_167_cast_fp16 = reshape(shape = var_2433, x = attn_23_cast_fp16)[name = tensor<string, []>("input_167_cast_fp16")];
            tensor<int32, [2]> var_2440 = const()[name = tensor<string, []>("op_2440"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2442 = const()[name = tensor<string, []>("op_2442"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_115_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_115_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_115_pad_0 = const()[name = tensor<string, []>("pretrained_out_115_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_5_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(211372160))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(212191424))), name = tensor<string, []>("layers_5_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_5_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_5_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(212191552)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_115_cast_fp16 = conv(bias = layers_5_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_2442, groups = var_2153, pad = pretrained_out_115_pad_0, pad_type = pretrained_out_115_pad_type_0, strides = var_2440, weight = layers_5_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_167_cast_fp16)[name = tensor<string, []>("pretrained_out_115_cast_fp16")];
            tensor<int32, [2]> var_2446 = const()[name = tensor<string, []>("op_2446"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2448 = const()[name = tensor<string, []>("op_2448"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_169_pad_type_0 = const()[name = tensor<string, []>("input_169_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_169_pad_0 = const()[name = tensor<string, []>("input_169_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_5_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_5_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(212194176)))];
            tensor<fp16, [1, 16, 1, 1]> input_169_cast_fp16 = conv(dilations = var_2448, groups = var_2153, pad = input_169_pad_0, pad_type = input_169_pad_type_0, strides = var_2446, weight = layers_5_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_167_cast_fp16)[name = tensor<string, []>("input_169_cast_fp16")];
            tensor<int32, [2]> var_2452 = const()[name = tensor<string, []>("op_2452"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2454 = const()[name = tensor<string, []>("op_2454"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_229_pad_type_0 = const()[name = tensor<string, []>("lora_out_229_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_229_pad_0 = const()[name = tensor<string, []>("lora_out_229_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_231_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_231_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(212235200)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_231_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_2454, groups = var_2153, pad = lora_out_229_pad_0, pad_type = lora_out_229_pad_type_0, strides = var_2452, weight = lora_out_231_weight_0_to_fp16, x = input_169_cast_fp16)[name = tensor<string, []>("lora_out_231_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_81_cast_fp16 = add(x = pretrained_out_115_cast_fp16, y = lora_out_231_cast_fp16)[name = tensor<string, []>("obj_81_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_35_cast_fp16 = add(x = inputs_33_cast_fp16, y = obj_81_cast_fp16)[name = tensor<string, []>("inputs_35_cast_fp16")];
            tensor<int32, [1]> var_2463 = const()[name = tensor<string, []>("op_2463"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_35_cast_fp16 = reduce_mean(axes = var_2463, keep_dims = var_2154, x = inputs_35_cast_fp16)[name = tensor<string, []>("channels_mean_35_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_35_cast_fp16 = sub(x = inputs_35_cast_fp16, y = channels_mean_35_cast_fp16)[name = tensor<string, []>("zero_mean_35_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_35_cast_fp16 = mul(x = zero_mean_35_cast_fp16, y = zero_mean_35_cast_fp16)[name = tensor<string, []>("zero_mean_sq_35_cast_fp16")];
            tensor<int32, [1]> var_2467 = const()[name = tensor<string, []>("op_2467"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_2468_cast_fp16 = reduce_mean(axes = var_2467, keep_dims = var_2154, x = zero_mean_sq_35_cast_fp16)[name = tensor<string, []>("op_2468_cast_fp16")];
            tensor<fp16, []> var_2469_to_fp16 = const()[name = tensor<string, []>("op_2469_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_2470_cast_fp16 = add(x = var_2468_cast_fp16, y = var_2469_to_fp16)[name = tensor<string, []>("op_2470_cast_fp16")];
            tensor<fp32, []> denom_35_epsilon_0 = const()[name = tensor<string, []>("denom_35_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_35_cast_fp16 = rsqrt(epsilon = denom_35_epsilon_0, x = var_2470_cast_fp16)[name = tensor<string, []>("denom_35_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_35_cast_fp16 = mul(x = zero_mean_35_cast_fp16, y = denom_35_cast_fp16)[name = tensor<string, []>("out_35_cast_fp16")];
            tensor<fp16, [1280]> input_171_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_171_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(212276224)))];
            tensor<fp16, [1280]> input_171_beta_0_to_fp16 = const()[name = tensor<string, []>("input_171_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(212278848)))];
            tensor<fp16, []> input_171_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_171_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_171_cast_fp16 = batch_norm(beta = input_171_beta_0_to_fp16, epsilon = input_171_epsilon_0_to_fp16, gamma = input_171_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_35_cast_fp16)[name = tensor<string, []>("input_171_cast_fp16")];
            tensor<int32, [2]> var_2484 = const()[name = tensor<string, []>("op_2484"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2486 = const()[name = tensor<string, []>("op_2486"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_117_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_117_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_117_pad_0 = const()[name = tensor<string, []>("pretrained_out_117_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_5_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(212281472))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(215558336))), name = tensor<string, []>("layers_5_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_5_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_5_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(215558464)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_117_cast_fp16 = conv(bias = layers_5_fc1_pretrained_bias_to_fp16, dilations = var_2486, groups = var_2153, pad = pretrained_out_117_pad_0, pad_type = pretrained_out_117_pad_type_0, strides = var_2484, weight = layers_5_fc1_pretrained_weight_to_fp16_palettized, x = input_171_cast_fp16)[name = tensor<string, []>("pretrained_out_117_cast_fp16")];
            tensor<int32, [2]> var_2490 = const()[name = tensor<string, []>("op_2490"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2492 = const()[name = tensor<string, []>("op_2492"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_173_pad_type_0 = const()[name = tensor<string, []>("input_173_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_173_pad_0 = const()[name = tensor<string, []>("input_173_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_5_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_5_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(215568768)))];
            tensor<fp16, [1, 16, 1, 1]> input_173_cast_fp16 = conv(dilations = var_2492, groups = var_2153, pad = input_173_pad_0, pad_type = input_173_pad_type_0, strides = var_2490, weight = layers_5_fc1_loraA_weight_to_fp16, x = input_171_cast_fp16)[name = tensor<string, []>("input_173_cast_fp16")];
            tensor<int32, [2]> var_2496 = const()[name = tensor<string, []>("op_2496"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2498 = const()[name = tensor<string, []>("op_2498"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_233_pad_type_0 = const()[name = tensor<string, []>("lora_out_233_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_233_pad_0 = const()[name = tensor<string, []>("lora_out_233_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_235_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_235_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(215609792)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_235_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_2498, groups = var_2153, pad = lora_out_233_pad_0, pad_type = lora_out_233_pad_type_0, strides = var_2496, weight = lora_out_235_weight_0_to_fp16, x = input_173_cast_fp16)[name = tensor<string, []>("lora_out_235_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_175_cast_fp16 = add(x = pretrained_out_117_cast_fp16, y = lora_out_235_cast_fp16)[name = tensor<string, []>("input_175_cast_fp16")];
            tensor<string, []> input_177_mode_0 = const()[name = tensor<string, []>("input_177_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_177_cast_fp16 = gelu(mode = input_177_mode_0, x = input_175_cast_fp16)[name = tensor<string, []>("input_177_cast_fp16")];
            tensor<int32, [2]> var_2510 = const()[name = tensor<string, []>("op_2510"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2512 = const()[name = tensor<string, []>("op_2512"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_119_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_119_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_119_pad_0 = const()[name = tensor<string, []>("pretrained_out_119_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_5_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(215773696))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(219050560))), name = tensor<string, []>("layers_5_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_5_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_5_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(219050688)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_119_cast_fp16 = conv(bias = layers_5_fc2_pretrained_bias_to_fp16, dilations = var_2512, groups = var_2153, pad = pretrained_out_119_pad_0, pad_type = pretrained_out_119_pad_type_0, strides = var_2510, weight = layers_5_fc2_pretrained_weight_to_fp16_palettized, x = input_177_cast_fp16)[name = tensor<string, []>("pretrained_out_119_cast_fp16")];
            tensor<int32, [2]> var_2516 = const()[name = tensor<string, []>("op_2516"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2518 = const()[name = tensor<string, []>("op_2518"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_179_pad_type_0 = const()[name = tensor<string, []>("input_179_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_179_pad_0 = const()[name = tensor<string, []>("input_179_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_5_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_5_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(219053312)))];
            tensor<fp16, [1, 16, 1, 1]> input_179_cast_fp16 = conv(dilations = var_2518, groups = var_2153, pad = input_179_pad_0, pad_type = input_179_pad_type_0, strides = var_2516, weight = layers_5_fc2_loraA_weight_to_fp16, x = input_177_cast_fp16)[name = tensor<string, []>("input_179_cast_fp16")];
            tensor<int32, [2]> var_2522 = const()[name = tensor<string, []>("op_2522"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2524 = const()[name = tensor<string, []>("op_2524"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_237_pad_type_0 = const()[name = tensor<string, []>("lora_out_237_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_237_pad_0 = const()[name = tensor<string, []>("lora_out_237_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_239_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_239_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(219217216)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_239_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_2524, groups = var_2153, pad = lora_out_237_pad_0, pad_type = lora_out_237_pad_type_0, strides = var_2522, weight = lora_out_239_weight_0_to_fp16, x = input_179_cast_fp16)[name = tensor<string, []>("lora_out_239_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_13_cast_fp16 = add(x = pretrained_out_119_cast_fp16, y = lora_out_239_cast_fp16)[name = tensor<string, []>("hidden_states_13_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_37_cast_fp16 = add(x = inputs_35_cast_fp16, y = hidden_states_13_cast_fp16)[name = tensor<string, []>("inputs_37_cast_fp16")];
            tensor<int32, []> var_2540 = const()[name = tensor<string, []>("op_2540"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_2547 = const()[name = tensor<string, []>("op_2547"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_2548 = const()[name = tensor<string, []>("op_2548"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_2560 = const()[name = tensor<string, []>("op_2560"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_37_cast_fp16 = reduce_mean(axes = var_2560, keep_dims = var_2548, x = inputs_37_cast_fp16)[name = tensor<string, []>("channels_mean_37_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_37_cast_fp16 = sub(x = inputs_37_cast_fp16, y = channels_mean_37_cast_fp16)[name = tensor<string, []>("zero_mean_37_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_37_cast_fp16 = mul(x = zero_mean_37_cast_fp16, y = zero_mean_37_cast_fp16)[name = tensor<string, []>("zero_mean_sq_37_cast_fp16")];
            tensor<int32, [1]> var_2564 = const()[name = tensor<string, []>("op_2564"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_2565_cast_fp16 = reduce_mean(axes = var_2564, keep_dims = var_2548, x = zero_mean_sq_37_cast_fp16)[name = tensor<string, []>("op_2565_cast_fp16")];
            tensor<fp16, []> var_2566_to_fp16 = const()[name = tensor<string, []>("op_2566_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_2567_cast_fp16 = add(x = var_2565_cast_fp16, y = var_2566_to_fp16)[name = tensor<string, []>("op_2567_cast_fp16")];
            tensor<fp32, []> denom_37_epsilon_0 = const()[name = tensor<string, []>("denom_37_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_37_cast_fp16 = rsqrt(epsilon = denom_37_epsilon_0, x = var_2567_cast_fp16)[name = tensor<string, []>("denom_37_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_37_cast_fp16 = mul(x = zero_mean_37_cast_fp16, y = denom_37_cast_fp16)[name = tensor<string, []>("out_37_cast_fp16")];
            tensor<fp16, [1280]> obj_85_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_85_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(219258240)))];
            tensor<fp16, [1280]> obj_85_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_85_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(219260864)))];
            tensor<fp16, []> obj_85_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_85_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_85_cast_fp16 = batch_norm(beta = obj_85_beta_0_to_fp16, epsilon = obj_85_epsilon_0_to_fp16, gamma = obj_85_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_37_cast_fp16)[name = tensor<string, []>("obj_85_cast_fp16")];
            tensor<int32, [2]> var_2585 = const()[name = tensor<string, []>("op_2585"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2587 = const()[name = tensor<string, []>("op_2587"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_121_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_121_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_121_pad_0 = const()[name = tensor<string, []>("pretrained_out_121_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_6_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(219263488))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(220082752))), name = tensor<string, []>("layers_6_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_6_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_6_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(220082880)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_121_cast_fp16 = conv(bias = layers_6_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_2587, groups = var_2547, pad = pretrained_out_121_pad_0, pad_type = pretrained_out_121_pad_type_0, strides = var_2585, weight = layers_6_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_85_cast_fp16)[name = tensor<string, []>("pretrained_out_121_cast_fp16")];
            tensor<int32, [2]> var_2591 = const()[name = tensor<string, []>("op_2591"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2593 = const()[name = tensor<string, []>("op_2593"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_181_pad_type_0 = const()[name = tensor<string, []>("input_181_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_181_pad_0 = const()[name = tensor<string, []>("input_181_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_6_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_6_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(220085504)))];
            tensor<fp16, [1, 16, 1, 1]> input_181_cast_fp16 = conv(dilations = var_2593, groups = var_2547, pad = input_181_pad_0, pad_type = input_181_pad_type_0, strides = var_2591, weight = layers_6_self_attn_q_proj_loraA_weight_to_fp16, x = obj_85_cast_fp16)[name = tensor<string, []>("input_181_cast_fp16")];
            tensor<int32, [2]> var_2597 = const()[name = tensor<string, []>("op_2597"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2599 = const()[name = tensor<string, []>("op_2599"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_241_pad_type_0 = const()[name = tensor<string, []>("lora_out_241_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_241_pad_0 = const()[name = tensor<string, []>("lora_out_241_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_243_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_243_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(220126528)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_243_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_2599, groups = var_2547, pad = lora_out_241_pad_0, pad_type = lora_out_241_pad_type_0, strides = var_2597, weight = lora_out_243_weight_0_to_fp16, x = input_181_cast_fp16)[name = tensor<string, []>("lora_out_243_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_25_cast_fp16 = add(x = pretrained_out_121_cast_fp16, y = lora_out_243_cast_fp16)[name = tensor<string, []>("query_25_cast_fp16")];
            tensor<int32, [2]> var_2609 = const()[name = tensor<string, []>("op_2609"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2611 = const()[name = tensor<string, []>("op_2611"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_123_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_123_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_123_pad_0 = const()[name = tensor<string, []>("pretrained_out_123_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_6_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(220167552))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(220986816))), name = tensor<string, []>("layers_6_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_123_cast_fp16 = conv(dilations = var_2611, groups = var_2547, pad = pretrained_out_123_pad_0, pad_type = pretrained_out_123_pad_type_0, strides = var_2609, weight = layers_6_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_85_cast_fp16)[name = tensor<string, []>("pretrained_out_123_cast_fp16")];
            tensor<int32, [2]> var_2615 = const()[name = tensor<string, []>("op_2615"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2617 = const()[name = tensor<string, []>("op_2617"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_183_pad_type_0 = const()[name = tensor<string, []>("input_183_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_183_pad_0 = const()[name = tensor<string, []>("input_183_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_6_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_6_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(220986944)))];
            tensor<fp16, [1, 16, 1, 1]> input_183_cast_fp16 = conv(dilations = var_2617, groups = var_2547, pad = input_183_pad_0, pad_type = input_183_pad_type_0, strides = var_2615, weight = layers_6_self_attn_k_proj_loraA_weight_to_fp16, x = obj_85_cast_fp16)[name = tensor<string, []>("input_183_cast_fp16")];
            tensor<int32, [2]> var_2621 = const()[name = tensor<string, []>("op_2621"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2623 = const()[name = tensor<string, []>("op_2623"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_245_pad_type_0 = const()[name = tensor<string, []>("lora_out_245_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_245_pad_0 = const()[name = tensor<string, []>("lora_out_245_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_247_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_247_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(221027968)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_247_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_2623, groups = var_2547, pad = lora_out_245_pad_0, pad_type = lora_out_245_pad_type_0, strides = var_2621, weight = lora_out_247_weight_0_to_fp16, x = input_183_cast_fp16)[name = tensor<string, []>("lora_out_247_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_13_cast_fp16 = add(x = pretrained_out_123_cast_fp16, y = lora_out_247_cast_fp16)[name = tensor<string, []>("current_key_13_cast_fp16")];
            tensor<int32, [2]> var_2634 = const()[name = tensor<string, []>("op_2634"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2636 = const()[name = tensor<string, []>("op_2636"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_125_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_125_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_125_pad_0 = const()[name = tensor<string, []>("pretrained_out_125_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_6_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(221068992))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(221888256))), name = tensor<string, []>("layers_6_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_6_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_6_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(221888384)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_125_cast_fp16 = conv(bias = layers_6_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_2636, groups = var_2547, pad = pretrained_out_125_pad_0, pad_type = pretrained_out_125_pad_type_0, strides = var_2634, weight = layers_6_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_85_cast_fp16)[name = tensor<string, []>("pretrained_out_125_cast_fp16")];
            tensor<int32, [2]> var_2640 = const()[name = tensor<string, []>("op_2640"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2642 = const()[name = tensor<string, []>("op_2642"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_185_pad_type_0 = const()[name = tensor<string, []>("input_185_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_185_pad_0 = const()[name = tensor<string, []>("input_185_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_6_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_6_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(221891008)))];
            tensor<fp16, [1, 16, 1, 1]> input_185_cast_fp16 = conv(dilations = var_2642, groups = var_2547, pad = input_185_pad_0, pad_type = input_185_pad_type_0, strides = var_2640, weight = layers_6_self_attn_v_proj_loraA_weight_to_fp16, x = obj_85_cast_fp16)[name = tensor<string, []>("input_185_cast_fp16")];
            tensor<int32, [2]> var_2646 = const()[name = tensor<string, []>("op_2646"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2648 = const()[name = tensor<string, []>("op_2648"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_249_pad_type_0 = const()[name = tensor<string, []>("lora_out_249_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_249_pad_0 = const()[name = tensor<string, []>("lora_out_249_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_251_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_251_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(221932032)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_251_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_2648, groups = var_2547, pad = lora_out_249_pad_0, pad_type = lora_out_249_pad_type_0, strides = var_2646, weight = lora_out_251_weight_0_to_fp16, x = input_185_cast_fp16)[name = tensor<string, []>("lora_out_251_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_13_cast_fp16 = add(x = pretrained_out_125_cast_fp16, y = lora_out_251_cast_fp16)[name = tensor<string, []>("current_value_13_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_2658_cast_fp16 = mul(x = current_key_13_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_2658_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_2660_cast_fp16 = mul(x = var_103_cast_fp16_6, y = var_295_cast_fp16)[name = tensor<string, []>("op_2660_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_25_cast_fp16 = add(x = var_2658_cast_fp16, y = var_2660_cast_fp16)[name = tensor<string, []>("key_25_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_2662_cast_fp16 = mul(x = current_value_13_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_2662_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_2664_cast_fp16 = mul(x = var_138_cast_fp16_6, y = var_295_cast_fp16)[name = tensor<string, []>("op_2664_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_25_cast_fp16 = add(x = var_2662_cast_fp16, y = var_2664_cast_fp16)[name = tensor<string, []>("value_25_cast_fp16")];
            tensor<int32, [4]> var_2667 = const()[name = tensor<string, []>("op_2667"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_2668_cast_fp16 = reshape(shape = var_2667, x = query_25_cast_fp16)[name = tensor<string, []>("op_2668_cast_fp16")];
            tensor<fp16, []> var_2669_to_fp16 = const()[name = tensor<string, []>("op_2669_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_2670_cast_fp16 = mul(x = var_2668_cast_fp16, y = var_2669_to_fp16)[name = tensor<string, []>("op_2670_cast_fp16")];
            tensor<int32, [4]> var_2671 = const()[name = tensor<string, []>("op_2671"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_2672_cast_fp16 = reshape(shape = var_2671, x = key_25_cast_fp16)[name = tensor<string, []>("op_2672_cast_fp16")];
            tensor<bool, []> mh_w_37_transpose_x_0 = const()[name = tensor<string, []>("mh_w_37_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_37_transpose_y_0 = const()[name = tensor<string, []>("mh_w_37_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_37_cast_fp16 = matmul(transpose_x = mh_w_37_transpose_x_0, transpose_y = mh_w_37_transpose_y_0, x = var_2670_cast_fp16, y = var_2672_cast_fp16)[name = tensor<string, []>("mh_w_37_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_39_cast_fp16 = add(x = mh_w_37_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_39_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_2680_cast_fp16 = softmax(axis = var_2540, x = mh_w_39_cast_fp16)[name = tensor<string, []>("op_2680_cast_fp16")];
            tensor<int32, [4]> var_2681 = const()[name = tensor<string, []>("op_2681"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_2682_cast_fp16 = reshape(shape = var_2681, x = value_25_cast_fp16)[name = tensor<string, []>("op_2682_cast_fp16")];
            tensor<bool, []> attn_25_transpose_x_0 = const()[name = tensor<string, []>("attn_25_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_25_transpose_y_0 = const()[name = tensor<string, []>("attn_25_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_25_cast_fp16 = matmul(transpose_x = attn_25_transpose_x_0, transpose_y = attn_25_transpose_y_0, x = var_2682_cast_fp16, y = var_2680_cast_fp16)[name = tensor<string, []>("attn_25_cast_fp16")];
            tensor<int32, [4]> var_2685 = const()[name = tensor<string, []>("op_2685"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_187_cast_fp16 = reshape(shape = var_2685, x = attn_25_cast_fp16)[name = tensor<string, []>("input_187_cast_fp16")];
            tensor<int32, [2]> var_2692 = const()[name = tensor<string, []>("op_2692"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2694 = const()[name = tensor<string, []>("op_2694"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_127_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_127_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_127_pad_0 = const()[name = tensor<string, []>("pretrained_out_127_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_6_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(221973056))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(222792320))), name = tensor<string, []>("layers_6_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_6_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_6_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(222792448)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_127_cast_fp16 = conv(bias = layers_6_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_2694, groups = var_2547, pad = pretrained_out_127_pad_0, pad_type = pretrained_out_127_pad_type_0, strides = var_2692, weight = layers_6_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_187_cast_fp16)[name = tensor<string, []>("pretrained_out_127_cast_fp16")];
            tensor<int32, [2]> var_2698 = const()[name = tensor<string, []>("op_2698"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2700 = const()[name = tensor<string, []>("op_2700"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_189_pad_type_0 = const()[name = tensor<string, []>("input_189_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_189_pad_0 = const()[name = tensor<string, []>("input_189_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_6_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_6_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(222795072)))];
            tensor<fp16, [1, 16, 1, 1]> input_189_cast_fp16 = conv(dilations = var_2700, groups = var_2547, pad = input_189_pad_0, pad_type = input_189_pad_type_0, strides = var_2698, weight = layers_6_self_attn_o_proj_loraA_weight_to_fp16, x = input_187_cast_fp16)[name = tensor<string, []>("input_189_cast_fp16")];
            tensor<int32, [2]> var_2704 = const()[name = tensor<string, []>("op_2704"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2706 = const()[name = tensor<string, []>("op_2706"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_253_pad_type_0 = const()[name = tensor<string, []>("lora_out_253_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_253_pad_0 = const()[name = tensor<string, []>("lora_out_253_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_255_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_255_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(222836096)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_255_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_2706, groups = var_2547, pad = lora_out_253_pad_0, pad_type = lora_out_253_pad_type_0, strides = var_2704, weight = lora_out_255_weight_0_to_fp16, x = input_189_cast_fp16)[name = tensor<string, []>("lora_out_255_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_91_cast_fp16 = add(x = pretrained_out_127_cast_fp16, y = lora_out_255_cast_fp16)[name = tensor<string, []>("obj_91_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_39_cast_fp16 = add(x = inputs_37_cast_fp16, y = obj_91_cast_fp16)[name = tensor<string, []>("inputs_39_cast_fp16")];
            tensor<int32, [1]> var_2719 = const()[name = tensor<string, []>("op_2719"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_39_cast_fp16 = reduce_mean(axes = var_2719, keep_dims = var_2548, x = inputs_39_cast_fp16)[name = tensor<string, []>("channels_mean_39_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_39_cast_fp16 = sub(x = inputs_39_cast_fp16, y = channels_mean_39_cast_fp16)[name = tensor<string, []>("zero_mean_39_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_39_cast_fp16 = mul(x = zero_mean_39_cast_fp16, y = zero_mean_39_cast_fp16)[name = tensor<string, []>("zero_mean_sq_39_cast_fp16")];
            tensor<int32, [1]> var_2723 = const()[name = tensor<string, []>("op_2723"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_2724_cast_fp16 = reduce_mean(axes = var_2723, keep_dims = var_2548, x = zero_mean_sq_39_cast_fp16)[name = tensor<string, []>("op_2724_cast_fp16")];
            tensor<fp16, []> var_2725_to_fp16 = const()[name = tensor<string, []>("op_2725_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_2726_cast_fp16 = add(x = var_2724_cast_fp16, y = var_2725_to_fp16)[name = tensor<string, []>("op_2726_cast_fp16")];
            tensor<fp32, []> denom_39_epsilon_0 = const()[name = tensor<string, []>("denom_39_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_39_cast_fp16 = rsqrt(epsilon = denom_39_epsilon_0, x = var_2726_cast_fp16)[name = tensor<string, []>("denom_39_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_39_cast_fp16 = mul(x = zero_mean_39_cast_fp16, y = denom_39_cast_fp16)[name = tensor<string, []>("out_39_cast_fp16")];
            tensor<fp16, [1280]> obj_93_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_93_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(222877120)))];
            tensor<fp16, [1280]> obj_93_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_93_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(222879744)))];
            tensor<fp16, []> obj_93_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_93_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_93_cast_fp16 = batch_norm(beta = obj_93_beta_0_to_fp16, epsilon = obj_93_epsilon_0_to_fp16, gamma = obj_93_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_39_cast_fp16)[name = tensor<string, []>("obj_93_cast_fp16")];
            tensor<int32, [2]> var_2744 = const()[name = tensor<string, []>("op_2744"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2746 = const()[name = tensor<string, []>("op_2746"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_129_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_129_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_129_pad_0 = const()[name = tensor<string, []>("pretrained_out_129_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_6_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(222882368))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(223701632))), name = tensor<string, []>("layers_6_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_6_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_6_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(223701760)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_129_cast_fp16 = conv(bias = layers_6_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_2746, groups = var_2547, pad = pretrained_out_129_pad_0, pad_type = pretrained_out_129_pad_type_0, strides = var_2744, weight = layers_6_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_93_cast_fp16)[name = tensor<string, []>("pretrained_out_129_cast_fp16")];
            tensor<int32, [2]> var_2750 = const()[name = tensor<string, []>("op_2750"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2752 = const()[name = tensor<string, []>("op_2752"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_191_pad_type_0 = const()[name = tensor<string, []>("input_191_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_191_pad_0 = const()[name = tensor<string, []>("input_191_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_6_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_6_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(223704384)))];
            tensor<fp16, [1, 16, 1, 1]> input_191_cast_fp16 = conv(dilations = var_2752, groups = var_2547, pad = input_191_pad_0, pad_type = input_191_pad_type_0, strides = var_2750, weight = layers_6_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_93_cast_fp16)[name = tensor<string, []>("input_191_cast_fp16")];
            tensor<int32, [2]> var_2756 = const()[name = tensor<string, []>("op_2756"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2758 = const()[name = tensor<string, []>("op_2758"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_257_pad_type_0 = const()[name = tensor<string, []>("lora_out_257_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_257_pad_0 = const()[name = tensor<string, []>("lora_out_257_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_259_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_259_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(223745408)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_259_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_2758, groups = var_2547, pad = lora_out_257_pad_0, pad_type = lora_out_257_pad_type_0, strides = var_2756, weight = lora_out_259_weight_0_to_fp16, x = input_191_cast_fp16)[name = tensor<string, []>("lora_out_259_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_27_cast_fp16 = add(x = pretrained_out_129_cast_fp16, y = lora_out_259_cast_fp16)[name = tensor<string, []>("query_27_cast_fp16")];
            tensor<int32, [2]> var_2768 = const()[name = tensor<string, []>("op_2768"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2770 = const()[name = tensor<string, []>("op_2770"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_131_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_131_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_131_pad_0 = const()[name = tensor<string, []>("pretrained_out_131_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_6_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(223786432))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(224605696))), name = tensor<string, []>("layers_6_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_131_cast_fp16 = conv(dilations = var_2770, groups = var_2547, pad = pretrained_out_131_pad_0, pad_type = pretrained_out_131_pad_type_0, strides = var_2768, weight = layers_6_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_131_cast_fp16")];
            tensor<int32, [2]> var_2774 = const()[name = tensor<string, []>("op_2774"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2776 = const()[name = tensor<string, []>("op_2776"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_193_pad_type_0 = const()[name = tensor<string, []>("input_193_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_193_pad_0 = const()[name = tensor<string, []>("input_193_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_6_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_6_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(224605824)))];
            tensor<fp16, [1, 16, 1, 1500]> input_193_cast_fp16 = conv(dilations = var_2776, groups = var_2547, pad = input_193_pad_0, pad_type = input_193_pad_type_0, strides = var_2774, weight = layers_6_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_193_cast_fp16")];
            tensor<int32, [2]> var_2780 = const()[name = tensor<string, []>("op_2780"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2782 = const()[name = tensor<string, []>("op_2782"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_261_pad_type_0 = const()[name = tensor<string, []>("lora_out_261_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_261_pad_0 = const()[name = tensor<string, []>("lora_out_261_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_263_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_263_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(224646848)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_263_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_2782, groups = var_2547, pad = lora_out_261_pad_0, pad_type = lora_out_261_pad_type_0, strides = var_2780, weight = lora_out_263_weight_0_to_fp16, x = input_193_cast_fp16)[name = tensor<string, []>("lora_out_263_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_27_cast_fp16 = add(x = pretrained_out_131_cast_fp16, y = lora_out_263_cast_fp16)[name = tensor<string, []>("key_27_cast_fp16")];
            tensor<int32, [2]> var_2793 = const()[name = tensor<string, []>("op_2793"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2795 = const()[name = tensor<string, []>("op_2795"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_133_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_133_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_133_pad_0 = const()[name = tensor<string, []>("pretrained_out_133_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_6_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(224687872))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(225507136))), name = tensor<string, []>("layers_6_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_6_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_6_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(225507264)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_133_cast_fp16 = conv(bias = layers_6_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_2795, groups = var_2547, pad = pretrained_out_133_pad_0, pad_type = pretrained_out_133_pad_type_0, strides = var_2793, weight = layers_6_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_133_cast_fp16")];
            tensor<int32, [2]> var_2799 = const()[name = tensor<string, []>("op_2799"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2801 = const()[name = tensor<string, []>("op_2801"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_195_pad_type_0 = const()[name = tensor<string, []>("input_195_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_195_pad_0 = const()[name = tensor<string, []>("input_195_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_6_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_6_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(225509888)))];
            tensor<fp16, [1, 16, 1, 1500]> input_195_cast_fp16 = conv(dilations = var_2801, groups = var_2547, pad = input_195_pad_0, pad_type = input_195_pad_type_0, strides = var_2799, weight = layers_6_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_195_cast_fp16")];
            tensor<int32, [2]> var_2805 = const()[name = tensor<string, []>("op_2805"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2807 = const()[name = tensor<string, []>("op_2807"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_265_pad_type_0 = const()[name = tensor<string, []>("lora_out_265_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_265_pad_0 = const()[name = tensor<string, []>("lora_out_265_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_267_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_267_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(225550912)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_267_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_2807, groups = var_2547, pad = lora_out_265_pad_0, pad_type = lora_out_265_pad_type_0, strides = var_2805, weight = lora_out_267_weight_0_to_fp16, x = input_195_cast_fp16)[name = tensor<string, []>("lora_out_267_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_27_cast_fp16 = add(x = pretrained_out_133_cast_fp16, y = lora_out_267_cast_fp16)[name = tensor<string, []>("value_27_cast_fp16")];
            tensor<int32, [4]> var_2814 = const()[name = tensor<string, []>("op_2814"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_2815_cast_fp16 = reshape(shape = var_2814, x = query_27_cast_fp16)[name = tensor<string, []>("op_2815_cast_fp16")];
            tensor<fp16, []> var_2816_to_fp16 = const()[name = tensor<string, []>("op_2816_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_2817_cast_fp16 = mul(x = var_2815_cast_fp16, y = var_2816_to_fp16)[name = tensor<string, []>("op_2817_cast_fp16")];
            tensor<int32, [4]> var_2818 = const()[name = tensor<string, []>("op_2818"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_2819_cast_fp16 = reshape(shape = var_2818, x = key_27_cast_fp16)[name = tensor<string, []>("op_2819_cast_fp16")];
            tensor<bool, []> mh_w_41_transpose_x_0 = const()[name = tensor<string, []>("mh_w_41_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_41_transpose_y_0 = const()[name = tensor<string, []>("mh_w_41_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_41_cast_fp16 = matmul(transpose_x = mh_w_41_transpose_x_0, transpose_y = mh_w_41_transpose_y_0, x = var_2817_cast_fp16, y = var_2819_cast_fp16)[name = tensor<string, []>("mh_w_41_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_97_cast_fp16 = softmax(axis = var_2540, x = mh_w_41_cast_fp16)[name = tensor<string, []>("obj_97_cast_fp16")];
            tensor<int32, [4]> var_2823 = const()[name = tensor<string, []>("op_2823"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_2824_cast_fp16 = reshape(shape = var_2823, x = value_27_cast_fp16)[name = tensor<string, []>("op_2824_cast_fp16")];
            tensor<bool, []> attn_27_transpose_x_0 = const()[name = tensor<string, []>("attn_27_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_27_transpose_y_0 = const()[name = tensor<string, []>("attn_27_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_27_cast_fp16 = matmul(transpose_x = attn_27_transpose_x_0, transpose_y = attn_27_transpose_y_0, x = var_2824_cast_fp16, y = obj_97_cast_fp16)[name = tensor<string, []>("attn_27_cast_fp16")];
            tensor<int32, [4]> var_2827 = const()[name = tensor<string, []>("op_2827"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_197_cast_fp16 = reshape(shape = var_2827, x = attn_27_cast_fp16)[name = tensor<string, []>("input_197_cast_fp16")];
            tensor<int32, [2]> var_2834 = const()[name = tensor<string, []>("op_2834"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2836 = const()[name = tensor<string, []>("op_2836"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_135_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_135_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_135_pad_0 = const()[name = tensor<string, []>("pretrained_out_135_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_6_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(225591936))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(226411200))), name = tensor<string, []>("layers_6_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_6_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_6_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(226411328)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_135_cast_fp16 = conv(bias = layers_6_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_2836, groups = var_2547, pad = pretrained_out_135_pad_0, pad_type = pretrained_out_135_pad_type_0, strides = var_2834, weight = layers_6_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_197_cast_fp16)[name = tensor<string, []>("pretrained_out_135_cast_fp16")];
            tensor<int32, [2]> var_2840 = const()[name = tensor<string, []>("op_2840"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2842 = const()[name = tensor<string, []>("op_2842"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_199_pad_type_0 = const()[name = tensor<string, []>("input_199_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_199_pad_0 = const()[name = tensor<string, []>("input_199_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_6_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_6_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(226413952)))];
            tensor<fp16, [1, 16, 1, 1]> input_199_cast_fp16 = conv(dilations = var_2842, groups = var_2547, pad = input_199_pad_0, pad_type = input_199_pad_type_0, strides = var_2840, weight = layers_6_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_197_cast_fp16)[name = tensor<string, []>("input_199_cast_fp16")];
            tensor<int32, [2]> var_2846 = const()[name = tensor<string, []>("op_2846"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2848 = const()[name = tensor<string, []>("op_2848"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_269_pad_type_0 = const()[name = tensor<string, []>("lora_out_269_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_269_pad_0 = const()[name = tensor<string, []>("lora_out_269_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_271_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_271_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(226454976)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_271_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_2848, groups = var_2547, pad = lora_out_269_pad_0, pad_type = lora_out_269_pad_type_0, strides = var_2846, weight = lora_out_271_weight_0_to_fp16, x = input_199_cast_fp16)[name = tensor<string, []>("lora_out_271_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_95_cast_fp16 = add(x = pretrained_out_135_cast_fp16, y = lora_out_271_cast_fp16)[name = tensor<string, []>("obj_95_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_41_cast_fp16 = add(x = inputs_39_cast_fp16, y = obj_95_cast_fp16)[name = tensor<string, []>("inputs_41_cast_fp16")];
            tensor<int32, [1]> var_2857 = const()[name = tensor<string, []>("op_2857"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_41_cast_fp16 = reduce_mean(axes = var_2857, keep_dims = var_2548, x = inputs_41_cast_fp16)[name = tensor<string, []>("channels_mean_41_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_41_cast_fp16 = sub(x = inputs_41_cast_fp16, y = channels_mean_41_cast_fp16)[name = tensor<string, []>("zero_mean_41_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_41_cast_fp16 = mul(x = zero_mean_41_cast_fp16, y = zero_mean_41_cast_fp16)[name = tensor<string, []>("zero_mean_sq_41_cast_fp16")];
            tensor<int32, [1]> var_2861 = const()[name = tensor<string, []>("op_2861"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_2862_cast_fp16 = reduce_mean(axes = var_2861, keep_dims = var_2548, x = zero_mean_sq_41_cast_fp16)[name = tensor<string, []>("op_2862_cast_fp16")];
            tensor<fp16, []> var_2863_to_fp16 = const()[name = tensor<string, []>("op_2863_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_2864_cast_fp16 = add(x = var_2862_cast_fp16, y = var_2863_to_fp16)[name = tensor<string, []>("op_2864_cast_fp16")];
            tensor<fp32, []> denom_41_epsilon_0 = const()[name = tensor<string, []>("denom_41_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_41_cast_fp16 = rsqrt(epsilon = denom_41_epsilon_0, x = var_2864_cast_fp16)[name = tensor<string, []>("denom_41_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_41_cast_fp16 = mul(x = zero_mean_41_cast_fp16, y = denom_41_cast_fp16)[name = tensor<string, []>("out_41_cast_fp16")];
            tensor<fp16, [1280]> input_201_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_201_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(226496000)))];
            tensor<fp16, [1280]> input_201_beta_0_to_fp16 = const()[name = tensor<string, []>("input_201_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(226498624)))];
            tensor<fp16, []> input_201_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_201_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_201_cast_fp16 = batch_norm(beta = input_201_beta_0_to_fp16, epsilon = input_201_epsilon_0_to_fp16, gamma = input_201_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_41_cast_fp16)[name = tensor<string, []>("input_201_cast_fp16")];
            tensor<int32, [2]> var_2878 = const()[name = tensor<string, []>("op_2878"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2880 = const()[name = tensor<string, []>("op_2880"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_137_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_137_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_137_pad_0 = const()[name = tensor<string, []>("pretrained_out_137_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_6_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(226501248))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(229778112))), name = tensor<string, []>("layers_6_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_6_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_6_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(229778240)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_137_cast_fp16 = conv(bias = layers_6_fc1_pretrained_bias_to_fp16, dilations = var_2880, groups = var_2547, pad = pretrained_out_137_pad_0, pad_type = pretrained_out_137_pad_type_0, strides = var_2878, weight = layers_6_fc1_pretrained_weight_to_fp16_palettized, x = input_201_cast_fp16)[name = tensor<string, []>("pretrained_out_137_cast_fp16")];
            tensor<int32, [2]> var_2884 = const()[name = tensor<string, []>("op_2884"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2886 = const()[name = tensor<string, []>("op_2886"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_203_pad_type_0 = const()[name = tensor<string, []>("input_203_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_203_pad_0 = const()[name = tensor<string, []>("input_203_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_6_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_6_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(229788544)))];
            tensor<fp16, [1, 16, 1, 1]> input_203_cast_fp16 = conv(dilations = var_2886, groups = var_2547, pad = input_203_pad_0, pad_type = input_203_pad_type_0, strides = var_2884, weight = layers_6_fc1_loraA_weight_to_fp16, x = input_201_cast_fp16)[name = tensor<string, []>("input_203_cast_fp16")];
            tensor<int32, [2]> var_2890 = const()[name = tensor<string, []>("op_2890"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2892 = const()[name = tensor<string, []>("op_2892"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_273_pad_type_0 = const()[name = tensor<string, []>("lora_out_273_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_273_pad_0 = const()[name = tensor<string, []>("lora_out_273_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_275_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_275_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(229829568)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_275_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_2892, groups = var_2547, pad = lora_out_273_pad_0, pad_type = lora_out_273_pad_type_0, strides = var_2890, weight = lora_out_275_weight_0_to_fp16, x = input_203_cast_fp16)[name = tensor<string, []>("lora_out_275_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_205_cast_fp16 = add(x = pretrained_out_137_cast_fp16, y = lora_out_275_cast_fp16)[name = tensor<string, []>("input_205_cast_fp16")];
            tensor<string, []> input_207_mode_0 = const()[name = tensor<string, []>("input_207_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_207_cast_fp16 = gelu(mode = input_207_mode_0, x = input_205_cast_fp16)[name = tensor<string, []>("input_207_cast_fp16")];
            tensor<int32, [2]> var_2904 = const()[name = tensor<string, []>("op_2904"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2906 = const()[name = tensor<string, []>("op_2906"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_139_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_139_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_139_pad_0 = const()[name = tensor<string, []>("pretrained_out_139_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_6_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(229993472))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(233270336))), name = tensor<string, []>("layers_6_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_6_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_6_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(233270464)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_139_cast_fp16 = conv(bias = layers_6_fc2_pretrained_bias_to_fp16, dilations = var_2906, groups = var_2547, pad = pretrained_out_139_pad_0, pad_type = pretrained_out_139_pad_type_0, strides = var_2904, weight = layers_6_fc2_pretrained_weight_to_fp16_palettized, x = input_207_cast_fp16)[name = tensor<string, []>("pretrained_out_139_cast_fp16")];
            tensor<int32, [2]> var_2910 = const()[name = tensor<string, []>("op_2910"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2912 = const()[name = tensor<string, []>("op_2912"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_209_pad_type_0 = const()[name = tensor<string, []>("input_209_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_209_pad_0 = const()[name = tensor<string, []>("input_209_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_6_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_6_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(233273088)))];
            tensor<fp16, [1, 16, 1, 1]> input_209_cast_fp16 = conv(dilations = var_2912, groups = var_2547, pad = input_209_pad_0, pad_type = input_209_pad_type_0, strides = var_2910, weight = layers_6_fc2_loraA_weight_to_fp16, x = input_207_cast_fp16)[name = tensor<string, []>("input_209_cast_fp16")];
            tensor<int32, [2]> var_2916 = const()[name = tensor<string, []>("op_2916"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2918 = const()[name = tensor<string, []>("op_2918"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_277_pad_type_0 = const()[name = tensor<string, []>("lora_out_277_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_277_pad_0 = const()[name = tensor<string, []>("lora_out_277_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_279_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_279_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(233436992)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_279_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_2918, groups = var_2547, pad = lora_out_277_pad_0, pad_type = lora_out_277_pad_type_0, strides = var_2916, weight = lora_out_279_weight_0_to_fp16, x = input_209_cast_fp16)[name = tensor<string, []>("lora_out_279_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_15_cast_fp16 = add(x = pretrained_out_139_cast_fp16, y = lora_out_279_cast_fp16)[name = tensor<string, []>("hidden_states_15_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_43_cast_fp16 = add(x = inputs_41_cast_fp16, y = hidden_states_15_cast_fp16)[name = tensor<string, []>("inputs_43_cast_fp16")];
            tensor<int32, []> var_2934 = const()[name = tensor<string, []>("op_2934"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_2941 = const()[name = tensor<string, []>("op_2941"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_2942 = const()[name = tensor<string, []>("op_2942"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_2954 = const()[name = tensor<string, []>("op_2954"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_43_cast_fp16 = reduce_mean(axes = var_2954, keep_dims = var_2942, x = inputs_43_cast_fp16)[name = tensor<string, []>("channels_mean_43_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_43_cast_fp16 = sub(x = inputs_43_cast_fp16, y = channels_mean_43_cast_fp16)[name = tensor<string, []>("zero_mean_43_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_43_cast_fp16 = mul(x = zero_mean_43_cast_fp16, y = zero_mean_43_cast_fp16)[name = tensor<string, []>("zero_mean_sq_43_cast_fp16")];
            tensor<int32, [1]> var_2958 = const()[name = tensor<string, []>("op_2958"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_2959_cast_fp16 = reduce_mean(axes = var_2958, keep_dims = var_2942, x = zero_mean_sq_43_cast_fp16)[name = tensor<string, []>("op_2959_cast_fp16")];
            tensor<fp16, []> var_2960_to_fp16 = const()[name = tensor<string, []>("op_2960_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_2961_cast_fp16 = add(x = var_2959_cast_fp16, y = var_2960_to_fp16)[name = tensor<string, []>("op_2961_cast_fp16")];
            tensor<fp32, []> denom_43_epsilon_0 = const()[name = tensor<string, []>("denom_43_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_43_cast_fp16 = rsqrt(epsilon = denom_43_epsilon_0, x = var_2961_cast_fp16)[name = tensor<string, []>("denom_43_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_43_cast_fp16 = mul(x = zero_mean_43_cast_fp16, y = denom_43_cast_fp16)[name = tensor<string, []>("out_43_cast_fp16")];
            tensor<fp16, [1280]> obj_99_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_99_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(233478016)))];
            tensor<fp16, [1280]> obj_99_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_99_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(233480640)))];
            tensor<fp16, []> obj_99_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_99_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_99_cast_fp16 = batch_norm(beta = obj_99_beta_0_to_fp16, epsilon = obj_99_epsilon_0_to_fp16, gamma = obj_99_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_43_cast_fp16)[name = tensor<string, []>("obj_99_cast_fp16")];
            tensor<int32, [2]> var_2979 = const()[name = tensor<string, []>("op_2979"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2981 = const()[name = tensor<string, []>("op_2981"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_141_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_141_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_141_pad_0 = const()[name = tensor<string, []>("pretrained_out_141_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_7_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(233483264))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(234302528))), name = tensor<string, []>("layers_7_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_7_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_7_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(234302656)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_141_cast_fp16 = conv(bias = layers_7_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_2981, groups = var_2941, pad = pretrained_out_141_pad_0, pad_type = pretrained_out_141_pad_type_0, strides = var_2979, weight = layers_7_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_99_cast_fp16)[name = tensor<string, []>("pretrained_out_141_cast_fp16")];
            tensor<int32, [2]> var_2985 = const()[name = tensor<string, []>("op_2985"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2987 = const()[name = tensor<string, []>("op_2987"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_211_pad_type_0 = const()[name = tensor<string, []>("input_211_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_211_pad_0 = const()[name = tensor<string, []>("input_211_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_7_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_7_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(234305280)))];
            tensor<fp16, [1, 16, 1, 1]> input_211_cast_fp16 = conv(dilations = var_2987, groups = var_2941, pad = input_211_pad_0, pad_type = input_211_pad_type_0, strides = var_2985, weight = layers_7_self_attn_q_proj_loraA_weight_to_fp16, x = obj_99_cast_fp16)[name = tensor<string, []>("input_211_cast_fp16")];
            tensor<int32, [2]> var_2991 = const()[name = tensor<string, []>("op_2991"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_2993 = const()[name = tensor<string, []>("op_2993"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_281_pad_type_0 = const()[name = tensor<string, []>("lora_out_281_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_281_pad_0 = const()[name = tensor<string, []>("lora_out_281_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_283_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_283_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(234346304)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_283_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_2993, groups = var_2941, pad = lora_out_281_pad_0, pad_type = lora_out_281_pad_type_0, strides = var_2991, weight = lora_out_283_weight_0_to_fp16, x = input_211_cast_fp16)[name = tensor<string, []>("lora_out_283_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_29_cast_fp16 = add(x = pretrained_out_141_cast_fp16, y = lora_out_283_cast_fp16)[name = tensor<string, []>("query_29_cast_fp16")];
            tensor<int32, [2]> var_3003 = const()[name = tensor<string, []>("op_3003"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3005 = const()[name = tensor<string, []>("op_3005"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_143_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_143_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_143_pad_0 = const()[name = tensor<string, []>("pretrained_out_143_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_7_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(234387328))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(235206592))), name = tensor<string, []>("layers_7_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_143_cast_fp16 = conv(dilations = var_3005, groups = var_2941, pad = pretrained_out_143_pad_0, pad_type = pretrained_out_143_pad_type_0, strides = var_3003, weight = layers_7_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_99_cast_fp16)[name = tensor<string, []>("pretrained_out_143_cast_fp16")];
            tensor<int32, [2]> var_3009 = const()[name = tensor<string, []>("op_3009"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3011 = const()[name = tensor<string, []>("op_3011"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_213_pad_type_0 = const()[name = tensor<string, []>("input_213_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_213_pad_0 = const()[name = tensor<string, []>("input_213_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_7_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_7_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(235206720)))];
            tensor<fp16, [1, 16, 1, 1]> input_213_cast_fp16 = conv(dilations = var_3011, groups = var_2941, pad = input_213_pad_0, pad_type = input_213_pad_type_0, strides = var_3009, weight = layers_7_self_attn_k_proj_loraA_weight_to_fp16, x = obj_99_cast_fp16)[name = tensor<string, []>("input_213_cast_fp16")];
            tensor<int32, [2]> var_3015 = const()[name = tensor<string, []>("op_3015"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3017 = const()[name = tensor<string, []>("op_3017"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_285_pad_type_0 = const()[name = tensor<string, []>("lora_out_285_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_285_pad_0 = const()[name = tensor<string, []>("lora_out_285_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_287_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_287_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(235247744)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_287_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_3017, groups = var_2941, pad = lora_out_285_pad_0, pad_type = lora_out_285_pad_type_0, strides = var_3015, weight = lora_out_287_weight_0_to_fp16, x = input_213_cast_fp16)[name = tensor<string, []>("lora_out_287_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_15_cast_fp16 = add(x = pretrained_out_143_cast_fp16, y = lora_out_287_cast_fp16)[name = tensor<string, []>("current_key_15_cast_fp16")];
            tensor<int32, [2]> var_3028 = const()[name = tensor<string, []>("op_3028"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3030 = const()[name = tensor<string, []>("op_3030"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_145_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_145_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_145_pad_0 = const()[name = tensor<string, []>("pretrained_out_145_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_7_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(235288768))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(236108032))), name = tensor<string, []>("layers_7_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_7_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_7_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(236108160)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_145_cast_fp16 = conv(bias = layers_7_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_3030, groups = var_2941, pad = pretrained_out_145_pad_0, pad_type = pretrained_out_145_pad_type_0, strides = var_3028, weight = layers_7_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_99_cast_fp16)[name = tensor<string, []>("pretrained_out_145_cast_fp16")];
            tensor<int32, [2]> var_3034 = const()[name = tensor<string, []>("op_3034"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3036 = const()[name = tensor<string, []>("op_3036"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_215_pad_type_0 = const()[name = tensor<string, []>("input_215_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_215_pad_0 = const()[name = tensor<string, []>("input_215_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_7_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_7_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(236110784)))];
            tensor<fp16, [1, 16, 1, 1]> input_215_cast_fp16 = conv(dilations = var_3036, groups = var_2941, pad = input_215_pad_0, pad_type = input_215_pad_type_0, strides = var_3034, weight = layers_7_self_attn_v_proj_loraA_weight_to_fp16, x = obj_99_cast_fp16)[name = tensor<string, []>("input_215_cast_fp16")];
            tensor<int32, [2]> var_3040 = const()[name = tensor<string, []>("op_3040"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3042 = const()[name = tensor<string, []>("op_3042"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_289_pad_type_0 = const()[name = tensor<string, []>("lora_out_289_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_289_pad_0 = const()[name = tensor<string, []>("lora_out_289_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_291_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_291_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(236151808)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_291_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_3042, groups = var_2941, pad = lora_out_289_pad_0, pad_type = lora_out_289_pad_type_0, strides = var_3040, weight = lora_out_291_weight_0_to_fp16, x = input_215_cast_fp16)[name = tensor<string, []>("lora_out_291_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_15_cast_fp16 = add(x = pretrained_out_145_cast_fp16, y = lora_out_291_cast_fp16)[name = tensor<string, []>("current_value_15_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_3052_cast_fp16 = mul(x = current_key_15_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_3052_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_3054_cast_fp16 = mul(x = var_103_cast_fp16_7, y = var_295_cast_fp16)[name = tensor<string, []>("op_3054_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_29_cast_fp16 = add(x = var_3052_cast_fp16, y = var_3054_cast_fp16)[name = tensor<string, []>("key_29_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_3056_cast_fp16 = mul(x = current_value_15_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_3056_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_3058_cast_fp16 = mul(x = var_138_cast_fp16_7, y = var_295_cast_fp16)[name = tensor<string, []>("op_3058_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_29_cast_fp16 = add(x = var_3056_cast_fp16, y = var_3058_cast_fp16)[name = tensor<string, []>("value_29_cast_fp16")];
            tensor<int32, [4]> var_3061 = const()[name = tensor<string, []>("op_3061"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_3062_cast_fp16 = reshape(shape = var_3061, x = query_29_cast_fp16)[name = tensor<string, []>("op_3062_cast_fp16")];
            tensor<fp16, []> var_3063_to_fp16 = const()[name = tensor<string, []>("op_3063_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_3064_cast_fp16 = mul(x = var_3062_cast_fp16, y = var_3063_to_fp16)[name = tensor<string, []>("op_3064_cast_fp16")];
            tensor<int32, [4]> var_3065 = const()[name = tensor<string, []>("op_3065"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_3066_cast_fp16 = reshape(shape = var_3065, x = key_29_cast_fp16)[name = tensor<string, []>("op_3066_cast_fp16")];
            tensor<bool, []> mh_w_43_transpose_x_0 = const()[name = tensor<string, []>("mh_w_43_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_43_transpose_y_0 = const()[name = tensor<string, []>("mh_w_43_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_43_cast_fp16 = matmul(transpose_x = mh_w_43_transpose_x_0, transpose_y = mh_w_43_transpose_y_0, x = var_3064_cast_fp16, y = var_3066_cast_fp16)[name = tensor<string, []>("mh_w_43_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_45_cast_fp16 = add(x = mh_w_43_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_45_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_3074_cast_fp16 = softmax(axis = var_2934, x = mh_w_45_cast_fp16)[name = tensor<string, []>("op_3074_cast_fp16")];
            tensor<int32, [4]> var_3075 = const()[name = tensor<string, []>("op_3075"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_3076_cast_fp16 = reshape(shape = var_3075, x = value_29_cast_fp16)[name = tensor<string, []>("op_3076_cast_fp16")];
            tensor<bool, []> attn_29_transpose_x_0 = const()[name = tensor<string, []>("attn_29_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_29_transpose_y_0 = const()[name = tensor<string, []>("attn_29_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_29_cast_fp16 = matmul(transpose_x = attn_29_transpose_x_0, transpose_y = attn_29_transpose_y_0, x = var_3076_cast_fp16, y = var_3074_cast_fp16)[name = tensor<string, []>("attn_29_cast_fp16")];
            tensor<int32, [4]> var_3079 = const()[name = tensor<string, []>("op_3079"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_217_cast_fp16 = reshape(shape = var_3079, x = attn_29_cast_fp16)[name = tensor<string, []>("input_217_cast_fp16")];
            tensor<int32, [2]> var_3086 = const()[name = tensor<string, []>("op_3086"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3088 = const()[name = tensor<string, []>("op_3088"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_147_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_147_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_147_pad_0 = const()[name = tensor<string, []>("pretrained_out_147_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_7_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(236192832))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(237012096))), name = tensor<string, []>("layers_7_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_7_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_7_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(237012224)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_147_cast_fp16 = conv(bias = layers_7_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_3088, groups = var_2941, pad = pretrained_out_147_pad_0, pad_type = pretrained_out_147_pad_type_0, strides = var_3086, weight = layers_7_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_217_cast_fp16)[name = tensor<string, []>("pretrained_out_147_cast_fp16")];
            tensor<int32, [2]> var_3092 = const()[name = tensor<string, []>("op_3092"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3094 = const()[name = tensor<string, []>("op_3094"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_219_pad_type_0 = const()[name = tensor<string, []>("input_219_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_219_pad_0 = const()[name = tensor<string, []>("input_219_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_7_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_7_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(237014848)))];
            tensor<fp16, [1, 16, 1, 1]> input_219_cast_fp16 = conv(dilations = var_3094, groups = var_2941, pad = input_219_pad_0, pad_type = input_219_pad_type_0, strides = var_3092, weight = layers_7_self_attn_o_proj_loraA_weight_to_fp16, x = input_217_cast_fp16)[name = tensor<string, []>("input_219_cast_fp16")];
            tensor<int32, [2]> var_3098 = const()[name = tensor<string, []>("op_3098"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3100 = const()[name = tensor<string, []>("op_3100"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_293_pad_type_0 = const()[name = tensor<string, []>("lora_out_293_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_293_pad_0 = const()[name = tensor<string, []>("lora_out_293_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_295_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_295_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(237055872)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_295_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_3100, groups = var_2941, pad = lora_out_293_pad_0, pad_type = lora_out_293_pad_type_0, strides = var_3098, weight = lora_out_295_weight_0_to_fp16, x = input_219_cast_fp16)[name = tensor<string, []>("lora_out_295_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_105_cast_fp16 = add(x = pretrained_out_147_cast_fp16, y = lora_out_295_cast_fp16)[name = tensor<string, []>("obj_105_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_45_cast_fp16 = add(x = inputs_43_cast_fp16, y = obj_105_cast_fp16)[name = tensor<string, []>("inputs_45_cast_fp16")];
            tensor<int32, [1]> var_3113 = const()[name = tensor<string, []>("op_3113"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_45_cast_fp16 = reduce_mean(axes = var_3113, keep_dims = var_2942, x = inputs_45_cast_fp16)[name = tensor<string, []>("channels_mean_45_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_45_cast_fp16 = sub(x = inputs_45_cast_fp16, y = channels_mean_45_cast_fp16)[name = tensor<string, []>("zero_mean_45_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_45_cast_fp16 = mul(x = zero_mean_45_cast_fp16, y = zero_mean_45_cast_fp16)[name = tensor<string, []>("zero_mean_sq_45_cast_fp16")];
            tensor<int32, [1]> var_3117 = const()[name = tensor<string, []>("op_3117"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_3118_cast_fp16 = reduce_mean(axes = var_3117, keep_dims = var_2942, x = zero_mean_sq_45_cast_fp16)[name = tensor<string, []>("op_3118_cast_fp16")];
            tensor<fp16, []> var_3119_to_fp16 = const()[name = tensor<string, []>("op_3119_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_3120_cast_fp16 = add(x = var_3118_cast_fp16, y = var_3119_to_fp16)[name = tensor<string, []>("op_3120_cast_fp16")];
            tensor<fp32, []> denom_45_epsilon_0 = const()[name = tensor<string, []>("denom_45_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_45_cast_fp16 = rsqrt(epsilon = denom_45_epsilon_0, x = var_3120_cast_fp16)[name = tensor<string, []>("denom_45_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_45_cast_fp16 = mul(x = zero_mean_45_cast_fp16, y = denom_45_cast_fp16)[name = tensor<string, []>("out_45_cast_fp16")];
            tensor<fp16, [1280]> obj_107_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_107_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(237096896)))];
            tensor<fp16, [1280]> obj_107_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_107_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(237099520)))];
            tensor<fp16, []> obj_107_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_107_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_107_cast_fp16 = batch_norm(beta = obj_107_beta_0_to_fp16, epsilon = obj_107_epsilon_0_to_fp16, gamma = obj_107_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_45_cast_fp16)[name = tensor<string, []>("obj_107_cast_fp16")];
            tensor<int32, [2]> var_3138 = const()[name = tensor<string, []>("op_3138"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3140 = const()[name = tensor<string, []>("op_3140"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_149_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_149_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_149_pad_0 = const()[name = tensor<string, []>("pretrained_out_149_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_7_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(237102144))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(237921408))), name = tensor<string, []>("layers_7_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_7_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_7_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(237921536)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_149_cast_fp16 = conv(bias = layers_7_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_3140, groups = var_2941, pad = pretrained_out_149_pad_0, pad_type = pretrained_out_149_pad_type_0, strides = var_3138, weight = layers_7_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_107_cast_fp16)[name = tensor<string, []>("pretrained_out_149_cast_fp16")];
            tensor<int32, [2]> var_3144 = const()[name = tensor<string, []>("op_3144"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3146 = const()[name = tensor<string, []>("op_3146"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_221_pad_type_0 = const()[name = tensor<string, []>("input_221_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_221_pad_0 = const()[name = tensor<string, []>("input_221_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_7_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_7_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(237924160)))];
            tensor<fp16, [1, 16, 1, 1]> input_221_cast_fp16 = conv(dilations = var_3146, groups = var_2941, pad = input_221_pad_0, pad_type = input_221_pad_type_0, strides = var_3144, weight = layers_7_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_107_cast_fp16)[name = tensor<string, []>("input_221_cast_fp16")];
            tensor<int32, [2]> var_3150 = const()[name = tensor<string, []>("op_3150"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3152 = const()[name = tensor<string, []>("op_3152"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_297_pad_type_0 = const()[name = tensor<string, []>("lora_out_297_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_297_pad_0 = const()[name = tensor<string, []>("lora_out_297_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_299_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_299_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(237965184)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_299_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_3152, groups = var_2941, pad = lora_out_297_pad_0, pad_type = lora_out_297_pad_type_0, strides = var_3150, weight = lora_out_299_weight_0_to_fp16, x = input_221_cast_fp16)[name = tensor<string, []>("lora_out_299_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_31_cast_fp16 = add(x = pretrained_out_149_cast_fp16, y = lora_out_299_cast_fp16)[name = tensor<string, []>("query_31_cast_fp16")];
            tensor<int32, [2]> var_3162 = const()[name = tensor<string, []>("op_3162"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3164 = const()[name = tensor<string, []>("op_3164"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_151_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_151_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_151_pad_0 = const()[name = tensor<string, []>("pretrained_out_151_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_7_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(238006208))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(238825472))), name = tensor<string, []>("layers_7_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_151_cast_fp16 = conv(dilations = var_3164, groups = var_2941, pad = pretrained_out_151_pad_0, pad_type = pretrained_out_151_pad_type_0, strides = var_3162, weight = layers_7_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_151_cast_fp16")];
            tensor<int32, [2]> var_3168 = const()[name = tensor<string, []>("op_3168"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3170 = const()[name = tensor<string, []>("op_3170"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_223_pad_type_0 = const()[name = tensor<string, []>("input_223_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_223_pad_0 = const()[name = tensor<string, []>("input_223_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_7_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_7_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(238825600)))];
            tensor<fp16, [1, 16, 1, 1500]> input_223_cast_fp16 = conv(dilations = var_3170, groups = var_2941, pad = input_223_pad_0, pad_type = input_223_pad_type_0, strides = var_3168, weight = layers_7_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_223_cast_fp16")];
            tensor<int32, [2]> var_3174 = const()[name = tensor<string, []>("op_3174"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3176 = const()[name = tensor<string, []>("op_3176"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_301_pad_type_0 = const()[name = tensor<string, []>("lora_out_301_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_301_pad_0 = const()[name = tensor<string, []>("lora_out_301_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_303_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_303_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(238866624)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_303_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_3176, groups = var_2941, pad = lora_out_301_pad_0, pad_type = lora_out_301_pad_type_0, strides = var_3174, weight = lora_out_303_weight_0_to_fp16, x = input_223_cast_fp16)[name = tensor<string, []>("lora_out_303_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_31_cast_fp16 = add(x = pretrained_out_151_cast_fp16, y = lora_out_303_cast_fp16)[name = tensor<string, []>("key_31_cast_fp16")];
            tensor<int32, [2]> var_3187 = const()[name = tensor<string, []>("op_3187"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3189 = const()[name = tensor<string, []>("op_3189"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_153_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_153_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_153_pad_0 = const()[name = tensor<string, []>("pretrained_out_153_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_7_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(238907648))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(239726912))), name = tensor<string, []>("layers_7_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_7_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_7_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(239727040)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_153_cast_fp16 = conv(bias = layers_7_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_3189, groups = var_2941, pad = pretrained_out_153_pad_0, pad_type = pretrained_out_153_pad_type_0, strides = var_3187, weight = layers_7_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_153_cast_fp16")];
            tensor<int32, [2]> var_3193 = const()[name = tensor<string, []>("op_3193"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3195 = const()[name = tensor<string, []>("op_3195"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_225_pad_type_0 = const()[name = tensor<string, []>("input_225_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_225_pad_0 = const()[name = tensor<string, []>("input_225_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_7_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_7_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(239729664)))];
            tensor<fp16, [1, 16, 1, 1500]> input_225_cast_fp16 = conv(dilations = var_3195, groups = var_2941, pad = input_225_pad_0, pad_type = input_225_pad_type_0, strides = var_3193, weight = layers_7_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_225_cast_fp16")];
            tensor<int32, [2]> var_3199 = const()[name = tensor<string, []>("op_3199"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3201 = const()[name = tensor<string, []>("op_3201"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_305_pad_type_0 = const()[name = tensor<string, []>("lora_out_305_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_305_pad_0 = const()[name = tensor<string, []>("lora_out_305_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_307_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_307_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(239770688)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_307_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_3201, groups = var_2941, pad = lora_out_305_pad_0, pad_type = lora_out_305_pad_type_0, strides = var_3199, weight = lora_out_307_weight_0_to_fp16, x = input_225_cast_fp16)[name = tensor<string, []>("lora_out_307_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_31_cast_fp16 = add(x = pretrained_out_153_cast_fp16, y = lora_out_307_cast_fp16)[name = tensor<string, []>("value_31_cast_fp16")];
            tensor<int32, [4]> var_3208 = const()[name = tensor<string, []>("op_3208"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_3209_cast_fp16 = reshape(shape = var_3208, x = query_31_cast_fp16)[name = tensor<string, []>("op_3209_cast_fp16")];
            tensor<fp16, []> var_3210_to_fp16 = const()[name = tensor<string, []>("op_3210_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_3211_cast_fp16 = mul(x = var_3209_cast_fp16, y = var_3210_to_fp16)[name = tensor<string, []>("op_3211_cast_fp16")];
            tensor<int32, [4]> var_3212 = const()[name = tensor<string, []>("op_3212"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_3213_cast_fp16 = reshape(shape = var_3212, x = key_31_cast_fp16)[name = tensor<string, []>("op_3213_cast_fp16")];
            tensor<bool, []> mh_w_47_transpose_x_0 = const()[name = tensor<string, []>("mh_w_47_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_47_transpose_y_0 = const()[name = tensor<string, []>("mh_w_47_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_47_cast_fp16 = matmul(transpose_x = mh_w_47_transpose_x_0, transpose_y = mh_w_47_transpose_y_0, x = var_3211_cast_fp16, y = var_3213_cast_fp16)[name = tensor<string, []>("mh_w_47_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_111_cast_fp16 = softmax(axis = var_2934, x = mh_w_47_cast_fp16)[name = tensor<string, []>("obj_111_cast_fp16")];
            tensor<int32, [4]> var_3217 = const()[name = tensor<string, []>("op_3217"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_3218_cast_fp16 = reshape(shape = var_3217, x = value_31_cast_fp16)[name = tensor<string, []>("op_3218_cast_fp16")];
            tensor<bool, []> attn_31_transpose_x_0 = const()[name = tensor<string, []>("attn_31_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_31_transpose_y_0 = const()[name = tensor<string, []>("attn_31_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_31_cast_fp16 = matmul(transpose_x = attn_31_transpose_x_0, transpose_y = attn_31_transpose_y_0, x = var_3218_cast_fp16, y = obj_111_cast_fp16)[name = tensor<string, []>("attn_31_cast_fp16")];
            tensor<int32, [4]> var_3221 = const()[name = tensor<string, []>("op_3221"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_227_cast_fp16 = reshape(shape = var_3221, x = attn_31_cast_fp16)[name = tensor<string, []>("input_227_cast_fp16")];
            tensor<int32, [2]> var_3228 = const()[name = tensor<string, []>("op_3228"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3230 = const()[name = tensor<string, []>("op_3230"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_155_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_155_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_155_pad_0 = const()[name = tensor<string, []>("pretrained_out_155_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_7_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(239811712))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(240630976))), name = tensor<string, []>("layers_7_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_7_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_7_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(240631104)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_155_cast_fp16 = conv(bias = layers_7_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_3230, groups = var_2941, pad = pretrained_out_155_pad_0, pad_type = pretrained_out_155_pad_type_0, strides = var_3228, weight = layers_7_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_227_cast_fp16)[name = tensor<string, []>("pretrained_out_155_cast_fp16")];
            tensor<int32, [2]> var_3234 = const()[name = tensor<string, []>("op_3234"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3236 = const()[name = tensor<string, []>("op_3236"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_229_pad_type_0 = const()[name = tensor<string, []>("input_229_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_229_pad_0 = const()[name = tensor<string, []>("input_229_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_7_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_7_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(240633728)))];
            tensor<fp16, [1, 16, 1, 1]> input_229_cast_fp16 = conv(dilations = var_3236, groups = var_2941, pad = input_229_pad_0, pad_type = input_229_pad_type_0, strides = var_3234, weight = layers_7_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_227_cast_fp16)[name = tensor<string, []>("input_229_cast_fp16")];
            tensor<int32, [2]> var_3240 = const()[name = tensor<string, []>("op_3240"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3242 = const()[name = tensor<string, []>("op_3242"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_309_pad_type_0 = const()[name = tensor<string, []>("lora_out_309_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_309_pad_0 = const()[name = tensor<string, []>("lora_out_309_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_311_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_311_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(240674752)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_311_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_3242, groups = var_2941, pad = lora_out_309_pad_0, pad_type = lora_out_309_pad_type_0, strides = var_3240, weight = lora_out_311_weight_0_to_fp16, x = input_229_cast_fp16)[name = tensor<string, []>("lora_out_311_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_109_cast_fp16 = add(x = pretrained_out_155_cast_fp16, y = lora_out_311_cast_fp16)[name = tensor<string, []>("obj_109_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_47_cast_fp16 = add(x = inputs_45_cast_fp16, y = obj_109_cast_fp16)[name = tensor<string, []>("inputs_47_cast_fp16")];
            tensor<int32, [1]> var_3254 = const()[name = tensor<string, []>("op_3254"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_47_cast_fp16 = reduce_mean(axes = var_3254, keep_dims = var_2942, x = inputs_47_cast_fp16)[name = tensor<string, []>("channels_mean_47_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_47_cast_fp16 = sub(x = inputs_47_cast_fp16, y = channels_mean_47_cast_fp16)[name = tensor<string, []>("zero_mean_47_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_47_cast_fp16 = mul(x = zero_mean_47_cast_fp16, y = zero_mean_47_cast_fp16)[name = tensor<string, []>("zero_mean_sq_47_cast_fp16")];
            tensor<int32, [1]> var_3258 = const()[name = tensor<string, []>("op_3258"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_3259_cast_fp16 = reduce_mean(axes = var_3258, keep_dims = var_2942, x = zero_mean_sq_47_cast_fp16)[name = tensor<string, []>("op_3259_cast_fp16")];
            tensor<fp16, []> var_3260_to_fp16 = const()[name = tensor<string, []>("op_3260_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_3261_cast_fp16 = add(x = var_3259_cast_fp16, y = var_3260_to_fp16)[name = tensor<string, []>("op_3261_cast_fp16")];
            tensor<fp32, []> denom_47_epsilon_0 = const()[name = tensor<string, []>("denom_47_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_47_cast_fp16 = rsqrt(epsilon = denom_47_epsilon_0, x = var_3261_cast_fp16)[name = tensor<string, []>("denom_47_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_47_cast_fp16 = mul(x = zero_mean_47_cast_fp16, y = denom_47_cast_fp16)[name = tensor<string, []>("out_47_cast_fp16")];
            tensor<fp16, [1280]> input_231_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_231_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(240715776)))];
            tensor<fp16, [1280]> input_231_beta_0_to_fp16 = const()[name = tensor<string, []>("input_231_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(240718400)))];
            tensor<fp16, []> input_231_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_231_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_231_cast_fp16 = batch_norm(beta = input_231_beta_0_to_fp16, epsilon = input_231_epsilon_0_to_fp16, gamma = input_231_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_47_cast_fp16)[name = tensor<string, []>("input_231_cast_fp16")];
            tensor<int32, [2]> var_3275 = const()[name = tensor<string, []>("op_3275"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3277 = const()[name = tensor<string, []>("op_3277"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_157_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_157_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_157_pad_0 = const()[name = tensor<string, []>("pretrained_out_157_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_7_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(240721024))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(243997888))), name = tensor<string, []>("layers_7_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_7_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_7_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(243998016)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_157_cast_fp16 = conv(bias = layers_7_fc1_pretrained_bias_to_fp16, dilations = var_3277, groups = var_2941, pad = pretrained_out_157_pad_0, pad_type = pretrained_out_157_pad_type_0, strides = var_3275, weight = layers_7_fc1_pretrained_weight_to_fp16_palettized, x = input_231_cast_fp16)[name = tensor<string, []>("pretrained_out_157_cast_fp16")];
            tensor<int32, [2]> var_3281 = const()[name = tensor<string, []>("op_3281"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3283 = const()[name = tensor<string, []>("op_3283"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_233_pad_type_0 = const()[name = tensor<string, []>("input_233_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_233_pad_0 = const()[name = tensor<string, []>("input_233_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_7_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_7_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(244008320)))];
            tensor<fp16, [1, 16, 1, 1]> input_233_cast_fp16 = conv(dilations = var_3283, groups = var_2941, pad = input_233_pad_0, pad_type = input_233_pad_type_0, strides = var_3281, weight = layers_7_fc1_loraA_weight_to_fp16, x = input_231_cast_fp16)[name = tensor<string, []>("input_233_cast_fp16")];
            tensor<int32, [2]> var_3287 = const()[name = tensor<string, []>("op_3287"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3289 = const()[name = tensor<string, []>("op_3289"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_313_pad_type_0 = const()[name = tensor<string, []>("lora_out_313_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_313_pad_0 = const()[name = tensor<string, []>("lora_out_313_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_315_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_315_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(244049344)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_315_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_3289, groups = var_2941, pad = lora_out_313_pad_0, pad_type = lora_out_313_pad_type_0, strides = var_3287, weight = lora_out_315_weight_0_to_fp16, x = input_233_cast_fp16)[name = tensor<string, []>("lora_out_315_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_235_cast_fp16 = add(x = pretrained_out_157_cast_fp16, y = lora_out_315_cast_fp16)[name = tensor<string, []>("input_235_cast_fp16")];
            tensor<string, []> input_237_mode_0 = const()[name = tensor<string, []>("input_237_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_237_cast_fp16 = gelu(mode = input_237_mode_0, x = input_235_cast_fp16)[name = tensor<string, []>("input_237_cast_fp16")];
            tensor<int32, [2]> var_3301 = const()[name = tensor<string, []>("op_3301"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3303 = const()[name = tensor<string, []>("op_3303"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_159_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_159_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_159_pad_0 = const()[name = tensor<string, []>("pretrained_out_159_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_7_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(244213248))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(247490112))), name = tensor<string, []>("layers_7_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_7_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_7_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(247490240)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_159_cast_fp16 = conv(bias = layers_7_fc2_pretrained_bias_to_fp16, dilations = var_3303, groups = var_2941, pad = pretrained_out_159_pad_0, pad_type = pretrained_out_159_pad_type_0, strides = var_3301, weight = layers_7_fc2_pretrained_weight_to_fp16_palettized, x = input_237_cast_fp16)[name = tensor<string, []>("pretrained_out_159_cast_fp16")];
            tensor<int32, [2]> var_3307 = const()[name = tensor<string, []>("op_3307"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3309 = const()[name = tensor<string, []>("op_3309"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_239_pad_type_0 = const()[name = tensor<string, []>("input_239_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_239_pad_0 = const()[name = tensor<string, []>("input_239_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_7_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_7_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(247492864)))];
            tensor<fp16, [1, 16, 1, 1]> input_239_cast_fp16 = conv(dilations = var_3309, groups = var_2941, pad = input_239_pad_0, pad_type = input_239_pad_type_0, strides = var_3307, weight = layers_7_fc2_loraA_weight_to_fp16, x = input_237_cast_fp16)[name = tensor<string, []>("input_239_cast_fp16")];
            tensor<int32, [2]> var_3313 = const()[name = tensor<string, []>("op_3313"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3315 = const()[name = tensor<string, []>("op_3315"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_317_pad_type_0 = const()[name = tensor<string, []>("lora_out_317_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_317_pad_0 = const()[name = tensor<string, []>("lora_out_317_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_319_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_319_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(247656768)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_319_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_3315, groups = var_2941, pad = lora_out_317_pad_0, pad_type = lora_out_317_pad_type_0, strides = var_3313, weight = lora_out_319_weight_0_to_fp16, x = input_239_cast_fp16)[name = tensor<string, []>("lora_out_319_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_17_cast_fp16 = add(x = pretrained_out_159_cast_fp16, y = lora_out_319_cast_fp16)[name = tensor<string, []>("hidden_states_17_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_49_cast_fp16 = add(x = inputs_47_cast_fp16, y = hidden_states_17_cast_fp16)[name = tensor<string, []>("inputs_49_cast_fp16")];
            tensor<int32, []> var_3332 = const()[name = tensor<string, []>("op_3332"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_3339 = const()[name = tensor<string, []>("op_3339"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_3340 = const()[name = tensor<string, []>("op_3340"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_3352 = const()[name = tensor<string, []>("op_3352"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_49_cast_fp16 = reduce_mean(axes = var_3352, keep_dims = var_3340, x = inputs_49_cast_fp16)[name = tensor<string, []>("channels_mean_49_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_49_cast_fp16 = sub(x = inputs_49_cast_fp16, y = channels_mean_49_cast_fp16)[name = tensor<string, []>("zero_mean_49_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_49_cast_fp16 = mul(x = zero_mean_49_cast_fp16, y = zero_mean_49_cast_fp16)[name = tensor<string, []>("zero_mean_sq_49_cast_fp16")];
            tensor<int32, [1]> var_3356 = const()[name = tensor<string, []>("op_3356"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_3357_cast_fp16 = reduce_mean(axes = var_3356, keep_dims = var_3340, x = zero_mean_sq_49_cast_fp16)[name = tensor<string, []>("op_3357_cast_fp16")];
            tensor<fp16, []> var_3358_to_fp16 = const()[name = tensor<string, []>("op_3358_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_3359_cast_fp16 = add(x = var_3357_cast_fp16, y = var_3358_to_fp16)[name = tensor<string, []>("op_3359_cast_fp16")];
            tensor<fp32, []> denom_49_epsilon_0 = const()[name = tensor<string, []>("denom_49_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_49_cast_fp16 = rsqrt(epsilon = denom_49_epsilon_0, x = var_3359_cast_fp16)[name = tensor<string, []>("denom_49_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_49_cast_fp16 = mul(x = zero_mean_49_cast_fp16, y = denom_49_cast_fp16)[name = tensor<string, []>("out_49_cast_fp16")];
            tensor<fp16, [1280]> obj_113_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_113_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(247697792)))];
            tensor<fp16, [1280]> obj_113_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_113_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(247700416)))];
            tensor<fp16, []> obj_113_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_113_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_113_cast_fp16 = batch_norm(beta = obj_113_beta_0_to_fp16, epsilon = obj_113_epsilon_0_to_fp16, gamma = obj_113_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_49_cast_fp16)[name = tensor<string, []>("obj_113_cast_fp16")];
            tensor<int32, [2]> var_3377 = const()[name = tensor<string, []>("op_3377"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3379 = const()[name = tensor<string, []>("op_3379"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_161_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_161_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_161_pad_0 = const()[name = tensor<string, []>("pretrained_out_161_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_8_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(247703040))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(248522304))), name = tensor<string, []>("layers_8_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_8_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_8_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(248522432)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_161_cast_fp16 = conv(bias = layers_8_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_3379, groups = var_3339, pad = pretrained_out_161_pad_0, pad_type = pretrained_out_161_pad_type_0, strides = var_3377, weight = layers_8_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_113_cast_fp16)[name = tensor<string, []>("pretrained_out_161_cast_fp16")];
            tensor<int32, [2]> var_3383 = const()[name = tensor<string, []>("op_3383"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3385 = const()[name = tensor<string, []>("op_3385"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_241_pad_type_0 = const()[name = tensor<string, []>("input_241_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_241_pad_0 = const()[name = tensor<string, []>("input_241_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_8_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_8_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(248525056)))];
            tensor<fp16, [1, 16, 1, 1]> input_241_cast_fp16 = conv(dilations = var_3385, groups = var_3339, pad = input_241_pad_0, pad_type = input_241_pad_type_0, strides = var_3383, weight = layers_8_self_attn_q_proj_loraA_weight_to_fp16, x = obj_113_cast_fp16)[name = tensor<string, []>("input_241_cast_fp16")];
            tensor<int32, [2]> var_3389 = const()[name = tensor<string, []>("op_3389"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3391 = const()[name = tensor<string, []>("op_3391"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_321_pad_type_0 = const()[name = tensor<string, []>("lora_out_321_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_321_pad_0 = const()[name = tensor<string, []>("lora_out_321_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_323_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_323_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(248566080)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_323_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_3391, groups = var_3339, pad = lora_out_321_pad_0, pad_type = lora_out_321_pad_type_0, strides = var_3389, weight = lora_out_323_weight_0_to_fp16, x = input_241_cast_fp16)[name = tensor<string, []>("lora_out_323_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_33_cast_fp16 = add(x = pretrained_out_161_cast_fp16, y = lora_out_323_cast_fp16)[name = tensor<string, []>("query_33_cast_fp16")];
            tensor<int32, [2]> var_3401 = const()[name = tensor<string, []>("op_3401"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3403 = const()[name = tensor<string, []>("op_3403"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_163_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_163_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_163_pad_0 = const()[name = tensor<string, []>("pretrained_out_163_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_8_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(248607104))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(249426368))), name = tensor<string, []>("layers_8_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_163_cast_fp16 = conv(dilations = var_3403, groups = var_3339, pad = pretrained_out_163_pad_0, pad_type = pretrained_out_163_pad_type_0, strides = var_3401, weight = layers_8_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_113_cast_fp16)[name = tensor<string, []>("pretrained_out_163_cast_fp16")];
            tensor<int32, [2]> var_3407 = const()[name = tensor<string, []>("op_3407"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3409 = const()[name = tensor<string, []>("op_3409"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_243_pad_type_0 = const()[name = tensor<string, []>("input_243_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_243_pad_0 = const()[name = tensor<string, []>("input_243_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_8_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_8_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(249426496)))];
            tensor<fp16, [1, 16, 1, 1]> input_243_cast_fp16 = conv(dilations = var_3409, groups = var_3339, pad = input_243_pad_0, pad_type = input_243_pad_type_0, strides = var_3407, weight = layers_8_self_attn_k_proj_loraA_weight_to_fp16, x = obj_113_cast_fp16)[name = tensor<string, []>("input_243_cast_fp16")];
            tensor<int32, [2]> var_3413 = const()[name = tensor<string, []>("op_3413"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3415 = const()[name = tensor<string, []>("op_3415"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_325_pad_type_0 = const()[name = tensor<string, []>("lora_out_325_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_325_pad_0 = const()[name = tensor<string, []>("lora_out_325_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_327_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_327_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(249467520)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_327_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_3415, groups = var_3339, pad = lora_out_325_pad_0, pad_type = lora_out_325_pad_type_0, strides = var_3413, weight = lora_out_327_weight_0_to_fp16, x = input_243_cast_fp16)[name = tensor<string, []>("lora_out_327_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_17_cast_fp16 = add(x = pretrained_out_163_cast_fp16, y = lora_out_327_cast_fp16)[name = tensor<string, []>("current_key_17_cast_fp16")];
            tensor<int32, [2]> var_3426 = const()[name = tensor<string, []>("op_3426"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3428 = const()[name = tensor<string, []>("op_3428"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_165_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_165_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_165_pad_0 = const()[name = tensor<string, []>("pretrained_out_165_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_8_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(249508544))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(250327808))), name = tensor<string, []>("layers_8_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_8_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_8_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(250327936)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_165_cast_fp16 = conv(bias = layers_8_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_3428, groups = var_3339, pad = pretrained_out_165_pad_0, pad_type = pretrained_out_165_pad_type_0, strides = var_3426, weight = layers_8_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_113_cast_fp16)[name = tensor<string, []>("pretrained_out_165_cast_fp16")];
            tensor<int32, [2]> var_3432 = const()[name = tensor<string, []>("op_3432"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3434 = const()[name = tensor<string, []>("op_3434"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_245_pad_type_0 = const()[name = tensor<string, []>("input_245_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_245_pad_0 = const()[name = tensor<string, []>("input_245_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_8_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_8_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(250330560)))];
            tensor<fp16, [1, 16, 1, 1]> input_245_cast_fp16 = conv(dilations = var_3434, groups = var_3339, pad = input_245_pad_0, pad_type = input_245_pad_type_0, strides = var_3432, weight = layers_8_self_attn_v_proj_loraA_weight_to_fp16, x = obj_113_cast_fp16)[name = tensor<string, []>("input_245_cast_fp16")];
            tensor<int32, [2]> var_3438 = const()[name = tensor<string, []>("op_3438"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3440 = const()[name = tensor<string, []>("op_3440"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_329_pad_type_0 = const()[name = tensor<string, []>("lora_out_329_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_329_pad_0 = const()[name = tensor<string, []>("lora_out_329_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_331_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_331_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(250371584)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_331_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_3440, groups = var_3339, pad = lora_out_329_pad_0, pad_type = lora_out_329_pad_type_0, strides = var_3438, weight = lora_out_331_weight_0_to_fp16, x = input_245_cast_fp16)[name = tensor<string, []>("lora_out_331_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_17_cast_fp16 = add(x = pretrained_out_165_cast_fp16, y = lora_out_331_cast_fp16)[name = tensor<string, []>("current_value_17_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_3450_cast_fp16 = mul(x = current_key_17_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_3450_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_3452_cast_fp16 = mul(x = var_103_cast_fp16_8, y = var_295_cast_fp16)[name = tensor<string, []>("op_3452_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_33_cast_fp16 = add(x = var_3450_cast_fp16, y = var_3452_cast_fp16)[name = tensor<string, []>("key_33_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_3454_cast_fp16 = mul(x = current_value_17_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_3454_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_3456_cast_fp16 = mul(x = var_138_cast_fp16_8, y = var_295_cast_fp16)[name = tensor<string, []>("op_3456_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_33_cast_fp16 = add(x = var_3454_cast_fp16, y = var_3456_cast_fp16)[name = tensor<string, []>("value_33_cast_fp16")];
            tensor<int32, [4]> var_3459 = const()[name = tensor<string, []>("op_3459"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_3460_cast_fp16 = reshape(shape = var_3459, x = query_33_cast_fp16)[name = tensor<string, []>("op_3460_cast_fp16")];
            tensor<fp16, []> var_3461_to_fp16 = const()[name = tensor<string, []>("op_3461_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_3462_cast_fp16 = mul(x = var_3460_cast_fp16, y = var_3461_to_fp16)[name = tensor<string, []>("op_3462_cast_fp16")];
            tensor<int32, [4]> var_3463 = const()[name = tensor<string, []>("op_3463"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_3464_cast_fp16 = reshape(shape = var_3463, x = key_33_cast_fp16)[name = tensor<string, []>("op_3464_cast_fp16")];
            tensor<bool, []> mh_w_49_transpose_x_0 = const()[name = tensor<string, []>("mh_w_49_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_49_transpose_y_0 = const()[name = tensor<string, []>("mh_w_49_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_49_cast_fp16 = matmul(transpose_x = mh_w_49_transpose_x_0, transpose_y = mh_w_49_transpose_y_0, x = var_3462_cast_fp16, y = var_3464_cast_fp16)[name = tensor<string, []>("mh_w_49_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_51_cast_fp16 = add(x = mh_w_49_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_51_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_3472_cast_fp16 = softmax(axis = var_3332, x = mh_w_51_cast_fp16)[name = tensor<string, []>("op_3472_cast_fp16")];
            tensor<int32, [4]> var_3473 = const()[name = tensor<string, []>("op_3473"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_3474_cast_fp16 = reshape(shape = var_3473, x = value_33_cast_fp16)[name = tensor<string, []>("op_3474_cast_fp16")];
            tensor<bool, []> attn_33_transpose_x_0 = const()[name = tensor<string, []>("attn_33_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_33_transpose_y_0 = const()[name = tensor<string, []>("attn_33_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_33_cast_fp16 = matmul(transpose_x = attn_33_transpose_x_0, transpose_y = attn_33_transpose_y_0, x = var_3474_cast_fp16, y = var_3472_cast_fp16)[name = tensor<string, []>("attn_33_cast_fp16")];
            tensor<int32, [4]> var_3477 = const()[name = tensor<string, []>("op_3477"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_247_cast_fp16 = reshape(shape = var_3477, x = attn_33_cast_fp16)[name = tensor<string, []>("input_247_cast_fp16")];
            tensor<int32, [2]> var_3484 = const()[name = tensor<string, []>("op_3484"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3486 = const()[name = tensor<string, []>("op_3486"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_167_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_167_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_167_pad_0 = const()[name = tensor<string, []>("pretrained_out_167_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_8_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(250412608))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(251231872))), name = tensor<string, []>("layers_8_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_8_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_8_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(251232000)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_167_cast_fp16 = conv(bias = layers_8_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_3486, groups = var_3339, pad = pretrained_out_167_pad_0, pad_type = pretrained_out_167_pad_type_0, strides = var_3484, weight = layers_8_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_247_cast_fp16)[name = tensor<string, []>("pretrained_out_167_cast_fp16")];
            tensor<int32, [2]> var_3490 = const()[name = tensor<string, []>("op_3490"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3492 = const()[name = tensor<string, []>("op_3492"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_249_pad_type_0 = const()[name = tensor<string, []>("input_249_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_249_pad_0 = const()[name = tensor<string, []>("input_249_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_8_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_8_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(251234624)))];
            tensor<fp16, [1, 16, 1, 1]> input_249_cast_fp16 = conv(dilations = var_3492, groups = var_3339, pad = input_249_pad_0, pad_type = input_249_pad_type_0, strides = var_3490, weight = layers_8_self_attn_o_proj_loraA_weight_to_fp16, x = input_247_cast_fp16)[name = tensor<string, []>("input_249_cast_fp16")];
            tensor<int32, [2]> var_3496 = const()[name = tensor<string, []>("op_3496"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3498 = const()[name = tensor<string, []>("op_3498"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_333_pad_type_0 = const()[name = tensor<string, []>("lora_out_333_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_333_pad_0 = const()[name = tensor<string, []>("lora_out_333_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_335_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_335_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(251275648)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_335_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_3498, groups = var_3339, pad = lora_out_333_pad_0, pad_type = lora_out_333_pad_type_0, strides = var_3496, weight = lora_out_335_weight_0_to_fp16, x = input_249_cast_fp16)[name = tensor<string, []>("lora_out_335_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_119_cast_fp16 = add(x = pretrained_out_167_cast_fp16, y = lora_out_335_cast_fp16)[name = tensor<string, []>("obj_119_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_51_cast_fp16 = add(x = inputs_49_cast_fp16, y = obj_119_cast_fp16)[name = tensor<string, []>("inputs_51_cast_fp16")];
            tensor<int32, [1]> var_3511 = const()[name = tensor<string, []>("op_3511"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_51_cast_fp16 = reduce_mean(axes = var_3511, keep_dims = var_3340, x = inputs_51_cast_fp16)[name = tensor<string, []>("channels_mean_51_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_51_cast_fp16 = sub(x = inputs_51_cast_fp16, y = channels_mean_51_cast_fp16)[name = tensor<string, []>("zero_mean_51_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_51_cast_fp16 = mul(x = zero_mean_51_cast_fp16, y = zero_mean_51_cast_fp16)[name = tensor<string, []>("zero_mean_sq_51_cast_fp16")];
            tensor<int32, [1]> var_3515 = const()[name = tensor<string, []>("op_3515"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_3516_cast_fp16 = reduce_mean(axes = var_3515, keep_dims = var_3340, x = zero_mean_sq_51_cast_fp16)[name = tensor<string, []>("op_3516_cast_fp16")];
            tensor<fp16, []> var_3517_to_fp16 = const()[name = tensor<string, []>("op_3517_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_3518_cast_fp16 = add(x = var_3516_cast_fp16, y = var_3517_to_fp16)[name = tensor<string, []>("op_3518_cast_fp16")];
            tensor<fp32, []> denom_51_epsilon_0 = const()[name = tensor<string, []>("denom_51_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_51_cast_fp16 = rsqrt(epsilon = denom_51_epsilon_0, x = var_3518_cast_fp16)[name = tensor<string, []>("denom_51_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_51_cast_fp16 = mul(x = zero_mean_51_cast_fp16, y = denom_51_cast_fp16)[name = tensor<string, []>("out_51_cast_fp16")];
            tensor<fp16, [1280]> obj_121_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_121_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(251316672)))];
            tensor<fp16, [1280]> obj_121_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_121_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(251319296)))];
            tensor<fp16, []> obj_121_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_121_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_121_cast_fp16 = batch_norm(beta = obj_121_beta_0_to_fp16, epsilon = obj_121_epsilon_0_to_fp16, gamma = obj_121_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_51_cast_fp16)[name = tensor<string, []>("obj_121_cast_fp16")];
            tensor<int32, [2]> var_3536 = const()[name = tensor<string, []>("op_3536"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3538 = const()[name = tensor<string, []>("op_3538"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_169_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_169_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_169_pad_0 = const()[name = tensor<string, []>("pretrained_out_169_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_8_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(251321920))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(252141184))), name = tensor<string, []>("layers_8_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_8_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_8_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(252141312)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_169_cast_fp16 = conv(bias = layers_8_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_3538, groups = var_3339, pad = pretrained_out_169_pad_0, pad_type = pretrained_out_169_pad_type_0, strides = var_3536, weight = layers_8_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_121_cast_fp16)[name = tensor<string, []>("pretrained_out_169_cast_fp16")];
            tensor<int32, [2]> var_3542 = const()[name = tensor<string, []>("op_3542"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3544 = const()[name = tensor<string, []>("op_3544"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_251_pad_type_0 = const()[name = tensor<string, []>("input_251_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_251_pad_0 = const()[name = tensor<string, []>("input_251_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_8_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_8_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(252143936)))];
            tensor<fp16, [1, 16, 1, 1]> input_251_cast_fp16 = conv(dilations = var_3544, groups = var_3339, pad = input_251_pad_0, pad_type = input_251_pad_type_0, strides = var_3542, weight = layers_8_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_121_cast_fp16)[name = tensor<string, []>("input_251_cast_fp16")];
            tensor<int32, [2]> var_3548 = const()[name = tensor<string, []>("op_3548"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3550 = const()[name = tensor<string, []>("op_3550"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_337_pad_type_0 = const()[name = tensor<string, []>("lora_out_337_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_337_pad_0 = const()[name = tensor<string, []>("lora_out_337_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_339_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_339_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(252184960)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_339_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_3550, groups = var_3339, pad = lora_out_337_pad_0, pad_type = lora_out_337_pad_type_0, strides = var_3548, weight = lora_out_339_weight_0_to_fp16, x = input_251_cast_fp16)[name = tensor<string, []>("lora_out_339_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_35_cast_fp16 = add(x = pretrained_out_169_cast_fp16, y = lora_out_339_cast_fp16)[name = tensor<string, []>("query_35_cast_fp16")];
            tensor<int32, [2]> var_3560 = const()[name = tensor<string, []>("op_3560"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3562 = const()[name = tensor<string, []>("op_3562"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_171_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_171_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_171_pad_0 = const()[name = tensor<string, []>("pretrained_out_171_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_8_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(252225984))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(253045248))), name = tensor<string, []>("layers_8_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_171_cast_fp16 = conv(dilations = var_3562, groups = var_3339, pad = pretrained_out_171_pad_0, pad_type = pretrained_out_171_pad_type_0, strides = var_3560, weight = layers_8_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_171_cast_fp16")];
            tensor<int32, [2]> var_3566 = const()[name = tensor<string, []>("op_3566"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3568 = const()[name = tensor<string, []>("op_3568"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_253_pad_type_0 = const()[name = tensor<string, []>("input_253_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_253_pad_0 = const()[name = tensor<string, []>("input_253_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_8_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_8_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(253045376)))];
            tensor<fp16, [1, 16, 1, 1500]> input_253_cast_fp16 = conv(dilations = var_3568, groups = var_3339, pad = input_253_pad_0, pad_type = input_253_pad_type_0, strides = var_3566, weight = layers_8_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_253_cast_fp16")];
            tensor<int32, [2]> var_3572 = const()[name = tensor<string, []>("op_3572"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3574 = const()[name = tensor<string, []>("op_3574"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_341_pad_type_0 = const()[name = tensor<string, []>("lora_out_341_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_341_pad_0 = const()[name = tensor<string, []>("lora_out_341_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_343_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_343_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(253086400)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_343_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_3574, groups = var_3339, pad = lora_out_341_pad_0, pad_type = lora_out_341_pad_type_0, strides = var_3572, weight = lora_out_343_weight_0_to_fp16, x = input_253_cast_fp16)[name = tensor<string, []>("lora_out_343_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_35_cast_fp16 = add(x = pretrained_out_171_cast_fp16, y = lora_out_343_cast_fp16)[name = tensor<string, []>("key_35_cast_fp16")];
            tensor<int32, [2]> var_3585 = const()[name = tensor<string, []>("op_3585"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3587 = const()[name = tensor<string, []>("op_3587"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_173_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_173_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_173_pad_0 = const()[name = tensor<string, []>("pretrained_out_173_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_8_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(253127424))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(253946688))), name = tensor<string, []>("layers_8_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_8_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_8_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(253946816)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_173_cast_fp16 = conv(bias = layers_8_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_3587, groups = var_3339, pad = pretrained_out_173_pad_0, pad_type = pretrained_out_173_pad_type_0, strides = var_3585, weight = layers_8_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_173_cast_fp16")];
            tensor<int32, [2]> var_3591 = const()[name = tensor<string, []>("op_3591"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3593 = const()[name = tensor<string, []>("op_3593"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_255_pad_type_0 = const()[name = tensor<string, []>("input_255_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_255_pad_0 = const()[name = tensor<string, []>("input_255_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_8_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_8_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(253949440)))];
            tensor<fp16, [1, 16, 1, 1500]> input_255_cast_fp16 = conv(dilations = var_3593, groups = var_3339, pad = input_255_pad_0, pad_type = input_255_pad_type_0, strides = var_3591, weight = layers_8_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_255_cast_fp16")];
            tensor<int32, [2]> var_3597 = const()[name = tensor<string, []>("op_3597"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3599 = const()[name = tensor<string, []>("op_3599"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_345_pad_type_0 = const()[name = tensor<string, []>("lora_out_345_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_345_pad_0 = const()[name = tensor<string, []>("lora_out_345_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_347_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_347_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(253990464)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_347_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_3599, groups = var_3339, pad = lora_out_345_pad_0, pad_type = lora_out_345_pad_type_0, strides = var_3597, weight = lora_out_347_weight_0_to_fp16, x = input_255_cast_fp16)[name = tensor<string, []>("lora_out_347_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_35_cast_fp16 = add(x = pretrained_out_173_cast_fp16, y = lora_out_347_cast_fp16)[name = tensor<string, []>("value_35_cast_fp16")];
            tensor<int32, [4]> var_3606 = const()[name = tensor<string, []>("op_3606"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_3607_cast_fp16 = reshape(shape = var_3606, x = query_35_cast_fp16)[name = tensor<string, []>("op_3607_cast_fp16")];
            tensor<fp16, []> var_3608_to_fp16 = const()[name = tensor<string, []>("op_3608_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_3609_cast_fp16 = mul(x = var_3607_cast_fp16, y = var_3608_to_fp16)[name = tensor<string, []>("op_3609_cast_fp16")];
            tensor<int32, [4]> var_3610 = const()[name = tensor<string, []>("op_3610"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_3611_cast_fp16 = reshape(shape = var_3610, x = key_35_cast_fp16)[name = tensor<string, []>("op_3611_cast_fp16")];
            tensor<bool, []> mh_w_53_transpose_x_0 = const()[name = tensor<string, []>("mh_w_53_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_53_transpose_y_0 = const()[name = tensor<string, []>("mh_w_53_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_53_cast_fp16 = matmul(transpose_x = mh_w_53_transpose_x_0, transpose_y = mh_w_53_transpose_y_0, x = var_3609_cast_fp16, y = var_3611_cast_fp16)[name = tensor<string, []>("mh_w_53_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_125_cast_fp16 = softmax(axis = var_3332, x = mh_w_53_cast_fp16)[name = tensor<string, []>("obj_125_cast_fp16")];
            tensor<int32, [4]> var_3615 = const()[name = tensor<string, []>("op_3615"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_3616_cast_fp16 = reshape(shape = var_3615, x = value_35_cast_fp16)[name = tensor<string, []>("op_3616_cast_fp16")];
            tensor<bool, []> attn_35_transpose_x_0 = const()[name = tensor<string, []>("attn_35_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_35_transpose_y_0 = const()[name = tensor<string, []>("attn_35_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_35_cast_fp16 = matmul(transpose_x = attn_35_transpose_x_0, transpose_y = attn_35_transpose_y_0, x = var_3616_cast_fp16, y = obj_125_cast_fp16)[name = tensor<string, []>("attn_35_cast_fp16")];
            tensor<int32, [4]> var_3619 = const()[name = tensor<string, []>("op_3619"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_257_cast_fp16 = reshape(shape = var_3619, x = attn_35_cast_fp16)[name = tensor<string, []>("input_257_cast_fp16")];
            tensor<int32, [2]> var_3626 = const()[name = tensor<string, []>("op_3626"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3628 = const()[name = tensor<string, []>("op_3628"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_175_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_175_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_175_pad_0 = const()[name = tensor<string, []>("pretrained_out_175_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_8_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(254031488))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(254850752))), name = tensor<string, []>("layers_8_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_8_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_8_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(254850880)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_175_cast_fp16 = conv(bias = layers_8_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_3628, groups = var_3339, pad = pretrained_out_175_pad_0, pad_type = pretrained_out_175_pad_type_0, strides = var_3626, weight = layers_8_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_257_cast_fp16)[name = tensor<string, []>("pretrained_out_175_cast_fp16")];
            tensor<int32, [2]> var_3632 = const()[name = tensor<string, []>("op_3632"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3634 = const()[name = tensor<string, []>("op_3634"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_259_pad_type_0 = const()[name = tensor<string, []>("input_259_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_259_pad_0 = const()[name = tensor<string, []>("input_259_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_8_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_8_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(254853504)))];
            tensor<fp16, [1, 16, 1, 1]> input_259_cast_fp16 = conv(dilations = var_3634, groups = var_3339, pad = input_259_pad_0, pad_type = input_259_pad_type_0, strides = var_3632, weight = layers_8_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_257_cast_fp16)[name = tensor<string, []>("input_259_cast_fp16")];
            tensor<int32, [2]> var_3638 = const()[name = tensor<string, []>("op_3638"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3640 = const()[name = tensor<string, []>("op_3640"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_349_pad_type_0 = const()[name = tensor<string, []>("lora_out_349_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_349_pad_0 = const()[name = tensor<string, []>("lora_out_349_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_351_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_351_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(254894528)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_351_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_3640, groups = var_3339, pad = lora_out_349_pad_0, pad_type = lora_out_349_pad_type_0, strides = var_3638, weight = lora_out_351_weight_0_to_fp16, x = input_259_cast_fp16)[name = tensor<string, []>("lora_out_351_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_123_cast_fp16 = add(x = pretrained_out_175_cast_fp16, y = lora_out_351_cast_fp16)[name = tensor<string, []>("obj_123_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_53_cast_fp16 = add(x = inputs_51_cast_fp16, y = obj_123_cast_fp16)[name = tensor<string, []>("inputs_53_cast_fp16")];
            tensor<int32, [1]> var_3649 = const()[name = tensor<string, []>("op_3649"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_53_cast_fp16 = reduce_mean(axes = var_3649, keep_dims = var_3340, x = inputs_53_cast_fp16)[name = tensor<string, []>("channels_mean_53_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_53_cast_fp16 = sub(x = inputs_53_cast_fp16, y = channels_mean_53_cast_fp16)[name = tensor<string, []>("zero_mean_53_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_53_cast_fp16 = mul(x = zero_mean_53_cast_fp16, y = zero_mean_53_cast_fp16)[name = tensor<string, []>("zero_mean_sq_53_cast_fp16")];
            tensor<int32, [1]> var_3653 = const()[name = tensor<string, []>("op_3653"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_3654_cast_fp16 = reduce_mean(axes = var_3653, keep_dims = var_3340, x = zero_mean_sq_53_cast_fp16)[name = tensor<string, []>("op_3654_cast_fp16")];
            tensor<fp16, []> var_3655_to_fp16 = const()[name = tensor<string, []>("op_3655_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_3656_cast_fp16 = add(x = var_3654_cast_fp16, y = var_3655_to_fp16)[name = tensor<string, []>("op_3656_cast_fp16")];
            tensor<fp32, []> denom_53_epsilon_0 = const()[name = tensor<string, []>("denom_53_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_53_cast_fp16 = rsqrt(epsilon = denom_53_epsilon_0, x = var_3656_cast_fp16)[name = tensor<string, []>("denom_53_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_53_cast_fp16 = mul(x = zero_mean_53_cast_fp16, y = denom_53_cast_fp16)[name = tensor<string, []>("out_53_cast_fp16")];
            tensor<fp16, [1280]> input_261_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_261_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(254935552)))];
            tensor<fp16, [1280]> input_261_beta_0_to_fp16 = const()[name = tensor<string, []>("input_261_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(254938176)))];
            tensor<fp16, []> input_261_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_261_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_261_cast_fp16 = batch_norm(beta = input_261_beta_0_to_fp16, epsilon = input_261_epsilon_0_to_fp16, gamma = input_261_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_53_cast_fp16)[name = tensor<string, []>("input_261_cast_fp16")];
            tensor<int32, [2]> var_3670 = const()[name = tensor<string, []>("op_3670"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3672 = const()[name = tensor<string, []>("op_3672"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_177_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_177_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_177_pad_0 = const()[name = tensor<string, []>("pretrained_out_177_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_8_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(254940800))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(258217664))), name = tensor<string, []>("layers_8_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_8_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_8_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(258217792)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_177_cast_fp16 = conv(bias = layers_8_fc1_pretrained_bias_to_fp16, dilations = var_3672, groups = var_3339, pad = pretrained_out_177_pad_0, pad_type = pretrained_out_177_pad_type_0, strides = var_3670, weight = layers_8_fc1_pretrained_weight_to_fp16_palettized, x = input_261_cast_fp16)[name = tensor<string, []>("pretrained_out_177_cast_fp16")];
            tensor<int32, [2]> var_3676 = const()[name = tensor<string, []>("op_3676"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3678 = const()[name = tensor<string, []>("op_3678"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_263_pad_type_0 = const()[name = tensor<string, []>("input_263_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_263_pad_0 = const()[name = tensor<string, []>("input_263_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_8_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_8_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(258228096)))];
            tensor<fp16, [1, 16, 1, 1]> input_263_cast_fp16 = conv(dilations = var_3678, groups = var_3339, pad = input_263_pad_0, pad_type = input_263_pad_type_0, strides = var_3676, weight = layers_8_fc1_loraA_weight_to_fp16, x = input_261_cast_fp16)[name = tensor<string, []>("input_263_cast_fp16")];
            tensor<int32, [2]> var_3682 = const()[name = tensor<string, []>("op_3682"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3684 = const()[name = tensor<string, []>("op_3684"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_353_pad_type_0 = const()[name = tensor<string, []>("lora_out_353_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_353_pad_0 = const()[name = tensor<string, []>("lora_out_353_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_355_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_355_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(258269120)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_355_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_3684, groups = var_3339, pad = lora_out_353_pad_0, pad_type = lora_out_353_pad_type_0, strides = var_3682, weight = lora_out_355_weight_0_to_fp16, x = input_263_cast_fp16)[name = tensor<string, []>("lora_out_355_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_265_cast_fp16 = add(x = pretrained_out_177_cast_fp16, y = lora_out_355_cast_fp16)[name = tensor<string, []>("input_265_cast_fp16")];
            tensor<string, []> input_267_mode_0 = const()[name = tensor<string, []>("input_267_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_267_cast_fp16 = gelu(mode = input_267_mode_0, x = input_265_cast_fp16)[name = tensor<string, []>("input_267_cast_fp16")];
            tensor<int32, [2]> var_3696 = const()[name = tensor<string, []>("op_3696"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3698 = const()[name = tensor<string, []>("op_3698"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_179_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_179_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_179_pad_0 = const()[name = tensor<string, []>("pretrained_out_179_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_8_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(258433024))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(261709888))), name = tensor<string, []>("layers_8_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_8_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_8_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(261710016)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_179_cast_fp16 = conv(bias = layers_8_fc2_pretrained_bias_to_fp16, dilations = var_3698, groups = var_3339, pad = pretrained_out_179_pad_0, pad_type = pretrained_out_179_pad_type_0, strides = var_3696, weight = layers_8_fc2_pretrained_weight_to_fp16_palettized, x = input_267_cast_fp16)[name = tensor<string, []>("pretrained_out_179_cast_fp16")];
            tensor<int32, [2]> var_3702 = const()[name = tensor<string, []>("op_3702"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3704 = const()[name = tensor<string, []>("op_3704"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_269_pad_type_0 = const()[name = tensor<string, []>("input_269_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_269_pad_0 = const()[name = tensor<string, []>("input_269_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_8_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_8_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(261712640)))];
            tensor<fp16, [1, 16, 1, 1]> input_269_cast_fp16 = conv(dilations = var_3704, groups = var_3339, pad = input_269_pad_0, pad_type = input_269_pad_type_0, strides = var_3702, weight = layers_8_fc2_loraA_weight_to_fp16, x = input_267_cast_fp16)[name = tensor<string, []>("input_269_cast_fp16")];
            tensor<int32, [2]> var_3708 = const()[name = tensor<string, []>("op_3708"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3710 = const()[name = tensor<string, []>("op_3710"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_357_pad_type_0 = const()[name = tensor<string, []>("lora_out_357_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_357_pad_0 = const()[name = tensor<string, []>("lora_out_357_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_359_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_359_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(261876544)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_359_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_3710, groups = var_3339, pad = lora_out_357_pad_0, pad_type = lora_out_357_pad_type_0, strides = var_3708, weight = lora_out_359_weight_0_to_fp16, x = input_269_cast_fp16)[name = tensor<string, []>("lora_out_359_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_19_cast_fp16 = add(x = pretrained_out_179_cast_fp16, y = lora_out_359_cast_fp16)[name = tensor<string, []>("hidden_states_19_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_55_cast_fp16 = add(x = inputs_53_cast_fp16, y = hidden_states_19_cast_fp16)[name = tensor<string, []>("inputs_55_cast_fp16")];
            tensor<int32, []> var_3726 = const()[name = tensor<string, []>("op_3726"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_3733 = const()[name = tensor<string, []>("op_3733"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_3734 = const()[name = tensor<string, []>("op_3734"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_3746 = const()[name = tensor<string, []>("op_3746"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_55_cast_fp16 = reduce_mean(axes = var_3746, keep_dims = var_3734, x = inputs_55_cast_fp16)[name = tensor<string, []>("channels_mean_55_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_55_cast_fp16 = sub(x = inputs_55_cast_fp16, y = channels_mean_55_cast_fp16)[name = tensor<string, []>("zero_mean_55_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_55_cast_fp16 = mul(x = zero_mean_55_cast_fp16, y = zero_mean_55_cast_fp16)[name = tensor<string, []>("zero_mean_sq_55_cast_fp16")];
            tensor<int32, [1]> var_3750 = const()[name = tensor<string, []>("op_3750"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_3751_cast_fp16 = reduce_mean(axes = var_3750, keep_dims = var_3734, x = zero_mean_sq_55_cast_fp16)[name = tensor<string, []>("op_3751_cast_fp16")];
            tensor<fp16, []> var_3752_to_fp16 = const()[name = tensor<string, []>("op_3752_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_3753_cast_fp16 = add(x = var_3751_cast_fp16, y = var_3752_to_fp16)[name = tensor<string, []>("op_3753_cast_fp16")];
            tensor<fp32, []> denom_55_epsilon_0 = const()[name = tensor<string, []>("denom_55_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_55_cast_fp16 = rsqrt(epsilon = denom_55_epsilon_0, x = var_3753_cast_fp16)[name = tensor<string, []>("denom_55_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_55_cast_fp16 = mul(x = zero_mean_55_cast_fp16, y = denom_55_cast_fp16)[name = tensor<string, []>("out_55_cast_fp16")];
            tensor<fp16, [1280]> obj_127_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_127_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(261917568)))];
            tensor<fp16, [1280]> obj_127_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_127_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(261920192)))];
            tensor<fp16, []> obj_127_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_127_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_127_cast_fp16 = batch_norm(beta = obj_127_beta_0_to_fp16, epsilon = obj_127_epsilon_0_to_fp16, gamma = obj_127_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_55_cast_fp16)[name = tensor<string, []>("obj_127_cast_fp16")];
            tensor<int32, [2]> var_3771 = const()[name = tensor<string, []>("op_3771"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3773 = const()[name = tensor<string, []>("op_3773"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_181_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_181_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_181_pad_0 = const()[name = tensor<string, []>("pretrained_out_181_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_9_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(261922816))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(262742080))), name = tensor<string, []>("layers_9_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_9_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_9_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(262742208)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_181_cast_fp16 = conv(bias = layers_9_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_3773, groups = var_3733, pad = pretrained_out_181_pad_0, pad_type = pretrained_out_181_pad_type_0, strides = var_3771, weight = layers_9_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_127_cast_fp16)[name = tensor<string, []>("pretrained_out_181_cast_fp16")];
            tensor<int32, [2]> var_3777 = const()[name = tensor<string, []>("op_3777"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3779 = const()[name = tensor<string, []>("op_3779"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_271_pad_type_0 = const()[name = tensor<string, []>("input_271_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_271_pad_0 = const()[name = tensor<string, []>("input_271_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_9_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_9_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(262744832)))];
            tensor<fp16, [1, 16, 1, 1]> input_271_cast_fp16 = conv(dilations = var_3779, groups = var_3733, pad = input_271_pad_0, pad_type = input_271_pad_type_0, strides = var_3777, weight = layers_9_self_attn_q_proj_loraA_weight_to_fp16, x = obj_127_cast_fp16)[name = tensor<string, []>("input_271_cast_fp16")];
            tensor<int32, [2]> var_3783 = const()[name = tensor<string, []>("op_3783"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3785 = const()[name = tensor<string, []>("op_3785"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_361_pad_type_0 = const()[name = tensor<string, []>("lora_out_361_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_361_pad_0 = const()[name = tensor<string, []>("lora_out_361_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_363_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_363_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(262785856)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_363_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_3785, groups = var_3733, pad = lora_out_361_pad_0, pad_type = lora_out_361_pad_type_0, strides = var_3783, weight = lora_out_363_weight_0_to_fp16, x = input_271_cast_fp16)[name = tensor<string, []>("lora_out_363_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_37_cast_fp16 = add(x = pretrained_out_181_cast_fp16, y = lora_out_363_cast_fp16)[name = tensor<string, []>("query_37_cast_fp16")];
            tensor<int32, [2]> var_3795 = const()[name = tensor<string, []>("op_3795"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3797 = const()[name = tensor<string, []>("op_3797"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_183_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_183_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_183_pad_0 = const()[name = tensor<string, []>("pretrained_out_183_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_9_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(262826880))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(263646144))), name = tensor<string, []>("layers_9_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_183_cast_fp16 = conv(dilations = var_3797, groups = var_3733, pad = pretrained_out_183_pad_0, pad_type = pretrained_out_183_pad_type_0, strides = var_3795, weight = layers_9_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_127_cast_fp16)[name = tensor<string, []>("pretrained_out_183_cast_fp16")];
            tensor<int32, [2]> var_3801 = const()[name = tensor<string, []>("op_3801"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3803 = const()[name = tensor<string, []>("op_3803"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_273_pad_type_0 = const()[name = tensor<string, []>("input_273_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_273_pad_0 = const()[name = tensor<string, []>("input_273_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_9_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_9_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(263646272)))];
            tensor<fp16, [1, 16, 1, 1]> input_273_cast_fp16 = conv(dilations = var_3803, groups = var_3733, pad = input_273_pad_0, pad_type = input_273_pad_type_0, strides = var_3801, weight = layers_9_self_attn_k_proj_loraA_weight_to_fp16, x = obj_127_cast_fp16)[name = tensor<string, []>("input_273_cast_fp16")];
            tensor<int32, [2]> var_3807 = const()[name = tensor<string, []>("op_3807"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3809 = const()[name = tensor<string, []>("op_3809"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_365_pad_type_0 = const()[name = tensor<string, []>("lora_out_365_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_365_pad_0 = const()[name = tensor<string, []>("lora_out_365_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_367_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_367_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(263687296)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_367_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_3809, groups = var_3733, pad = lora_out_365_pad_0, pad_type = lora_out_365_pad_type_0, strides = var_3807, weight = lora_out_367_weight_0_to_fp16, x = input_273_cast_fp16)[name = tensor<string, []>("lora_out_367_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_19_cast_fp16 = add(x = pretrained_out_183_cast_fp16, y = lora_out_367_cast_fp16)[name = tensor<string, []>("current_key_19_cast_fp16")];
            tensor<int32, [2]> var_3820 = const()[name = tensor<string, []>("op_3820"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3822 = const()[name = tensor<string, []>("op_3822"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_185_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_185_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_185_pad_0 = const()[name = tensor<string, []>("pretrained_out_185_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_9_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(263728320))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(264547584))), name = tensor<string, []>("layers_9_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_9_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_9_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(264547712)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_185_cast_fp16 = conv(bias = layers_9_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_3822, groups = var_3733, pad = pretrained_out_185_pad_0, pad_type = pretrained_out_185_pad_type_0, strides = var_3820, weight = layers_9_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_127_cast_fp16)[name = tensor<string, []>("pretrained_out_185_cast_fp16")];
            tensor<int32, [2]> var_3826 = const()[name = tensor<string, []>("op_3826"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3828 = const()[name = tensor<string, []>("op_3828"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_275_pad_type_0 = const()[name = tensor<string, []>("input_275_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_275_pad_0 = const()[name = tensor<string, []>("input_275_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_9_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_9_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(264550336)))];
            tensor<fp16, [1, 16, 1, 1]> input_275_cast_fp16 = conv(dilations = var_3828, groups = var_3733, pad = input_275_pad_0, pad_type = input_275_pad_type_0, strides = var_3826, weight = layers_9_self_attn_v_proj_loraA_weight_to_fp16, x = obj_127_cast_fp16)[name = tensor<string, []>("input_275_cast_fp16")];
            tensor<int32, [2]> var_3832 = const()[name = tensor<string, []>("op_3832"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3834 = const()[name = tensor<string, []>("op_3834"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_369_pad_type_0 = const()[name = tensor<string, []>("lora_out_369_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_369_pad_0 = const()[name = tensor<string, []>("lora_out_369_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_371_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_371_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(264591360)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_371_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_3834, groups = var_3733, pad = lora_out_369_pad_0, pad_type = lora_out_369_pad_type_0, strides = var_3832, weight = lora_out_371_weight_0_to_fp16, x = input_275_cast_fp16)[name = tensor<string, []>("lora_out_371_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_19_cast_fp16 = add(x = pretrained_out_185_cast_fp16, y = lora_out_371_cast_fp16)[name = tensor<string, []>("current_value_19_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_3844_cast_fp16 = mul(x = current_key_19_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_3844_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_3846_cast_fp16 = mul(x = var_103_cast_fp16_9, y = var_295_cast_fp16)[name = tensor<string, []>("op_3846_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_37_cast_fp16 = add(x = var_3844_cast_fp16, y = var_3846_cast_fp16)[name = tensor<string, []>("key_37_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_3848_cast_fp16 = mul(x = current_value_19_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_3848_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_3850_cast_fp16 = mul(x = var_138_cast_fp16_9, y = var_295_cast_fp16)[name = tensor<string, []>("op_3850_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_37_cast_fp16 = add(x = var_3848_cast_fp16, y = var_3850_cast_fp16)[name = tensor<string, []>("value_37_cast_fp16")];
            tensor<int32, [4]> var_3853 = const()[name = tensor<string, []>("op_3853"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_3854_cast_fp16 = reshape(shape = var_3853, x = query_37_cast_fp16)[name = tensor<string, []>("op_3854_cast_fp16")];
            tensor<fp16, []> var_3855_to_fp16 = const()[name = tensor<string, []>("op_3855_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_3856_cast_fp16 = mul(x = var_3854_cast_fp16, y = var_3855_to_fp16)[name = tensor<string, []>("op_3856_cast_fp16")];
            tensor<int32, [4]> var_3857 = const()[name = tensor<string, []>("op_3857"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_3858_cast_fp16 = reshape(shape = var_3857, x = key_37_cast_fp16)[name = tensor<string, []>("op_3858_cast_fp16")];
            tensor<bool, []> mh_w_55_transpose_x_0 = const()[name = tensor<string, []>("mh_w_55_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_55_transpose_y_0 = const()[name = tensor<string, []>("mh_w_55_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_55_cast_fp16 = matmul(transpose_x = mh_w_55_transpose_x_0, transpose_y = mh_w_55_transpose_y_0, x = var_3856_cast_fp16, y = var_3858_cast_fp16)[name = tensor<string, []>("mh_w_55_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_57_cast_fp16 = add(x = mh_w_55_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_57_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_3866_cast_fp16 = softmax(axis = var_3726, x = mh_w_57_cast_fp16)[name = tensor<string, []>("op_3866_cast_fp16")];
            tensor<int32, [4]> var_3867 = const()[name = tensor<string, []>("op_3867"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_3868_cast_fp16 = reshape(shape = var_3867, x = value_37_cast_fp16)[name = tensor<string, []>("op_3868_cast_fp16")];
            tensor<bool, []> attn_37_transpose_x_0 = const()[name = tensor<string, []>("attn_37_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_37_transpose_y_0 = const()[name = tensor<string, []>("attn_37_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_37_cast_fp16 = matmul(transpose_x = attn_37_transpose_x_0, transpose_y = attn_37_transpose_y_0, x = var_3868_cast_fp16, y = var_3866_cast_fp16)[name = tensor<string, []>("attn_37_cast_fp16")];
            tensor<int32, [4]> var_3871 = const()[name = tensor<string, []>("op_3871"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_277_cast_fp16 = reshape(shape = var_3871, x = attn_37_cast_fp16)[name = tensor<string, []>("input_277_cast_fp16")];
            tensor<int32, [2]> var_3878 = const()[name = tensor<string, []>("op_3878"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3880 = const()[name = tensor<string, []>("op_3880"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_187_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_187_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_187_pad_0 = const()[name = tensor<string, []>("pretrained_out_187_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_9_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(264632384))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(265451648))), name = tensor<string, []>("layers_9_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_9_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_9_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(265451776)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_187_cast_fp16 = conv(bias = layers_9_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_3880, groups = var_3733, pad = pretrained_out_187_pad_0, pad_type = pretrained_out_187_pad_type_0, strides = var_3878, weight = layers_9_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_277_cast_fp16)[name = tensor<string, []>("pretrained_out_187_cast_fp16")];
            tensor<int32, [2]> var_3884 = const()[name = tensor<string, []>("op_3884"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3886 = const()[name = tensor<string, []>("op_3886"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_279_pad_type_0 = const()[name = tensor<string, []>("input_279_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_279_pad_0 = const()[name = tensor<string, []>("input_279_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_9_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_9_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(265454400)))];
            tensor<fp16, [1, 16, 1, 1]> input_279_cast_fp16 = conv(dilations = var_3886, groups = var_3733, pad = input_279_pad_0, pad_type = input_279_pad_type_0, strides = var_3884, weight = layers_9_self_attn_o_proj_loraA_weight_to_fp16, x = input_277_cast_fp16)[name = tensor<string, []>("input_279_cast_fp16")];
            tensor<int32, [2]> var_3890 = const()[name = tensor<string, []>("op_3890"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3892 = const()[name = tensor<string, []>("op_3892"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_373_pad_type_0 = const()[name = tensor<string, []>("lora_out_373_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_373_pad_0 = const()[name = tensor<string, []>("lora_out_373_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_375_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_375_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(265495424)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_375_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_3892, groups = var_3733, pad = lora_out_373_pad_0, pad_type = lora_out_373_pad_type_0, strides = var_3890, weight = lora_out_375_weight_0_to_fp16, x = input_279_cast_fp16)[name = tensor<string, []>("lora_out_375_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_133_cast_fp16 = add(x = pretrained_out_187_cast_fp16, y = lora_out_375_cast_fp16)[name = tensor<string, []>("obj_133_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_57_cast_fp16 = add(x = inputs_55_cast_fp16, y = obj_133_cast_fp16)[name = tensor<string, []>("inputs_57_cast_fp16")];
            tensor<int32, [1]> var_3905 = const()[name = tensor<string, []>("op_3905"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_57_cast_fp16 = reduce_mean(axes = var_3905, keep_dims = var_3734, x = inputs_57_cast_fp16)[name = tensor<string, []>("channels_mean_57_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_57_cast_fp16 = sub(x = inputs_57_cast_fp16, y = channels_mean_57_cast_fp16)[name = tensor<string, []>("zero_mean_57_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_57_cast_fp16 = mul(x = zero_mean_57_cast_fp16, y = zero_mean_57_cast_fp16)[name = tensor<string, []>("zero_mean_sq_57_cast_fp16")];
            tensor<int32, [1]> var_3909 = const()[name = tensor<string, []>("op_3909"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_3910_cast_fp16 = reduce_mean(axes = var_3909, keep_dims = var_3734, x = zero_mean_sq_57_cast_fp16)[name = tensor<string, []>("op_3910_cast_fp16")];
            tensor<fp16, []> var_3911_to_fp16 = const()[name = tensor<string, []>("op_3911_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_3912_cast_fp16 = add(x = var_3910_cast_fp16, y = var_3911_to_fp16)[name = tensor<string, []>("op_3912_cast_fp16")];
            tensor<fp32, []> denom_57_epsilon_0 = const()[name = tensor<string, []>("denom_57_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_57_cast_fp16 = rsqrt(epsilon = denom_57_epsilon_0, x = var_3912_cast_fp16)[name = tensor<string, []>("denom_57_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_57_cast_fp16 = mul(x = zero_mean_57_cast_fp16, y = denom_57_cast_fp16)[name = tensor<string, []>("out_57_cast_fp16")];
            tensor<fp16, [1280]> obj_135_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_135_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(265536448)))];
            tensor<fp16, [1280]> obj_135_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_135_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(265539072)))];
            tensor<fp16, []> obj_135_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_135_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_135_cast_fp16 = batch_norm(beta = obj_135_beta_0_to_fp16, epsilon = obj_135_epsilon_0_to_fp16, gamma = obj_135_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_57_cast_fp16)[name = tensor<string, []>("obj_135_cast_fp16")];
            tensor<int32, [2]> var_3930 = const()[name = tensor<string, []>("op_3930"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3932 = const()[name = tensor<string, []>("op_3932"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_189_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_189_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_189_pad_0 = const()[name = tensor<string, []>("pretrained_out_189_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_9_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(265541696))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(266360960))), name = tensor<string, []>("layers_9_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_9_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_9_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(266361088)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_189_cast_fp16 = conv(bias = layers_9_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_3932, groups = var_3733, pad = pretrained_out_189_pad_0, pad_type = pretrained_out_189_pad_type_0, strides = var_3930, weight = layers_9_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_135_cast_fp16)[name = tensor<string, []>("pretrained_out_189_cast_fp16")];
            tensor<int32, [2]> var_3936 = const()[name = tensor<string, []>("op_3936"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3938 = const()[name = tensor<string, []>("op_3938"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_281_pad_type_0 = const()[name = tensor<string, []>("input_281_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_281_pad_0 = const()[name = tensor<string, []>("input_281_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_9_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_9_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(266363712)))];
            tensor<fp16, [1, 16, 1, 1]> input_281_cast_fp16 = conv(dilations = var_3938, groups = var_3733, pad = input_281_pad_0, pad_type = input_281_pad_type_0, strides = var_3936, weight = layers_9_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_135_cast_fp16)[name = tensor<string, []>("input_281_cast_fp16")];
            tensor<int32, [2]> var_3942 = const()[name = tensor<string, []>("op_3942"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3944 = const()[name = tensor<string, []>("op_3944"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_377_pad_type_0 = const()[name = tensor<string, []>("lora_out_377_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_377_pad_0 = const()[name = tensor<string, []>("lora_out_377_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_379_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_379_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(266404736)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_379_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_3944, groups = var_3733, pad = lora_out_377_pad_0, pad_type = lora_out_377_pad_type_0, strides = var_3942, weight = lora_out_379_weight_0_to_fp16, x = input_281_cast_fp16)[name = tensor<string, []>("lora_out_379_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_39_cast_fp16 = add(x = pretrained_out_189_cast_fp16, y = lora_out_379_cast_fp16)[name = tensor<string, []>("query_39_cast_fp16")];
            tensor<int32, [2]> var_3954 = const()[name = tensor<string, []>("op_3954"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3956 = const()[name = tensor<string, []>("op_3956"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_191_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_191_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_191_pad_0 = const()[name = tensor<string, []>("pretrained_out_191_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_9_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(266445760))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(267265024))), name = tensor<string, []>("layers_9_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_191_cast_fp16 = conv(dilations = var_3956, groups = var_3733, pad = pretrained_out_191_pad_0, pad_type = pretrained_out_191_pad_type_0, strides = var_3954, weight = layers_9_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_191_cast_fp16")];
            tensor<int32, [2]> var_3960 = const()[name = tensor<string, []>("op_3960"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3962 = const()[name = tensor<string, []>("op_3962"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_283_pad_type_0 = const()[name = tensor<string, []>("input_283_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_283_pad_0 = const()[name = tensor<string, []>("input_283_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_9_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_9_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(267265152)))];
            tensor<fp16, [1, 16, 1, 1500]> input_283_cast_fp16 = conv(dilations = var_3962, groups = var_3733, pad = input_283_pad_0, pad_type = input_283_pad_type_0, strides = var_3960, weight = layers_9_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_283_cast_fp16")];
            tensor<int32, [2]> var_3966 = const()[name = tensor<string, []>("op_3966"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3968 = const()[name = tensor<string, []>("op_3968"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_381_pad_type_0 = const()[name = tensor<string, []>("lora_out_381_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_381_pad_0 = const()[name = tensor<string, []>("lora_out_381_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_383_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_383_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(267306176)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_383_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_3968, groups = var_3733, pad = lora_out_381_pad_0, pad_type = lora_out_381_pad_type_0, strides = var_3966, weight = lora_out_383_weight_0_to_fp16, x = input_283_cast_fp16)[name = tensor<string, []>("lora_out_383_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_39_cast_fp16 = add(x = pretrained_out_191_cast_fp16, y = lora_out_383_cast_fp16)[name = tensor<string, []>("key_39_cast_fp16")];
            tensor<int32, [2]> var_3979 = const()[name = tensor<string, []>("op_3979"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3981 = const()[name = tensor<string, []>("op_3981"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_193_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_193_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_193_pad_0 = const()[name = tensor<string, []>("pretrained_out_193_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_9_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(267347200))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(268166464))), name = tensor<string, []>("layers_9_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_9_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_9_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(268166592)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_193_cast_fp16 = conv(bias = layers_9_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_3981, groups = var_3733, pad = pretrained_out_193_pad_0, pad_type = pretrained_out_193_pad_type_0, strides = var_3979, weight = layers_9_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_193_cast_fp16")];
            tensor<int32, [2]> var_3985 = const()[name = tensor<string, []>("op_3985"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3987 = const()[name = tensor<string, []>("op_3987"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_285_pad_type_0 = const()[name = tensor<string, []>("input_285_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_285_pad_0 = const()[name = tensor<string, []>("input_285_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_9_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_9_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(268169216)))];
            tensor<fp16, [1, 16, 1, 1500]> input_285_cast_fp16 = conv(dilations = var_3987, groups = var_3733, pad = input_285_pad_0, pad_type = input_285_pad_type_0, strides = var_3985, weight = layers_9_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_285_cast_fp16")];
            tensor<int32, [2]> var_3991 = const()[name = tensor<string, []>("op_3991"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_3993 = const()[name = tensor<string, []>("op_3993"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_385_pad_type_0 = const()[name = tensor<string, []>("lora_out_385_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_385_pad_0 = const()[name = tensor<string, []>("lora_out_385_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_387_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_387_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(268210240)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_387_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_3993, groups = var_3733, pad = lora_out_385_pad_0, pad_type = lora_out_385_pad_type_0, strides = var_3991, weight = lora_out_387_weight_0_to_fp16, x = input_285_cast_fp16)[name = tensor<string, []>("lora_out_387_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_39_cast_fp16 = add(x = pretrained_out_193_cast_fp16, y = lora_out_387_cast_fp16)[name = tensor<string, []>("value_39_cast_fp16")];
            tensor<int32, [4]> var_4000 = const()[name = tensor<string, []>("op_4000"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_4001_cast_fp16 = reshape(shape = var_4000, x = query_39_cast_fp16)[name = tensor<string, []>("op_4001_cast_fp16")];
            tensor<fp16, []> var_4002_to_fp16 = const()[name = tensor<string, []>("op_4002_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_4003_cast_fp16 = mul(x = var_4001_cast_fp16, y = var_4002_to_fp16)[name = tensor<string, []>("op_4003_cast_fp16")];
            tensor<int32, [4]> var_4004 = const()[name = tensor<string, []>("op_4004"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_4005_cast_fp16 = reshape(shape = var_4004, x = key_39_cast_fp16)[name = tensor<string, []>("op_4005_cast_fp16")];
            tensor<bool, []> mh_w_59_transpose_x_0 = const()[name = tensor<string, []>("mh_w_59_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_59_transpose_y_0 = const()[name = tensor<string, []>("mh_w_59_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_59_cast_fp16 = matmul(transpose_x = mh_w_59_transpose_x_0, transpose_y = mh_w_59_transpose_y_0, x = var_4003_cast_fp16, y = var_4005_cast_fp16)[name = tensor<string, []>("mh_w_59_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_139_cast_fp16 = softmax(axis = var_3726, x = mh_w_59_cast_fp16)[name = tensor<string, []>("obj_139_cast_fp16")];
            tensor<int32, [4]> var_4009 = const()[name = tensor<string, []>("op_4009"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_4010_cast_fp16 = reshape(shape = var_4009, x = value_39_cast_fp16)[name = tensor<string, []>("op_4010_cast_fp16")];
            tensor<bool, []> attn_39_transpose_x_0 = const()[name = tensor<string, []>("attn_39_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_39_transpose_y_0 = const()[name = tensor<string, []>("attn_39_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_39_cast_fp16 = matmul(transpose_x = attn_39_transpose_x_0, transpose_y = attn_39_transpose_y_0, x = var_4010_cast_fp16, y = obj_139_cast_fp16)[name = tensor<string, []>("attn_39_cast_fp16")];
            tensor<int32, [4]> var_4013 = const()[name = tensor<string, []>("op_4013"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_287_cast_fp16 = reshape(shape = var_4013, x = attn_39_cast_fp16)[name = tensor<string, []>("input_287_cast_fp16")];
            tensor<int32, [2]> var_4020 = const()[name = tensor<string, []>("op_4020"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4022 = const()[name = tensor<string, []>("op_4022"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_195_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_195_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_195_pad_0 = const()[name = tensor<string, []>("pretrained_out_195_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_9_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(268251264))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(269070528))), name = tensor<string, []>("layers_9_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_9_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_9_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(269070656)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_195_cast_fp16 = conv(bias = layers_9_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_4022, groups = var_3733, pad = pretrained_out_195_pad_0, pad_type = pretrained_out_195_pad_type_0, strides = var_4020, weight = layers_9_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_287_cast_fp16)[name = tensor<string, []>("pretrained_out_195_cast_fp16")];
            tensor<int32, [2]> var_4026 = const()[name = tensor<string, []>("op_4026"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4028 = const()[name = tensor<string, []>("op_4028"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_289_pad_type_0 = const()[name = tensor<string, []>("input_289_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_289_pad_0 = const()[name = tensor<string, []>("input_289_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_9_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_9_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(269073280)))];
            tensor<fp16, [1, 16, 1, 1]> input_289_cast_fp16 = conv(dilations = var_4028, groups = var_3733, pad = input_289_pad_0, pad_type = input_289_pad_type_0, strides = var_4026, weight = layers_9_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_287_cast_fp16)[name = tensor<string, []>("input_289_cast_fp16")];
            tensor<int32, [2]> var_4032 = const()[name = tensor<string, []>("op_4032"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4034 = const()[name = tensor<string, []>("op_4034"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_389_pad_type_0 = const()[name = tensor<string, []>("lora_out_389_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_389_pad_0 = const()[name = tensor<string, []>("lora_out_389_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_391_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_391_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(269114304)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_391_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_4034, groups = var_3733, pad = lora_out_389_pad_0, pad_type = lora_out_389_pad_type_0, strides = var_4032, weight = lora_out_391_weight_0_to_fp16, x = input_289_cast_fp16)[name = tensor<string, []>("lora_out_391_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_137_cast_fp16 = add(x = pretrained_out_195_cast_fp16, y = lora_out_391_cast_fp16)[name = tensor<string, []>("obj_137_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_59_cast_fp16 = add(x = inputs_57_cast_fp16, y = obj_137_cast_fp16)[name = tensor<string, []>("inputs_59_cast_fp16")];
            tensor<int32, [1]> var_4043 = const()[name = tensor<string, []>("op_4043"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_59_cast_fp16 = reduce_mean(axes = var_4043, keep_dims = var_3734, x = inputs_59_cast_fp16)[name = tensor<string, []>("channels_mean_59_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_59_cast_fp16 = sub(x = inputs_59_cast_fp16, y = channels_mean_59_cast_fp16)[name = tensor<string, []>("zero_mean_59_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_59_cast_fp16 = mul(x = zero_mean_59_cast_fp16, y = zero_mean_59_cast_fp16)[name = tensor<string, []>("zero_mean_sq_59_cast_fp16")];
            tensor<int32, [1]> var_4047 = const()[name = tensor<string, []>("op_4047"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_4048_cast_fp16 = reduce_mean(axes = var_4047, keep_dims = var_3734, x = zero_mean_sq_59_cast_fp16)[name = tensor<string, []>("op_4048_cast_fp16")];
            tensor<fp16, []> var_4049_to_fp16 = const()[name = tensor<string, []>("op_4049_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_4050_cast_fp16 = add(x = var_4048_cast_fp16, y = var_4049_to_fp16)[name = tensor<string, []>("op_4050_cast_fp16")];
            tensor<fp32, []> denom_59_epsilon_0 = const()[name = tensor<string, []>("denom_59_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_59_cast_fp16 = rsqrt(epsilon = denom_59_epsilon_0, x = var_4050_cast_fp16)[name = tensor<string, []>("denom_59_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_59_cast_fp16 = mul(x = zero_mean_59_cast_fp16, y = denom_59_cast_fp16)[name = tensor<string, []>("out_59_cast_fp16")];
            tensor<fp16, [1280]> input_291_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_291_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(269155328)))];
            tensor<fp16, [1280]> input_291_beta_0_to_fp16 = const()[name = tensor<string, []>("input_291_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(269157952)))];
            tensor<fp16, []> input_291_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_291_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_291_cast_fp16 = batch_norm(beta = input_291_beta_0_to_fp16, epsilon = input_291_epsilon_0_to_fp16, gamma = input_291_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_59_cast_fp16)[name = tensor<string, []>("input_291_cast_fp16")];
            tensor<int32, [2]> var_4064 = const()[name = tensor<string, []>("op_4064"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4066 = const()[name = tensor<string, []>("op_4066"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_197_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_197_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_197_pad_0 = const()[name = tensor<string, []>("pretrained_out_197_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_9_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(269160576))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(272437440))), name = tensor<string, []>("layers_9_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_9_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_9_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(272437568)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_197_cast_fp16 = conv(bias = layers_9_fc1_pretrained_bias_to_fp16, dilations = var_4066, groups = var_3733, pad = pretrained_out_197_pad_0, pad_type = pretrained_out_197_pad_type_0, strides = var_4064, weight = layers_9_fc1_pretrained_weight_to_fp16_palettized, x = input_291_cast_fp16)[name = tensor<string, []>("pretrained_out_197_cast_fp16")];
            tensor<int32, [2]> var_4070 = const()[name = tensor<string, []>("op_4070"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4072 = const()[name = tensor<string, []>("op_4072"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_293_pad_type_0 = const()[name = tensor<string, []>("input_293_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_293_pad_0 = const()[name = tensor<string, []>("input_293_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_9_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_9_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(272447872)))];
            tensor<fp16, [1, 16, 1, 1]> input_293_cast_fp16 = conv(dilations = var_4072, groups = var_3733, pad = input_293_pad_0, pad_type = input_293_pad_type_0, strides = var_4070, weight = layers_9_fc1_loraA_weight_to_fp16, x = input_291_cast_fp16)[name = tensor<string, []>("input_293_cast_fp16")];
            tensor<int32, [2]> var_4076 = const()[name = tensor<string, []>("op_4076"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4078 = const()[name = tensor<string, []>("op_4078"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_393_pad_type_0 = const()[name = tensor<string, []>("lora_out_393_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_393_pad_0 = const()[name = tensor<string, []>("lora_out_393_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_395_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_395_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(272488896)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_395_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_4078, groups = var_3733, pad = lora_out_393_pad_0, pad_type = lora_out_393_pad_type_0, strides = var_4076, weight = lora_out_395_weight_0_to_fp16, x = input_293_cast_fp16)[name = tensor<string, []>("lora_out_395_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_295_cast_fp16 = add(x = pretrained_out_197_cast_fp16, y = lora_out_395_cast_fp16)[name = tensor<string, []>("input_295_cast_fp16")];
            tensor<string, []> input_297_mode_0 = const()[name = tensor<string, []>("input_297_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_297_cast_fp16 = gelu(mode = input_297_mode_0, x = input_295_cast_fp16)[name = tensor<string, []>("input_297_cast_fp16")];
            tensor<int32, [2]> var_4090 = const()[name = tensor<string, []>("op_4090"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4092 = const()[name = tensor<string, []>("op_4092"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_199_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_199_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_199_pad_0 = const()[name = tensor<string, []>("pretrained_out_199_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_9_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(272652800))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(275929664))), name = tensor<string, []>("layers_9_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_9_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_9_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(275929792)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_199_cast_fp16 = conv(bias = layers_9_fc2_pretrained_bias_to_fp16, dilations = var_4092, groups = var_3733, pad = pretrained_out_199_pad_0, pad_type = pretrained_out_199_pad_type_0, strides = var_4090, weight = layers_9_fc2_pretrained_weight_to_fp16_palettized, x = input_297_cast_fp16)[name = tensor<string, []>("pretrained_out_199_cast_fp16")];
            tensor<int32, [2]> var_4096 = const()[name = tensor<string, []>("op_4096"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4098 = const()[name = tensor<string, []>("op_4098"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_299_pad_type_0 = const()[name = tensor<string, []>("input_299_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_299_pad_0 = const()[name = tensor<string, []>("input_299_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_9_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_9_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(275932416)))];
            tensor<fp16, [1, 16, 1, 1]> input_299_cast_fp16 = conv(dilations = var_4098, groups = var_3733, pad = input_299_pad_0, pad_type = input_299_pad_type_0, strides = var_4096, weight = layers_9_fc2_loraA_weight_to_fp16, x = input_297_cast_fp16)[name = tensor<string, []>("input_299_cast_fp16")];
            tensor<int32, [2]> var_4102 = const()[name = tensor<string, []>("op_4102"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4104 = const()[name = tensor<string, []>("op_4104"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_397_pad_type_0 = const()[name = tensor<string, []>("lora_out_397_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_397_pad_0 = const()[name = tensor<string, []>("lora_out_397_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_399_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_399_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(276096320)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_399_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_4104, groups = var_3733, pad = lora_out_397_pad_0, pad_type = lora_out_397_pad_type_0, strides = var_4102, weight = lora_out_399_weight_0_to_fp16, x = input_299_cast_fp16)[name = tensor<string, []>("lora_out_399_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_21_cast_fp16 = add(x = pretrained_out_199_cast_fp16, y = lora_out_399_cast_fp16)[name = tensor<string, []>("hidden_states_21_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_61_cast_fp16 = add(x = inputs_59_cast_fp16, y = hidden_states_21_cast_fp16)[name = tensor<string, []>("inputs_61_cast_fp16")];
            tensor<int32, []> var_4120 = const()[name = tensor<string, []>("op_4120"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_4127 = const()[name = tensor<string, []>("op_4127"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_4128 = const()[name = tensor<string, []>("op_4128"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_4140 = const()[name = tensor<string, []>("op_4140"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_61_cast_fp16 = reduce_mean(axes = var_4140, keep_dims = var_4128, x = inputs_61_cast_fp16)[name = tensor<string, []>("channels_mean_61_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_61_cast_fp16 = sub(x = inputs_61_cast_fp16, y = channels_mean_61_cast_fp16)[name = tensor<string, []>("zero_mean_61_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_61_cast_fp16 = mul(x = zero_mean_61_cast_fp16, y = zero_mean_61_cast_fp16)[name = tensor<string, []>("zero_mean_sq_61_cast_fp16")];
            tensor<int32, [1]> var_4144 = const()[name = tensor<string, []>("op_4144"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_4145_cast_fp16 = reduce_mean(axes = var_4144, keep_dims = var_4128, x = zero_mean_sq_61_cast_fp16)[name = tensor<string, []>("op_4145_cast_fp16")];
            tensor<fp16, []> var_4146_to_fp16 = const()[name = tensor<string, []>("op_4146_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_4147_cast_fp16 = add(x = var_4145_cast_fp16, y = var_4146_to_fp16)[name = tensor<string, []>("op_4147_cast_fp16")];
            tensor<fp32, []> denom_61_epsilon_0 = const()[name = tensor<string, []>("denom_61_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_61_cast_fp16 = rsqrt(epsilon = denom_61_epsilon_0, x = var_4147_cast_fp16)[name = tensor<string, []>("denom_61_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_61_cast_fp16 = mul(x = zero_mean_61_cast_fp16, y = denom_61_cast_fp16)[name = tensor<string, []>("out_61_cast_fp16")];
            tensor<fp16, [1280]> obj_141_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_141_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(276137344)))];
            tensor<fp16, [1280]> obj_141_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_141_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(276139968)))];
            tensor<fp16, []> obj_141_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_141_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_141_cast_fp16 = batch_norm(beta = obj_141_beta_0_to_fp16, epsilon = obj_141_epsilon_0_to_fp16, gamma = obj_141_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_61_cast_fp16)[name = tensor<string, []>("obj_141_cast_fp16")];
            tensor<int32, [2]> var_4165 = const()[name = tensor<string, []>("op_4165"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4167 = const()[name = tensor<string, []>("op_4167"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_201_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_201_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_201_pad_0 = const()[name = tensor<string, []>("pretrained_out_201_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_10_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(276142592))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(276961856))), name = tensor<string, []>("layers_10_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_10_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_10_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(276961984)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_201_cast_fp16 = conv(bias = layers_10_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_4167, groups = var_4127, pad = pretrained_out_201_pad_0, pad_type = pretrained_out_201_pad_type_0, strides = var_4165, weight = layers_10_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_141_cast_fp16)[name = tensor<string, []>("pretrained_out_201_cast_fp16")];
            tensor<int32, [2]> var_4171 = const()[name = tensor<string, []>("op_4171"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4173 = const()[name = tensor<string, []>("op_4173"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_301_pad_type_0 = const()[name = tensor<string, []>("input_301_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_301_pad_0 = const()[name = tensor<string, []>("input_301_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_10_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_10_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(276964608)))];
            tensor<fp16, [1, 16, 1, 1]> input_301_cast_fp16 = conv(dilations = var_4173, groups = var_4127, pad = input_301_pad_0, pad_type = input_301_pad_type_0, strides = var_4171, weight = layers_10_self_attn_q_proj_loraA_weight_to_fp16, x = obj_141_cast_fp16)[name = tensor<string, []>("input_301_cast_fp16")];
            tensor<int32, [2]> var_4177 = const()[name = tensor<string, []>("op_4177"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4179 = const()[name = tensor<string, []>("op_4179"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_401_pad_type_0 = const()[name = tensor<string, []>("lora_out_401_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_401_pad_0 = const()[name = tensor<string, []>("lora_out_401_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_403_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_403_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(277005632)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_403_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_4179, groups = var_4127, pad = lora_out_401_pad_0, pad_type = lora_out_401_pad_type_0, strides = var_4177, weight = lora_out_403_weight_0_to_fp16, x = input_301_cast_fp16)[name = tensor<string, []>("lora_out_403_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_41_cast_fp16 = add(x = pretrained_out_201_cast_fp16, y = lora_out_403_cast_fp16)[name = tensor<string, []>("query_41_cast_fp16")];
            tensor<int32, [2]> var_4189 = const()[name = tensor<string, []>("op_4189"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4191 = const()[name = tensor<string, []>("op_4191"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_203_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_203_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_203_pad_0 = const()[name = tensor<string, []>("pretrained_out_203_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_10_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(277046656))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(277865920))), name = tensor<string, []>("layers_10_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_203_cast_fp16 = conv(dilations = var_4191, groups = var_4127, pad = pretrained_out_203_pad_0, pad_type = pretrained_out_203_pad_type_0, strides = var_4189, weight = layers_10_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_141_cast_fp16)[name = tensor<string, []>("pretrained_out_203_cast_fp16")];
            tensor<int32, [2]> var_4195 = const()[name = tensor<string, []>("op_4195"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4197 = const()[name = tensor<string, []>("op_4197"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_303_pad_type_0 = const()[name = tensor<string, []>("input_303_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_303_pad_0 = const()[name = tensor<string, []>("input_303_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_10_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_10_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(277866048)))];
            tensor<fp16, [1, 16, 1, 1]> input_303_cast_fp16 = conv(dilations = var_4197, groups = var_4127, pad = input_303_pad_0, pad_type = input_303_pad_type_0, strides = var_4195, weight = layers_10_self_attn_k_proj_loraA_weight_to_fp16, x = obj_141_cast_fp16)[name = tensor<string, []>("input_303_cast_fp16")];
            tensor<int32, [2]> var_4201 = const()[name = tensor<string, []>("op_4201"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4203 = const()[name = tensor<string, []>("op_4203"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_405_pad_type_0 = const()[name = tensor<string, []>("lora_out_405_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_405_pad_0 = const()[name = tensor<string, []>("lora_out_405_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_407_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_407_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(277907072)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_407_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_4203, groups = var_4127, pad = lora_out_405_pad_0, pad_type = lora_out_405_pad_type_0, strides = var_4201, weight = lora_out_407_weight_0_to_fp16, x = input_303_cast_fp16)[name = tensor<string, []>("lora_out_407_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_21_cast_fp16 = add(x = pretrained_out_203_cast_fp16, y = lora_out_407_cast_fp16)[name = tensor<string, []>("current_key_21_cast_fp16")];
            tensor<int32, [2]> var_4214 = const()[name = tensor<string, []>("op_4214"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4216 = const()[name = tensor<string, []>("op_4216"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_205_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_205_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_205_pad_0 = const()[name = tensor<string, []>("pretrained_out_205_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_10_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(277948096))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(278767360))), name = tensor<string, []>("layers_10_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_10_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_10_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(278767488)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_205_cast_fp16 = conv(bias = layers_10_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_4216, groups = var_4127, pad = pretrained_out_205_pad_0, pad_type = pretrained_out_205_pad_type_0, strides = var_4214, weight = layers_10_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_141_cast_fp16)[name = tensor<string, []>("pretrained_out_205_cast_fp16")];
            tensor<int32, [2]> var_4220 = const()[name = tensor<string, []>("op_4220"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4222 = const()[name = tensor<string, []>("op_4222"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_305_pad_type_0 = const()[name = tensor<string, []>("input_305_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_305_pad_0 = const()[name = tensor<string, []>("input_305_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_10_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_10_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(278770112)))];
            tensor<fp16, [1, 16, 1, 1]> input_305_cast_fp16 = conv(dilations = var_4222, groups = var_4127, pad = input_305_pad_0, pad_type = input_305_pad_type_0, strides = var_4220, weight = layers_10_self_attn_v_proj_loraA_weight_to_fp16, x = obj_141_cast_fp16)[name = tensor<string, []>("input_305_cast_fp16")];
            tensor<int32, [2]> var_4226 = const()[name = tensor<string, []>("op_4226"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4228 = const()[name = tensor<string, []>("op_4228"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_409_pad_type_0 = const()[name = tensor<string, []>("lora_out_409_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_409_pad_0 = const()[name = tensor<string, []>("lora_out_409_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_411_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_411_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(278811136)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_411_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_4228, groups = var_4127, pad = lora_out_409_pad_0, pad_type = lora_out_409_pad_type_0, strides = var_4226, weight = lora_out_411_weight_0_to_fp16, x = input_305_cast_fp16)[name = tensor<string, []>("lora_out_411_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_21_cast_fp16 = add(x = pretrained_out_205_cast_fp16, y = lora_out_411_cast_fp16)[name = tensor<string, []>("current_value_21_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_4238_cast_fp16 = mul(x = current_key_21_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_4238_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_4240_cast_fp16 = mul(x = var_103_cast_fp16_10, y = var_295_cast_fp16)[name = tensor<string, []>("op_4240_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_41_cast_fp16 = add(x = var_4238_cast_fp16, y = var_4240_cast_fp16)[name = tensor<string, []>("key_41_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_4242_cast_fp16 = mul(x = current_value_21_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_4242_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_4244_cast_fp16 = mul(x = var_138_cast_fp16_10, y = var_295_cast_fp16)[name = tensor<string, []>("op_4244_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_41_cast_fp16 = add(x = var_4242_cast_fp16, y = var_4244_cast_fp16)[name = tensor<string, []>("value_41_cast_fp16")];
            tensor<int32, [4]> var_4247 = const()[name = tensor<string, []>("op_4247"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_4248_cast_fp16 = reshape(shape = var_4247, x = query_41_cast_fp16)[name = tensor<string, []>("op_4248_cast_fp16")];
            tensor<fp16, []> var_4249_to_fp16 = const()[name = tensor<string, []>("op_4249_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_4250_cast_fp16 = mul(x = var_4248_cast_fp16, y = var_4249_to_fp16)[name = tensor<string, []>("op_4250_cast_fp16")];
            tensor<int32, [4]> var_4251 = const()[name = tensor<string, []>("op_4251"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_4252_cast_fp16 = reshape(shape = var_4251, x = key_41_cast_fp16)[name = tensor<string, []>("op_4252_cast_fp16")];
            tensor<bool, []> mh_w_61_transpose_x_0 = const()[name = tensor<string, []>("mh_w_61_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_61_transpose_y_0 = const()[name = tensor<string, []>("mh_w_61_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_61_cast_fp16 = matmul(transpose_x = mh_w_61_transpose_x_0, transpose_y = mh_w_61_transpose_y_0, x = var_4250_cast_fp16, y = var_4252_cast_fp16)[name = tensor<string, []>("mh_w_61_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_63_cast_fp16 = add(x = mh_w_61_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_63_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_4260_cast_fp16 = softmax(axis = var_4120, x = mh_w_63_cast_fp16)[name = tensor<string, []>("op_4260_cast_fp16")];
            tensor<int32, [4]> var_4261 = const()[name = tensor<string, []>("op_4261"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_4262_cast_fp16 = reshape(shape = var_4261, x = value_41_cast_fp16)[name = tensor<string, []>("op_4262_cast_fp16")];
            tensor<bool, []> attn_41_transpose_x_0 = const()[name = tensor<string, []>("attn_41_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_41_transpose_y_0 = const()[name = tensor<string, []>("attn_41_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_41_cast_fp16 = matmul(transpose_x = attn_41_transpose_x_0, transpose_y = attn_41_transpose_y_0, x = var_4262_cast_fp16, y = var_4260_cast_fp16)[name = tensor<string, []>("attn_41_cast_fp16")];
            tensor<int32, [4]> var_4265 = const()[name = tensor<string, []>("op_4265"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_307_cast_fp16 = reshape(shape = var_4265, x = attn_41_cast_fp16)[name = tensor<string, []>("input_307_cast_fp16")];
            tensor<int32, [2]> var_4272 = const()[name = tensor<string, []>("op_4272"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4274 = const()[name = tensor<string, []>("op_4274"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_207_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_207_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_207_pad_0 = const()[name = tensor<string, []>("pretrained_out_207_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_10_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(278852160))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(279671424))), name = tensor<string, []>("layers_10_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_10_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_10_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(279671552)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_207_cast_fp16 = conv(bias = layers_10_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_4274, groups = var_4127, pad = pretrained_out_207_pad_0, pad_type = pretrained_out_207_pad_type_0, strides = var_4272, weight = layers_10_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_307_cast_fp16)[name = tensor<string, []>("pretrained_out_207_cast_fp16")];
            tensor<int32, [2]> var_4278 = const()[name = tensor<string, []>("op_4278"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4280 = const()[name = tensor<string, []>("op_4280"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_309_pad_type_0 = const()[name = tensor<string, []>("input_309_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_309_pad_0 = const()[name = tensor<string, []>("input_309_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_10_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_10_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(279674176)))];
            tensor<fp16, [1, 16, 1, 1]> input_309_cast_fp16 = conv(dilations = var_4280, groups = var_4127, pad = input_309_pad_0, pad_type = input_309_pad_type_0, strides = var_4278, weight = layers_10_self_attn_o_proj_loraA_weight_to_fp16, x = input_307_cast_fp16)[name = tensor<string, []>("input_309_cast_fp16")];
            tensor<int32, [2]> var_4284 = const()[name = tensor<string, []>("op_4284"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4286 = const()[name = tensor<string, []>("op_4286"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_413_pad_type_0 = const()[name = tensor<string, []>("lora_out_413_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_413_pad_0 = const()[name = tensor<string, []>("lora_out_413_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_415_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_415_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(279715200)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_415_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_4286, groups = var_4127, pad = lora_out_413_pad_0, pad_type = lora_out_413_pad_type_0, strides = var_4284, weight = lora_out_415_weight_0_to_fp16, x = input_309_cast_fp16)[name = tensor<string, []>("lora_out_415_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_147_cast_fp16 = add(x = pretrained_out_207_cast_fp16, y = lora_out_415_cast_fp16)[name = tensor<string, []>("obj_147_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_63_cast_fp16 = add(x = inputs_61_cast_fp16, y = obj_147_cast_fp16)[name = tensor<string, []>("inputs_63_cast_fp16")];
            tensor<int32, [1]> var_4299 = const()[name = tensor<string, []>("op_4299"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_63_cast_fp16 = reduce_mean(axes = var_4299, keep_dims = var_4128, x = inputs_63_cast_fp16)[name = tensor<string, []>("channels_mean_63_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_63_cast_fp16 = sub(x = inputs_63_cast_fp16, y = channels_mean_63_cast_fp16)[name = tensor<string, []>("zero_mean_63_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_63_cast_fp16 = mul(x = zero_mean_63_cast_fp16, y = zero_mean_63_cast_fp16)[name = tensor<string, []>("zero_mean_sq_63_cast_fp16")];
            tensor<int32, [1]> var_4303 = const()[name = tensor<string, []>("op_4303"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_4304_cast_fp16 = reduce_mean(axes = var_4303, keep_dims = var_4128, x = zero_mean_sq_63_cast_fp16)[name = tensor<string, []>("op_4304_cast_fp16")];
            tensor<fp16, []> var_4305_to_fp16 = const()[name = tensor<string, []>("op_4305_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_4306_cast_fp16 = add(x = var_4304_cast_fp16, y = var_4305_to_fp16)[name = tensor<string, []>("op_4306_cast_fp16")];
            tensor<fp32, []> denom_63_epsilon_0 = const()[name = tensor<string, []>("denom_63_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_63_cast_fp16 = rsqrt(epsilon = denom_63_epsilon_0, x = var_4306_cast_fp16)[name = tensor<string, []>("denom_63_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_63_cast_fp16 = mul(x = zero_mean_63_cast_fp16, y = denom_63_cast_fp16)[name = tensor<string, []>("out_63_cast_fp16")];
            tensor<fp16, [1280]> obj_149_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_149_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(279756224)))];
            tensor<fp16, [1280]> obj_149_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_149_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(279758848)))];
            tensor<fp16, []> obj_149_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_149_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_149_cast_fp16 = batch_norm(beta = obj_149_beta_0_to_fp16, epsilon = obj_149_epsilon_0_to_fp16, gamma = obj_149_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_63_cast_fp16)[name = tensor<string, []>("obj_149_cast_fp16")];
            tensor<int32, [2]> var_4324 = const()[name = tensor<string, []>("op_4324"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4326 = const()[name = tensor<string, []>("op_4326"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_209_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_209_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_209_pad_0 = const()[name = tensor<string, []>("pretrained_out_209_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_10_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(279761472))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(280580736))), name = tensor<string, []>("layers_10_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_10_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_10_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(280580864)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_209_cast_fp16 = conv(bias = layers_10_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_4326, groups = var_4127, pad = pretrained_out_209_pad_0, pad_type = pretrained_out_209_pad_type_0, strides = var_4324, weight = layers_10_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_149_cast_fp16)[name = tensor<string, []>("pretrained_out_209_cast_fp16")];
            tensor<int32, [2]> var_4330 = const()[name = tensor<string, []>("op_4330"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4332 = const()[name = tensor<string, []>("op_4332"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_311_pad_type_0 = const()[name = tensor<string, []>("input_311_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_311_pad_0 = const()[name = tensor<string, []>("input_311_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_10_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_10_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(280583488)))];
            tensor<fp16, [1, 16, 1, 1]> input_311_cast_fp16 = conv(dilations = var_4332, groups = var_4127, pad = input_311_pad_0, pad_type = input_311_pad_type_0, strides = var_4330, weight = layers_10_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_149_cast_fp16)[name = tensor<string, []>("input_311_cast_fp16")];
            tensor<int32, [2]> var_4336 = const()[name = tensor<string, []>("op_4336"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4338 = const()[name = tensor<string, []>("op_4338"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_417_pad_type_0 = const()[name = tensor<string, []>("lora_out_417_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_417_pad_0 = const()[name = tensor<string, []>("lora_out_417_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_419_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_419_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(280624512)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_419_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_4338, groups = var_4127, pad = lora_out_417_pad_0, pad_type = lora_out_417_pad_type_0, strides = var_4336, weight = lora_out_419_weight_0_to_fp16, x = input_311_cast_fp16)[name = tensor<string, []>("lora_out_419_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_43_cast_fp16 = add(x = pretrained_out_209_cast_fp16, y = lora_out_419_cast_fp16)[name = tensor<string, []>("query_43_cast_fp16")];
            tensor<int32, [2]> var_4348 = const()[name = tensor<string, []>("op_4348"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4350 = const()[name = tensor<string, []>("op_4350"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_211_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_211_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_211_pad_0 = const()[name = tensor<string, []>("pretrained_out_211_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_10_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(280665536))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(281484800))), name = tensor<string, []>("layers_10_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_211_cast_fp16 = conv(dilations = var_4350, groups = var_4127, pad = pretrained_out_211_pad_0, pad_type = pretrained_out_211_pad_type_0, strides = var_4348, weight = layers_10_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_211_cast_fp16")];
            tensor<int32, [2]> var_4354 = const()[name = tensor<string, []>("op_4354"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4356 = const()[name = tensor<string, []>("op_4356"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_313_pad_type_0 = const()[name = tensor<string, []>("input_313_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_313_pad_0 = const()[name = tensor<string, []>("input_313_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_10_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_10_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(281484928)))];
            tensor<fp16, [1, 16, 1, 1500]> input_313_cast_fp16 = conv(dilations = var_4356, groups = var_4127, pad = input_313_pad_0, pad_type = input_313_pad_type_0, strides = var_4354, weight = layers_10_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_313_cast_fp16")];
            tensor<int32, [2]> var_4360 = const()[name = tensor<string, []>("op_4360"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4362 = const()[name = tensor<string, []>("op_4362"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_421_pad_type_0 = const()[name = tensor<string, []>("lora_out_421_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_421_pad_0 = const()[name = tensor<string, []>("lora_out_421_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_423_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_423_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(281525952)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_423_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_4362, groups = var_4127, pad = lora_out_421_pad_0, pad_type = lora_out_421_pad_type_0, strides = var_4360, weight = lora_out_423_weight_0_to_fp16, x = input_313_cast_fp16)[name = tensor<string, []>("lora_out_423_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_43_cast_fp16 = add(x = pretrained_out_211_cast_fp16, y = lora_out_423_cast_fp16)[name = tensor<string, []>("key_43_cast_fp16")];
            tensor<int32, [2]> var_4373 = const()[name = tensor<string, []>("op_4373"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4375 = const()[name = tensor<string, []>("op_4375"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_213_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_213_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_213_pad_0 = const()[name = tensor<string, []>("pretrained_out_213_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_10_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(281566976))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(282386240))), name = tensor<string, []>("layers_10_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_10_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_10_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(282386368)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_213_cast_fp16 = conv(bias = layers_10_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_4375, groups = var_4127, pad = pretrained_out_213_pad_0, pad_type = pretrained_out_213_pad_type_0, strides = var_4373, weight = layers_10_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_213_cast_fp16")];
            tensor<int32, [2]> var_4379 = const()[name = tensor<string, []>("op_4379"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4381 = const()[name = tensor<string, []>("op_4381"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_315_pad_type_0 = const()[name = tensor<string, []>("input_315_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_315_pad_0 = const()[name = tensor<string, []>("input_315_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_10_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_10_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(282388992)))];
            tensor<fp16, [1, 16, 1, 1500]> input_315_cast_fp16 = conv(dilations = var_4381, groups = var_4127, pad = input_315_pad_0, pad_type = input_315_pad_type_0, strides = var_4379, weight = layers_10_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_315_cast_fp16")];
            tensor<int32, [2]> var_4385 = const()[name = tensor<string, []>("op_4385"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4387 = const()[name = tensor<string, []>("op_4387"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_425_pad_type_0 = const()[name = tensor<string, []>("lora_out_425_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_425_pad_0 = const()[name = tensor<string, []>("lora_out_425_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_427_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_427_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(282430016)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_427_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_4387, groups = var_4127, pad = lora_out_425_pad_0, pad_type = lora_out_425_pad_type_0, strides = var_4385, weight = lora_out_427_weight_0_to_fp16, x = input_315_cast_fp16)[name = tensor<string, []>("lora_out_427_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_43_cast_fp16 = add(x = pretrained_out_213_cast_fp16, y = lora_out_427_cast_fp16)[name = tensor<string, []>("value_43_cast_fp16")];
            tensor<int32, [4]> var_4394 = const()[name = tensor<string, []>("op_4394"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_4395_cast_fp16 = reshape(shape = var_4394, x = query_43_cast_fp16)[name = tensor<string, []>("op_4395_cast_fp16")];
            tensor<fp16, []> var_4396_to_fp16 = const()[name = tensor<string, []>("op_4396_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_4397_cast_fp16 = mul(x = var_4395_cast_fp16, y = var_4396_to_fp16)[name = tensor<string, []>("op_4397_cast_fp16")];
            tensor<int32, [4]> var_4398 = const()[name = tensor<string, []>("op_4398"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_4399_cast_fp16 = reshape(shape = var_4398, x = key_43_cast_fp16)[name = tensor<string, []>("op_4399_cast_fp16")];
            tensor<bool, []> mh_w_65_transpose_x_0 = const()[name = tensor<string, []>("mh_w_65_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_65_transpose_y_0 = const()[name = tensor<string, []>("mh_w_65_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_65_cast_fp16 = matmul(transpose_x = mh_w_65_transpose_x_0, transpose_y = mh_w_65_transpose_y_0, x = var_4397_cast_fp16, y = var_4399_cast_fp16)[name = tensor<string, []>("mh_w_65_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_153_cast_fp16 = softmax(axis = var_4120, x = mh_w_65_cast_fp16)[name = tensor<string, []>("obj_153_cast_fp16")];
            tensor<int32, [4]> var_4403 = const()[name = tensor<string, []>("op_4403"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_4404_cast_fp16 = reshape(shape = var_4403, x = value_43_cast_fp16)[name = tensor<string, []>("op_4404_cast_fp16")];
            tensor<bool, []> attn_43_transpose_x_0 = const()[name = tensor<string, []>("attn_43_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_43_transpose_y_0 = const()[name = tensor<string, []>("attn_43_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_43_cast_fp16 = matmul(transpose_x = attn_43_transpose_x_0, transpose_y = attn_43_transpose_y_0, x = var_4404_cast_fp16, y = obj_153_cast_fp16)[name = tensor<string, []>("attn_43_cast_fp16")];
            tensor<int32, [4]> var_4407 = const()[name = tensor<string, []>("op_4407"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_317_cast_fp16 = reshape(shape = var_4407, x = attn_43_cast_fp16)[name = tensor<string, []>("input_317_cast_fp16")];
            tensor<int32, [2]> var_4414 = const()[name = tensor<string, []>("op_4414"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4416 = const()[name = tensor<string, []>("op_4416"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_215_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_215_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_215_pad_0 = const()[name = tensor<string, []>("pretrained_out_215_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_10_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(282471040))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(283290304))), name = tensor<string, []>("layers_10_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_10_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_10_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(283290432)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_215_cast_fp16 = conv(bias = layers_10_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_4416, groups = var_4127, pad = pretrained_out_215_pad_0, pad_type = pretrained_out_215_pad_type_0, strides = var_4414, weight = layers_10_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_317_cast_fp16)[name = tensor<string, []>("pretrained_out_215_cast_fp16")];
            tensor<int32, [2]> var_4420 = const()[name = tensor<string, []>("op_4420"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4422 = const()[name = tensor<string, []>("op_4422"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_319_pad_type_0 = const()[name = tensor<string, []>("input_319_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_319_pad_0 = const()[name = tensor<string, []>("input_319_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_10_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_10_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(283293056)))];
            tensor<fp16, [1, 16, 1, 1]> input_319_cast_fp16 = conv(dilations = var_4422, groups = var_4127, pad = input_319_pad_0, pad_type = input_319_pad_type_0, strides = var_4420, weight = layers_10_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_317_cast_fp16)[name = tensor<string, []>("input_319_cast_fp16")];
            tensor<int32, [2]> var_4426 = const()[name = tensor<string, []>("op_4426"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4428 = const()[name = tensor<string, []>("op_4428"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_429_pad_type_0 = const()[name = tensor<string, []>("lora_out_429_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_429_pad_0 = const()[name = tensor<string, []>("lora_out_429_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_431_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_431_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(283334080)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_431_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_4428, groups = var_4127, pad = lora_out_429_pad_0, pad_type = lora_out_429_pad_type_0, strides = var_4426, weight = lora_out_431_weight_0_to_fp16, x = input_319_cast_fp16)[name = tensor<string, []>("lora_out_431_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_151_cast_fp16 = add(x = pretrained_out_215_cast_fp16, y = lora_out_431_cast_fp16)[name = tensor<string, []>("obj_151_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_65_cast_fp16 = add(x = inputs_63_cast_fp16, y = obj_151_cast_fp16)[name = tensor<string, []>("inputs_65_cast_fp16")];
            tensor<int32, [1]> var_4440 = const()[name = tensor<string, []>("op_4440"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_65_cast_fp16 = reduce_mean(axes = var_4440, keep_dims = var_4128, x = inputs_65_cast_fp16)[name = tensor<string, []>("channels_mean_65_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_65_cast_fp16 = sub(x = inputs_65_cast_fp16, y = channels_mean_65_cast_fp16)[name = tensor<string, []>("zero_mean_65_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_65_cast_fp16 = mul(x = zero_mean_65_cast_fp16, y = zero_mean_65_cast_fp16)[name = tensor<string, []>("zero_mean_sq_65_cast_fp16")];
            tensor<int32, [1]> var_4444 = const()[name = tensor<string, []>("op_4444"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_4445_cast_fp16 = reduce_mean(axes = var_4444, keep_dims = var_4128, x = zero_mean_sq_65_cast_fp16)[name = tensor<string, []>("op_4445_cast_fp16")];
            tensor<fp16, []> var_4446_to_fp16 = const()[name = tensor<string, []>("op_4446_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_4447_cast_fp16 = add(x = var_4445_cast_fp16, y = var_4446_to_fp16)[name = tensor<string, []>("op_4447_cast_fp16")];
            tensor<fp32, []> denom_65_epsilon_0 = const()[name = tensor<string, []>("denom_65_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_65_cast_fp16 = rsqrt(epsilon = denom_65_epsilon_0, x = var_4447_cast_fp16)[name = tensor<string, []>("denom_65_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_65_cast_fp16 = mul(x = zero_mean_65_cast_fp16, y = denom_65_cast_fp16)[name = tensor<string, []>("out_65_cast_fp16")];
            tensor<fp16, [1280]> input_321_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_321_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(283375104)))];
            tensor<fp16, [1280]> input_321_beta_0_to_fp16 = const()[name = tensor<string, []>("input_321_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(283377728)))];
            tensor<fp16, []> input_321_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_321_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_321_cast_fp16 = batch_norm(beta = input_321_beta_0_to_fp16, epsilon = input_321_epsilon_0_to_fp16, gamma = input_321_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_65_cast_fp16)[name = tensor<string, []>("input_321_cast_fp16")];
            tensor<int32, [2]> var_4461 = const()[name = tensor<string, []>("op_4461"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4463 = const()[name = tensor<string, []>("op_4463"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_217_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_217_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_217_pad_0 = const()[name = tensor<string, []>("pretrained_out_217_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_10_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(283380352))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(286657216))), name = tensor<string, []>("layers_10_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_10_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_10_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(286657344)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_217_cast_fp16 = conv(bias = layers_10_fc1_pretrained_bias_to_fp16, dilations = var_4463, groups = var_4127, pad = pretrained_out_217_pad_0, pad_type = pretrained_out_217_pad_type_0, strides = var_4461, weight = layers_10_fc1_pretrained_weight_to_fp16_palettized, x = input_321_cast_fp16)[name = tensor<string, []>("pretrained_out_217_cast_fp16")];
            tensor<int32, [2]> var_4467 = const()[name = tensor<string, []>("op_4467"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4469 = const()[name = tensor<string, []>("op_4469"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_323_pad_type_0 = const()[name = tensor<string, []>("input_323_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_323_pad_0 = const()[name = tensor<string, []>("input_323_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_10_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_10_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(286667648)))];
            tensor<fp16, [1, 16, 1, 1]> input_323_cast_fp16 = conv(dilations = var_4469, groups = var_4127, pad = input_323_pad_0, pad_type = input_323_pad_type_0, strides = var_4467, weight = layers_10_fc1_loraA_weight_to_fp16, x = input_321_cast_fp16)[name = tensor<string, []>("input_323_cast_fp16")];
            tensor<int32, [2]> var_4473 = const()[name = tensor<string, []>("op_4473"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4475 = const()[name = tensor<string, []>("op_4475"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_433_pad_type_0 = const()[name = tensor<string, []>("lora_out_433_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_433_pad_0 = const()[name = tensor<string, []>("lora_out_433_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_435_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_435_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(286708672)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_435_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_4475, groups = var_4127, pad = lora_out_433_pad_0, pad_type = lora_out_433_pad_type_0, strides = var_4473, weight = lora_out_435_weight_0_to_fp16, x = input_323_cast_fp16)[name = tensor<string, []>("lora_out_435_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_325_cast_fp16 = add(x = pretrained_out_217_cast_fp16, y = lora_out_435_cast_fp16)[name = tensor<string, []>("input_325_cast_fp16")];
            tensor<string, []> input_327_mode_0 = const()[name = tensor<string, []>("input_327_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_327_cast_fp16 = gelu(mode = input_327_mode_0, x = input_325_cast_fp16)[name = tensor<string, []>("input_327_cast_fp16")];
            tensor<int32, [2]> var_4487 = const()[name = tensor<string, []>("op_4487"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4489 = const()[name = tensor<string, []>("op_4489"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_219_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_219_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_219_pad_0 = const()[name = tensor<string, []>("pretrained_out_219_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_10_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(286872576))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(290149440))), name = tensor<string, []>("layers_10_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_10_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_10_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(290149568)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_219_cast_fp16 = conv(bias = layers_10_fc2_pretrained_bias_to_fp16, dilations = var_4489, groups = var_4127, pad = pretrained_out_219_pad_0, pad_type = pretrained_out_219_pad_type_0, strides = var_4487, weight = layers_10_fc2_pretrained_weight_to_fp16_palettized, x = input_327_cast_fp16)[name = tensor<string, []>("pretrained_out_219_cast_fp16")];
            tensor<int32, [2]> var_4493 = const()[name = tensor<string, []>("op_4493"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4495 = const()[name = tensor<string, []>("op_4495"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_329_pad_type_0 = const()[name = tensor<string, []>("input_329_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_329_pad_0 = const()[name = tensor<string, []>("input_329_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_10_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_10_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(290152192)))];
            tensor<fp16, [1, 16, 1, 1]> input_329_cast_fp16 = conv(dilations = var_4495, groups = var_4127, pad = input_329_pad_0, pad_type = input_329_pad_type_0, strides = var_4493, weight = layers_10_fc2_loraA_weight_to_fp16, x = input_327_cast_fp16)[name = tensor<string, []>("input_329_cast_fp16")];
            tensor<int32, [2]> var_4499 = const()[name = tensor<string, []>("op_4499"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4501 = const()[name = tensor<string, []>("op_4501"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_437_pad_type_0 = const()[name = tensor<string, []>("lora_out_437_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_437_pad_0 = const()[name = tensor<string, []>("lora_out_437_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_439_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_439_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(290316096)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_439_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_4501, groups = var_4127, pad = lora_out_437_pad_0, pad_type = lora_out_437_pad_type_0, strides = var_4499, weight = lora_out_439_weight_0_to_fp16, x = input_329_cast_fp16)[name = tensor<string, []>("lora_out_439_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_23_cast_fp16 = add(x = pretrained_out_219_cast_fp16, y = lora_out_439_cast_fp16)[name = tensor<string, []>("hidden_states_23_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_67_cast_fp16 = add(x = inputs_65_cast_fp16, y = hidden_states_23_cast_fp16)[name = tensor<string, []>("inputs_67_cast_fp16")];
            tensor<int32, []> var_4518 = const()[name = tensor<string, []>("op_4518"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_4525 = const()[name = tensor<string, []>("op_4525"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_4526 = const()[name = tensor<string, []>("op_4526"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_4538 = const()[name = tensor<string, []>("op_4538"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_67_cast_fp16 = reduce_mean(axes = var_4538, keep_dims = var_4526, x = inputs_67_cast_fp16)[name = tensor<string, []>("channels_mean_67_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_67_cast_fp16 = sub(x = inputs_67_cast_fp16, y = channels_mean_67_cast_fp16)[name = tensor<string, []>("zero_mean_67_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_67_cast_fp16 = mul(x = zero_mean_67_cast_fp16, y = zero_mean_67_cast_fp16)[name = tensor<string, []>("zero_mean_sq_67_cast_fp16")];
            tensor<int32, [1]> var_4542 = const()[name = tensor<string, []>("op_4542"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_4543_cast_fp16 = reduce_mean(axes = var_4542, keep_dims = var_4526, x = zero_mean_sq_67_cast_fp16)[name = tensor<string, []>("op_4543_cast_fp16")];
            tensor<fp16, []> var_4544_to_fp16 = const()[name = tensor<string, []>("op_4544_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_4545_cast_fp16 = add(x = var_4543_cast_fp16, y = var_4544_to_fp16)[name = tensor<string, []>("op_4545_cast_fp16")];
            tensor<fp32, []> denom_67_epsilon_0 = const()[name = tensor<string, []>("denom_67_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_67_cast_fp16 = rsqrt(epsilon = denom_67_epsilon_0, x = var_4545_cast_fp16)[name = tensor<string, []>("denom_67_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_67_cast_fp16 = mul(x = zero_mean_67_cast_fp16, y = denom_67_cast_fp16)[name = tensor<string, []>("out_67_cast_fp16")];
            tensor<fp16, [1280]> obj_155_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_155_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(290357120)))];
            tensor<fp16, [1280]> obj_155_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_155_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(290359744)))];
            tensor<fp16, []> obj_155_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_155_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_155_cast_fp16 = batch_norm(beta = obj_155_beta_0_to_fp16, epsilon = obj_155_epsilon_0_to_fp16, gamma = obj_155_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_67_cast_fp16)[name = tensor<string, []>("obj_155_cast_fp16")];
            tensor<int32, [2]> var_4563 = const()[name = tensor<string, []>("op_4563"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4565 = const()[name = tensor<string, []>("op_4565"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_221_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_221_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_221_pad_0 = const()[name = tensor<string, []>("pretrained_out_221_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_11_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(290362368))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(291181632))), name = tensor<string, []>("layers_11_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_11_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_11_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(291181760)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_221_cast_fp16 = conv(bias = layers_11_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_4565, groups = var_4525, pad = pretrained_out_221_pad_0, pad_type = pretrained_out_221_pad_type_0, strides = var_4563, weight = layers_11_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_155_cast_fp16)[name = tensor<string, []>("pretrained_out_221_cast_fp16")];
            tensor<int32, [2]> var_4569 = const()[name = tensor<string, []>("op_4569"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4571 = const()[name = tensor<string, []>("op_4571"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_331_pad_type_0 = const()[name = tensor<string, []>("input_331_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_331_pad_0 = const()[name = tensor<string, []>("input_331_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_11_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_11_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(291184384)))];
            tensor<fp16, [1, 16, 1, 1]> input_331_cast_fp16 = conv(dilations = var_4571, groups = var_4525, pad = input_331_pad_0, pad_type = input_331_pad_type_0, strides = var_4569, weight = layers_11_self_attn_q_proj_loraA_weight_to_fp16, x = obj_155_cast_fp16)[name = tensor<string, []>("input_331_cast_fp16")];
            tensor<int32, [2]> var_4575 = const()[name = tensor<string, []>("op_4575"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4577 = const()[name = tensor<string, []>("op_4577"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_441_pad_type_0 = const()[name = tensor<string, []>("lora_out_441_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_441_pad_0 = const()[name = tensor<string, []>("lora_out_441_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_443_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_443_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(291225408)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_443_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_4577, groups = var_4525, pad = lora_out_441_pad_0, pad_type = lora_out_441_pad_type_0, strides = var_4575, weight = lora_out_443_weight_0_to_fp16, x = input_331_cast_fp16)[name = tensor<string, []>("lora_out_443_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_45_cast_fp16 = add(x = pretrained_out_221_cast_fp16, y = lora_out_443_cast_fp16)[name = tensor<string, []>("query_45_cast_fp16")];
            tensor<int32, [2]> var_4587 = const()[name = tensor<string, []>("op_4587"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4589 = const()[name = tensor<string, []>("op_4589"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_223_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_223_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_223_pad_0 = const()[name = tensor<string, []>("pretrained_out_223_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_11_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(291266432))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(292085696))), name = tensor<string, []>("layers_11_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_223_cast_fp16 = conv(dilations = var_4589, groups = var_4525, pad = pretrained_out_223_pad_0, pad_type = pretrained_out_223_pad_type_0, strides = var_4587, weight = layers_11_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_155_cast_fp16)[name = tensor<string, []>("pretrained_out_223_cast_fp16")];
            tensor<int32, [2]> var_4593 = const()[name = tensor<string, []>("op_4593"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4595 = const()[name = tensor<string, []>("op_4595"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_333_pad_type_0 = const()[name = tensor<string, []>("input_333_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_333_pad_0 = const()[name = tensor<string, []>("input_333_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_11_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_11_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(292085824)))];
            tensor<fp16, [1, 16, 1, 1]> input_333_cast_fp16 = conv(dilations = var_4595, groups = var_4525, pad = input_333_pad_0, pad_type = input_333_pad_type_0, strides = var_4593, weight = layers_11_self_attn_k_proj_loraA_weight_to_fp16, x = obj_155_cast_fp16)[name = tensor<string, []>("input_333_cast_fp16")];
            tensor<int32, [2]> var_4599 = const()[name = tensor<string, []>("op_4599"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4601 = const()[name = tensor<string, []>("op_4601"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_445_pad_type_0 = const()[name = tensor<string, []>("lora_out_445_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_445_pad_0 = const()[name = tensor<string, []>("lora_out_445_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_447_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_447_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(292126848)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_447_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_4601, groups = var_4525, pad = lora_out_445_pad_0, pad_type = lora_out_445_pad_type_0, strides = var_4599, weight = lora_out_447_weight_0_to_fp16, x = input_333_cast_fp16)[name = tensor<string, []>("lora_out_447_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_23_cast_fp16 = add(x = pretrained_out_223_cast_fp16, y = lora_out_447_cast_fp16)[name = tensor<string, []>("current_key_23_cast_fp16")];
            tensor<int32, [2]> var_4612 = const()[name = tensor<string, []>("op_4612"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4614 = const()[name = tensor<string, []>("op_4614"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_225_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_225_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_225_pad_0 = const()[name = tensor<string, []>("pretrained_out_225_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_11_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(292167872))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(292987136))), name = tensor<string, []>("layers_11_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_11_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_11_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(292987264)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_225_cast_fp16 = conv(bias = layers_11_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_4614, groups = var_4525, pad = pretrained_out_225_pad_0, pad_type = pretrained_out_225_pad_type_0, strides = var_4612, weight = layers_11_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_155_cast_fp16)[name = tensor<string, []>("pretrained_out_225_cast_fp16")];
            tensor<int32, [2]> var_4618 = const()[name = tensor<string, []>("op_4618"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4620 = const()[name = tensor<string, []>("op_4620"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_335_pad_type_0 = const()[name = tensor<string, []>("input_335_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_335_pad_0 = const()[name = tensor<string, []>("input_335_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_11_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_11_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(292989888)))];
            tensor<fp16, [1, 16, 1, 1]> input_335_cast_fp16 = conv(dilations = var_4620, groups = var_4525, pad = input_335_pad_0, pad_type = input_335_pad_type_0, strides = var_4618, weight = layers_11_self_attn_v_proj_loraA_weight_to_fp16, x = obj_155_cast_fp16)[name = tensor<string, []>("input_335_cast_fp16")];
            tensor<int32, [2]> var_4624 = const()[name = tensor<string, []>("op_4624"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4626 = const()[name = tensor<string, []>("op_4626"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_449_pad_type_0 = const()[name = tensor<string, []>("lora_out_449_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_449_pad_0 = const()[name = tensor<string, []>("lora_out_449_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_451_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_451_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(293030912)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_451_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_4626, groups = var_4525, pad = lora_out_449_pad_0, pad_type = lora_out_449_pad_type_0, strides = var_4624, weight = lora_out_451_weight_0_to_fp16, x = input_335_cast_fp16)[name = tensor<string, []>("lora_out_451_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_23_cast_fp16 = add(x = pretrained_out_225_cast_fp16, y = lora_out_451_cast_fp16)[name = tensor<string, []>("current_value_23_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_4636_cast_fp16 = mul(x = current_key_23_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_4636_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_4638_cast_fp16 = mul(x = var_103_cast_fp16_11, y = var_295_cast_fp16)[name = tensor<string, []>("op_4638_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_45_cast_fp16 = add(x = var_4636_cast_fp16, y = var_4638_cast_fp16)[name = tensor<string, []>("key_45_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_4640_cast_fp16 = mul(x = current_value_23_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_4640_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_4642_cast_fp16 = mul(x = var_138_cast_fp16_11, y = var_295_cast_fp16)[name = tensor<string, []>("op_4642_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_45_cast_fp16 = add(x = var_4640_cast_fp16, y = var_4642_cast_fp16)[name = tensor<string, []>("value_45_cast_fp16")];
            tensor<int32, [4]> var_4645 = const()[name = tensor<string, []>("op_4645"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_4646_cast_fp16 = reshape(shape = var_4645, x = query_45_cast_fp16)[name = tensor<string, []>("op_4646_cast_fp16")];
            tensor<fp16, []> var_4647_to_fp16 = const()[name = tensor<string, []>("op_4647_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_4648_cast_fp16 = mul(x = var_4646_cast_fp16, y = var_4647_to_fp16)[name = tensor<string, []>("op_4648_cast_fp16")];
            tensor<int32, [4]> var_4649 = const()[name = tensor<string, []>("op_4649"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_4650_cast_fp16 = reshape(shape = var_4649, x = key_45_cast_fp16)[name = tensor<string, []>("op_4650_cast_fp16")];
            tensor<bool, []> mh_w_67_transpose_x_0 = const()[name = tensor<string, []>("mh_w_67_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_67_transpose_y_0 = const()[name = tensor<string, []>("mh_w_67_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_67_cast_fp16 = matmul(transpose_x = mh_w_67_transpose_x_0, transpose_y = mh_w_67_transpose_y_0, x = var_4648_cast_fp16, y = var_4650_cast_fp16)[name = tensor<string, []>("mh_w_67_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_69_cast_fp16 = add(x = mh_w_67_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_69_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_4658_cast_fp16 = softmax(axis = var_4518, x = mh_w_69_cast_fp16)[name = tensor<string, []>("op_4658_cast_fp16")];
            tensor<int32, [4]> var_4659 = const()[name = tensor<string, []>("op_4659"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_4660_cast_fp16 = reshape(shape = var_4659, x = value_45_cast_fp16)[name = tensor<string, []>("op_4660_cast_fp16")];
            tensor<bool, []> attn_45_transpose_x_0 = const()[name = tensor<string, []>("attn_45_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_45_transpose_y_0 = const()[name = tensor<string, []>("attn_45_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_45_cast_fp16 = matmul(transpose_x = attn_45_transpose_x_0, transpose_y = attn_45_transpose_y_0, x = var_4660_cast_fp16, y = var_4658_cast_fp16)[name = tensor<string, []>("attn_45_cast_fp16")];
            tensor<int32, [4]> var_4663 = const()[name = tensor<string, []>("op_4663"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_337_cast_fp16 = reshape(shape = var_4663, x = attn_45_cast_fp16)[name = tensor<string, []>("input_337_cast_fp16")];
            tensor<int32, [2]> var_4670 = const()[name = tensor<string, []>("op_4670"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4672 = const()[name = tensor<string, []>("op_4672"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_227_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_227_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_227_pad_0 = const()[name = tensor<string, []>("pretrained_out_227_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_11_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(293071936))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(293891200))), name = tensor<string, []>("layers_11_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_11_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_11_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(293891328)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_227_cast_fp16 = conv(bias = layers_11_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_4672, groups = var_4525, pad = pretrained_out_227_pad_0, pad_type = pretrained_out_227_pad_type_0, strides = var_4670, weight = layers_11_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_337_cast_fp16)[name = tensor<string, []>("pretrained_out_227_cast_fp16")];
            tensor<int32, [2]> var_4676 = const()[name = tensor<string, []>("op_4676"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4678 = const()[name = tensor<string, []>("op_4678"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_339_pad_type_0 = const()[name = tensor<string, []>("input_339_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_339_pad_0 = const()[name = tensor<string, []>("input_339_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_11_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_11_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(293893952)))];
            tensor<fp16, [1, 16, 1, 1]> input_339_cast_fp16 = conv(dilations = var_4678, groups = var_4525, pad = input_339_pad_0, pad_type = input_339_pad_type_0, strides = var_4676, weight = layers_11_self_attn_o_proj_loraA_weight_to_fp16, x = input_337_cast_fp16)[name = tensor<string, []>("input_339_cast_fp16")];
            tensor<int32, [2]> var_4682 = const()[name = tensor<string, []>("op_4682"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4684 = const()[name = tensor<string, []>("op_4684"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_453_pad_type_0 = const()[name = tensor<string, []>("lora_out_453_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_453_pad_0 = const()[name = tensor<string, []>("lora_out_453_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_455_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_455_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(293934976)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_455_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_4684, groups = var_4525, pad = lora_out_453_pad_0, pad_type = lora_out_453_pad_type_0, strides = var_4682, weight = lora_out_455_weight_0_to_fp16, x = input_339_cast_fp16)[name = tensor<string, []>("lora_out_455_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_161_cast_fp16 = add(x = pretrained_out_227_cast_fp16, y = lora_out_455_cast_fp16)[name = tensor<string, []>("obj_161_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_69_cast_fp16 = add(x = inputs_67_cast_fp16, y = obj_161_cast_fp16)[name = tensor<string, []>("inputs_69_cast_fp16")];
            tensor<int32, [1]> var_4697 = const()[name = tensor<string, []>("op_4697"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_69_cast_fp16 = reduce_mean(axes = var_4697, keep_dims = var_4526, x = inputs_69_cast_fp16)[name = tensor<string, []>("channels_mean_69_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_69_cast_fp16 = sub(x = inputs_69_cast_fp16, y = channels_mean_69_cast_fp16)[name = tensor<string, []>("zero_mean_69_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_69_cast_fp16 = mul(x = zero_mean_69_cast_fp16, y = zero_mean_69_cast_fp16)[name = tensor<string, []>("zero_mean_sq_69_cast_fp16")];
            tensor<int32, [1]> var_4701 = const()[name = tensor<string, []>("op_4701"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_4702_cast_fp16 = reduce_mean(axes = var_4701, keep_dims = var_4526, x = zero_mean_sq_69_cast_fp16)[name = tensor<string, []>("op_4702_cast_fp16")];
            tensor<fp16, []> var_4703_to_fp16 = const()[name = tensor<string, []>("op_4703_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_4704_cast_fp16 = add(x = var_4702_cast_fp16, y = var_4703_to_fp16)[name = tensor<string, []>("op_4704_cast_fp16")];
            tensor<fp32, []> denom_69_epsilon_0 = const()[name = tensor<string, []>("denom_69_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_69_cast_fp16 = rsqrt(epsilon = denom_69_epsilon_0, x = var_4704_cast_fp16)[name = tensor<string, []>("denom_69_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_69_cast_fp16 = mul(x = zero_mean_69_cast_fp16, y = denom_69_cast_fp16)[name = tensor<string, []>("out_69_cast_fp16")];
            tensor<fp16, [1280]> obj_163_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_163_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(293976000)))];
            tensor<fp16, [1280]> obj_163_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_163_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(293978624)))];
            tensor<fp16, []> obj_163_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_163_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_163_cast_fp16 = batch_norm(beta = obj_163_beta_0_to_fp16, epsilon = obj_163_epsilon_0_to_fp16, gamma = obj_163_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_69_cast_fp16)[name = tensor<string, []>("obj_163_cast_fp16")];
            tensor<int32, [2]> var_4722 = const()[name = tensor<string, []>("op_4722"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4724 = const()[name = tensor<string, []>("op_4724"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_229_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_229_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_229_pad_0 = const()[name = tensor<string, []>("pretrained_out_229_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_11_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(293981248))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(294800512))), name = tensor<string, []>("layers_11_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_11_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_11_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(294800640)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_229_cast_fp16 = conv(bias = layers_11_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_4724, groups = var_4525, pad = pretrained_out_229_pad_0, pad_type = pretrained_out_229_pad_type_0, strides = var_4722, weight = layers_11_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_163_cast_fp16)[name = tensor<string, []>("pretrained_out_229_cast_fp16")];
            tensor<int32, [2]> var_4728 = const()[name = tensor<string, []>("op_4728"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4730 = const()[name = tensor<string, []>("op_4730"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_341_pad_type_0 = const()[name = tensor<string, []>("input_341_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_341_pad_0 = const()[name = tensor<string, []>("input_341_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_11_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_11_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(294803264)))];
            tensor<fp16, [1, 16, 1, 1]> input_341_cast_fp16 = conv(dilations = var_4730, groups = var_4525, pad = input_341_pad_0, pad_type = input_341_pad_type_0, strides = var_4728, weight = layers_11_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_163_cast_fp16)[name = tensor<string, []>("input_341_cast_fp16")];
            tensor<int32, [2]> var_4734 = const()[name = tensor<string, []>("op_4734"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4736 = const()[name = tensor<string, []>("op_4736"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_457_pad_type_0 = const()[name = tensor<string, []>("lora_out_457_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_457_pad_0 = const()[name = tensor<string, []>("lora_out_457_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_459_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_459_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(294844288)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_459_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_4736, groups = var_4525, pad = lora_out_457_pad_0, pad_type = lora_out_457_pad_type_0, strides = var_4734, weight = lora_out_459_weight_0_to_fp16, x = input_341_cast_fp16)[name = tensor<string, []>("lora_out_459_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_47_cast_fp16 = add(x = pretrained_out_229_cast_fp16, y = lora_out_459_cast_fp16)[name = tensor<string, []>("query_47_cast_fp16")];
            tensor<int32, [2]> var_4746 = const()[name = tensor<string, []>("op_4746"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4748 = const()[name = tensor<string, []>("op_4748"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_231_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_231_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_231_pad_0 = const()[name = tensor<string, []>("pretrained_out_231_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_11_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(294885312))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(295704576))), name = tensor<string, []>("layers_11_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_231_cast_fp16 = conv(dilations = var_4748, groups = var_4525, pad = pretrained_out_231_pad_0, pad_type = pretrained_out_231_pad_type_0, strides = var_4746, weight = layers_11_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_231_cast_fp16")];
            tensor<int32, [2]> var_4752 = const()[name = tensor<string, []>("op_4752"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4754 = const()[name = tensor<string, []>("op_4754"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_343_pad_type_0 = const()[name = tensor<string, []>("input_343_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_343_pad_0 = const()[name = tensor<string, []>("input_343_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_11_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_11_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(295704704)))];
            tensor<fp16, [1, 16, 1, 1500]> input_343_cast_fp16 = conv(dilations = var_4754, groups = var_4525, pad = input_343_pad_0, pad_type = input_343_pad_type_0, strides = var_4752, weight = layers_11_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_343_cast_fp16")];
            tensor<int32, [2]> var_4758 = const()[name = tensor<string, []>("op_4758"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4760 = const()[name = tensor<string, []>("op_4760"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_461_pad_type_0 = const()[name = tensor<string, []>("lora_out_461_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_461_pad_0 = const()[name = tensor<string, []>("lora_out_461_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_463_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_463_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(295745728)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_463_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_4760, groups = var_4525, pad = lora_out_461_pad_0, pad_type = lora_out_461_pad_type_0, strides = var_4758, weight = lora_out_463_weight_0_to_fp16, x = input_343_cast_fp16)[name = tensor<string, []>("lora_out_463_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_47_cast_fp16 = add(x = pretrained_out_231_cast_fp16, y = lora_out_463_cast_fp16)[name = tensor<string, []>("key_47_cast_fp16")];
            tensor<int32, [2]> var_4771 = const()[name = tensor<string, []>("op_4771"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4773 = const()[name = tensor<string, []>("op_4773"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_233_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_233_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_233_pad_0 = const()[name = tensor<string, []>("pretrained_out_233_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_11_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(295786752))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(296606016))), name = tensor<string, []>("layers_11_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_11_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_11_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(296606144)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_233_cast_fp16 = conv(bias = layers_11_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_4773, groups = var_4525, pad = pretrained_out_233_pad_0, pad_type = pretrained_out_233_pad_type_0, strides = var_4771, weight = layers_11_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_233_cast_fp16")];
            tensor<int32, [2]> var_4777 = const()[name = tensor<string, []>("op_4777"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4779 = const()[name = tensor<string, []>("op_4779"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_345_pad_type_0 = const()[name = tensor<string, []>("input_345_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_345_pad_0 = const()[name = tensor<string, []>("input_345_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_11_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_11_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(296608768)))];
            tensor<fp16, [1, 16, 1, 1500]> input_345_cast_fp16 = conv(dilations = var_4779, groups = var_4525, pad = input_345_pad_0, pad_type = input_345_pad_type_0, strides = var_4777, weight = layers_11_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_345_cast_fp16")];
            tensor<int32, [2]> var_4783 = const()[name = tensor<string, []>("op_4783"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4785 = const()[name = tensor<string, []>("op_4785"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_465_pad_type_0 = const()[name = tensor<string, []>("lora_out_465_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_465_pad_0 = const()[name = tensor<string, []>("lora_out_465_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_467_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_467_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(296649792)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_467_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_4785, groups = var_4525, pad = lora_out_465_pad_0, pad_type = lora_out_465_pad_type_0, strides = var_4783, weight = lora_out_467_weight_0_to_fp16, x = input_345_cast_fp16)[name = tensor<string, []>("lora_out_467_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_47_cast_fp16 = add(x = pretrained_out_233_cast_fp16, y = lora_out_467_cast_fp16)[name = tensor<string, []>("value_47_cast_fp16")];
            tensor<int32, [4]> var_4792 = const()[name = tensor<string, []>("op_4792"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_4793_cast_fp16 = reshape(shape = var_4792, x = query_47_cast_fp16)[name = tensor<string, []>("op_4793_cast_fp16")];
            tensor<fp16, []> var_4794_to_fp16 = const()[name = tensor<string, []>("op_4794_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_4795_cast_fp16 = mul(x = var_4793_cast_fp16, y = var_4794_to_fp16)[name = tensor<string, []>("op_4795_cast_fp16")];
            tensor<int32, [4]> var_4796 = const()[name = tensor<string, []>("op_4796"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_4797_cast_fp16 = reshape(shape = var_4796, x = key_47_cast_fp16)[name = tensor<string, []>("op_4797_cast_fp16")];
            tensor<bool, []> mh_w_71_transpose_x_0 = const()[name = tensor<string, []>("mh_w_71_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_71_transpose_y_0 = const()[name = tensor<string, []>("mh_w_71_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_71_cast_fp16 = matmul(transpose_x = mh_w_71_transpose_x_0, transpose_y = mh_w_71_transpose_y_0, x = var_4795_cast_fp16, y = var_4797_cast_fp16)[name = tensor<string, []>("mh_w_71_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_167_cast_fp16 = softmax(axis = var_4518, x = mh_w_71_cast_fp16)[name = tensor<string, []>("obj_167_cast_fp16")];
            tensor<int32, [4]> var_4801 = const()[name = tensor<string, []>("op_4801"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_4802_cast_fp16 = reshape(shape = var_4801, x = value_47_cast_fp16)[name = tensor<string, []>("op_4802_cast_fp16")];
            tensor<bool, []> attn_47_transpose_x_0 = const()[name = tensor<string, []>("attn_47_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_47_transpose_y_0 = const()[name = tensor<string, []>("attn_47_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_47_cast_fp16 = matmul(transpose_x = attn_47_transpose_x_0, transpose_y = attn_47_transpose_y_0, x = var_4802_cast_fp16, y = obj_167_cast_fp16)[name = tensor<string, []>("attn_47_cast_fp16")];
            tensor<int32, [4]> var_4805 = const()[name = tensor<string, []>("op_4805"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_347_cast_fp16 = reshape(shape = var_4805, x = attn_47_cast_fp16)[name = tensor<string, []>("input_347_cast_fp16")];
            tensor<int32, [2]> var_4812 = const()[name = tensor<string, []>("op_4812"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4814 = const()[name = tensor<string, []>("op_4814"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_235_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_235_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_235_pad_0 = const()[name = tensor<string, []>("pretrained_out_235_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_11_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(296690816))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(297510080))), name = tensor<string, []>("layers_11_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_11_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_11_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(297510208)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_235_cast_fp16 = conv(bias = layers_11_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_4814, groups = var_4525, pad = pretrained_out_235_pad_0, pad_type = pretrained_out_235_pad_type_0, strides = var_4812, weight = layers_11_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_347_cast_fp16)[name = tensor<string, []>("pretrained_out_235_cast_fp16")];
            tensor<int32, [2]> var_4818 = const()[name = tensor<string, []>("op_4818"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4820 = const()[name = tensor<string, []>("op_4820"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_349_pad_type_0 = const()[name = tensor<string, []>("input_349_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_349_pad_0 = const()[name = tensor<string, []>("input_349_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_11_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_11_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(297512832)))];
            tensor<fp16, [1, 16, 1, 1]> input_349_cast_fp16 = conv(dilations = var_4820, groups = var_4525, pad = input_349_pad_0, pad_type = input_349_pad_type_0, strides = var_4818, weight = layers_11_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_347_cast_fp16)[name = tensor<string, []>("input_349_cast_fp16")];
            tensor<int32, [2]> var_4824 = const()[name = tensor<string, []>("op_4824"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4826 = const()[name = tensor<string, []>("op_4826"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_469_pad_type_0 = const()[name = tensor<string, []>("lora_out_469_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_469_pad_0 = const()[name = tensor<string, []>("lora_out_469_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_471_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_471_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(297553856)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_471_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_4826, groups = var_4525, pad = lora_out_469_pad_0, pad_type = lora_out_469_pad_type_0, strides = var_4824, weight = lora_out_471_weight_0_to_fp16, x = input_349_cast_fp16)[name = tensor<string, []>("lora_out_471_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_165_cast_fp16 = add(x = pretrained_out_235_cast_fp16, y = lora_out_471_cast_fp16)[name = tensor<string, []>("obj_165_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_71_cast_fp16 = add(x = inputs_69_cast_fp16, y = obj_165_cast_fp16)[name = tensor<string, []>("inputs_71_cast_fp16")];
            tensor<int32, [1]> var_4835 = const()[name = tensor<string, []>("op_4835"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_71_cast_fp16 = reduce_mean(axes = var_4835, keep_dims = var_4526, x = inputs_71_cast_fp16)[name = tensor<string, []>("channels_mean_71_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_71_cast_fp16 = sub(x = inputs_71_cast_fp16, y = channels_mean_71_cast_fp16)[name = tensor<string, []>("zero_mean_71_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_71_cast_fp16 = mul(x = zero_mean_71_cast_fp16, y = zero_mean_71_cast_fp16)[name = tensor<string, []>("zero_mean_sq_71_cast_fp16")];
            tensor<int32, [1]> var_4839 = const()[name = tensor<string, []>("op_4839"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_4840_cast_fp16 = reduce_mean(axes = var_4839, keep_dims = var_4526, x = zero_mean_sq_71_cast_fp16)[name = tensor<string, []>("op_4840_cast_fp16")];
            tensor<fp16, []> var_4841_to_fp16 = const()[name = tensor<string, []>("op_4841_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_4842_cast_fp16 = add(x = var_4840_cast_fp16, y = var_4841_to_fp16)[name = tensor<string, []>("op_4842_cast_fp16")];
            tensor<fp32, []> denom_71_epsilon_0 = const()[name = tensor<string, []>("denom_71_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_71_cast_fp16 = rsqrt(epsilon = denom_71_epsilon_0, x = var_4842_cast_fp16)[name = tensor<string, []>("denom_71_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_71_cast_fp16 = mul(x = zero_mean_71_cast_fp16, y = denom_71_cast_fp16)[name = tensor<string, []>("out_71_cast_fp16")];
            tensor<fp16, [1280]> input_351_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_351_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(297594880)))];
            tensor<fp16, [1280]> input_351_beta_0_to_fp16 = const()[name = tensor<string, []>("input_351_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(297597504)))];
            tensor<fp16, []> input_351_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_351_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_351_cast_fp16 = batch_norm(beta = input_351_beta_0_to_fp16, epsilon = input_351_epsilon_0_to_fp16, gamma = input_351_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_71_cast_fp16)[name = tensor<string, []>("input_351_cast_fp16")];
            tensor<int32, [2]> var_4856 = const()[name = tensor<string, []>("op_4856"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4858 = const()[name = tensor<string, []>("op_4858"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_237_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_237_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_237_pad_0 = const()[name = tensor<string, []>("pretrained_out_237_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_11_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(297600128))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(300876992))), name = tensor<string, []>("layers_11_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_11_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_11_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(300877120)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_237_cast_fp16 = conv(bias = layers_11_fc1_pretrained_bias_to_fp16, dilations = var_4858, groups = var_4525, pad = pretrained_out_237_pad_0, pad_type = pretrained_out_237_pad_type_0, strides = var_4856, weight = layers_11_fc1_pretrained_weight_to_fp16_palettized, x = input_351_cast_fp16)[name = tensor<string, []>("pretrained_out_237_cast_fp16")];
            tensor<int32, [2]> var_4862 = const()[name = tensor<string, []>("op_4862"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4864 = const()[name = tensor<string, []>("op_4864"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_353_pad_type_0 = const()[name = tensor<string, []>("input_353_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_353_pad_0 = const()[name = tensor<string, []>("input_353_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_11_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_11_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(300887424)))];
            tensor<fp16, [1, 16, 1, 1]> input_353_cast_fp16 = conv(dilations = var_4864, groups = var_4525, pad = input_353_pad_0, pad_type = input_353_pad_type_0, strides = var_4862, weight = layers_11_fc1_loraA_weight_to_fp16, x = input_351_cast_fp16)[name = tensor<string, []>("input_353_cast_fp16")];
            tensor<int32, [2]> var_4868 = const()[name = tensor<string, []>("op_4868"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4870 = const()[name = tensor<string, []>("op_4870"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_473_pad_type_0 = const()[name = tensor<string, []>("lora_out_473_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_473_pad_0 = const()[name = tensor<string, []>("lora_out_473_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_475_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_475_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(300928448)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_475_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_4870, groups = var_4525, pad = lora_out_473_pad_0, pad_type = lora_out_473_pad_type_0, strides = var_4868, weight = lora_out_475_weight_0_to_fp16, x = input_353_cast_fp16)[name = tensor<string, []>("lora_out_475_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_355_cast_fp16 = add(x = pretrained_out_237_cast_fp16, y = lora_out_475_cast_fp16)[name = tensor<string, []>("input_355_cast_fp16")];
            tensor<string, []> input_357_mode_0 = const()[name = tensor<string, []>("input_357_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_357_cast_fp16 = gelu(mode = input_357_mode_0, x = input_355_cast_fp16)[name = tensor<string, []>("input_357_cast_fp16")];
            tensor<int32, [2]> var_4882 = const()[name = tensor<string, []>("op_4882"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4884 = const()[name = tensor<string, []>("op_4884"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_239_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_239_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_239_pad_0 = const()[name = tensor<string, []>("pretrained_out_239_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_11_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(301092352))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(304369216))), name = tensor<string, []>("layers_11_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_11_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_11_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(304369344)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_239_cast_fp16 = conv(bias = layers_11_fc2_pretrained_bias_to_fp16, dilations = var_4884, groups = var_4525, pad = pretrained_out_239_pad_0, pad_type = pretrained_out_239_pad_type_0, strides = var_4882, weight = layers_11_fc2_pretrained_weight_to_fp16_palettized, x = input_357_cast_fp16)[name = tensor<string, []>("pretrained_out_239_cast_fp16")];
            tensor<int32, [2]> var_4888 = const()[name = tensor<string, []>("op_4888"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4890 = const()[name = tensor<string, []>("op_4890"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_359_pad_type_0 = const()[name = tensor<string, []>("input_359_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_359_pad_0 = const()[name = tensor<string, []>("input_359_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_11_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_11_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(304371968)))];
            tensor<fp16, [1, 16, 1, 1]> input_359_cast_fp16 = conv(dilations = var_4890, groups = var_4525, pad = input_359_pad_0, pad_type = input_359_pad_type_0, strides = var_4888, weight = layers_11_fc2_loraA_weight_to_fp16, x = input_357_cast_fp16)[name = tensor<string, []>("input_359_cast_fp16")];
            tensor<int32, [2]> var_4894 = const()[name = tensor<string, []>("op_4894"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4896 = const()[name = tensor<string, []>("op_4896"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_477_pad_type_0 = const()[name = tensor<string, []>("lora_out_477_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_477_pad_0 = const()[name = tensor<string, []>("lora_out_477_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_479_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_479_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(304535872)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_479_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_4896, groups = var_4525, pad = lora_out_477_pad_0, pad_type = lora_out_477_pad_type_0, strides = var_4894, weight = lora_out_479_weight_0_to_fp16, x = input_359_cast_fp16)[name = tensor<string, []>("lora_out_479_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_25_cast_fp16 = add(x = pretrained_out_239_cast_fp16, y = lora_out_479_cast_fp16)[name = tensor<string, []>("hidden_states_25_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_73_cast_fp16 = add(x = inputs_71_cast_fp16, y = hidden_states_25_cast_fp16)[name = tensor<string, []>("inputs_73_cast_fp16")];
            tensor<int32, []> var_4912 = const()[name = tensor<string, []>("op_4912"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_4919 = const()[name = tensor<string, []>("op_4919"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_4920 = const()[name = tensor<string, []>("op_4920"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_4932 = const()[name = tensor<string, []>("op_4932"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_73_cast_fp16 = reduce_mean(axes = var_4932, keep_dims = var_4920, x = inputs_73_cast_fp16)[name = tensor<string, []>("channels_mean_73_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_73_cast_fp16 = sub(x = inputs_73_cast_fp16, y = channels_mean_73_cast_fp16)[name = tensor<string, []>("zero_mean_73_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_73_cast_fp16 = mul(x = zero_mean_73_cast_fp16, y = zero_mean_73_cast_fp16)[name = tensor<string, []>("zero_mean_sq_73_cast_fp16")];
            tensor<int32, [1]> var_4936 = const()[name = tensor<string, []>("op_4936"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_4937_cast_fp16 = reduce_mean(axes = var_4936, keep_dims = var_4920, x = zero_mean_sq_73_cast_fp16)[name = tensor<string, []>("op_4937_cast_fp16")];
            tensor<fp16, []> var_4938_to_fp16 = const()[name = tensor<string, []>("op_4938_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_4939_cast_fp16 = add(x = var_4937_cast_fp16, y = var_4938_to_fp16)[name = tensor<string, []>("op_4939_cast_fp16")];
            tensor<fp32, []> denom_73_epsilon_0 = const()[name = tensor<string, []>("denom_73_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_73_cast_fp16 = rsqrt(epsilon = denom_73_epsilon_0, x = var_4939_cast_fp16)[name = tensor<string, []>("denom_73_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_73_cast_fp16 = mul(x = zero_mean_73_cast_fp16, y = denom_73_cast_fp16)[name = tensor<string, []>("out_73_cast_fp16")];
            tensor<fp16, [1280]> obj_169_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_169_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(304576896)))];
            tensor<fp16, [1280]> obj_169_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_169_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(304579520)))];
            tensor<fp16, []> obj_169_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_169_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_169_cast_fp16 = batch_norm(beta = obj_169_beta_0_to_fp16, epsilon = obj_169_epsilon_0_to_fp16, gamma = obj_169_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_73_cast_fp16)[name = tensor<string, []>("obj_169_cast_fp16")];
            tensor<int32, [2]> var_4957 = const()[name = tensor<string, []>("op_4957"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4959 = const()[name = tensor<string, []>("op_4959"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_241_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_241_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_241_pad_0 = const()[name = tensor<string, []>("pretrained_out_241_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_12_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(304582144))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(305401408))), name = tensor<string, []>("layers_12_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_12_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_12_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(305401536)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_241_cast_fp16 = conv(bias = layers_12_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_4959, groups = var_4919, pad = pretrained_out_241_pad_0, pad_type = pretrained_out_241_pad_type_0, strides = var_4957, weight = layers_12_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_169_cast_fp16)[name = tensor<string, []>("pretrained_out_241_cast_fp16")];
            tensor<int32, [2]> var_4963 = const()[name = tensor<string, []>("op_4963"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4965 = const()[name = tensor<string, []>("op_4965"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_361_pad_type_0 = const()[name = tensor<string, []>("input_361_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_361_pad_0 = const()[name = tensor<string, []>("input_361_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_12_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_12_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(305404160)))];
            tensor<fp16, [1, 16, 1, 1]> input_361_cast_fp16 = conv(dilations = var_4965, groups = var_4919, pad = input_361_pad_0, pad_type = input_361_pad_type_0, strides = var_4963, weight = layers_12_self_attn_q_proj_loraA_weight_to_fp16, x = obj_169_cast_fp16)[name = tensor<string, []>("input_361_cast_fp16")];
            tensor<int32, [2]> var_4969 = const()[name = tensor<string, []>("op_4969"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4971 = const()[name = tensor<string, []>("op_4971"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_481_pad_type_0 = const()[name = tensor<string, []>("lora_out_481_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_481_pad_0 = const()[name = tensor<string, []>("lora_out_481_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_483_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_483_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(305445184)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_483_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_4971, groups = var_4919, pad = lora_out_481_pad_0, pad_type = lora_out_481_pad_type_0, strides = var_4969, weight = lora_out_483_weight_0_to_fp16, x = input_361_cast_fp16)[name = tensor<string, []>("lora_out_483_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_49_cast_fp16 = add(x = pretrained_out_241_cast_fp16, y = lora_out_483_cast_fp16)[name = tensor<string, []>("query_49_cast_fp16")];
            tensor<int32, [2]> var_4981 = const()[name = tensor<string, []>("op_4981"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4983 = const()[name = tensor<string, []>("op_4983"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_243_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_243_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_243_pad_0 = const()[name = tensor<string, []>("pretrained_out_243_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_12_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(305486208))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(306305472))), name = tensor<string, []>("layers_12_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_243_cast_fp16 = conv(dilations = var_4983, groups = var_4919, pad = pretrained_out_243_pad_0, pad_type = pretrained_out_243_pad_type_0, strides = var_4981, weight = layers_12_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_169_cast_fp16)[name = tensor<string, []>("pretrained_out_243_cast_fp16")];
            tensor<int32, [2]> var_4987 = const()[name = tensor<string, []>("op_4987"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4989 = const()[name = tensor<string, []>("op_4989"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_363_pad_type_0 = const()[name = tensor<string, []>("input_363_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_363_pad_0 = const()[name = tensor<string, []>("input_363_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_12_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_12_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(306305600)))];
            tensor<fp16, [1, 16, 1, 1]> input_363_cast_fp16 = conv(dilations = var_4989, groups = var_4919, pad = input_363_pad_0, pad_type = input_363_pad_type_0, strides = var_4987, weight = layers_12_self_attn_k_proj_loraA_weight_to_fp16, x = obj_169_cast_fp16)[name = tensor<string, []>("input_363_cast_fp16")];
            tensor<int32, [2]> var_4993 = const()[name = tensor<string, []>("op_4993"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_4995 = const()[name = tensor<string, []>("op_4995"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_485_pad_type_0 = const()[name = tensor<string, []>("lora_out_485_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_485_pad_0 = const()[name = tensor<string, []>("lora_out_485_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_487_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_487_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(306346624)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_487_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_4995, groups = var_4919, pad = lora_out_485_pad_0, pad_type = lora_out_485_pad_type_0, strides = var_4993, weight = lora_out_487_weight_0_to_fp16, x = input_363_cast_fp16)[name = tensor<string, []>("lora_out_487_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_25_cast_fp16 = add(x = pretrained_out_243_cast_fp16, y = lora_out_487_cast_fp16)[name = tensor<string, []>("current_key_25_cast_fp16")];
            tensor<int32, [2]> var_5006 = const()[name = tensor<string, []>("op_5006"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5008 = const()[name = tensor<string, []>("op_5008"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_245_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_245_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_245_pad_0 = const()[name = tensor<string, []>("pretrained_out_245_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_12_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(306387648))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(307206912))), name = tensor<string, []>("layers_12_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_12_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_12_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(307207040)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_245_cast_fp16 = conv(bias = layers_12_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_5008, groups = var_4919, pad = pretrained_out_245_pad_0, pad_type = pretrained_out_245_pad_type_0, strides = var_5006, weight = layers_12_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_169_cast_fp16)[name = tensor<string, []>("pretrained_out_245_cast_fp16")];
            tensor<int32, [2]> var_5012 = const()[name = tensor<string, []>("op_5012"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5014 = const()[name = tensor<string, []>("op_5014"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_365_pad_type_0 = const()[name = tensor<string, []>("input_365_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_365_pad_0 = const()[name = tensor<string, []>("input_365_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_12_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_12_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(307209664)))];
            tensor<fp16, [1, 16, 1, 1]> input_365_cast_fp16 = conv(dilations = var_5014, groups = var_4919, pad = input_365_pad_0, pad_type = input_365_pad_type_0, strides = var_5012, weight = layers_12_self_attn_v_proj_loraA_weight_to_fp16, x = obj_169_cast_fp16)[name = tensor<string, []>("input_365_cast_fp16")];
            tensor<int32, [2]> var_5018 = const()[name = tensor<string, []>("op_5018"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5020 = const()[name = tensor<string, []>("op_5020"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_489_pad_type_0 = const()[name = tensor<string, []>("lora_out_489_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_489_pad_0 = const()[name = tensor<string, []>("lora_out_489_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_491_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_491_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(307250688)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_491_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_5020, groups = var_4919, pad = lora_out_489_pad_0, pad_type = lora_out_489_pad_type_0, strides = var_5018, weight = lora_out_491_weight_0_to_fp16, x = input_365_cast_fp16)[name = tensor<string, []>("lora_out_491_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_25_cast_fp16 = add(x = pretrained_out_245_cast_fp16, y = lora_out_491_cast_fp16)[name = tensor<string, []>("current_value_25_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_5030_cast_fp16 = mul(x = current_key_25_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_5030_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_5032_cast_fp16 = mul(x = var_103_cast_fp16_12, y = var_295_cast_fp16)[name = tensor<string, []>("op_5032_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_49_cast_fp16 = add(x = var_5030_cast_fp16, y = var_5032_cast_fp16)[name = tensor<string, []>("key_49_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_5034_cast_fp16 = mul(x = current_value_25_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_5034_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_5036_cast_fp16 = mul(x = var_138_cast_fp16_12, y = var_295_cast_fp16)[name = tensor<string, []>("op_5036_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_49_cast_fp16 = add(x = var_5034_cast_fp16, y = var_5036_cast_fp16)[name = tensor<string, []>("value_49_cast_fp16")];
            tensor<int32, [4]> var_5039 = const()[name = tensor<string, []>("op_5039"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_5040_cast_fp16 = reshape(shape = var_5039, x = query_49_cast_fp16)[name = tensor<string, []>("op_5040_cast_fp16")];
            tensor<fp16, []> var_5041_to_fp16 = const()[name = tensor<string, []>("op_5041_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_5042_cast_fp16 = mul(x = var_5040_cast_fp16, y = var_5041_to_fp16)[name = tensor<string, []>("op_5042_cast_fp16")];
            tensor<int32, [4]> var_5043 = const()[name = tensor<string, []>("op_5043"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_5044_cast_fp16 = reshape(shape = var_5043, x = key_49_cast_fp16)[name = tensor<string, []>("op_5044_cast_fp16")];
            tensor<bool, []> mh_w_73_transpose_x_0 = const()[name = tensor<string, []>("mh_w_73_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_73_transpose_y_0 = const()[name = tensor<string, []>("mh_w_73_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_73_cast_fp16 = matmul(transpose_x = mh_w_73_transpose_x_0, transpose_y = mh_w_73_transpose_y_0, x = var_5042_cast_fp16, y = var_5044_cast_fp16)[name = tensor<string, []>("mh_w_73_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_75_cast_fp16 = add(x = mh_w_73_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_75_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_5052_cast_fp16 = softmax(axis = var_4912, x = mh_w_75_cast_fp16)[name = tensor<string, []>("op_5052_cast_fp16")];
            tensor<int32, [4]> var_5053 = const()[name = tensor<string, []>("op_5053"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_5054_cast_fp16 = reshape(shape = var_5053, x = value_49_cast_fp16)[name = tensor<string, []>("op_5054_cast_fp16")];
            tensor<bool, []> attn_49_transpose_x_0 = const()[name = tensor<string, []>("attn_49_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_49_transpose_y_0 = const()[name = tensor<string, []>("attn_49_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_49_cast_fp16 = matmul(transpose_x = attn_49_transpose_x_0, transpose_y = attn_49_transpose_y_0, x = var_5054_cast_fp16, y = var_5052_cast_fp16)[name = tensor<string, []>("attn_49_cast_fp16")];
            tensor<int32, [4]> var_5057 = const()[name = tensor<string, []>("op_5057"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_367_cast_fp16 = reshape(shape = var_5057, x = attn_49_cast_fp16)[name = tensor<string, []>("input_367_cast_fp16")];
            tensor<int32, [2]> var_5064 = const()[name = tensor<string, []>("op_5064"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5066 = const()[name = tensor<string, []>("op_5066"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_247_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_247_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_247_pad_0 = const()[name = tensor<string, []>("pretrained_out_247_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_12_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(307291712))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(308110976))), name = tensor<string, []>("layers_12_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_12_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_12_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(308111104)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_247_cast_fp16 = conv(bias = layers_12_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_5066, groups = var_4919, pad = pretrained_out_247_pad_0, pad_type = pretrained_out_247_pad_type_0, strides = var_5064, weight = layers_12_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_367_cast_fp16)[name = tensor<string, []>("pretrained_out_247_cast_fp16")];
            tensor<int32, [2]> var_5070 = const()[name = tensor<string, []>("op_5070"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5072 = const()[name = tensor<string, []>("op_5072"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_369_pad_type_0 = const()[name = tensor<string, []>("input_369_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_369_pad_0 = const()[name = tensor<string, []>("input_369_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_12_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_12_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(308113728)))];
            tensor<fp16, [1, 16, 1, 1]> input_369_cast_fp16 = conv(dilations = var_5072, groups = var_4919, pad = input_369_pad_0, pad_type = input_369_pad_type_0, strides = var_5070, weight = layers_12_self_attn_o_proj_loraA_weight_to_fp16, x = input_367_cast_fp16)[name = tensor<string, []>("input_369_cast_fp16")];
            tensor<int32, [2]> var_5076 = const()[name = tensor<string, []>("op_5076"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5078 = const()[name = tensor<string, []>("op_5078"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_493_pad_type_0 = const()[name = tensor<string, []>("lora_out_493_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_493_pad_0 = const()[name = tensor<string, []>("lora_out_493_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_495_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_495_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(308154752)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_495_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_5078, groups = var_4919, pad = lora_out_493_pad_0, pad_type = lora_out_493_pad_type_0, strides = var_5076, weight = lora_out_495_weight_0_to_fp16, x = input_369_cast_fp16)[name = tensor<string, []>("lora_out_495_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_175_cast_fp16 = add(x = pretrained_out_247_cast_fp16, y = lora_out_495_cast_fp16)[name = tensor<string, []>("obj_175_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_75_cast_fp16 = add(x = inputs_73_cast_fp16, y = obj_175_cast_fp16)[name = tensor<string, []>("inputs_75_cast_fp16")];
            tensor<int32, [1]> var_5091 = const()[name = tensor<string, []>("op_5091"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_75_cast_fp16 = reduce_mean(axes = var_5091, keep_dims = var_4920, x = inputs_75_cast_fp16)[name = tensor<string, []>("channels_mean_75_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_75_cast_fp16 = sub(x = inputs_75_cast_fp16, y = channels_mean_75_cast_fp16)[name = tensor<string, []>("zero_mean_75_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_75_cast_fp16 = mul(x = zero_mean_75_cast_fp16, y = zero_mean_75_cast_fp16)[name = tensor<string, []>("zero_mean_sq_75_cast_fp16")];
            tensor<int32, [1]> var_5095 = const()[name = tensor<string, []>("op_5095"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_5096_cast_fp16 = reduce_mean(axes = var_5095, keep_dims = var_4920, x = zero_mean_sq_75_cast_fp16)[name = tensor<string, []>("op_5096_cast_fp16")];
            tensor<fp16, []> var_5097_to_fp16 = const()[name = tensor<string, []>("op_5097_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_5098_cast_fp16 = add(x = var_5096_cast_fp16, y = var_5097_to_fp16)[name = tensor<string, []>("op_5098_cast_fp16")];
            tensor<fp32, []> denom_75_epsilon_0 = const()[name = tensor<string, []>("denom_75_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_75_cast_fp16 = rsqrt(epsilon = denom_75_epsilon_0, x = var_5098_cast_fp16)[name = tensor<string, []>("denom_75_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_75_cast_fp16 = mul(x = zero_mean_75_cast_fp16, y = denom_75_cast_fp16)[name = tensor<string, []>("out_75_cast_fp16")];
            tensor<fp16, [1280]> obj_177_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_177_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(308195776)))];
            tensor<fp16, [1280]> obj_177_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_177_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(308198400)))];
            tensor<fp16, []> obj_177_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_177_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_177_cast_fp16 = batch_norm(beta = obj_177_beta_0_to_fp16, epsilon = obj_177_epsilon_0_to_fp16, gamma = obj_177_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_75_cast_fp16)[name = tensor<string, []>("obj_177_cast_fp16")];
            tensor<int32, [2]> var_5116 = const()[name = tensor<string, []>("op_5116"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5118 = const()[name = tensor<string, []>("op_5118"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_249_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_249_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_249_pad_0 = const()[name = tensor<string, []>("pretrained_out_249_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_12_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(308201024))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(309020288))), name = tensor<string, []>("layers_12_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_12_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_12_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(309020416)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_249_cast_fp16 = conv(bias = layers_12_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_5118, groups = var_4919, pad = pretrained_out_249_pad_0, pad_type = pretrained_out_249_pad_type_0, strides = var_5116, weight = layers_12_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_177_cast_fp16)[name = tensor<string, []>("pretrained_out_249_cast_fp16")];
            tensor<int32, [2]> var_5122 = const()[name = tensor<string, []>("op_5122"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5124 = const()[name = tensor<string, []>("op_5124"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_371_pad_type_0 = const()[name = tensor<string, []>("input_371_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_371_pad_0 = const()[name = tensor<string, []>("input_371_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_12_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_12_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(309023040)))];
            tensor<fp16, [1, 16, 1, 1]> input_371_cast_fp16 = conv(dilations = var_5124, groups = var_4919, pad = input_371_pad_0, pad_type = input_371_pad_type_0, strides = var_5122, weight = layers_12_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_177_cast_fp16)[name = tensor<string, []>("input_371_cast_fp16")];
            tensor<int32, [2]> var_5128 = const()[name = tensor<string, []>("op_5128"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5130 = const()[name = tensor<string, []>("op_5130"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_497_pad_type_0 = const()[name = tensor<string, []>("lora_out_497_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_497_pad_0 = const()[name = tensor<string, []>("lora_out_497_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_499_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_499_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(309064064)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_499_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_5130, groups = var_4919, pad = lora_out_497_pad_0, pad_type = lora_out_497_pad_type_0, strides = var_5128, weight = lora_out_499_weight_0_to_fp16, x = input_371_cast_fp16)[name = tensor<string, []>("lora_out_499_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_51_cast_fp16 = add(x = pretrained_out_249_cast_fp16, y = lora_out_499_cast_fp16)[name = tensor<string, []>("query_51_cast_fp16")];
            tensor<int32, [2]> var_5140 = const()[name = tensor<string, []>("op_5140"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5142 = const()[name = tensor<string, []>("op_5142"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_251_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_251_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_251_pad_0 = const()[name = tensor<string, []>("pretrained_out_251_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_12_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(309105088))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(309924352))), name = tensor<string, []>("layers_12_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_251_cast_fp16 = conv(dilations = var_5142, groups = var_4919, pad = pretrained_out_251_pad_0, pad_type = pretrained_out_251_pad_type_0, strides = var_5140, weight = layers_12_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_251_cast_fp16")];
            tensor<int32, [2]> var_5146 = const()[name = tensor<string, []>("op_5146"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5148 = const()[name = tensor<string, []>("op_5148"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_373_pad_type_0 = const()[name = tensor<string, []>("input_373_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_373_pad_0 = const()[name = tensor<string, []>("input_373_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_12_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_12_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(309924480)))];
            tensor<fp16, [1, 16, 1, 1500]> input_373_cast_fp16 = conv(dilations = var_5148, groups = var_4919, pad = input_373_pad_0, pad_type = input_373_pad_type_0, strides = var_5146, weight = layers_12_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_373_cast_fp16")];
            tensor<int32, [2]> var_5152 = const()[name = tensor<string, []>("op_5152"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5154 = const()[name = tensor<string, []>("op_5154"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_501_pad_type_0 = const()[name = tensor<string, []>("lora_out_501_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_501_pad_0 = const()[name = tensor<string, []>("lora_out_501_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_503_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_503_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(309965504)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_503_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_5154, groups = var_4919, pad = lora_out_501_pad_0, pad_type = lora_out_501_pad_type_0, strides = var_5152, weight = lora_out_503_weight_0_to_fp16, x = input_373_cast_fp16)[name = tensor<string, []>("lora_out_503_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_51_cast_fp16 = add(x = pretrained_out_251_cast_fp16, y = lora_out_503_cast_fp16)[name = tensor<string, []>("key_51_cast_fp16")];
            tensor<int32, [2]> var_5165 = const()[name = tensor<string, []>("op_5165"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5167 = const()[name = tensor<string, []>("op_5167"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_253_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_253_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_253_pad_0 = const()[name = tensor<string, []>("pretrained_out_253_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_12_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(310006528))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(310825792))), name = tensor<string, []>("layers_12_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_12_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_12_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(310825920)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_253_cast_fp16 = conv(bias = layers_12_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_5167, groups = var_4919, pad = pretrained_out_253_pad_0, pad_type = pretrained_out_253_pad_type_0, strides = var_5165, weight = layers_12_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_253_cast_fp16")];
            tensor<int32, [2]> var_5171 = const()[name = tensor<string, []>("op_5171"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5173 = const()[name = tensor<string, []>("op_5173"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_375_pad_type_0 = const()[name = tensor<string, []>("input_375_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_375_pad_0 = const()[name = tensor<string, []>("input_375_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_12_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_12_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(310828544)))];
            tensor<fp16, [1, 16, 1, 1500]> input_375_cast_fp16 = conv(dilations = var_5173, groups = var_4919, pad = input_375_pad_0, pad_type = input_375_pad_type_0, strides = var_5171, weight = layers_12_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_375_cast_fp16")];
            tensor<int32, [2]> var_5177 = const()[name = tensor<string, []>("op_5177"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5179 = const()[name = tensor<string, []>("op_5179"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_505_pad_type_0 = const()[name = tensor<string, []>("lora_out_505_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_505_pad_0 = const()[name = tensor<string, []>("lora_out_505_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_507_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_507_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(310869568)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_507_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_5179, groups = var_4919, pad = lora_out_505_pad_0, pad_type = lora_out_505_pad_type_0, strides = var_5177, weight = lora_out_507_weight_0_to_fp16, x = input_375_cast_fp16)[name = tensor<string, []>("lora_out_507_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_51_cast_fp16 = add(x = pretrained_out_253_cast_fp16, y = lora_out_507_cast_fp16)[name = tensor<string, []>("value_51_cast_fp16")];
            tensor<int32, [4]> var_5186 = const()[name = tensor<string, []>("op_5186"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_5187_cast_fp16 = reshape(shape = var_5186, x = query_51_cast_fp16)[name = tensor<string, []>("op_5187_cast_fp16")];
            tensor<fp16, []> var_5188_to_fp16 = const()[name = tensor<string, []>("op_5188_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_5189_cast_fp16 = mul(x = var_5187_cast_fp16, y = var_5188_to_fp16)[name = tensor<string, []>("op_5189_cast_fp16")];
            tensor<int32, [4]> var_5190 = const()[name = tensor<string, []>("op_5190"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_5191_cast_fp16 = reshape(shape = var_5190, x = key_51_cast_fp16)[name = tensor<string, []>("op_5191_cast_fp16")];
            tensor<bool, []> mh_w_77_transpose_x_0 = const()[name = tensor<string, []>("mh_w_77_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_77_transpose_y_0 = const()[name = tensor<string, []>("mh_w_77_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_77_cast_fp16 = matmul(transpose_x = mh_w_77_transpose_x_0, transpose_y = mh_w_77_transpose_y_0, x = var_5189_cast_fp16, y = var_5191_cast_fp16)[name = tensor<string, []>("mh_w_77_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_181_cast_fp16 = softmax(axis = var_4912, x = mh_w_77_cast_fp16)[name = tensor<string, []>("obj_181_cast_fp16")];
            tensor<int32, [4]> var_5195 = const()[name = tensor<string, []>("op_5195"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_5196_cast_fp16 = reshape(shape = var_5195, x = value_51_cast_fp16)[name = tensor<string, []>("op_5196_cast_fp16")];
            tensor<bool, []> attn_51_transpose_x_0 = const()[name = tensor<string, []>("attn_51_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_51_transpose_y_0 = const()[name = tensor<string, []>("attn_51_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_51_cast_fp16 = matmul(transpose_x = attn_51_transpose_x_0, transpose_y = attn_51_transpose_y_0, x = var_5196_cast_fp16, y = obj_181_cast_fp16)[name = tensor<string, []>("attn_51_cast_fp16")];
            tensor<int32, [4]> var_5199 = const()[name = tensor<string, []>("op_5199"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_377_cast_fp16 = reshape(shape = var_5199, x = attn_51_cast_fp16)[name = tensor<string, []>("input_377_cast_fp16")];
            tensor<int32, [2]> var_5206 = const()[name = tensor<string, []>("op_5206"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5208 = const()[name = tensor<string, []>("op_5208"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_255_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_255_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_255_pad_0 = const()[name = tensor<string, []>("pretrained_out_255_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_12_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(310910592))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(311729856))), name = tensor<string, []>("layers_12_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_12_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_12_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(311729984)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_255_cast_fp16 = conv(bias = layers_12_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_5208, groups = var_4919, pad = pretrained_out_255_pad_0, pad_type = pretrained_out_255_pad_type_0, strides = var_5206, weight = layers_12_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_377_cast_fp16)[name = tensor<string, []>("pretrained_out_255_cast_fp16")];
            tensor<int32, [2]> var_5212 = const()[name = tensor<string, []>("op_5212"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5214 = const()[name = tensor<string, []>("op_5214"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_379_pad_type_0 = const()[name = tensor<string, []>("input_379_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_379_pad_0 = const()[name = tensor<string, []>("input_379_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_12_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_12_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(311732608)))];
            tensor<fp16, [1, 16, 1, 1]> input_379_cast_fp16 = conv(dilations = var_5214, groups = var_4919, pad = input_379_pad_0, pad_type = input_379_pad_type_0, strides = var_5212, weight = layers_12_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_377_cast_fp16)[name = tensor<string, []>("input_379_cast_fp16")];
            tensor<int32, [2]> var_5218 = const()[name = tensor<string, []>("op_5218"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5220 = const()[name = tensor<string, []>("op_5220"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_509_pad_type_0 = const()[name = tensor<string, []>("lora_out_509_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_509_pad_0 = const()[name = tensor<string, []>("lora_out_509_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_511_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_511_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(311773632)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_511_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_5220, groups = var_4919, pad = lora_out_509_pad_0, pad_type = lora_out_509_pad_type_0, strides = var_5218, weight = lora_out_511_weight_0_to_fp16, x = input_379_cast_fp16)[name = tensor<string, []>("lora_out_511_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_179_cast_fp16 = add(x = pretrained_out_255_cast_fp16, y = lora_out_511_cast_fp16)[name = tensor<string, []>("obj_179_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_77_cast_fp16 = add(x = inputs_75_cast_fp16, y = obj_179_cast_fp16)[name = tensor<string, []>("inputs_77_cast_fp16")];
            tensor<int32, [1]> var_5232 = const()[name = tensor<string, []>("op_5232"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_77_cast_fp16 = reduce_mean(axes = var_5232, keep_dims = var_4920, x = inputs_77_cast_fp16)[name = tensor<string, []>("channels_mean_77_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_77_cast_fp16 = sub(x = inputs_77_cast_fp16, y = channels_mean_77_cast_fp16)[name = tensor<string, []>("zero_mean_77_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_77_cast_fp16 = mul(x = zero_mean_77_cast_fp16, y = zero_mean_77_cast_fp16)[name = tensor<string, []>("zero_mean_sq_77_cast_fp16")];
            tensor<int32, [1]> var_5236 = const()[name = tensor<string, []>("op_5236"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_5237_cast_fp16 = reduce_mean(axes = var_5236, keep_dims = var_4920, x = zero_mean_sq_77_cast_fp16)[name = tensor<string, []>("op_5237_cast_fp16")];
            tensor<fp16, []> var_5238_to_fp16 = const()[name = tensor<string, []>("op_5238_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_5239_cast_fp16 = add(x = var_5237_cast_fp16, y = var_5238_to_fp16)[name = tensor<string, []>("op_5239_cast_fp16")];
            tensor<fp32, []> denom_77_epsilon_0 = const()[name = tensor<string, []>("denom_77_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_77_cast_fp16 = rsqrt(epsilon = denom_77_epsilon_0, x = var_5239_cast_fp16)[name = tensor<string, []>("denom_77_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_77_cast_fp16 = mul(x = zero_mean_77_cast_fp16, y = denom_77_cast_fp16)[name = tensor<string, []>("out_77_cast_fp16")];
            tensor<fp16, [1280]> input_381_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_381_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(311814656)))];
            tensor<fp16, [1280]> input_381_beta_0_to_fp16 = const()[name = tensor<string, []>("input_381_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(311817280)))];
            tensor<fp16, []> input_381_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_381_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_381_cast_fp16 = batch_norm(beta = input_381_beta_0_to_fp16, epsilon = input_381_epsilon_0_to_fp16, gamma = input_381_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_77_cast_fp16)[name = tensor<string, []>("input_381_cast_fp16")];
            tensor<int32, [2]> var_5253 = const()[name = tensor<string, []>("op_5253"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5255 = const()[name = tensor<string, []>("op_5255"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_257_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_257_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_257_pad_0 = const()[name = tensor<string, []>("pretrained_out_257_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_12_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(311819904))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(315096768))), name = tensor<string, []>("layers_12_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_12_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_12_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(315096896)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_257_cast_fp16 = conv(bias = layers_12_fc1_pretrained_bias_to_fp16, dilations = var_5255, groups = var_4919, pad = pretrained_out_257_pad_0, pad_type = pretrained_out_257_pad_type_0, strides = var_5253, weight = layers_12_fc1_pretrained_weight_to_fp16_palettized, x = input_381_cast_fp16)[name = tensor<string, []>("pretrained_out_257_cast_fp16")];
            tensor<int32, [2]> var_5259 = const()[name = tensor<string, []>("op_5259"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5261 = const()[name = tensor<string, []>("op_5261"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_383_pad_type_0 = const()[name = tensor<string, []>("input_383_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_383_pad_0 = const()[name = tensor<string, []>("input_383_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_12_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_12_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(315107200)))];
            tensor<fp16, [1, 16, 1, 1]> input_383_cast_fp16 = conv(dilations = var_5261, groups = var_4919, pad = input_383_pad_0, pad_type = input_383_pad_type_0, strides = var_5259, weight = layers_12_fc1_loraA_weight_to_fp16, x = input_381_cast_fp16)[name = tensor<string, []>("input_383_cast_fp16")];
            tensor<int32, [2]> var_5265 = const()[name = tensor<string, []>("op_5265"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5267 = const()[name = tensor<string, []>("op_5267"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_513_pad_type_0 = const()[name = tensor<string, []>("lora_out_513_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_513_pad_0 = const()[name = tensor<string, []>("lora_out_513_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_515_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_515_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(315148224)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_515_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_5267, groups = var_4919, pad = lora_out_513_pad_0, pad_type = lora_out_513_pad_type_0, strides = var_5265, weight = lora_out_515_weight_0_to_fp16, x = input_383_cast_fp16)[name = tensor<string, []>("lora_out_515_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_385_cast_fp16 = add(x = pretrained_out_257_cast_fp16, y = lora_out_515_cast_fp16)[name = tensor<string, []>("input_385_cast_fp16")];
            tensor<string, []> input_387_mode_0 = const()[name = tensor<string, []>("input_387_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_387_cast_fp16 = gelu(mode = input_387_mode_0, x = input_385_cast_fp16)[name = tensor<string, []>("input_387_cast_fp16")];
            tensor<int32, [2]> var_5279 = const()[name = tensor<string, []>("op_5279"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5281 = const()[name = tensor<string, []>("op_5281"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_259_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_259_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_259_pad_0 = const()[name = tensor<string, []>("pretrained_out_259_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_12_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(315312128))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(318588992))), name = tensor<string, []>("layers_12_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_12_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_12_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(318589120)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_259_cast_fp16 = conv(bias = layers_12_fc2_pretrained_bias_to_fp16, dilations = var_5281, groups = var_4919, pad = pretrained_out_259_pad_0, pad_type = pretrained_out_259_pad_type_0, strides = var_5279, weight = layers_12_fc2_pretrained_weight_to_fp16_palettized, x = input_387_cast_fp16)[name = tensor<string, []>("pretrained_out_259_cast_fp16")];
            tensor<int32, [2]> var_5285 = const()[name = tensor<string, []>("op_5285"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5287 = const()[name = tensor<string, []>("op_5287"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_389_pad_type_0 = const()[name = tensor<string, []>("input_389_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_389_pad_0 = const()[name = tensor<string, []>("input_389_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_12_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_12_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(318591744)))];
            tensor<fp16, [1, 16, 1, 1]> input_389_cast_fp16 = conv(dilations = var_5287, groups = var_4919, pad = input_389_pad_0, pad_type = input_389_pad_type_0, strides = var_5285, weight = layers_12_fc2_loraA_weight_to_fp16, x = input_387_cast_fp16)[name = tensor<string, []>("input_389_cast_fp16")];
            tensor<int32, [2]> var_5291 = const()[name = tensor<string, []>("op_5291"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5293 = const()[name = tensor<string, []>("op_5293"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_517_pad_type_0 = const()[name = tensor<string, []>("lora_out_517_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_517_pad_0 = const()[name = tensor<string, []>("lora_out_517_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_519_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_519_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(318755648)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_519_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_5293, groups = var_4919, pad = lora_out_517_pad_0, pad_type = lora_out_517_pad_type_0, strides = var_5291, weight = lora_out_519_weight_0_to_fp16, x = input_389_cast_fp16)[name = tensor<string, []>("lora_out_519_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_27_cast_fp16 = add(x = pretrained_out_259_cast_fp16, y = lora_out_519_cast_fp16)[name = tensor<string, []>("hidden_states_27_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_79_cast_fp16 = add(x = inputs_77_cast_fp16, y = hidden_states_27_cast_fp16)[name = tensor<string, []>("inputs_79_cast_fp16")];
            tensor<int32, []> var_5310 = const()[name = tensor<string, []>("op_5310"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_5317 = const()[name = tensor<string, []>("op_5317"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_5318 = const()[name = tensor<string, []>("op_5318"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_5330 = const()[name = tensor<string, []>("op_5330"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_79_cast_fp16 = reduce_mean(axes = var_5330, keep_dims = var_5318, x = inputs_79_cast_fp16)[name = tensor<string, []>("channels_mean_79_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_79_cast_fp16 = sub(x = inputs_79_cast_fp16, y = channels_mean_79_cast_fp16)[name = tensor<string, []>("zero_mean_79_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_79_cast_fp16 = mul(x = zero_mean_79_cast_fp16, y = zero_mean_79_cast_fp16)[name = tensor<string, []>("zero_mean_sq_79_cast_fp16")];
            tensor<int32, [1]> var_5334 = const()[name = tensor<string, []>("op_5334"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_5335_cast_fp16 = reduce_mean(axes = var_5334, keep_dims = var_5318, x = zero_mean_sq_79_cast_fp16)[name = tensor<string, []>("op_5335_cast_fp16")];
            tensor<fp16, []> var_5336_to_fp16 = const()[name = tensor<string, []>("op_5336_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_5337_cast_fp16 = add(x = var_5335_cast_fp16, y = var_5336_to_fp16)[name = tensor<string, []>("op_5337_cast_fp16")];
            tensor<fp32, []> denom_79_epsilon_0 = const()[name = tensor<string, []>("denom_79_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_79_cast_fp16 = rsqrt(epsilon = denom_79_epsilon_0, x = var_5337_cast_fp16)[name = tensor<string, []>("denom_79_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_79_cast_fp16 = mul(x = zero_mean_79_cast_fp16, y = denom_79_cast_fp16)[name = tensor<string, []>("out_79_cast_fp16")];
            tensor<fp16, [1280]> obj_183_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_183_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(318796672)))];
            tensor<fp16, [1280]> obj_183_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_183_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(318799296)))];
            tensor<fp16, []> obj_183_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_183_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_183_cast_fp16 = batch_norm(beta = obj_183_beta_0_to_fp16, epsilon = obj_183_epsilon_0_to_fp16, gamma = obj_183_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_79_cast_fp16)[name = tensor<string, []>("obj_183_cast_fp16")];
            tensor<int32, [2]> var_5355 = const()[name = tensor<string, []>("op_5355"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5357 = const()[name = tensor<string, []>("op_5357"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_261_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_261_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_261_pad_0 = const()[name = tensor<string, []>("pretrained_out_261_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_13_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(318801920))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(319621184))), name = tensor<string, []>("layers_13_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_13_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_13_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(319621312)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_261_cast_fp16 = conv(bias = layers_13_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_5357, groups = var_5317, pad = pretrained_out_261_pad_0, pad_type = pretrained_out_261_pad_type_0, strides = var_5355, weight = layers_13_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_183_cast_fp16)[name = tensor<string, []>("pretrained_out_261_cast_fp16")];
            tensor<int32, [2]> var_5361 = const()[name = tensor<string, []>("op_5361"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5363 = const()[name = tensor<string, []>("op_5363"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_391_pad_type_0 = const()[name = tensor<string, []>("input_391_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_391_pad_0 = const()[name = tensor<string, []>("input_391_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_13_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_13_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(319623936)))];
            tensor<fp16, [1, 16, 1, 1]> input_391_cast_fp16 = conv(dilations = var_5363, groups = var_5317, pad = input_391_pad_0, pad_type = input_391_pad_type_0, strides = var_5361, weight = layers_13_self_attn_q_proj_loraA_weight_to_fp16, x = obj_183_cast_fp16)[name = tensor<string, []>("input_391_cast_fp16")];
            tensor<int32, [2]> var_5367 = const()[name = tensor<string, []>("op_5367"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5369 = const()[name = tensor<string, []>("op_5369"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_521_pad_type_0 = const()[name = tensor<string, []>("lora_out_521_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_521_pad_0 = const()[name = tensor<string, []>("lora_out_521_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_523_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_523_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(319664960)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_523_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_5369, groups = var_5317, pad = lora_out_521_pad_0, pad_type = lora_out_521_pad_type_0, strides = var_5367, weight = lora_out_523_weight_0_to_fp16, x = input_391_cast_fp16)[name = tensor<string, []>("lora_out_523_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_53_cast_fp16 = add(x = pretrained_out_261_cast_fp16, y = lora_out_523_cast_fp16)[name = tensor<string, []>("query_53_cast_fp16")];
            tensor<int32, [2]> var_5379 = const()[name = tensor<string, []>("op_5379"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5381 = const()[name = tensor<string, []>("op_5381"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_263_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_263_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_263_pad_0 = const()[name = tensor<string, []>("pretrained_out_263_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_13_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(319705984))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(320525248))), name = tensor<string, []>("layers_13_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_263_cast_fp16 = conv(dilations = var_5381, groups = var_5317, pad = pretrained_out_263_pad_0, pad_type = pretrained_out_263_pad_type_0, strides = var_5379, weight = layers_13_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_183_cast_fp16)[name = tensor<string, []>("pretrained_out_263_cast_fp16")];
            tensor<int32, [2]> var_5385 = const()[name = tensor<string, []>("op_5385"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5387 = const()[name = tensor<string, []>("op_5387"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_393_pad_type_0 = const()[name = tensor<string, []>("input_393_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_393_pad_0 = const()[name = tensor<string, []>("input_393_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_13_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_13_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(320525376)))];
            tensor<fp16, [1, 16, 1, 1]> input_393_cast_fp16 = conv(dilations = var_5387, groups = var_5317, pad = input_393_pad_0, pad_type = input_393_pad_type_0, strides = var_5385, weight = layers_13_self_attn_k_proj_loraA_weight_to_fp16, x = obj_183_cast_fp16)[name = tensor<string, []>("input_393_cast_fp16")];
            tensor<int32, [2]> var_5391 = const()[name = tensor<string, []>("op_5391"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5393 = const()[name = tensor<string, []>("op_5393"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_525_pad_type_0 = const()[name = tensor<string, []>("lora_out_525_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_525_pad_0 = const()[name = tensor<string, []>("lora_out_525_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_527_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_527_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(320566400)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_527_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_5393, groups = var_5317, pad = lora_out_525_pad_0, pad_type = lora_out_525_pad_type_0, strides = var_5391, weight = lora_out_527_weight_0_to_fp16, x = input_393_cast_fp16)[name = tensor<string, []>("lora_out_527_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_27_cast_fp16 = add(x = pretrained_out_263_cast_fp16, y = lora_out_527_cast_fp16)[name = tensor<string, []>("current_key_27_cast_fp16")];
            tensor<int32, [2]> var_5404 = const()[name = tensor<string, []>("op_5404"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5406 = const()[name = tensor<string, []>("op_5406"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_265_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_265_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_265_pad_0 = const()[name = tensor<string, []>("pretrained_out_265_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_13_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(320607424))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(321426688))), name = tensor<string, []>("layers_13_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_13_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_13_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(321426816)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_265_cast_fp16 = conv(bias = layers_13_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_5406, groups = var_5317, pad = pretrained_out_265_pad_0, pad_type = pretrained_out_265_pad_type_0, strides = var_5404, weight = layers_13_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_183_cast_fp16)[name = tensor<string, []>("pretrained_out_265_cast_fp16")];
            tensor<int32, [2]> var_5410 = const()[name = tensor<string, []>("op_5410"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5412 = const()[name = tensor<string, []>("op_5412"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_395_pad_type_0 = const()[name = tensor<string, []>("input_395_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_395_pad_0 = const()[name = tensor<string, []>("input_395_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_13_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_13_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(321429440)))];
            tensor<fp16, [1, 16, 1, 1]> input_395_cast_fp16 = conv(dilations = var_5412, groups = var_5317, pad = input_395_pad_0, pad_type = input_395_pad_type_0, strides = var_5410, weight = layers_13_self_attn_v_proj_loraA_weight_to_fp16, x = obj_183_cast_fp16)[name = tensor<string, []>("input_395_cast_fp16")];
            tensor<int32, [2]> var_5416 = const()[name = tensor<string, []>("op_5416"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5418 = const()[name = tensor<string, []>("op_5418"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_529_pad_type_0 = const()[name = tensor<string, []>("lora_out_529_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_529_pad_0 = const()[name = tensor<string, []>("lora_out_529_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_531_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_531_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(321470464)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_531_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_5418, groups = var_5317, pad = lora_out_529_pad_0, pad_type = lora_out_529_pad_type_0, strides = var_5416, weight = lora_out_531_weight_0_to_fp16, x = input_395_cast_fp16)[name = tensor<string, []>("lora_out_531_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_27_cast_fp16 = add(x = pretrained_out_265_cast_fp16, y = lora_out_531_cast_fp16)[name = tensor<string, []>("current_value_27_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_5428_cast_fp16 = mul(x = current_key_27_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_5428_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_5430_cast_fp16 = mul(x = var_103_cast_fp16_13, y = var_295_cast_fp16)[name = tensor<string, []>("op_5430_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_53_cast_fp16 = add(x = var_5428_cast_fp16, y = var_5430_cast_fp16)[name = tensor<string, []>("key_53_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_5432_cast_fp16 = mul(x = current_value_27_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_5432_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_5434_cast_fp16 = mul(x = var_138_cast_fp16_13, y = var_295_cast_fp16)[name = tensor<string, []>("op_5434_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_53_cast_fp16 = add(x = var_5432_cast_fp16, y = var_5434_cast_fp16)[name = tensor<string, []>("value_53_cast_fp16")];
            tensor<int32, [4]> var_5437 = const()[name = tensor<string, []>("op_5437"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_5438_cast_fp16 = reshape(shape = var_5437, x = query_53_cast_fp16)[name = tensor<string, []>("op_5438_cast_fp16")];
            tensor<fp16, []> var_5439_to_fp16 = const()[name = tensor<string, []>("op_5439_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_5440_cast_fp16 = mul(x = var_5438_cast_fp16, y = var_5439_to_fp16)[name = tensor<string, []>("op_5440_cast_fp16")];
            tensor<int32, [4]> var_5441 = const()[name = tensor<string, []>("op_5441"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_5442_cast_fp16 = reshape(shape = var_5441, x = key_53_cast_fp16)[name = tensor<string, []>("op_5442_cast_fp16")];
            tensor<bool, []> mh_w_79_transpose_x_0 = const()[name = tensor<string, []>("mh_w_79_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_79_transpose_y_0 = const()[name = tensor<string, []>("mh_w_79_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_79_cast_fp16 = matmul(transpose_x = mh_w_79_transpose_x_0, transpose_y = mh_w_79_transpose_y_0, x = var_5440_cast_fp16, y = var_5442_cast_fp16)[name = tensor<string, []>("mh_w_79_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_81_cast_fp16 = add(x = mh_w_79_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_81_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_5450_cast_fp16 = softmax(axis = var_5310, x = mh_w_81_cast_fp16)[name = tensor<string, []>("op_5450_cast_fp16")];
            tensor<int32, [4]> var_5451 = const()[name = tensor<string, []>("op_5451"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_5452_cast_fp16 = reshape(shape = var_5451, x = value_53_cast_fp16)[name = tensor<string, []>("op_5452_cast_fp16")];
            tensor<bool, []> attn_53_transpose_x_0 = const()[name = tensor<string, []>("attn_53_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_53_transpose_y_0 = const()[name = tensor<string, []>("attn_53_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_53_cast_fp16 = matmul(transpose_x = attn_53_transpose_x_0, transpose_y = attn_53_transpose_y_0, x = var_5452_cast_fp16, y = var_5450_cast_fp16)[name = tensor<string, []>("attn_53_cast_fp16")];
            tensor<int32, [4]> var_5455 = const()[name = tensor<string, []>("op_5455"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_397_cast_fp16 = reshape(shape = var_5455, x = attn_53_cast_fp16)[name = tensor<string, []>("input_397_cast_fp16")];
            tensor<int32, [2]> var_5462 = const()[name = tensor<string, []>("op_5462"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5464 = const()[name = tensor<string, []>("op_5464"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_267_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_267_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_267_pad_0 = const()[name = tensor<string, []>("pretrained_out_267_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_13_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(321511488))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(322330752))), name = tensor<string, []>("layers_13_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_13_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_13_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(322330880)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_267_cast_fp16 = conv(bias = layers_13_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_5464, groups = var_5317, pad = pretrained_out_267_pad_0, pad_type = pretrained_out_267_pad_type_0, strides = var_5462, weight = layers_13_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_397_cast_fp16)[name = tensor<string, []>("pretrained_out_267_cast_fp16")];
            tensor<int32, [2]> var_5468 = const()[name = tensor<string, []>("op_5468"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5470 = const()[name = tensor<string, []>("op_5470"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_399_pad_type_0 = const()[name = tensor<string, []>("input_399_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_399_pad_0 = const()[name = tensor<string, []>("input_399_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_13_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_13_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(322333504)))];
            tensor<fp16, [1, 16, 1, 1]> input_399_cast_fp16 = conv(dilations = var_5470, groups = var_5317, pad = input_399_pad_0, pad_type = input_399_pad_type_0, strides = var_5468, weight = layers_13_self_attn_o_proj_loraA_weight_to_fp16, x = input_397_cast_fp16)[name = tensor<string, []>("input_399_cast_fp16")];
            tensor<int32, [2]> var_5474 = const()[name = tensor<string, []>("op_5474"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5476 = const()[name = tensor<string, []>("op_5476"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_533_pad_type_0 = const()[name = tensor<string, []>("lora_out_533_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_533_pad_0 = const()[name = tensor<string, []>("lora_out_533_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_535_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_535_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(322374528)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_535_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_5476, groups = var_5317, pad = lora_out_533_pad_0, pad_type = lora_out_533_pad_type_0, strides = var_5474, weight = lora_out_535_weight_0_to_fp16, x = input_399_cast_fp16)[name = tensor<string, []>("lora_out_535_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_189_cast_fp16 = add(x = pretrained_out_267_cast_fp16, y = lora_out_535_cast_fp16)[name = tensor<string, []>("obj_189_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_81_cast_fp16 = add(x = inputs_79_cast_fp16, y = obj_189_cast_fp16)[name = tensor<string, []>("inputs_81_cast_fp16")];
            tensor<int32, [1]> var_5489 = const()[name = tensor<string, []>("op_5489"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_81_cast_fp16 = reduce_mean(axes = var_5489, keep_dims = var_5318, x = inputs_81_cast_fp16)[name = tensor<string, []>("channels_mean_81_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_81_cast_fp16 = sub(x = inputs_81_cast_fp16, y = channels_mean_81_cast_fp16)[name = tensor<string, []>("zero_mean_81_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_81_cast_fp16 = mul(x = zero_mean_81_cast_fp16, y = zero_mean_81_cast_fp16)[name = tensor<string, []>("zero_mean_sq_81_cast_fp16")];
            tensor<int32, [1]> var_5493 = const()[name = tensor<string, []>("op_5493"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_5494_cast_fp16 = reduce_mean(axes = var_5493, keep_dims = var_5318, x = zero_mean_sq_81_cast_fp16)[name = tensor<string, []>("op_5494_cast_fp16")];
            tensor<fp16, []> var_5495_to_fp16 = const()[name = tensor<string, []>("op_5495_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_5496_cast_fp16 = add(x = var_5494_cast_fp16, y = var_5495_to_fp16)[name = tensor<string, []>("op_5496_cast_fp16")];
            tensor<fp32, []> denom_81_epsilon_0 = const()[name = tensor<string, []>("denom_81_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_81_cast_fp16 = rsqrt(epsilon = denom_81_epsilon_0, x = var_5496_cast_fp16)[name = tensor<string, []>("denom_81_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_81_cast_fp16 = mul(x = zero_mean_81_cast_fp16, y = denom_81_cast_fp16)[name = tensor<string, []>("out_81_cast_fp16")];
            tensor<fp16, [1280]> obj_191_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_191_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(322415552)))];
            tensor<fp16, [1280]> obj_191_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_191_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(322418176)))];
            tensor<fp16, []> obj_191_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_191_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_191_cast_fp16 = batch_norm(beta = obj_191_beta_0_to_fp16, epsilon = obj_191_epsilon_0_to_fp16, gamma = obj_191_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_81_cast_fp16)[name = tensor<string, []>("obj_191_cast_fp16")];
            tensor<int32, [2]> var_5514 = const()[name = tensor<string, []>("op_5514"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5516 = const()[name = tensor<string, []>("op_5516"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_269_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_269_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_269_pad_0 = const()[name = tensor<string, []>("pretrained_out_269_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_13_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(322420800))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(323240064))), name = tensor<string, []>("layers_13_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_13_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_13_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(323240192)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_269_cast_fp16 = conv(bias = layers_13_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_5516, groups = var_5317, pad = pretrained_out_269_pad_0, pad_type = pretrained_out_269_pad_type_0, strides = var_5514, weight = layers_13_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_191_cast_fp16)[name = tensor<string, []>("pretrained_out_269_cast_fp16")];
            tensor<int32, [2]> var_5520 = const()[name = tensor<string, []>("op_5520"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5522 = const()[name = tensor<string, []>("op_5522"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_401_pad_type_0 = const()[name = tensor<string, []>("input_401_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_401_pad_0 = const()[name = tensor<string, []>("input_401_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_13_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_13_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(323242816)))];
            tensor<fp16, [1, 16, 1, 1]> input_401_cast_fp16 = conv(dilations = var_5522, groups = var_5317, pad = input_401_pad_0, pad_type = input_401_pad_type_0, strides = var_5520, weight = layers_13_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_191_cast_fp16)[name = tensor<string, []>("input_401_cast_fp16")];
            tensor<int32, [2]> var_5526 = const()[name = tensor<string, []>("op_5526"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5528 = const()[name = tensor<string, []>("op_5528"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_537_pad_type_0 = const()[name = tensor<string, []>("lora_out_537_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_537_pad_0 = const()[name = tensor<string, []>("lora_out_537_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_539_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_539_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(323283840)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_539_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_5528, groups = var_5317, pad = lora_out_537_pad_0, pad_type = lora_out_537_pad_type_0, strides = var_5526, weight = lora_out_539_weight_0_to_fp16, x = input_401_cast_fp16)[name = tensor<string, []>("lora_out_539_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_55_cast_fp16 = add(x = pretrained_out_269_cast_fp16, y = lora_out_539_cast_fp16)[name = tensor<string, []>("query_55_cast_fp16")];
            tensor<int32, [2]> var_5538 = const()[name = tensor<string, []>("op_5538"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5540 = const()[name = tensor<string, []>("op_5540"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_271_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_271_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_271_pad_0 = const()[name = tensor<string, []>("pretrained_out_271_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_13_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(323324864))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(324144128))), name = tensor<string, []>("layers_13_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_271_cast_fp16 = conv(dilations = var_5540, groups = var_5317, pad = pretrained_out_271_pad_0, pad_type = pretrained_out_271_pad_type_0, strides = var_5538, weight = layers_13_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_271_cast_fp16")];
            tensor<int32, [2]> var_5544 = const()[name = tensor<string, []>("op_5544"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5546 = const()[name = tensor<string, []>("op_5546"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_403_pad_type_0 = const()[name = tensor<string, []>("input_403_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_403_pad_0 = const()[name = tensor<string, []>("input_403_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_13_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_13_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(324144256)))];
            tensor<fp16, [1, 16, 1, 1500]> input_403_cast_fp16 = conv(dilations = var_5546, groups = var_5317, pad = input_403_pad_0, pad_type = input_403_pad_type_0, strides = var_5544, weight = layers_13_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_403_cast_fp16")];
            tensor<int32, [2]> var_5550 = const()[name = tensor<string, []>("op_5550"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5552 = const()[name = tensor<string, []>("op_5552"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_541_pad_type_0 = const()[name = tensor<string, []>("lora_out_541_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_541_pad_0 = const()[name = tensor<string, []>("lora_out_541_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_543_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_543_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(324185280)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_543_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_5552, groups = var_5317, pad = lora_out_541_pad_0, pad_type = lora_out_541_pad_type_0, strides = var_5550, weight = lora_out_543_weight_0_to_fp16, x = input_403_cast_fp16)[name = tensor<string, []>("lora_out_543_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_55_cast_fp16 = add(x = pretrained_out_271_cast_fp16, y = lora_out_543_cast_fp16)[name = tensor<string, []>("key_55_cast_fp16")];
            tensor<int32, [2]> var_5563 = const()[name = tensor<string, []>("op_5563"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5565 = const()[name = tensor<string, []>("op_5565"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_273_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_273_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_273_pad_0 = const()[name = tensor<string, []>("pretrained_out_273_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_13_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(324226304))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(325045568))), name = tensor<string, []>("layers_13_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_13_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_13_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(325045696)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_273_cast_fp16 = conv(bias = layers_13_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_5565, groups = var_5317, pad = pretrained_out_273_pad_0, pad_type = pretrained_out_273_pad_type_0, strides = var_5563, weight = layers_13_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_273_cast_fp16")];
            tensor<int32, [2]> var_5569 = const()[name = tensor<string, []>("op_5569"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5571 = const()[name = tensor<string, []>("op_5571"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_405_pad_type_0 = const()[name = tensor<string, []>("input_405_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_405_pad_0 = const()[name = tensor<string, []>("input_405_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_13_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_13_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(325048320)))];
            tensor<fp16, [1, 16, 1, 1500]> input_405_cast_fp16 = conv(dilations = var_5571, groups = var_5317, pad = input_405_pad_0, pad_type = input_405_pad_type_0, strides = var_5569, weight = layers_13_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_405_cast_fp16")];
            tensor<int32, [2]> var_5575 = const()[name = tensor<string, []>("op_5575"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5577 = const()[name = tensor<string, []>("op_5577"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_545_pad_type_0 = const()[name = tensor<string, []>("lora_out_545_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_545_pad_0 = const()[name = tensor<string, []>("lora_out_545_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_547_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_547_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(325089344)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_547_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_5577, groups = var_5317, pad = lora_out_545_pad_0, pad_type = lora_out_545_pad_type_0, strides = var_5575, weight = lora_out_547_weight_0_to_fp16, x = input_405_cast_fp16)[name = tensor<string, []>("lora_out_547_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_55_cast_fp16 = add(x = pretrained_out_273_cast_fp16, y = lora_out_547_cast_fp16)[name = tensor<string, []>("value_55_cast_fp16")];
            tensor<int32, [4]> var_5584 = const()[name = tensor<string, []>("op_5584"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_5585_cast_fp16 = reshape(shape = var_5584, x = query_55_cast_fp16)[name = tensor<string, []>("op_5585_cast_fp16")];
            tensor<fp16, []> var_5586_to_fp16 = const()[name = tensor<string, []>("op_5586_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_5587_cast_fp16 = mul(x = var_5585_cast_fp16, y = var_5586_to_fp16)[name = tensor<string, []>("op_5587_cast_fp16")];
            tensor<int32, [4]> var_5588 = const()[name = tensor<string, []>("op_5588"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_5589_cast_fp16 = reshape(shape = var_5588, x = key_55_cast_fp16)[name = tensor<string, []>("op_5589_cast_fp16")];
            tensor<bool, []> mh_w_83_transpose_x_0 = const()[name = tensor<string, []>("mh_w_83_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_83_transpose_y_0 = const()[name = tensor<string, []>("mh_w_83_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_83_cast_fp16 = matmul(transpose_x = mh_w_83_transpose_x_0, transpose_y = mh_w_83_transpose_y_0, x = var_5587_cast_fp16, y = var_5589_cast_fp16)[name = tensor<string, []>("mh_w_83_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_195_cast_fp16 = softmax(axis = var_5310, x = mh_w_83_cast_fp16)[name = tensor<string, []>("obj_195_cast_fp16")];
            tensor<int32, [4]> var_5593 = const()[name = tensor<string, []>("op_5593"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_5594_cast_fp16 = reshape(shape = var_5593, x = value_55_cast_fp16)[name = tensor<string, []>("op_5594_cast_fp16")];
            tensor<bool, []> attn_55_transpose_x_0 = const()[name = tensor<string, []>("attn_55_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_55_transpose_y_0 = const()[name = tensor<string, []>("attn_55_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_55_cast_fp16 = matmul(transpose_x = attn_55_transpose_x_0, transpose_y = attn_55_transpose_y_0, x = var_5594_cast_fp16, y = obj_195_cast_fp16)[name = tensor<string, []>("attn_55_cast_fp16")];
            tensor<int32, [4]> var_5597 = const()[name = tensor<string, []>("op_5597"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_407_cast_fp16 = reshape(shape = var_5597, x = attn_55_cast_fp16)[name = tensor<string, []>("input_407_cast_fp16")];
            tensor<int32, [2]> var_5604 = const()[name = tensor<string, []>("op_5604"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5606 = const()[name = tensor<string, []>("op_5606"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_275_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_275_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_275_pad_0 = const()[name = tensor<string, []>("pretrained_out_275_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_13_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(325130368))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(325949632))), name = tensor<string, []>("layers_13_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_13_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_13_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(325949760)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_275_cast_fp16 = conv(bias = layers_13_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_5606, groups = var_5317, pad = pretrained_out_275_pad_0, pad_type = pretrained_out_275_pad_type_0, strides = var_5604, weight = layers_13_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_407_cast_fp16)[name = tensor<string, []>("pretrained_out_275_cast_fp16")];
            tensor<int32, [2]> var_5610 = const()[name = tensor<string, []>("op_5610"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5612 = const()[name = tensor<string, []>("op_5612"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_409_pad_type_0 = const()[name = tensor<string, []>("input_409_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_409_pad_0 = const()[name = tensor<string, []>("input_409_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_13_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_13_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(325952384)))];
            tensor<fp16, [1, 16, 1, 1]> input_409_cast_fp16 = conv(dilations = var_5612, groups = var_5317, pad = input_409_pad_0, pad_type = input_409_pad_type_0, strides = var_5610, weight = layers_13_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_407_cast_fp16)[name = tensor<string, []>("input_409_cast_fp16")];
            tensor<int32, [2]> var_5616 = const()[name = tensor<string, []>("op_5616"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5618 = const()[name = tensor<string, []>("op_5618"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_549_pad_type_0 = const()[name = tensor<string, []>("lora_out_549_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_549_pad_0 = const()[name = tensor<string, []>("lora_out_549_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_551_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_551_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(325993408)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_551_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_5618, groups = var_5317, pad = lora_out_549_pad_0, pad_type = lora_out_549_pad_type_0, strides = var_5616, weight = lora_out_551_weight_0_to_fp16, x = input_409_cast_fp16)[name = tensor<string, []>("lora_out_551_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_193_cast_fp16 = add(x = pretrained_out_275_cast_fp16, y = lora_out_551_cast_fp16)[name = tensor<string, []>("obj_193_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_83_cast_fp16 = add(x = inputs_81_cast_fp16, y = obj_193_cast_fp16)[name = tensor<string, []>("inputs_83_cast_fp16")];
            tensor<int32, [1]> var_5630 = const()[name = tensor<string, []>("op_5630"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_83_cast_fp16 = reduce_mean(axes = var_5630, keep_dims = var_5318, x = inputs_83_cast_fp16)[name = tensor<string, []>("channels_mean_83_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_83_cast_fp16 = sub(x = inputs_83_cast_fp16, y = channels_mean_83_cast_fp16)[name = tensor<string, []>("zero_mean_83_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_83_cast_fp16 = mul(x = zero_mean_83_cast_fp16, y = zero_mean_83_cast_fp16)[name = tensor<string, []>("zero_mean_sq_83_cast_fp16")];
            tensor<int32, [1]> var_5634 = const()[name = tensor<string, []>("op_5634"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_5635_cast_fp16 = reduce_mean(axes = var_5634, keep_dims = var_5318, x = zero_mean_sq_83_cast_fp16)[name = tensor<string, []>("op_5635_cast_fp16")];
            tensor<fp16, []> var_5636_to_fp16 = const()[name = tensor<string, []>("op_5636_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_5637_cast_fp16 = add(x = var_5635_cast_fp16, y = var_5636_to_fp16)[name = tensor<string, []>("op_5637_cast_fp16")];
            tensor<fp32, []> denom_83_epsilon_0 = const()[name = tensor<string, []>("denom_83_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_83_cast_fp16 = rsqrt(epsilon = denom_83_epsilon_0, x = var_5637_cast_fp16)[name = tensor<string, []>("denom_83_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_83_cast_fp16 = mul(x = zero_mean_83_cast_fp16, y = denom_83_cast_fp16)[name = tensor<string, []>("out_83_cast_fp16")];
            tensor<fp16, [1280]> input_411_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_411_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(326034432)))];
            tensor<fp16, [1280]> input_411_beta_0_to_fp16 = const()[name = tensor<string, []>("input_411_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(326037056)))];
            tensor<fp16, []> input_411_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_411_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_411_cast_fp16 = batch_norm(beta = input_411_beta_0_to_fp16, epsilon = input_411_epsilon_0_to_fp16, gamma = input_411_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_83_cast_fp16)[name = tensor<string, []>("input_411_cast_fp16")];
            tensor<int32, [2]> var_5651 = const()[name = tensor<string, []>("op_5651"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5653 = const()[name = tensor<string, []>("op_5653"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_277_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_277_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_277_pad_0 = const()[name = tensor<string, []>("pretrained_out_277_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_13_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(326039680))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(329316544))), name = tensor<string, []>("layers_13_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_13_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_13_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(329316672)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_277_cast_fp16 = conv(bias = layers_13_fc1_pretrained_bias_to_fp16, dilations = var_5653, groups = var_5317, pad = pretrained_out_277_pad_0, pad_type = pretrained_out_277_pad_type_0, strides = var_5651, weight = layers_13_fc1_pretrained_weight_to_fp16_palettized, x = input_411_cast_fp16)[name = tensor<string, []>("pretrained_out_277_cast_fp16")];
            tensor<int32, [2]> var_5657 = const()[name = tensor<string, []>("op_5657"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5659 = const()[name = tensor<string, []>("op_5659"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_413_pad_type_0 = const()[name = tensor<string, []>("input_413_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_413_pad_0 = const()[name = tensor<string, []>("input_413_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_13_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_13_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(329326976)))];
            tensor<fp16, [1, 16, 1, 1]> input_413_cast_fp16 = conv(dilations = var_5659, groups = var_5317, pad = input_413_pad_0, pad_type = input_413_pad_type_0, strides = var_5657, weight = layers_13_fc1_loraA_weight_to_fp16, x = input_411_cast_fp16)[name = tensor<string, []>("input_413_cast_fp16")];
            tensor<int32, [2]> var_5663 = const()[name = tensor<string, []>("op_5663"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5665 = const()[name = tensor<string, []>("op_5665"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_553_pad_type_0 = const()[name = tensor<string, []>("lora_out_553_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_553_pad_0 = const()[name = tensor<string, []>("lora_out_553_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_555_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_555_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(329368000)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_555_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_5665, groups = var_5317, pad = lora_out_553_pad_0, pad_type = lora_out_553_pad_type_0, strides = var_5663, weight = lora_out_555_weight_0_to_fp16, x = input_413_cast_fp16)[name = tensor<string, []>("lora_out_555_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_415_cast_fp16 = add(x = pretrained_out_277_cast_fp16, y = lora_out_555_cast_fp16)[name = tensor<string, []>("input_415_cast_fp16")];
            tensor<string, []> input_417_mode_0 = const()[name = tensor<string, []>("input_417_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_417_cast_fp16 = gelu(mode = input_417_mode_0, x = input_415_cast_fp16)[name = tensor<string, []>("input_417_cast_fp16")];
            tensor<int32, [2]> var_5677 = const()[name = tensor<string, []>("op_5677"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5679 = const()[name = tensor<string, []>("op_5679"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_279_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_279_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_279_pad_0 = const()[name = tensor<string, []>("pretrained_out_279_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_13_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [4915200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(329531904))), lut = tensor<fp16, [64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(334447168))), name = tensor<string, []>("layers_13_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_13_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_13_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(334447360)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_279_cast_fp16 = conv(bias = layers_13_fc2_pretrained_bias_to_fp16, dilations = var_5679, groups = var_5317, pad = pretrained_out_279_pad_0, pad_type = pretrained_out_279_pad_type_0, strides = var_5677, weight = layers_13_fc2_pretrained_weight_to_fp16_palettized, x = input_417_cast_fp16)[name = tensor<string, []>("pretrained_out_279_cast_fp16")];
            tensor<int32, [2]> var_5683 = const()[name = tensor<string, []>("op_5683"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5685 = const()[name = tensor<string, []>("op_5685"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_419_pad_type_0 = const()[name = tensor<string, []>("input_419_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_419_pad_0 = const()[name = tensor<string, []>("input_419_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_13_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_13_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(334449984)))];
            tensor<fp16, [1, 16, 1, 1]> input_419_cast_fp16 = conv(dilations = var_5685, groups = var_5317, pad = input_419_pad_0, pad_type = input_419_pad_type_0, strides = var_5683, weight = layers_13_fc2_loraA_weight_to_fp16, x = input_417_cast_fp16)[name = tensor<string, []>("input_419_cast_fp16")];
            tensor<int32, [2]> var_5689 = const()[name = tensor<string, []>("op_5689"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5691 = const()[name = tensor<string, []>("op_5691"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_557_pad_type_0 = const()[name = tensor<string, []>("lora_out_557_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_557_pad_0 = const()[name = tensor<string, []>("lora_out_557_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_559_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_559_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(334613888)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_559_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_5691, groups = var_5317, pad = lora_out_557_pad_0, pad_type = lora_out_557_pad_type_0, strides = var_5689, weight = lora_out_559_weight_0_to_fp16, x = input_419_cast_fp16)[name = tensor<string, []>("lora_out_559_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_29_cast_fp16 = add(x = pretrained_out_279_cast_fp16, y = lora_out_559_cast_fp16)[name = tensor<string, []>("hidden_states_29_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_85_cast_fp16 = add(x = inputs_83_cast_fp16, y = hidden_states_29_cast_fp16)[name = tensor<string, []>("inputs_85_cast_fp16")];
            tensor<int32, []> var_5708 = const()[name = tensor<string, []>("op_5708"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_5715 = const()[name = tensor<string, []>("op_5715"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_5716 = const()[name = tensor<string, []>("op_5716"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_5728 = const()[name = tensor<string, []>("op_5728"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_85_cast_fp16 = reduce_mean(axes = var_5728, keep_dims = var_5716, x = inputs_85_cast_fp16)[name = tensor<string, []>("channels_mean_85_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_85_cast_fp16 = sub(x = inputs_85_cast_fp16, y = channels_mean_85_cast_fp16)[name = tensor<string, []>("zero_mean_85_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_85_cast_fp16 = mul(x = zero_mean_85_cast_fp16, y = zero_mean_85_cast_fp16)[name = tensor<string, []>("zero_mean_sq_85_cast_fp16")];
            tensor<int32, [1]> var_5732 = const()[name = tensor<string, []>("op_5732"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_5733_cast_fp16 = reduce_mean(axes = var_5732, keep_dims = var_5716, x = zero_mean_sq_85_cast_fp16)[name = tensor<string, []>("op_5733_cast_fp16")];
            tensor<fp16, []> var_5734_to_fp16 = const()[name = tensor<string, []>("op_5734_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_5735_cast_fp16 = add(x = var_5733_cast_fp16, y = var_5734_to_fp16)[name = tensor<string, []>("op_5735_cast_fp16")];
            tensor<fp32, []> denom_85_epsilon_0 = const()[name = tensor<string, []>("denom_85_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_85_cast_fp16 = rsqrt(epsilon = denom_85_epsilon_0, x = var_5735_cast_fp16)[name = tensor<string, []>("denom_85_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_85_cast_fp16 = mul(x = zero_mean_85_cast_fp16, y = denom_85_cast_fp16)[name = tensor<string, []>("out_85_cast_fp16")];
            tensor<fp16, [1280]> obj_197_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_197_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(334654912)))];
            tensor<fp16, [1280]> obj_197_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_197_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(334657536)))];
            tensor<fp16, []> obj_197_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_197_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_197_cast_fp16 = batch_norm(beta = obj_197_beta_0_to_fp16, epsilon = obj_197_epsilon_0_to_fp16, gamma = obj_197_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_85_cast_fp16)[name = tensor<string, []>("obj_197_cast_fp16")];
            tensor<int32, [2]> var_5753 = const()[name = tensor<string, []>("op_5753"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5755 = const()[name = tensor<string, []>("op_5755"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_281_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_281_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_281_pad_0 = const()[name = tensor<string, []>("pretrained_out_281_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_14_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(334660160))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(335479424))), name = tensor<string, []>("layers_14_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_14_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_14_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(335479552)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_281_cast_fp16 = conv(bias = layers_14_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_5755, groups = var_5715, pad = pretrained_out_281_pad_0, pad_type = pretrained_out_281_pad_type_0, strides = var_5753, weight = layers_14_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_197_cast_fp16)[name = tensor<string, []>("pretrained_out_281_cast_fp16")];
            tensor<int32, [2]> var_5759 = const()[name = tensor<string, []>("op_5759"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5761 = const()[name = tensor<string, []>("op_5761"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_421_pad_type_0 = const()[name = tensor<string, []>("input_421_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_421_pad_0 = const()[name = tensor<string, []>("input_421_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_14_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_14_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(335482176)))];
            tensor<fp16, [1, 16, 1, 1]> input_421_cast_fp16 = conv(dilations = var_5761, groups = var_5715, pad = input_421_pad_0, pad_type = input_421_pad_type_0, strides = var_5759, weight = layers_14_self_attn_q_proj_loraA_weight_to_fp16, x = obj_197_cast_fp16)[name = tensor<string, []>("input_421_cast_fp16")];
            tensor<int32, [2]> var_5765 = const()[name = tensor<string, []>("op_5765"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5767 = const()[name = tensor<string, []>("op_5767"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_561_pad_type_0 = const()[name = tensor<string, []>("lora_out_561_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_561_pad_0 = const()[name = tensor<string, []>("lora_out_561_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_563_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_563_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(335523200)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_563_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_5767, groups = var_5715, pad = lora_out_561_pad_0, pad_type = lora_out_561_pad_type_0, strides = var_5765, weight = lora_out_563_weight_0_to_fp16, x = input_421_cast_fp16)[name = tensor<string, []>("lora_out_563_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_57_cast_fp16 = add(x = pretrained_out_281_cast_fp16, y = lora_out_563_cast_fp16)[name = tensor<string, []>("query_57_cast_fp16")];
            tensor<int32, [2]> var_5777 = const()[name = tensor<string, []>("op_5777"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5779 = const()[name = tensor<string, []>("op_5779"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_283_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_283_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_283_pad_0 = const()[name = tensor<string, []>("pretrained_out_283_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_14_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(335564224))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(336383488))), name = tensor<string, []>("layers_14_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_283_cast_fp16 = conv(dilations = var_5779, groups = var_5715, pad = pretrained_out_283_pad_0, pad_type = pretrained_out_283_pad_type_0, strides = var_5777, weight = layers_14_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_197_cast_fp16)[name = tensor<string, []>("pretrained_out_283_cast_fp16")];
            tensor<int32, [2]> var_5783 = const()[name = tensor<string, []>("op_5783"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5785 = const()[name = tensor<string, []>("op_5785"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_423_pad_type_0 = const()[name = tensor<string, []>("input_423_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_423_pad_0 = const()[name = tensor<string, []>("input_423_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_14_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_14_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(336383616)))];
            tensor<fp16, [1, 16, 1, 1]> input_423_cast_fp16 = conv(dilations = var_5785, groups = var_5715, pad = input_423_pad_0, pad_type = input_423_pad_type_0, strides = var_5783, weight = layers_14_self_attn_k_proj_loraA_weight_to_fp16, x = obj_197_cast_fp16)[name = tensor<string, []>("input_423_cast_fp16")];
            tensor<int32, [2]> var_5789 = const()[name = tensor<string, []>("op_5789"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5791 = const()[name = tensor<string, []>("op_5791"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_565_pad_type_0 = const()[name = tensor<string, []>("lora_out_565_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_565_pad_0 = const()[name = tensor<string, []>("lora_out_565_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_567_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_567_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(336424640)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_567_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_5791, groups = var_5715, pad = lora_out_565_pad_0, pad_type = lora_out_565_pad_type_0, strides = var_5789, weight = lora_out_567_weight_0_to_fp16, x = input_423_cast_fp16)[name = tensor<string, []>("lora_out_567_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_29_cast_fp16 = add(x = pretrained_out_283_cast_fp16, y = lora_out_567_cast_fp16)[name = tensor<string, []>("current_key_29_cast_fp16")];
            tensor<int32, [2]> var_5802 = const()[name = tensor<string, []>("op_5802"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5804 = const()[name = tensor<string, []>("op_5804"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_285_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_285_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_285_pad_0 = const()[name = tensor<string, []>("pretrained_out_285_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_14_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(336465664))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(337284928))), name = tensor<string, []>("layers_14_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_14_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_14_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(337285056)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_285_cast_fp16 = conv(bias = layers_14_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_5804, groups = var_5715, pad = pretrained_out_285_pad_0, pad_type = pretrained_out_285_pad_type_0, strides = var_5802, weight = layers_14_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_197_cast_fp16)[name = tensor<string, []>("pretrained_out_285_cast_fp16")];
            tensor<int32, [2]> var_5808 = const()[name = tensor<string, []>("op_5808"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5810 = const()[name = tensor<string, []>("op_5810"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_425_pad_type_0 = const()[name = tensor<string, []>("input_425_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_425_pad_0 = const()[name = tensor<string, []>("input_425_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_14_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_14_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(337287680)))];
            tensor<fp16, [1, 16, 1, 1]> input_425_cast_fp16 = conv(dilations = var_5810, groups = var_5715, pad = input_425_pad_0, pad_type = input_425_pad_type_0, strides = var_5808, weight = layers_14_self_attn_v_proj_loraA_weight_to_fp16, x = obj_197_cast_fp16)[name = tensor<string, []>("input_425_cast_fp16")];
            tensor<int32, [2]> var_5814 = const()[name = tensor<string, []>("op_5814"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5816 = const()[name = tensor<string, []>("op_5816"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_569_pad_type_0 = const()[name = tensor<string, []>("lora_out_569_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_569_pad_0 = const()[name = tensor<string, []>("lora_out_569_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_571_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_571_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(337328704)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_571_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_5816, groups = var_5715, pad = lora_out_569_pad_0, pad_type = lora_out_569_pad_type_0, strides = var_5814, weight = lora_out_571_weight_0_to_fp16, x = input_425_cast_fp16)[name = tensor<string, []>("lora_out_571_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_29_cast_fp16 = add(x = pretrained_out_285_cast_fp16, y = lora_out_571_cast_fp16)[name = tensor<string, []>("current_value_29_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_5826_cast_fp16 = mul(x = current_key_29_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_5826_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_5828_cast_fp16 = mul(x = var_103_cast_fp16_14, y = var_295_cast_fp16)[name = tensor<string, []>("op_5828_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_57_cast_fp16 = add(x = var_5826_cast_fp16, y = var_5828_cast_fp16)[name = tensor<string, []>("key_57_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_5830_cast_fp16 = mul(x = current_value_29_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_5830_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_5832_cast_fp16 = mul(x = var_138_cast_fp16_14, y = var_295_cast_fp16)[name = tensor<string, []>("op_5832_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_57_cast_fp16 = add(x = var_5830_cast_fp16, y = var_5832_cast_fp16)[name = tensor<string, []>("value_57_cast_fp16")];
            tensor<int32, [4]> var_5835 = const()[name = tensor<string, []>("op_5835"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_5836_cast_fp16 = reshape(shape = var_5835, x = query_57_cast_fp16)[name = tensor<string, []>("op_5836_cast_fp16")];
            tensor<fp16, []> var_5837_to_fp16 = const()[name = tensor<string, []>("op_5837_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_5838_cast_fp16 = mul(x = var_5836_cast_fp16, y = var_5837_to_fp16)[name = tensor<string, []>("op_5838_cast_fp16")];
            tensor<int32, [4]> var_5839 = const()[name = tensor<string, []>("op_5839"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_5840_cast_fp16 = reshape(shape = var_5839, x = key_57_cast_fp16)[name = tensor<string, []>("op_5840_cast_fp16")];
            tensor<bool, []> mh_w_85_transpose_x_0 = const()[name = tensor<string, []>("mh_w_85_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_85_transpose_y_0 = const()[name = tensor<string, []>("mh_w_85_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_85_cast_fp16 = matmul(transpose_x = mh_w_85_transpose_x_0, transpose_y = mh_w_85_transpose_y_0, x = var_5838_cast_fp16, y = var_5840_cast_fp16)[name = tensor<string, []>("mh_w_85_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_87_cast_fp16 = add(x = mh_w_85_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_87_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_5848_cast_fp16 = softmax(axis = var_5708, x = mh_w_87_cast_fp16)[name = tensor<string, []>("op_5848_cast_fp16")];
            tensor<int32, [4]> var_5849 = const()[name = tensor<string, []>("op_5849"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_5850_cast_fp16 = reshape(shape = var_5849, x = value_57_cast_fp16)[name = tensor<string, []>("op_5850_cast_fp16")];
            tensor<bool, []> attn_57_transpose_x_0 = const()[name = tensor<string, []>("attn_57_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_57_transpose_y_0 = const()[name = tensor<string, []>("attn_57_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_57_cast_fp16 = matmul(transpose_x = attn_57_transpose_x_0, transpose_y = attn_57_transpose_y_0, x = var_5850_cast_fp16, y = var_5848_cast_fp16)[name = tensor<string, []>("attn_57_cast_fp16")];
            tensor<int32, [4]> var_5853 = const()[name = tensor<string, []>("op_5853"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_427_cast_fp16 = reshape(shape = var_5853, x = attn_57_cast_fp16)[name = tensor<string, []>("input_427_cast_fp16")];
            tensor<int32, [2]> var_5860 = const()[name = tensor<string, []>("op_5860"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5862 = const()[name = tensor<string, []>("op_5862"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_287_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_287_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_287_pad_0 = const()[name = tensor<string, []>("pretrained_out_287_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_14_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(337369728))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(338188992))), name = tensor<string, []>("layers_14_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_14_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_14_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(338189120)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_287_cast_fp16 = conv(bias = layers_14_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_5862, groups = var_5715, pad = pretrained_out_287_pad_0, pad_type = pretrained_out_287_pad_type_0, strides = var_5860, weight = layers_14_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_427_cast_fp16)[name = tensor<string, []>("pretrained_out_287_cast_fp16")];
            tensor<int32, [2]> var_5866 = const()[name = tensor<string, []>("op_5866"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5868 = const()[name = tensor<string, []>("op_5868"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_429_pad_type_0 = const()[name = tensor<string, []>("input_429_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_429_pad_0 = const()[name = tensor<string, []>("input_429_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_14_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_14_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(338191744)))];
            tensor<fp16, [1, 16, 1, 1]> input_429_cast_fp16 = conv(dilations = var_5868, groups = var_5715, pad = input_429_pad_0, pad_type = input_429_pad_type_0, strides = var_5866, weight = layers_14_self_attn_o_proj_loraA_weight_to_fp16, x = input_427_cast_fp16)[name = tensor<string, []>("input_429_cast_fp16")];
            tensor<int32, [2]> var_5872 = const()[name = tensor<string, []>("op_5872"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5874 = const()[name = tensor<string, []>("op_5874"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_573_pad_type_0 = const()[name = tensor<string, []>("lora_out_573_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_573_pad_0 = const()[name = tensor<string, []>("lora_out_573_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_575_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_575_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(338232768)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_575_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_5874, groups = var_5715, pad = lora_out_573_pad_0, pad_type = lora_out_573_pad_type_0, strides = var_5872, weight = lora_out_575_weight_0_to_fp16, x = input_429_cast_fp16)[name = tensor<string, []>("lora_out_575_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_203_cast_fp16 = add(x = pretrained_out_287_cast_fp16, y = lora_out_575_cast_fp16)[name = tensor<string, []>("obj_203_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_87_cast_fp16 = add(x = inputs_85_cast_fp16, y = obj_203_cast_fp16)[name = tensor<string, []>("inputs_87_cast_fp16")];
            tensor<int32, [1]> var_5887 = const()[name = tensor<string, []>("op_5887"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_87_cast_fp16 = reduce_mean(axes = var_5887, keep_dims = var_5716, x = inputs_87_cast_fp16)[name = tensor<string, []>("channels_mean_87_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_87_cast_fp16 = sub(x = inputs_87_cast_fp16, y = channels_mean_87_cast_fp16)[name = tensor<string, []>("zero_mean_87_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_87_cast_fp16 = mul(x = zero_mean_87_cast_fp16, y = zero_mean_87_cast_fp16)[name = tensor<string, []>("zero_mean_sq_87_cast_fp16")];
            tensor<int32, [1]> var_5891 = const()[name = tensor<string, []>("op_5891"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_5892_cast_fp16 = reduce_mean(axes = var_5891, keep_dims = var_5716, x = zero_mean_sq_87_cast_fp16)[name = tensor<string, []>("op_5892_cast_fp16")];
            tensor<fp16, []> var_5893_to_fp16 = const()[name = tensor<string, []>("op_5893_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_5894_cast_fp16 = add(x = var_5892_cast_fp16, y = var_5893_to_fp16)[name = tensor<string, []>("op_5894_cast_fp16")];
            tensor<fp32, []> denom_87_epsilon_0 = const()[name = tensor<string, []>("denom_87_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_87_cast_fp16 = rsqrt(epsilon = denom_87_epsilon_0, x = var_5894_cast_fp16)[name = tensor<string, []>("denom_87_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_87_cast_fp16 = mul(x = zero_mean_87_cast_fp16, y = denom_87_cast_fp16)[name = tensor<string, []>("out_87_cast_fp16")];
            tensor<fp16, [1280]> obj_205_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_205_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(338273792)))];
            tensor<fp16, [1280]> obj_205_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_205_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(338276416)))];
            tensor<fp16, []> obj_205_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_205_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_205_cast_fp16 = batch_norm(beta = obj_205_beta_0_to_fp16, epsilon = obj_205_epsilon_0_to_fp16, gamma = obj_205_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_87_cast_fp16)[name = tensor<string, []>("obj_205_cast_fp16")];
            tensor<int32, [2]> var_5912 = const()[name = tensor<string, []>("op_5912"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5914 = const()[name = tensor<string, []>("op_5914"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_289_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_289_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_289_pad_0 = const()[name = tensor<string, []>("pretrained_out_289_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_14_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(338279040))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(339098304))), name = tensor<string, []>("layers_14_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_14_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_14_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(339098432)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_289_cast_fp16 = conv(bias = layers_14_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_5914, groups = var_5715, pad = pretrained_out_289_pad_0, pad_type = pretrained_out_289_pad_type_0, strides = var_5912, weight = layers_14_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_205_cast_fp16)[name = tensor<string, []>("pretrained_out_289_cast_fp16")];
            tensor<int32, [2]> var_5918 = const()[name = tensor<string, []>("op_5918"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5920 = const()[name = tensor<string, []>("op_5920"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_431_pad_type_0 = const()[name = tensor<string, []>("input_431_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_431_pad_0 = const()[name = tensor<string, []>("input_431_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_14_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_14_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(339101056)))];
            tensor<fp16, [1, 16, 1, 1]> input_431_cast_fp16 = conv(dilations = var_5920, groups = var_5715, pad = input_431_pad_0, pad_type = input_431_pad_type_0, strides = var_5918, weight = layers_14_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_205_cast_fp16)[name = tensor<string, []>("input_431_cast_fp16")];
            tensor<int32, [2]> var_5924 = const()[name = tensor<string, []>("op_5924"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5926 = const()[name = tensor<string, []>("op_5926"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_577_pad_type_0 = const()[name = tensor<string, []>("lora_out_577_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_577_pad_0 = const()[name = tensor<string, []>("lora_out_577_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_579_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_579_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(339142080)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_579_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_5926, groups = var_5715, pad = lora_out_577_pad_0, pad_type = lora_out_577_pad_type_0, strides = var_5924, weight = lora_out_579_weight_0_to_fp16, x = input_431_cast_fp16)[name = tensor<string, []>("lora_out_579_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_59_cast_fp16 = add(x = pretrained_out_289_cast_fp16, y = lora_out_579_cast_fp16)[name = tensor<string, []>("query_59_cast_fp16")];
            tensor<int32, [2]> var_5936 = const()[name = tensor<string, []>("op_5936"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5938 = const()[name = tensor<string, []>("op_5938"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_291_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_291_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_291_pad_0 = const()[name = tensor<string, []>("pretrained_out_291_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_14_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(339183104))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(340002368))), name = tensor<string, []>("layers_14_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_291_cast_fp16 = conv(dilations = var_5938, groups = var_5715, pad = pretrained_out_291_pad_0, pad_type = pretrained_out_291_pad_type_0, strides = var_5936, weight = layers_14_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_291_cast_fp16")];
            tensor<int32, [2]> var_5942 = const()[name = tensor<string, []>("op_5942"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5944 = const()[name = tensor<string, []>("op_5944"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_433_pad_type_0 = const()[name = tensor<string, []>("input_433_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_433_pad_0 = const()[name = tensor<string, []>("input_433_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_14_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_14_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(340002496)))];
            tensor<fp16, [1, 16, 1, 1500]> input_433_cast_fp16 = conv(dilations = var_5944, groups = var_5715, pad = input_433_pad_0, pad_type = input_433_pad_type_0, strides = var_5942, weight = layers_14_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_433_cast_fp16")];
            tensor<int32, [2]> var_5948 = const()[name = tensor<string, []>("op_5948"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5950 = const()[name = tensor<string, []>("op_5950"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_581_pad_type_0 = const()[name = tensor<string, []>("lora_out_581_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_581_pad_0 = const()[name = tensor<string, []>("lora_out_581_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_583_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_583_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(340043520)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_583_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_5950, groups = var_5715, pad = lora_out_581_pad_0, pad_type = lora_out_581_pad_type_0, strides = var_5948, weight = lora_out_583_weight_0_to_fp16, x = input_433_cast_fp16)[name = tensor<string, []>("lora_out_583_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_59_cast_fp16 = add(x = pretrained_out_291_cast_fp16, y = lora_out_583_cast_fp16)[name = tensor<string, []>("key_59_cast_fp16")];
            tensor<int32, [2]> var_5961 = const()[name = tensor<string, []>("op_5961"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5963 = const()[name = tensor<string, []>("op_5963"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_293_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_293_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_293_pad_0 = const()[name = tensor<string, []>("pretrained_out_293_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_14_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(340084544))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(340903808))), name = tensor<string, []>("layers_14_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_14_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_14_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(340903936)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_293_cast_fp16 = conv(bias = layers_14_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_5963, groups = var_5715, pad = pretrained_out_293_pad_0, pad_type = pretrained_out_293_pad_type_0, strides = var_5961, weight = layers_14_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_293_cast_fp16")];
            tensor<int32, [2]> var_5967 = const()[name = tensor<string, []>("op_5967"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5969 = const()[name = tensor<string, []>("op_5969"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_435_pad_type_0 = const()[name = tensor<string, []>("input_435_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_435_pad_0 = const()[name = tensor<string, []>("input_435_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_14_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_14_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(340906560)))];
            tensor<fp16, [1, 16, 1, 1500]> input_435_cast_fp16 = conv(dilations = var_5969, groups = var_5715, pad = input_435_pad_0, pad_type = input_435_pad_type_0, strides = var_5967, weight = layers_14_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_435_cast_fp16")];
            tensor<int32, [2]> var_5973 = const()[name = tensor<string, []>("op_5973"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_5975 = const()[name = tensor<string, []>("op_5975"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_585_pad_type_0 = const()[name = tensor<string, []>("lora_out_585_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_585_pad_0 = const()[name = tensor<string, []>("lora_out_585_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_587_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_587_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(340947584)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_587_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_5975, groups = var_5715, pad = lora_out_585_pad_0, pad_type = lora_out_585_pad_type_0, strides = var_5973, weight = lora_out_587_weight_0_to_fp16, x = input_435_cast_fp16)[name = tensor<string, []>("lora_out_587_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_59_cast_fp16 = add(x = pretrained_out_293_cast_fp16, y = lora_out_587_cast_fp16)[name = tensor<string, []>("value_59_cast_fp16")];
            tensor<int32, [4]> var_5982 = const()[name = tensor<string, []>("op_5982"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_5983_cast_fp16 = reshape(shape = var_5982, x = query_59_cast_fp16)[name = tensor<string, []>("op_5983_cast_fp16")];
            tensor<fp16, []> var_5984_to_fp16 = const()[name = tensor<string, []>("op_5984_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_5985_cast_fp16 = mul(x = var_5983_cast_fp16, y = var_5984_to_fp16)[name = tensor<string, []>("op_5985_cast_fp16")];
            tensor<int32, [4]> var_5986 = const()[name = tensor<string, []>("op_5986"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_5987_cast_fp16 = reshape(shape = var_5986, x = key_59_cast_fp16)[name = tensor<string, []>("op_5987_cast_fp16")];
            tensor<bool, []> mh_w_89_transpose_x_0 = const()[name = tensor<string, []>("mh_w_89_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_89_transpose_y_0 = const()[name = tensor<string, []>("mh_w_89_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_89_cast_fp16 = matmul(transpose_x = mh_w_89_transpose_x_0, transpose_y = mh_w_89_transpose_y_0, x = var_5985_cast_fp16, y = var_5987_cast_fp16)[name = tensor<string, []>("mh_w_89_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_209_cast_fp16 = softmax(axis = var_5708, x = mh_w_89_cast_fp16)[name = tensor<string, []>("obj_209_cast_fp16")];
            tensor<int32, [4]> var_5991 = const()[name = tensor<string, []>("op_5991"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_5992_cast_fp16 = reshape(shape = var_5991, x = value_59_cast_fp16)[name = tensor<string, []>("op_5992_cast_fp16")];
            tensor<bool, []> attn_59_transpose_x_0 = const()[name = tensor<string, []>("attn_59_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_59_transpose_y_0 = const()[name = tensor<string, []>("attn_59_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_59_cast_fp16 = matmul(transpose_x = attn_59_transpose_x_0, transpose_y = attn_59_transpose_y_0, x = var_5992_cast_fp16, y = obj_209_cast_fp16)[name = tensor<string, []>("attn_59_cast_fp16")];
            tensor<int32, [4]> var_5995 = const()[name = tensor<string, []>("op_5995"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_437_cast_fp16 = reshape(shape = var_5995, x = attn_59_cast_fp16)[name = tensor<string, []>("input_437_cast_fp16")];
            tensor<int32, [2]> var_6002 = const()[name = tensor<string, []>("op_6002"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6004 = const()[name = tensor<string, []>("op_6004"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_295_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_295_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_295_pad_0 = const()[name = tensor<string, []>("pretrained_out_295_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_14_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(340988608))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(341807872))), name = tensor<string, []>("layers_14_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_14_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_14_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(341808000)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_295_cast_fp16 = conv(bias = layers_14_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_6004, groups = var_5715, pad = pretrained_out_295_pad_0, pad_type = pretrained_out_295_pad_type_0, strides = var_6002, weight = layers_14_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_437_cast_fp16)[name = tensor<string, []>("pretrained_out_295_cast_fp16")];
            tensor<int32, [2]> var_6008 = const()[name = tensor<string, []>("op_6008"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6010 = const()[name = tensor<string, []>("op_6010"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_439_pad_type_0 = const()[name = tensor<string, []>("input_439_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_439_pad_0 = const()[name = tensor<string, []>("input_439_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_14_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_14_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(341810624)))];
            tensor<fp16, [1, 16, 1, 1]> input_439_cast_fp16 = conv(dilations = var_6010, groups = var_5715, pad = input_439_pad_0, pad_type = input_439_pad_type_0, strides = var_6008, weight = layers_14_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_437_cast_fp16)[name = tensor<string, []>("input_439_cast_fp16")];
            tensor<int32, [2]> var_6014 = const()[name = tensor<string, []>("op_6014"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6016 = const()[name = tensor<string, []>("op_6016"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_589_pad_type_0 = const()[name = tensor<string, []>("lora_out_589_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_589_pad_0 = const()[name = tensor<string, []>("lora_out_589_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_591_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_591_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(341851648)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_591_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_6016, groups = var_5715, pad = lora_out_589_pad_0, pad_type = lora_out_589_pad_type_0, strides = var_6014, weight = lora_out_591_weight_0_to_fp16, x = input_439_cast_fp16)[name = tensor<string, []>("lora_out_591_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_207_cast_fp16 = add(x = pretrained_out_295_cast_fp16, y = lora_out_591_cast_fp16)[name = tensor<string, []>("obj_207_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_89_cast_fp16 = add(x = inputs_87_cast_fp16, y = obj_207_cast_fp16)[name = tensor<string, []>("inputs_89_cast_fp16")];
            tensor<int32, [1]> var_6025 = const()[name = tensor<string, []>("op_6025"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_89_cast_fp16 = reduce_mean(axes = var_6025, keep_dims = var_5716, x = inputs_89_cast_fp16)[name = tensor<string, []>("channels_mean_89_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_89_cast_fp16 = sub(x = inputs_89_cast_fp16, y = channels_mean_89_cast_fp16)[name = tensor<string, []>("zero_mean_89_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_89_cast_fp16 = mul(x = zero_mean_89_cast_fp16, y = zero_mean_89_cast_fp16)[name = tensor<string, []>("zero_mean_sq_89_cast_fp16")];
            tensor<int32, [1]> var_6029 = const()[name = tensor<string, []>("op_6029"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_6030_cast_fp16 = reduce_mean(axes = var_6029, keep_dims = var_5716, x = zero_mean_sq_89_cast_fp16)[name = tensor<string, []>("op_6030_cast_fp16")];
            tensor<fp16, []> var_6031_to_fp16 = const()[name = tensor<string, []>("op_6031_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_6032_cast_fp16 = add(x = var_6030_cast_fp16, y = var_6031_to_fp16)[name = tensor<string, []>("op_6032_cast_fp16")];
            tensor<fp32, []> denom_89_epsilon_0 = const()[name = tensor<string, []>("denom_89_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_89_cast_fp16 = rsqrt(epsilon = denom_89_epsilon_0, x = var_6032_cast_fp16)[name = tensor<string, []>("denom_89_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_89_cast_fp16 = mul(x = zero_mean_89_cast_fp16, y = denom_89_cast_fp16)[name = tensor<string, []>("out_89_cast_fp16")];
            tensor<fp16, [1280]> input_441_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_441_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(341892672)))];
            tensor<fp16, [1280]> input_441_beta_0_to_fp16 = const()[name = tensor<string, []>("input_441_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(341895296)))];
            tensor<fp16, []> input_441_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_441_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_441_cast_fp16 = batch_norm(beta = input_441_beta_0_to_fp16, epsilon = input_441_epsilon_0_to_fp16, gamma = input_441_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_89_cast_fp16)[name = tensor<string, []>("input_441_cast_fp16")];
            tensor<int32, [2]> var_6046 = const()[name = tensor<string, []>("op_6046"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6048 = const()[name = tensor<string, []>("op_6048"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_297_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_297_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_297_pad_0 = const()[name = tensor<string, []>("pretrained_out_297_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_14_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(341897920))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(345174784))), name = tensor<string, []>("layers_14_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_14_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_14_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(345174912)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_297_cast_fp16 = conv(bias = layers_14_fc1_pretrained_bias_to_fp16, dilations = var_6048, groups = var_5715, pad = pretrained_out_297_pad_0, pad_type = pretrained_out_297_pad_type_0, strides = var_6046, weight = layers_14_fc1_pretrained_weight_to_fp16_palettized, x = input_441_cast_fp16)[name = tensor<string, []>("pretrained_out_297_cast_fp16")];
            tensor<int32, [2]> var_6052 = const()[name = tensor<string, []>("op_6052"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6054 = const()[name = tensor<string, []>("op_6054"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_443_pad_type_0 = const()[name = tensor<string, []>("input_443_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_443_pad_0 = const()[name = tensor<string, []>("input_443_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_14_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_14_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(345185216)))];
            tensor<fp16, [1, 16, 1, 1]> input_443_cast_fp16 = conv(dilations = var_6054, groups = var_5715, pad = input_443_pad_0, pad_type = input_443_pad_type_0, strides = var_6052, weight = layers_14_fc1_loraA_weight_to_fp16, x = input_441_cast_fp16)[name = tensor<string, []>("input_443_cast_fp16")];
            tensor<int32, [2]> var_6058 = const()[name = tensor<string, []>("op_6058"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6060 = const()[name = tensor<string, []>("op_6060"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_593_pad_type_0 = const()[name = tensor<string, []>("lora_out_593_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_593_pad_0 = const()[name = tensor<string, []>("lora_out_593_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_595_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_595_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(345226240)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_595_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_6060, groups = var_5715, pad = lora_out_593_pad_0, pad_type = lora_out_593_pad_type_0, strides = var_6058, weight = lora_out_595_weight_0_to_fp16, x = input_443_cast_fp16)[name = tensor<string, []>("lora_out_595_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_445_cast_fp16 = add(x = pretrained_out_297_cast_fp16, y = lora_out_595_cast_fp16)[name = tensor<string, []>("input_445_cast_fp16")];
            tensor<string, []> input_447_mode_0 = const()[name = tensor<string, []>("input_447_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_447_cast_fp16 = gelu(mode = input_447_mode_0, x = input_445_cast_fp16)[name = tensor<string, []>("input_447_cast_fp16")];
            tensor<int32, [2]> var_6072 = const()[name = tensor<string, []>("op_6072"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6074 = const()[name = tensor<string, []>("op_6074"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_299_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_299_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_299_pad_0 = const()[name = tensor<string, []>("pretrained_out_299_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_14_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(345390144))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(348667008))), name = tensor<string, []>("layers_14_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_14_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_14_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(348667136)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_299_cast_fp16 = conv(bias = layers_14_fc2_pretrained_bias_to_fp16, dilations = var_6074, groups = var_5715, pad = pretrained_out_299_pad_0, pad_type = pretrained_out_299_pad_type_0, strides = var_6072, weight = layers_14_fc2_pretrained_weight_to_fp16_palettized, x = input_447_cast_fp16)[name = tensor<string, []>("pretrained_out_299_cast_fp16")];
            tensor<int32, [2]> var_6078 = const()[name = tensor<string, []>("op_6078"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6080 = const()[name = tensor<string, []>("op_6080"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_449_pad_type_0 = const()[name = tensor<string, []>("input_449_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_449_pad_0 = const()[name = tensor<string, []>("input_449_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_14_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_14_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(348669760)))];
            tensor<fp16, [1, 16, 1, 1]> input_449_cast_fp16 = conv(dilations = var_6080, groups = var_5715, pad = input_449_pad_0, pad_type = input_449_pad_type_0, strides = var_6078, weight = layers_14_fc2_loraA_weight_to_fp16, x = input_447_cast_fp16)[name = tensor<string, []>("input_449_cast_fp16")];
            tensor<int32, [2]> var_6084 = const()[name = tensor<string, []>("op_6084"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6086 = const()[name = tensor<string, []>("op_6086"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_597_pad_type_0 = const()[name = tensor<string, []>("lora_out_597_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_597_pad_0 = const()[name = tensor<string, []>("lora_out_597_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_599_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_599_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(348833664)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_599_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_6086, groups = var_5715, pad = lora_out_597_pad_0, pad_type = lora_out_597_pad_type_0, strides = var_6084, weight = lora_out_599_weight_0_to_fp16, x = input_449_cast_fp16)[name = tensor<string, []>("lora_out_599_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_31_cast_fp16 = add(x = pretrained_out_299_cast_fp16, y = lora_out_599_cast_fp16)[name = tensor<string, []>("hidden_states_31_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_91_cast_fp16 = add(x = inputs_89_cast_fp16, y = hidden_states_31_cast_fp16)[name = tensor<string, []>("inputs_91_cast_fp16")];
            tensor<int32, []> var_6102 = const()[name = tensor<string, []>("op_6102"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_6109 = const()[name = tensor<string, []>("op_6109"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_6110 = const()[name = tensor<string, []>("op_6110"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_6122 = const()[name = tensor<string, []>("op_6122"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_91_cast_fp16 = reduce_mean(axes = var_6122, keep_dims = var_6110, x = inputs_91_cast_fp16)[name = tensor<string, []>("channels_mean_91_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_91_cast_fp16 = sub(x = inputs_91_cast_fp16, y = channels_mean_91_cast_fp16)[name = tensor<string, []>("zero_mean_91_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_91_cast_fp16 = mul(x = zero_mean_91_cast_fp16, y = zero_mean_91_cast_fp16)[name = tensor<string, []>("zero_mean_sq_91_cast_fp16")];
            tensor<int32, [1]> var_6126 = const()[name = tensor<string, []>("op_6126"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_6127_cast_fp16 = reduce_mean(axes = var_6126, keep_dims = var_6110, x = zero_mean_sq_91_cast_fp16)[name = tensor<string, []>("op_6127_cast_fp16")];
            tensor<fp16, []> var_6128_to_fp16 = const()[name = tensor<string, []>("op_6128_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_6129_cast_fp16 = add(x = var_6127_cast_fp16, y = var_6128_to_fp16)[name = tensor<string, []>("op_6129_cast_fp16")];
            tensor<fp32, []> denom_91_epsilon_0 = const()[name = tensor<string, []>("denom_91_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_91_cast_fp16 = rsqrt(epsilon = denom_91_epsilon_0, x = var_6129_cast_fp16)[name = tensor<string, []>("denom_91_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_91_cast_fp16 = mul(x = zero_mean_91_cast_fp16, y = denom_91_cast_fp16)[name = tensor<string, []>("out_91_cast_fp16")];
            tensor<fp16, [1280]> obj_211_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_211_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(348874688)))];
            tensor<fp16, [1280]> obj_211_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_211_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(348877312)))];
            tensor<fp16, []> obj_211_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_211_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_211_cast_fp16 = batch_norm(beta = obj_211_beta_0_to_fp16, epsilon = obj_211_epsilon_0_to_fp16, gamma = obj_211_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_91_cast_fp16)[name = tensor<string, []>("obj_211_cast_fp16")];
            tensor<int32, [2]> var_6147 = const()[name = tensor<string, []>("op_6147"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6149 = const()[name = tensor<string, []>("op_6149"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_301_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_301_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_301_pad_0 = const()[name = tensor<string, []>("pretrained_out_301_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_15_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(348879936))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(349699200))), name = tensor<string, []>("layers_15_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_15_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_15_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(349699328)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_301_cast_fp16 = conv(bias = layers_15_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_6149, groups = var_6109, pad = pretrained_out_301_pad_0, pad_type = pretrained_out_301_pad_type_0, strides = var_6147, weight = layers_15_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_211_cast_fp16)[name = tensor<string, []>("pretrained_out_301_cast_fp16")];
            tensor<int32, [2]> var_6153 = const()[name = tensor<string, []>("op_6153"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6155 = const()[name = tensor<string, []>("op_6155"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_451_pad_type_0 = const()[name = tensor<string, []>("input_451_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_451_pad_0 = const()[name = tensor<string, []>("input_451_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_15_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_15_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(349701952)))];
            tensor<fp16, [1, 16, 1, 1]> input_451_cast_fp16 = conv(dilations = var_6155, groups = var_6109, pad = input_451_pad_0, pad_type = input_451_pad_type_0, strides = var_6153, weight = layers_15_self_attn_q_proj_loraA_weight_to_fp16, x = obj_211_cast_fp16)[name = tensor<string, []>("input_451_cast_fp16")];
            tensor<int32, [2]> var_6159 = const()[name = tensor<string, []>("op_6159"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6161 = const()[name = tensor<string, []>("op_6161"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_601_pad_type_0 = const()[name = tensor<string, []>("lora_out_601_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_601_pad_0 = const()[name = tensor<string, []>("lora_out_601_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_603_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_603_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(349742976)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_603_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_6161, groups = var_6109, pad = lora_out_601_pad_0, pad_type = lora_out_601_pad_type_0, strides = var_6159, weight = lora_out_603_weight_0_to_fp16, x = input_451_cast_fp16)[name = tensor<string, []>("lora_out_603_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_61_cast_fp16 = add(x = pretrained_out_301_cast_fp16, y = lora_out_603_cast_fp16)[name = tensor<string, []>("query_61_cast_fp16")];
            tensor<int32, [2]> var_6171 = const()[name = tensor<string, []>("op_6171"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6173 = const()[name = tensor<string, []>("op_6173"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_303_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_303_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_303_pad_0 = const()[name = tensor<string, []>("pretrained_out_303_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_15_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(349784000))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(350603264))), name = tensor<string, []>("layers_15_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_303_cast_fp16 = conv(dilations = var_6173, groups = var_6109, pad = pretrained_out_303_pad_0, pad_type = pretrained_out_303_pad_type_0, strides = var_6171, weight = layers_15_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_211_cast_fp16)[name = tensor<string, []>("pretrained_out_303_cast_fp16")];
            tensor<int32, [2]> var_6177 = const()[name = tensor<string, []>("op_6177"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6179 = const()[name = tensor<string, []>("op_6179"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_453_pad_type_0 = const()[name = tensor<string, []>("input_453_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_453_pad_0 = const()[name = tensor<string, []>("input_453_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_15_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_15_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(350603392)))];
            tensor<fp16, [1, 16, 1, 1]> input_453_cast_fp16 = conv(dilations = var_6179, groups = var_6109, pad = input_453_pad_0, pad_type = input_453_pad_type_0, strides = var_6177, weight = layers_15_self_attn_k_proj_loraA_weight_to_fp16, x = obj_211_cast_fp16)[name = tensor<string, []>("input_453_cast_fp16")];
            tensor<int32, [2]> var_6183 = const()[name = tensor<string, []>("op_6183"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6185 = const()[name = tensor<string, []>("op_6185"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_605_pad_type_0 = const()[name = tensor<string, []>("lora_out_605_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_605_pad_0 = const()[name = tensor<string, []>("lora_out_605_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_607_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_607_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(350644416)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_607_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_6185, groups = var_6109, pad = lora_out_605_pad_0, pad_type = lora_out_605_pad_type_0, strides = var_6183, weight = lora_out_607_weight_0_to_fp16, x = input_453_cast_fp16)[name = tensor<string, []>("lora_out_607_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_31_cast_fp16 = add(x = pretrained_out_303_cast_fp16, y = lora_out_607_cast_fp16)[name = tensor<string, []>("current_key_31_cast_fp16")];
            tensor<int32, [2]> var_6196 = const()[name = tensor<string, []>("op_6196"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6198 = const()[name = tensor<string, []>("op_6198"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_305_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_305_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_305_pad_0 = const()[name = tensor<string, []>("pretrained_out_305_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_15_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(350685440))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(351504704))), name = tensor<string, []>("layers_15_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_15_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_15_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(351504832)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_305_cast_fp16 = conv(bias = layers_15_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_6198, groups = var_6109, pad = pretrained_out_305_pad_0, pad_type = pretrained_out_305_pad_type_0, strides = var_6196, weight = layers_15_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_211_cast_fp16)[name = tensor<string, []>("pretrained_out_305_cast_fp16")];
            tensor<int32, [2]> var_6202 = const()[name = tensor<string, []>("op_6202"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6204 = const()[name = tensor<string, []>("op_6204"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_455_pad_type_0 = const()[name = tensor<string, []>("input_455_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_455_pad_0 = const()[name = tensor<string, []>("input_455_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_15_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_15_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(351507456)))];
            tensor<fp16, [1, 16, 1, 1]> input_455_cast_fp16 = conv(dilations = var_6204, groups = var_6109, pad = input_455_pad_0, pad_type = input_455_pad_type_0, strides = var_6202, weight = layers_15_self_attn_v_proj_loraA_weight_to_fp16, x = obj_211_cast_fp16)[name = tensor<string, []>("input_455_cast_fp16")];
            tensor<int32, [2]> var_6208 = const()[name = tensor<string, []>("op_6208"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6210 = const()[name = tensor<string, []>("op_6210"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_609_pad_type_0 = const()[name = tensor<string, []>("lora_out_609_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_609_pad_0 = const()[name = tensor<string, []>("lora_out_609_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_611_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_611_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(351548480)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_611_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_6210, groups = var_6109, pad = lora_out_609_pad_0, pad_type = lora_out_609_pad_type_0, strides = var_6208, weight = lora_out_611_weight_0_to_fp16, x = input_455_cast_fp16)[name = tensor<string, []>("lora_out_611_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_31_cast_fp16 = add(x = pretrained_out_305_cast_fp16, y = lora_out_611_cast_fp16)[name = tensor<string, []>("current_value_31_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_6220_cast_fp16 = mul(x = current_key_31_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_6220_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_6222_cast_fp16 = mul(x = var_103_cast_fp16_15, y = var_295_cast_fp16)[name = tensor<string, []>("op_6222_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_61_cast_fp16 = add(x = var_6220_cast_fp16, y = var_6222_cast_fp16)[name = tensor<string, []>("key_61_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_6224_cast_fp16 = mul(x = current_value_31_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_6224_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_6226_cast_fp16 = mul(x = var_138_cast_fp16_15, y = var_295_cast_fp16)[name = tensor<string, []>("op_6226_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_61_cast_fp16 = add(x = var_6224_cast_fp16, y = var_6226_cast_fp16)[name = tensor<string, []>("value_61_cast_fp16")];
            tensor<int32, [4]> var_6229 = const()[name = tensor<string, []>("op_6229"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_6230_cast_fp16 = reshape(shape = var_6229, x = query_61_cast_fp16)[name = tensor<string, []>("op_6230_cast_fp16")];
            tensor<fp16, []> var_6231_to_fp16 = const()[name = tensor<string, []>("op_6231_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_6232_cast_fp16 = mul(x = var_6230_cast_fp16, y = var_6231_to_fp16)[name = tensor<string, []>("op_6232_cast_fp16")];
            tensor<int32, [4]> var_6233 = const()[name = tensor<string, []>("op_6233"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_6234_cast_fp16 = reshape(shape = var_6233, x = key_61_cast_fp16)[name = tensor<string, []>("op_6234_cast_fp16")];
            tensor<bool, []> mh_w_91_transpose_x_0 = const()[name = tensor<string, []>("mh_w_91_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_91_transpose_y_0 = const()[name = tensor<string, []>("mh_w_91_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_91_cast_fp16 = matmul(transpose_x = mh_w_91_transpose_x_0, transpose_y = mh_w_91_transpose_y_0, x = var_6232_cast_fp16, y = var_6234_cast_fp16)[name = tensor<string, []>("mh_w_91_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_93_cast_fp16 = add(x = mh_w_91_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_93_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_6242_cast_fp16 = softmax(axis = var_6102, x = mh_w_93_cast_fp16)[name = tensor<string, []>("op_6242_cast_fp16")];
            tensor<int32, [4]> var_6243 = const()[name = tensor<string, []>("op_6243"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_6244_cast_fp16 = reshape(shape = var_6243, x = value_61_cast_fp16)[name = tensor<string, []>("op_6244_cast_fp16")];
            tensor<bool, []> attn_61_transpose_x_0 = const()[name = tensor<string, []>("attn_61_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_61_transpose_y_0 = const()[name = tensor<string, []>("attn_61_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_61_cast_fp16 = matmul(transpose_x = attn_61_transpose_x_0, transpose_y = attn_61_transpose_y_0, x = var_6244_cast_fp16, y = var_6242_cast_fp16)[name = tensor<string, []>("attn_61_cast_fp16")];
            tensor<int32, [4]> var_6247 = const()[name = tensor<string, []>("op_6247"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_457_cast_fp16 = reshape(shape = var_6247, x = attn_61_cast_fp16)[name = tensor<string, []>("input_457_cast_fp16")];
            tensor<int32, [2]> var_6254 = const()[name = tensor<string, []>("op_6254"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6256 = const()[name = tensor<string, []>("op_6256"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_307_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_307_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_307_pad_0 = const()[name = tensor<string, []>("pretrained_out_307_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_15_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(351589504))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(352408768))), name = tensor<string, []>("layers_15_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_15_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_15_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(352408896)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_307_cast_fp16 = conv(bias = layers_15_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_6256, groups = var_6109, pad = pretrained_out_307_pad_0, pad_type = pretrained_out_307_pad_type_0, strides = var_6254, weight = layers_15_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_457_cast_fp16)[name = tensor<string, []>("pretrained_out_307_cast_fp16")];
            tensor<int32, [2]> var_6260 = const()[name = tensor<string, []>("op_6260"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6262 = const()[name = tensor<string, []>("op_6262"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_459_pad_type_0 = const()[name = tensor<string, []>("input_459_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_459_pad_0 = const()[name = tensor<string, []>("input_459_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_15_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_15_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(352411520)))];
            tensor<fp16, [1, 16, 1, 1]> input_459_cast_fp16 = conv(dilations = var_6262, groups = var_6109, pad = input_459_pad_0, pad_type = input_459_pad_type_0, strides = var_6260, weight = layers_15_self_attn_o_proj_loraA_weight_to_fp16, x = input_457_cast_fp16)[name = tensor<string, []>("input_459_cast_fp16")];
            tensor<int32, [2]> var_6266 = const()[name = tensor<string, []>("op_6266"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6268 = const()[name = tensor<string, []>("op_6268"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_613_pad_type_0 = const()[name = tensor<string, []>("lora_out_613_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_613_pad_0 = const()[name = tensor<string, []>("lora_out_613_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_615_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_615_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(352452544)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_615_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_6268, groups = var_6109, pad = lora_out_613_pad_0, pad_type = lora_out_613_pad_type_0, strides = var_6266, weight = lora_out_615_weight_0_to_fp16, x = input_459_cast_fp16)[name = tensor<string, []>("lora_out_615_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_217_cast_fp16 = add(x = pretrained_out_307_cast_fp16, y = lora_out_615_cast_fp16)[name = tensor<string, []>("obj_217_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_93_cast_fp16 = add(x = inputs_91_cast_fp16, y = obj_217_cast_fp16)[name = tensor<string, []>("inputs_93_cast_fp16")];
            tensor<int32, [1]> var_6281 = const()[name = tensor<string, []>("op_6281"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_93_cast_fp16 = reduce_mean(axes = var_6281, keep_dims = var_6110, x = inputs_93_cast_fp16)[name = tensor<string, []>("channels_mean_93_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_93_cast_fp16 = sub(x = inputs_93_cast_fp16, y = channels_mean_93_cast_fp16)[name = tensor<string, []>("zero_mean_93_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_93_cast_fp16 = mul(x = zero_mean_93_cast_fp16, y = zero_mean_93_cast_fp16)[name = tensor<string, []>("zero_mean_sq_93_cast_fp16")];
            tensor<int32, [1]> var_6285 = const()[name = tensor<string, []>("op_6285"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_6286_cast_fp16 = reduce_mean(axes = var_6285, keep_dims = var_6110, x = zero_mean_sq_93_cast_fp16)[name = tensor<string, []>("op_6286_cast_fp16")];
            tensor<fp16, []> var_6287_to_fp16 = const()[name = tensor<string, []>("op_6287_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_6288_cast_fp16 = add(x = var_6286_cast_fp16, y = var_6287_to_fp16)[name = tensor<string, []>("op_6288_cast_fp16")];
            tensor<fp32, []> denom_93_epsilon_0 = const()[name = tensor<string, []>("denom_93_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_93_cast_fp16 = rsqrt(epsilon = denom_93_epsilon_0, x = var_6288_cast_fp16)[name = tensor<string, []>("denom_93_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_93_cast_fp16 = mul(x = zero_mean_93_cast_fp16, y = denom_93_cast_fp16)[name = tensor<string, []>("out_93_cast_fp16")];
            tensor<fp16, [1280]> obj_219_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_219_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(352493568)))];
            tensor<fp16, [1280]> obj_219_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_219_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(352496192)))];
            tensor<fp16, []> obj_219_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_219_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_219_cast_fp16 = batch_norm(beta = obj_219_beta_0_to_fp16, epsilon = obj_219_epsilon_0_to_fp16, gamma = obj_219_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_93_cast_fp16)[name = tensor<string, []>("obj_219_cast_fp16")];
            tensor<int32, [2]> var_6306 = const()[name = tensor<string, []>("op_6306"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6308 = const()[name = tensor<string, []>("op_6308"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_309_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_309_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_309_pad_0 = const()[name = tensor<string, []>("pretrained_out_309_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_15_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(352498816))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(353318080))), name = tensor<string, []>("layers_15_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_15_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_15_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(353318208)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_309_cast_fp16 = conv(bias = layers_15_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_6308, groups = var_6109, pad = pretrained_out_309_pad_0, pad_type = pretrained_out_309_pad_type_0, strides = var_6306, weight = layers_15_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_219_cast_fp16)[name = tensor<string, []>("pretrained_out_309_cast_fp16")];
            tensor<int32, [2]> var_6312 = const()[name = tensor<string, []>("op_6312"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6314 = const()[name = tensor<string, []>("op_6314"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_461_pad_type_0 = const()[name = tensor<string, []>("input_461_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_461_pad_0 = const()[name = tensor<string, []>("input_461_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_15_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_15_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(353320832)))];
            tensor<fp16, [1, 16, 1, 1]> input_461_cast_fp16 = conv(dilations = var_6314, groups = var_6109, pad = input_461_pad_0, pad_type = input_461_pad_type_0, strides = var_6312, weight = layers_15_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_219_cast_fp16)[name = tensor<string, []>("input_461_cast_fp16")];
            tensor<int32, [2]> var_6318 = const()[name = tensor<string, []>("op_6318"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6320 = const()[name = tensor<string, []>("op_6320"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_617_pad_type_0 = const()[name = tensor<string, []>("lora_out_617_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_617_pad_0 = const()[name = tensor<string, []>("lora_out_617_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_619_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_619_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(353361856)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_619_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_6320, groups = var_6109, pad = lora_out_617_pad_0, pad_type = lora_out_617_pad_type_0, strides = var_6318, weight = lora_out_619_weight_0_to_fp16, x = input_461_cast_fp16)[name = tensor<string, []>("lora_out_619_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_63_cast_fp16 = add(x = pretrained_out_309_cast_fp16, y = lora_out_619_cast_fp16)[name = tensor<string, []>("query_63_cast_fp16")];
            tensor<int32, [2]> var_6330 = const()[name = tensor<string, []>("op_6330"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6332 = const()[name = tensor<string, []>("op_6332"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_311_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_311_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_311_pad_0 = const()[name = tensor<string, []>("pretrained_out_311_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_15_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(353402880))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(354222144))), name = tensor<string, []>("layers_15_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_311_cast_fp16 = conv(dilations = var_6332, groups = var_6109, pad = pretrained_out_311_pad_0, pad_type = pretrained_out_311_pad_type_0, strides = var_6330, weight = layers_15_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_311_cast_fp16")];
            tensor<int32, [2]> var_6336 = const()[name = tensor<string, []>("op_6336"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6338 = const()[name = tensor<string, []>("op_6338"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_463_pad_type_0 = const()[name = tensor<string, []>("input_463_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_463_pad_0 = const()[name = tensor<string, []>("input_463_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_15_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_15_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(354222272)))];
            tensor<fp16, [1, 16, 1, 1500]> input_463_cast_fp16 = conv(dilations = var_6338, groups = var_6109, pad = input_463_pad_0, pad_type = input_463_pad_type_0, strides = var_6336, weight = layers_15_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_463_cast_fp16")];
            tensor<int32, [2]> var_6342 = const()[name = tensor<string, []>("op_6342"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6344 = const()[name = tensor<string, []>("op_6344"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_621_pad_type_0 = const()[name = tensor<string, []>("lora_out_621_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_621_pad_0 = const()[name = tensor<string, []>("lora_out_621_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_623_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_623_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(354263296)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_623_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_6344, groups = var_6109, pad = lora_out_621_pad_0, pad_type = lora_out_621_pad_type_0, strides = var_6342, weight = lora_out_623_weight_0_to_fp16, x = input_463_cast_fp16)[name = tensor<string, []>("lora_out_623_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_63_cast_fp16 = add(x = pretrained_out_311_cast_fp16, y = lora_out_623_cast_fp16)[name = tensor<string, []>("key_63_cast_fp16")];
            tensor<int32, [2]> var_6355 = const()[name = tensor<string, []>("op_6355"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6357 = const()[name = tensor<string, []>("op_6357"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_313_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_313_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_313_pad_0 = const()[name = tensor<string, []>("pretrained_out_313_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_15_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(354304320))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(355123584))), name = tensor<string, []>("layers_15_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_15_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_15_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(355123712)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_313_cast_fp16 = conv(bias = layers_15_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_6357, groups = var_6109, pad = pretrained_out_313_pad_0, pad_type = pretrained_out_313_pad_type_0, strides = var_6355, weight = layers_15_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_313_cast_fp16")];
            tensor<int32, [2]> var_6361 = const()[name = tensor<string, []>("op_6361"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6363 = const()[name = tensor<string, []>("op_6363"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_465_pad_type_0 = const()[name = tensor<string, []>("input_465_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_465_pad_0 = const()[name = tensor<string, []>("input_465_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_15_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_15_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(355126336)))];
            tensor<fp16, [1, 16, 1, 1500]> input_465_cast_fp16 = conv(dilations = var_6363, groups = var_6109, pad = input_465_pad_0, pad_type = input_465_pad_type_0, strides = var_6361, weight = layers_15_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_465_cast_fp16")];
            tensor<int32, [2]> var_6367 = const()[name = tensor<string, []>("op_6367"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6369 = const()[name = tensor<string, []>("op_6369"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_625_pad_type_0 = const()[name = tensor<string, []>("lora_out_625_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_625_pad_0 = const()[name = tensor<string, []>("lora_out_625_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_627_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_627_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(355167360)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_627_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_6369, groups = var_6109, pad = lora_out_625_pad_0, pad_type = lora_out_625_pad_type_0, strides = var_6367, weight = lora_out_627_weight_0_to_fp16, x = input_465_cast_fp16)[name = tensor<string, []>("lora_out_627_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_63_cast_fp16 = add(x = pretrained_out_313_cast_fp16, y = lora_out_627_cast_fp16)[name = tensor<string, []>("value_63_cast_fp16")];
            tensor<int32, [4]> var_6376 = const()[name = tensor<string, []>("op_6376"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_6377_cast_fp16 = reshape(shape = var_6376, x = query_63_cast_fp16)[name = tensor<string, []>("op_6377_cast_fp16")];
            tensor<fp16, []> var_6378_to_fp16 = const()[name = tensor<string, []>("op_6378_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_6379_cast_fp16 = mul(x = var_6377_cast_fp16, y = var_6378_to_fp16)[name = tensor<string, []>("op_6379_cast_fp16")];
            tensor<int32, [4]> var_6380 = const()[name = tensor<string, []>("op_6380"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_6381_cast_fp16 = reshape(shape = var_6380, x = key_63_cast_fp16)[name = tensor<string, []>("op_6381_cast_fp16")];
            tensor<bool, []> mh_w_95_transpose_x_0 = const()[name = tensor<string, []>("mh_w_95_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_95_transpose_y_0 = const()[name = tensor<string, []>("mh_w_95_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_95_cast_fp16 = matmul(transpose_x = mh_w_95_transpose_x_0, transpose_y = mh_w_95_transpose_y_0, x = var_6379_cast_fp16, y = var_6381_cast_fp16)[name = tensor<string, []>("mh_w_95_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_223_cast_fp16 = softmax(axis = var_6102, x = mh_w_95_cast_fp16)[name = tensor<string, []>("obj_223_cast_fp16")];
            tensor<int32, [4]> var_6385 = const()[name = tensor<string, []>("op_6385"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_6386_cast_fp16 = reshape(shape = var_6385, x = value_63_cast_fp16)[name = tensor<string, []>("op_6386_cast_fp16")];
            tensor<bool, []> attn_63_transpose_x_0 = const()[name = tensor<string, []>("attn_63_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_63_transpose_y_0 = const()[name = tensor<string, []>("attn_63_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_63_cast_fp16 = matmul(transpose_x = attn_63_transpose_x_0, transpose_y = attn_63_transpose_y_0, x = var_6386_cast_fp16, y = obj_223_cast_fp16)[name = tensor<string, []>("attn_63_cast_fp16")];
            tensor<int32, [4]> var_6389 = const()[name = tensor<string, []>("op_6389"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_467_cast_fp16 = reshape(shape = var_6389, x = attn_63_cast_fp16)[name = tensor<string, []>("input_467_cast_fp16")];
            tensor<int32, [2]> var_6396 = const()[name = tensor<string, []>("op_6396"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6398 = const()[name = tensor<string, []>("op_6398"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_315_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_315_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_315_pad_0 = const()[name = tensor<string, []>("pretrained_out_315_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_15_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(355208384))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(356027648))), name = tensor<string, []>("layers_15_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_15_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_15_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(356027776)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_315_cast_fp16 = conv(bias = layers_15_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_6398, groups = var_6109, pad = pretrained_out_315_pad_0, pad_type = pretrained_out_315_pad_type_0, strides = var_6396, weight = layers_15_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_467_cast_fp16)[name = tensor<string, []>("pretrained_out_315_cast_fp16")];
            tensor<int32, [2]> var_6402 = const()[name = tensor<string, []>("op_6402"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6404 = const()[name = tensor<string, []>("op_6404"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_469_pad_type_0 = const()[name = tensor<string, []>("input_469_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_469_pad_0 = const()[name = tensor<string, []>("input_469_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_15_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_15_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(356030400)))];
            tensor<fp16, [1, 16, 1, 1]> input_469_cast_fp16 = conv(dilations = var_6404, groups = var_6109, pad = input_469_pad_0, pad_type = input_469_pad_type_0, strides = var_6402, weight = layers_15_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_467_cast_fp16)[name = tensor<string, []>("input_469_cast_fp16")];
            tensor<int32, [2]> var_6408 = const()[name = tensor<string, []>("op_6408"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6410 = const()[name = tensor<string, []>("op_6410"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_629_pad_type_0 = const()[name = tensor<string, []>("lora_out_629_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_629_pad_0 = const()[name = tensor<string, []>("lora_out_629_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_631_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_631_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(356071424)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_631_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_6410, groups = var_6109, pad = lora_out_629_pad_0, pad_type = lora_out_629_pad_type_0, strides = var_6408, weight = lora_out_631_weight_0_to_fp16, x = input_469_cast_fp16)[name = tensor<string, []>("lora_out_631_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_221_cast_fp16 = add(x = pretrained_out_315_cast_fp16, y = lora_out_631_cast_fp16)[name = tensor<string, []>("obj_221_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_95_cast_fp16 = add(x = inputs_93_cast_fp16, y = obj_221_cast_fp16)[name = tensor<string, []>("inputs_95_cast_fp16")];
            tensor<int32, [1]> var_6419 = const()[name = tensor<string, []>("op_6419"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_95_cast_fp16 = reduce_mean(axes = var_6419, keep_dims = var_6110, x = inputs_95_cast_fp16)[name = tensor<string, []>("channels_mean_95_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_95_cast_fp16 = sub(x = inputs_95_cast_fp16, y = channels_mean_95_cast_fp16)[name = tensor<string, []>("zero_mean_95_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_95_cast_fp16 = mul(x = zero_mean_95_cast_fp16, y = zero_mean_95_cast_fp16)[name = tensor<string, []>("zero_mean_sq_95_cast_fp16")];
            tensor<int32, [1]> var_6423 = const()[name = tensor<string, []>("op_6423"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_6424_cast_fp16 = reduce_mean(axes = var_6423, keep_dims = var_6110, x = zero_mean_sq_95_cast_fp16)[name = tensor<string, []>("op_6424_cast_fp16")];
            tensor<fp16, []> var_6425_to_fp16 = const()[name = tensor<string, []>("op_6425_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_6426_cast_fp16 = add(x = var_6424_cast_fp16, y = var_6425_to_fp16)[name = tensor<string, []>("op_6426_cast_fp16")];
            tensor<fp32, []> denom_95_epsilon_0 = const()[name = tensor<string, []>("denom_95_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_95_cast_fp16 = rsqrt(epsilon = denom_95_epsilon_0, x = var_6426_cast_fp16)[name = tensor<string, []>("denom_95_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_95_cast_fp16 = mul(x = zero_mean_95_cast_fp16, y = denom_95_cast_fp16)[name = tensor<string, []>("out_95_cast_fp16")];
            tensor<fp16, [1280]> input_471_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_471_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(356112448)))];
            tensor<fp16, [1280]> input_471_beta_0_to_fp16 = const()[name = tensor<string, []>("input_471_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(356115072)))];
            tensor<fp16, []> input_471_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_471_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_471_cast_fp16 = batch_norm(beta = input_471_beta_0_to_fp16, epsilon = input_471_epsilon_0_to_fp16, gamma = input_471_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_95_cast_fp16)[name = tensor<string, []>("input_471_cast_fp16")];
            tensor<int32, [2]> var_6440 = const()[name = tensor<string, []>("op_6440"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6442 = const()[name = tensor<string, []>("op_6442"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_317_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_317_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_317_pad_0 = const()[name = tensor<string, []>("pretrained_out_317_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_15_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(356117696))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(359394560))), name = tensor<string, []>("layers_15_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_15_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_15_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(359394688)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_317_cast_fp16 = conv(bias = layers_15_fc1_pretrained_bias_to_fp16, dilations = var_6442, groups = var_6109, pad = pretrained_out_317_pad_0, pad_type = pretrained_out_317_pad_type_0, strides = var_6440, weight = layers_15_fc1_pretrained_weight_to_fp16_palettized, x = input_471_cast_fp16)[name = tensor<string, []>("pretrained_out_317_cast_fp16")];
            tensor<int32, [2]> var_6446 = const()[name = tensor<string, []>("op_6446"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6448 = const()[name = tensor<string, []>("op_6448"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_473_pad_type_0 = const()[name = tensor<string, []>("input_473_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_473_pad_0 = const()[name = tensor<string, []>("input_473_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_15_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_15_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(359404992)))];
            tensor<fp16, [1, 16, 1, 1]> input_473_cast_fp16 = conv(dilations = var_6448, groups = var_6109, pad = input_473_pad_0, pad_type = input_473_pad_type_0, strides = var_6446, weight = layers_15_fc1_loraA_weight_to_fp16, x = input_471_cast_fp16)[name = tensor<string, []>("input_473_cast_fp16")];
            tensor<int32, [2]> var_6452 = const()[name = tensor<string, []>("op_6452"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6454 = const()[name = tensor<string, []>("op_6454"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_633_pad_type_0 = const()[name = tensor<string, []>("lora_out_633_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_633_pad_0 = const()[name = tensor<string, []>("lora_out_633_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_635_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_635_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(359446016)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_635_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_6454, groups = var_6109, pad = lora_out_633_pad_0, pad_type = lora_out_633_pad_type_0, strides = var_6452, weight = lora_out_635_weight_0_to_fp16, x = input_473_cast_fp16)[name = tensor<string, []>("lora_out_635_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_475_cast_fp16 = add(x = pretrained_out_317_cast_fp16, y = lora_out_635_cast_fp16)[name = tensor<string, []>("input_475_cast_fp16")];
            tensor<string, []> input_477_mode_0 = const()[name = tensor<string, []>("input_477_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_477_cast_fp16 = gelu(mode = input_477_mode_0, x = input_475_cast_fp16)[name = tensor<string, []>("input_477_cast_fp16")];
            tensor<int32, [2]> var_6466 = const()[name = tensor<string, []>("op_6466"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6468 = const()[name = tensor<string, []>("op_6468"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_319_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_319_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_319_pad_0 = const()[name = tensor<string, []>("pretrained_out_319_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_15_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(359609920))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(362886784))), name = tensor<string, []>("layers_15_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_15_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_15_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(362886912)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_319_cast_fp16 = conv(bias = layers_15_fc2_pretrained_bias_to_fp16, dilations = var_6468, groups = var_6109, pad = pretrained_out_319_pad_0, pad_type = pretrained_out_319_pad_type_0, strides = var_6466, weight = layers_15_fc2_pretrained_weight_to_fp16_palettized, x = input_477_cast_fp16)[name = tensor<string, []>("pretrained_out_319_cast_fp16")];
            tensor<int32, [2]> var_6472 = const()[name = tensor<string, []>("op_6472"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6474 = const()[name = tensor<string, []>("op_6474"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_479_pad_type_0 = const()[name = tensor<string, []>("input_479_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_479_pad_0 = const()[name = tensor<string, []>("input_479_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_15_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_15_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(362889536)))];
            tensor<fp16, [1, 16, 1, 1]> input_479_cast_fp16 = conv(dilations = var_6474, groups = var_6109, pad = input_479_pad_0, pad_type = input_479_pad_type_0, strides = var_6472, weight = layers_15_fc2_loraA_weight_to_fp16, x = input_477_cast_fp16)[name = tensor<string, []>("input_479_cast_fp16")];
            tensor<int32, [2]> var_6478 = const()[name = tensor<string, []>("op_6478"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6480 = const()[name = tensor<string, []>("op_6480"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_637_pad_type_0 = const()[name = tensor<string, []>("lora_out_637_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_637_pad_0 = const()[name = tensor<string, []>("lora_out_637_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_639_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_639_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(363053440)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_639_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_6480, groups = var_6109, pad = lora_out_637_pad_0, pad_type = lora_out_637_pad_type_0, strides = var_6478, weight = lora_out_639_weight_0_to_fp16, x = input_479_cast_fp16)[name = tensor<string, []>("lora_out_639_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_33_cast_fp16 = add(x = pretrained_out_319_cast_fp16, y = lora_out_639_cast_fp16)[name = tensor<string, []>("hidden_states_33_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_97_cast_fp16 = add(x = inputs_95_cast_fp16, y = hidden_states_33_cast_fp16)[name = tensor<string, []>("inputs_97_cast_fp16")];
            tensor<int32, []> var_6496 = const()[name = tensor<string, []>("op_6496"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_6503 = const()[name = tensor<string, []>("op_6503"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_6504 = const()[name = tensor<string, []>("op_6504"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_6516 = const()[name = tensor<string, []>("op_6516"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_97_cast_fp16 = reduce_mean(axes = var_6516, keep_dims = var_6504, x = inputs_97_cast_fp16)[name = tensor<string, []>("channels_mean_97_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_97_cast_fp16 = sub(x = inputs_97_cast_fp16, y = channels_mean_97_cast_fp16)[name = tensor<string, []>("zero_mean_97_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_97_cast_fp16 = mul(x = zero_mean_97_cast_fp16, y = zero_mean_97_cast_fp16)[name = tensor<string, []>("zero_mean_sq_97_cast_fp16")];
            tensor<int32, [1]> var_6520 = const()[name = tensor<string, []>("op_6520"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_6521_cast_fp16 = reduce_mean(axes = var_6520, keep_dims = var_6504, x = zero_mean_sq_97_cast_fp16)[name = tensor<string, []>("op_6521_cast_fp16")];
            tensor<fp16, []> var_6522_to_fp16 = const()[name = tensor<string, []>("op_6522_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_6523_cast_fp16 = add(x = var_6521_cast_fp16, y = var_6522_to_fp16)[name = tensor<string, []>("op_6523_cast_fp16")];
            tensor<fp32, []> denom_97_epsilon_0 = const()[name = tensor<string, []>("denom_97_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_97_cast_fp16 = rsqrt(epsilon = denom_97_epsilon_0, x = var_6523_cast_fp16)[name = tensor<string, []>("denom_97_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_97_cast_fp16 = mul(x = zero_mean_97_cast_fp16, y = denom_97_cast_fp16)[name = tensor<string, []>("out_97_cast_fp16")];
            tensor<fp16, [1280]> obj_225_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_225_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(363094464)))];
            tensor<fp16, [1280]> obj_225_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_225_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(363097088)))];
            tensor<fp16, []> obj_225_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_225_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_225_cast_fp16 = batch_norm(beta = obj_225_beta_0_to_fp16, epsilon = obj_225_epsilon_0_to_fp16, gamma = obj_225_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_97_cast_fp16)[name = tensor<string, []>("obj_225_cast_fp16")];
            tensor<int32, [2]> var_6541 = const()[name = tensor<string, []>("op_6541"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6543 = const()[name = tensor<string, []>("op_6543"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_321_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_321_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_321_pad_0 = const()[name = tensor<string, []>("pretrained_out_321_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_16_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(363099712))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(363918976))), name = tensor<string, []>("layers_16_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_16_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_16_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(363919104)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_321_cast_fp16 = conv(bias = layers_16_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_6543, groups = var_6503, pad = pretrained_out_321_pad_0, pad_type = pretrained_out_321_pad_type_0, strides = var_6541, weight = layers_16_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_225_cast_fp16)[name = tensor<string, []>("pretrained_out_321_cast_fp16")];
            tensor<int32, [2]> var_6547 = const()[name = tensor<string, []>("op_6547"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6549 = const()[name = tensor<string, []>("op_6549"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_481_pad_type_0 = const()[name = tensor<string, []>("input_481_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_481_pad_0 = const()[name = tensor<string, []>("input_481_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_16_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_16_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(363921728)))];
            tensor<fp16, [1, 16, 1, 1]> input_481_cast_fp16 = conv(dilations = var_6549, groups = var_6503, pad = input_481_pad_0, pad_type = input_481_pad_type_0, strides = var_6547, weight = layers_16_self_attn_q_proj_loraA_weight_to_fp16, x = obj_225_cast_fp16)[name = tensor<string, []>("input_481_cast_fp16")];
            tensor<int32, [2]> var_6553 = const()[name = tensor<string, []>("op_6553"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6555 = const()[name = tensor<string, []>("op_6555"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_641_pad_type_0 = const()[name = tensor<string, []>("lora_out_641_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_641_pad_0 = const()[name = tensor<string, []>("lora_out_641_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_643_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_643_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(363962752)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_643_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_6555, groups = var_6503, pad = lora_out_641_pad_0, pad_type = lora_out_641_pad_type_0, strides = var_6553, weight = lora_out_643_weight_0_to_fp16, x = input_481_cast_fp16)[name = tensor<string, []>("lora_out_643_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_65_cast_fp16 = add(x = pretrained_out_321_cast_fp16, y = lora_out_643_cast_fp16)[name = tensor<string, []>("query_65_cast_fp16")];
            tensor<int32, [2]> var_6565 = const()[name = tensor<string, []>("op_6565"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6567 = const()[name = tensor<string, []>("op_6567"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_323_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_323_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_323_pad_0 = const()[name = tensor<string, []>("pretrained_out_323_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_16_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(364003776))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(364823040))), name = tensor<string, []>("layers_16_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_323_cast_fp16 = conv(dilations = var_6567, groups = var_6503, pad = pretrained_out_323_pad_0, pad_type = pretrained_out_323_pad_type_0, strides = var_6565, weight = layers_16_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_225_cast_fp16)[name = tensor<string, []>("pretrained_out_323_cast_fp16")];
            tensor<int32, [2]> var_6571 = const()[name = tensor<string, []>("op_6571"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6573 = const()[name = tensor<string, []>("op_6573"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_483_pad_type_0 = const()[name = tensor<string, []>("input_483_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_483_pad_0 = const()[name = tensor<string, []>("input_483_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_16_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_16_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(364823168)))];
            tensor<fp16, [1, 16, 1, 1]> input_483_cast_fp16 = conv(dilations = var_6573, groups = var_6503, pad = input_483_pad_0, pad_type = input_483_pad_type_0, strides = var_6571, weight = layers_16_self_attn_k_proj_loraA_weight_to_fp16, x = obj_225_cast_fp16)[name = tensor<string, []>("input_483_cast_fp16")];
            tensor<int32, [2]> var_6577 = const()[name = tensor<string, []>("op_6577"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6579 = const()[name = tensor<string, []>("op_6579"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_645_pad_type_0 = const()[name = tensor<string, []>("lora_out_645_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_645_pad_0 = const()[name = tensor<string, []>("lora_out_645_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_647_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_647_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(364864192)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_647_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_6579, groups = var_6503, pad = lora_out_645_pad_0, pad_type = lora_out_645_pad_type_0, strides = var_6577, weight = lora_out_647_weight_0_to_fp16, x = input_483_cast_fp16)[name = tensor<string, []>("lora_out_647_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_33_cast_fp16 = add(x = pretrained_out_323_cast_fp16, y = lora_out_647_cast_fp16)[name = tensor<string, []>("current_key_33_cast_fp16")];
            tensor<int32, [2]> var_6590 = const()[name = tensor<string, []>("op_6590"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6592 = const()[name = tensor<string, []>("op_6592"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_325_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_325_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_325_pad_0 = const()[name = tensor<string, []>("pretrained_out_325_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_16_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(364905216))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(365724480))), name = tensor<string, []>("layers_16_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_16_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_16_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(365724608)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_325_cast_fp16 = conv(bias = layers_16_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_6592, groups = var_6503, pad = pretrained_out_325_pad_0, pad_type = pretrained_out_325_pad_type_0, strides = var_6590, weight = layers_16_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_225_cast_fp16)[name = tensor<string, []>("pretrained_out_325_cast_fp16")];
            tensor<int32, [2]> var_6596 = const()[name = tensor<string, []>("op_6596"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6598 = const()[name = tensor<string, []>("op_6598"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_485_pad_type_0 = const()[name = tensor<string, []>("input_485_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_485_pad_0 = const()[name = tensor<string, []>("input_485_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_16_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_16_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(365727232)))];
            tensor<fp16, [1, 16, 1, 1]> input_485_cast_fp16 = conv(dilations = var_6598, groups = var_6503, pad = input_485_pad_0, pad_type = input_485_pad_type_0, strides = var_6596, weight = layers_16_self_attn_v_proj_loraA_weight_to_fp16, x = obj_225_cast_fp16)[name = tensor<string, []>("input_485_cast_fp16")];
            tensor<int32, [2]> var_6602 = const()[name = tensor<string, []>("op_6602"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6604 = const()[name = tensor<string, []>("op_6604"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_649_pad_type_0 = const()[name = tensor<string, []>("lora_out_649_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_649_pad_0 = const()[name = tensor<string, []>("lora_out_649_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_651_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_651_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(365768256)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_651_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_6604, groups = var_6503, pad = lora_out_649_pad_0, pad_type = lora_out_649_pad_type_0, strides = var_6602, weight = lora_out_651_weight_0_to_fp16, x = input_485_cast_fp16)[name = tensor<string, []>("lora_out_651_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_33_cast_fp16 = add(x = pretrained_out_325_cast_fp16, y = lora_out_651_cast_fp16)[name = tensor<string, []>("current_value_33_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_6614_cast_fp16 = mul(x = current_key_33_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_6614_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_6616_cast_fp16 = mul(x = var_103_cast_fp16_16, y = var_295_cast_fp16)[name = tensor<string, []>("op_6616_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_65_cast_fp16 = add(x = var_6614_cast_fp16, y = var_6616_cast_fp16)[name = tensor<string, []>("key_65_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_6618_cast_fp16 = mul(x = current_value_33_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_6618_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_6620_cast_fp16 = mul(x = var_138_cast_fp16_16, y = var_295_cast_fp16)[name = tensor<string, []>("op_6620_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_65_cast_fp16 = add(x = var_6618_cast_fp16, y = var_6620_cast_fp16)[name = tensor<string, []>("value_65_cast_fp16")];
            tensor<int32, [4]> var_6623 = const()[name = tensor<string, []>("op_6623"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_6624_cast_fp16 = reshape(shape = var_6623, x = query_65_cast_fp16)[name = tensor<string, []>("op_6624_cast_fp16")];
            tensor<fp16, []> var_6625_to_fp16 = const()[name = tensor<string, []>("op_6625_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_6626_cast_fp16 = mul(x = var_6624_cast_fp16, y = var_6625_to_fp16)[name = tensor<string, []>("op_6626_cast_fp16")];
            tensor<int32, [4]> var_6627 = const()[name = tensor<string, []>("op_6627"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_6628_cast_fp16 = reshape(shape = var_6627, x = key_65_cast_fp16)[name = tensor<string, []>("op_6628_cast_fp16")];
            tensor<bool, []> mh_w_97_transpose_x_0 = const()[name = tensor<string, []>("mh_w_97_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_97_transpose_y_0 = const()[name = tensor<string, []>("mh_w_97_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_97_cast_fp16 = matmul(transpose_x = mh_w_97_transpose_x_0, transpose_y = mh_w_97_transpose_y_0, x = var_6626_cast_fp16, y = var_6628_cast_fp16)[name = tensor<string, []>("mh_w_97_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_99_cast_fp16 = add(x = mh_w_97_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_99_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_6636_cast_fp16 = softmax(axis = var_6496, x = mh_w_99_cast_fp16)[name = tensor<string, []>("op_6636_cast_fp16")];
            tensor<int32, [4]> var_6637 = const()[name = tensor<string, []>("op_6637"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_6638_cast_fp16 = reshape(shape = var_6637, x = value_65_cast_fp16)[name = tensor<string, []>("op_6638_cast_fp16")];
            tensor<bool, []> attn_65_transpose_x_0 = const()[name = tensor<string, []>("attn_65_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_65_transpose_y_0 = const()[name = tensor<string, []>("attn_65_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_65_cast_fp16 = matmul(transpose_x = attn_65_transpose_x_0, transpose_y = attn_65_transpose_y_0, x = var_6638_cast_fp16, y = var_6636_cast_fp16)[name = tensor<string, []>("attn_65_cast_fp16")];
            tensor<int32, [4]> var_6641 = const()[name = tensor<string, []>("op_6641"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_487_cast_fp16 = reshape(shape = var_6641, x = attn_65_cast_fp16)[name = tensor<string, []>("input_487_cast_fp16")];
            tensor<int32, [2]> var_6648 = const()[name = tensor<string, []>("op_6648"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6650 = const()[name = tensor<string, []>("op_6650"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_327_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_327_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_327_pad_0 = const()[name = tensor<string, []>("pretrained_out_327_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_16_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(365809280))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(366628544))), name = tensor<string, []>("layers_16_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_16_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_16_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(366628672)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_327_cast_fp16 = conv(bias = layers_16_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_6650, groups = var_6503, pad = pretrained_out_327_pad_0, pad_type = pretrained_out_327_pad_type_0, strides = var_6648, weight = layers_16_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_487_cast_fp16)[name = tensor<string, []>("pretrained_out_327_cast_fp16")];
            tensor<int32, [2]> var_6654 = const()[name = tensor<string, []>("op_6654"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6656 = const()[name = tensor<string, []>("op_6656"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_489_pad_type_0 = const()[name = tensor<string, []>("input_489_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_489_pad_0 = const()[name = tensor<string, []>("input_489_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_16_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_16_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(366631296)))];
            tensor<fp16, [1, 16, 1, 1]> input_489_cast_fp16 = conv(dilations = var_6656, groups = var_6503, pad = input_489_pad_0, pad_type = input_489_pad_type_0, strides = var_6654, weight = layers_16_self_attn_o_proj_loraA_weight_to_fp16, x = input_487_cast_fp16)[name = tensor<string, []>("input_489_cast_fp16")];
            tensor<int32, [2]> var_6660 = const()[name = tensor<string, []>("op_6660"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6662 = const()[name = tensor<string, []>("op_6662"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_653_pad_type_0 = const()[name = tensor<string, []>("lora_out_653_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_653_pad_0 = const()[name = tensor<string, []>("lora_out_653_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_655_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_655_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(366672320)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_655_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_6662, groups = var_6503, pad = lora_out_653_pad_0, pad_type = lora_out_653_pad_type_0, strides = var_6660, weight = lora_out_655_weight_0_to_fp16, x = input_489_cast_fp16)[name = tensor<string, []>("lora_out_655_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_231_cast_fp16 = add(x = pretrained_out_327_cast_fp16, y = lora_out_655_cast_fp16)[name = tensor<string, []>("obj_231_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_99_cast_fp16 = add(x = inputs_97_cast_fp16, y = obj_231_cast_fp16)[name = tensor<string, []>("inputs_99_cast_fp16")];
            tensor<int32, [1]> var_6675 = const()[name = tensor<string, []>("op_6675"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_99_cast_fp16 = reduce_mean(axes = var_6675, keep_dims = var_6504, x = inputs_99_cast_fp16)[name = tensor<string, []>("channels_mean_99_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_99_cast_fp16 = sub(x = inputs_99_cast_fp16, y = channels_mean_99_cast_fp16)[name = tensor<string, []>("zero_mean_99_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_99_cast_fp16 = mul(x = zero_mean_99_cast_fp16, y = zero_mean_99_cast_fp16)[name = tensor<string, []>("zero_mean_sq_99_cast_fp16")];
            tensor<int32, [1]> var_6679 = const()[name = tensor<string, []>("op_6679"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_6680_cast_fp16 = reduce_mean(axes = var_6679, keep_dims = var_6504, x = zero_mean_sq_99_cast_fp16)[name = tensor<string, []>("op_6680_cast_fp16")];
            tensor<fp16, []> var_6681_to_fp16 = const()[name = tensor<string, []>("op_6681_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_6682_cast_fp16 = add(x = var_6680_cast_fp16, y = var_6681_to_fp16)[name = tensor<string, []>("op_6682_cast_fp16")];
            tensor<fp32, []> denom_99_epsilon_0 = const()[name = tensor<string, []>("denom_99_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_99_cast_fp16 = rsqrt(epsilon = denom_99_epsilon_0, x = var_6682_cast_fp16)[name = tensor<string, []>("denom_99_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_99_cast_fp16 = mul(x = zero_mean_99_cast_fp16, y = denom_99_cast_fp16)[name = tensor<string, []>("out_99_cast_fp16")];
            tensor<fp16, [1280]> obj_233_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_233_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(366713344)))];
            tensor<fp16, [1280]> obj_233_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_233_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(366715968)))];
            tensor<fp16, []> obj_233_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_233_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_233_cast_fp16 = batch_norm(beta = obj_233_beta_0_to_fp16, epsilon = obj_233_epsilon_0_to_fp16, gamma = obj_233_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_99_cast_fp16)[name = tensor<string, []>("obj_233_cast_fp16")];
            tensor<int32, [2]> var_6700 = const()[name = tensor<string, []>("op_6700"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6702 = const()[name = tensor<string, []>("op_6702"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_329_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_329_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_329_pad_0 = const()[name = tensor<string, []>("pretrained_out_329_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_16_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(366718592))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(367537856))), name = tensor<string, []>("layers_16_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_16_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_16_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(367537984)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_329_cast_fp16 = conv(bias = layers_16_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_6702, groups = var_6503, pad = pretrained_out_329_pad_0, pad_type = pretrained_out_329_pad_type_0, strides = var_6700, weight = layers_16_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_233_cast_fp16)[name = tensor<string, []>("pretrained_out_329_cast_fp16")];
            tensor<int32, [2]> var_6706 = const()[name = tensor<string, []>("op_6706"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6708 = const()[name = tensor<string, []>("op_6708"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_491_pad_type_0 = const()[name = tensor<string, []>("input_491_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_491_pad_0 = const()[name = tensor<string, []>("input_491_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_16_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_16_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(367540608)))];
            tensor<fp16, [1, 16, 1, 1]> input_491_cast_fp16 = conv(dilations = var_6708, groups = var_6503, pad = input_491_pad_0, pad_type = input_491_pad_type_0, strides = var_6706, weight = layers_16_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_233_cast_fp16)[name = tensor<string, []>("input_491_cast_fp16")];
            tensor<int32, [2]> var_6712 = const()[name = tensor<string, []>("op_6712"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6714 = const()[name = tensor<string, []>("op_6714"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_657_pad_type_0 = const()[name = tensor<string, []>("lora_out_657_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_657_pad_0 = const()[name = tensor<string, []>("lora_out_657_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_659_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_659_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(367581632)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_659_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_6714, groups = var_6503, pad = lora_out_657_pad_0, pad_type = lora_out_657_pad_type_0, strides = var_6712, weight = lora_out_659_weight_0_to_fp16, x = input_491_cast_fp16)[name = tensor<string, []>("lora_out_659_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_67_cast_fp16 = add(x = pretrained_out_329_cast_fp16, y = lora_out_659_cast_fp16)[name = tensor<string, []>("query_67_cast_fp16")];
            tensor<int32, [2]> var_6724 = const()[name = tensor<string, []>("op_6724"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6726 = const()[name = tensor<string, []>("op_6726"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_331_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_331_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_331_pad_0 = const()[name = tensor<string, []>("pretrained_out_331_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_16_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(367622656))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(368441920))), name = tensor<string, []>("layers_16_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_331_cast_fp16 = conv(dilations = var_6726, groups = var_6503, pad = pretrained_out_331_pad_0, pad_type = pretrained_out_331_pad_type_0, strides = var_6724, weight = layers_16_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_331_cast_fp16")];
            tensor<int32, [2]> var_6730 = const()[name = tensor<string, []>("op_6730"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6732 = const()[name = tensor<string, []>("op_6732"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_493_pad_type_0 = const()[name = tensor<string, []>("input_493_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_493_pad_0 = const()[name = tensor<string, []>("input_493_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_16_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_16_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(368442048)))];
            tensor<fp16, [1, 16, 1, 1500]> input_493_cast_fp16 = conv(dilations = var_6732, groups = var_6503, pad = input_493_pad_0, pad_type = input_493_pad_type_0, strides = var_6730, weight = layers_16_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_493_cast_fp16")];
            tensor<int32, [2]> var_6736 = const()[name = tensor<string, []>("op_6736"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6738 = const()[name = tensor<string, []>("op_6738"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_661_pad_type_0 = const()[name = tensor<string, []>("lora_out_661_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_661_pad_0 = const()[name = tensor<string, []>("lora_out_661_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_663_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_663_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(368483072)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_663_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_6738, groups = var_6503, pad = lora_out_661_pad_0, pad_type = lora_out_661_pad_type_0, strides = var_6736, weight = lora_out_663_weight_0_to_fp16, x = input_493_cast_fp16)[name = tensor<string, []>("lora_out_663_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_67_cast_fp16 = add(x = pretrained_out_331_cast_fp16, y = lora_out_663_cast_fp16)[name = tensor<string, []>("key_67_cast_fp16")];
            tensor<int32, [2]> var_6749 = const()[name = tensor<string, []>("op_6749"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6751 = const()[name = tensor<string, []>("op_6751"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_333_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_333_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_333_pad_0 = const()[name = tensor<string, []>("pretrained_out_333_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_16_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(368524096))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(369343360))), name = tensor<string, []>("layers_16_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_16_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_16_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(369343488)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_333_cast_fp16 = conv(bias = layers_16_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_6751, groups = var_6503, pad = pretrained_out_333_pad_0, pad_type = pretrained_out_333_pad_type_0, strides = var_6749, weight = layers_16_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_333_cast_fp16")];
            tensor<int32, [2]> var_6755 = const()[name = tensor<string, []>("op_6755"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6757 = const()[name = tensor<string, []>("op_6757"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_495_pad_type_0 = const()[name = tensor<string, []>("input_495_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_495_pad_0 = const()[name = tensor<string, []>("input_495_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_16_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_16_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(369346112)))];
            tensor<fp16, [1, 16, 1, 1500]> input_495_cast_fp16 = conv(dilations = var_6757, groups = var_6503, pad = input_495_pad_0, pad_type = input_495_pad_type_0, strides = var_6755, weight = layers_16_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_495_cast_fp16")];
            tensor<int32, [2]> var_6761 = const()[name = tensor<string, []>("op_6761"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6763 = const()[name = tensor<string, []>("op_6763"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_665_pad_type_0 = const()[name = tensor<string, []>("lora_out_665_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_665_pad_0 = const()[name = tensor<string, []>("lora_out_665_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_667_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_667_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(369387136)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_667_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_6763, groups = var_6503, pad = lora_out_665_pad_0, pad_type = lora_out_665_pad_type_0, strides = var_6761, weight = lora_out_667_weight_0_to_fp16, x = input_495_cast_fp16)[name = tensor<string, []>("lora_out_667_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_67_cast_fp16 = add(x = pretrained_out_333_cast_fp16, y = lora_out_667_cast_fp16)[name = tensor<string, []>("value_67_cast_fp16")];
            tensor<int32, [4]> var_6770 = const()[name = tensor<string, []>("op_6770"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_6771_cast_fp16 = reshape(shape = var_6770, x = query_67_cast_fp16)[name = tensor<string, []>("op_6771_cast_fp16")];
            tensor<fp16, []> var_6772_to_fp16 = const()[name = tensor<string, []>("op_6772_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_6773_cast_fp16 = mul(x = var_6771_cast_fp16, y = var_6772_to_fp16)[name = tensor<string, []>("op_6773_cast_fp16")];
            tensor<int32, [4]> var_6774 = const()[name = tensor<string, []>("op_6774"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_6775_cast_fp16 = reshape(shape = var_6774, x = key_67_cast_fp16)[name = tensor<string, []>("op_6775_cast_fp16")];
            tensor<bool, []> mh_w_101_transpose_x_0 = const()[name = tensor<string, []>("mh_w_101_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_101_transpose_y_0 = const()[name = tensor<string, []>("mh_w_101_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_101_cast_fp16 = matmul(transpose_x = mh_w_101_transpose_x_0, transpose_y = mh_w_101_transpose_y_0, x = var_6773_cast_fp16, y = var_6775_cast_fp16)[name = tensor<string, []>("mh_w_101_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_237_cast_fp16 = softmax(axis = var_6496, x = mh_w_101_cast_fp16)[name = tensor<string, []>("obj_237_cast_fp16")];
            tensor<int32, [4]> var_6779 = const()[name = tensor<string, []>("op_6779"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_6780_cast_fp16 = reshape(shape = var_6779, x = value_67_cast_fp16)[name = tensor<string, []>("op_6780_cast_fp16")];
            tensor<bool, []> attn_67_transpose_x_0 = const()[name = tensor<string, []>("attn_67_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_67_transpose_y_0 = const()[name = tensor<string, []>("attn_67_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_67_cast_fp16 = matmul(transpose_x = attn_67_transpose_x_0, transpose_y = attn_67_transpose_y_0, x = var_6780_cast_fp16, y = obj_237_cast_fp16)[name = tensor<string, []>("attn_67_cast_fp16")];
            tensor<int32, [4]> var_6783 = const()[name = tensor<string, []>("op_6783"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_497_cast_fp16 = reshape(shape = var_6783, x = attn_67_cast_fp16)[name = tensor<string, []>("input_497_cast_fp16")];
            tensor<int32, [2]> var_6790 = const()[name = tensor<string, []>("op_6790"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6792 = const()[name = tensor<string, []>("op_6792"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_335_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_335_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_335_pad_0 = const()[name = tensor<string, []>("pretrained_out_335_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_16_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(369428160))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(370247424))), name = tensor<string, []>("layers_16_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_16_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_16_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(370247552)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_335_cast_fp16 = conv(bias = layers_16_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_6792, groups = var_6503, pad = pretrained_out_335_pad_0, pad_type = pretrained_out_335_pad_type_0, strides = var_6790, weight = layers_16_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_497_cast_fp16)[name = tensor<string, []>("pretrained_out_335_cast_fp16")];
            tensor<int32, [2]> var_6796 = const()[name = tensor<string, []>("op_6796"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6798 = const()[name = tensor<string, []>("op_6798"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_499_pad_type_0 = const()[name = tensor<string, []>("input_499_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_499_pad_0 = const()[name = tensor<string, []>("input_499_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_16_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_16_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(370250176)))];
            tensor<fp16, [1, 16, 1, 1]> input_499_cast_fp16 = conv(dilations = var_6798, groups = var_6503, pad = input_499_pad_0, pad_type = input_499_pad_type_0, strides = var_6796, weight = layers_16_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_497_cast_fp16)[name = tensor<string, []>("input_499_cast_fp16")];
            tensor<int32, [2]> var_6802 = const()[name = tensor<string, []>("op_6802"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6804 = const()[name = tensor<string, []>("op_6804"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_669_pad_type_0 = const()[name = tensor<string, []>("lora_out_669_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_669_pad_0 = const()[name = tensor<string, []>("lora_out_669_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_671_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_671_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(370291200)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_671_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_6804, groups = var_6503, pad = lora_out_669_pad_0, pad_type = lora_out_669_pad_type_0, strides = var_6802, weight = lora_out_671_weight_0_to_fp16, x = input_499_cast_fp16)[name = tensor<string, []>("lora_out_671_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_235_cast_fp16 = add(x = pretrained_out_335_cast_fp16, y = lora_out_671_cast_fp16)[name = tensor<string, []>("obj_235_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_101_cast_fp16 = add(x = inputs_99_cast_fp16, y = obj_235_cast_fp16)[name = tensor<string, []>("inputs_101_cast_fp16")];
            tensor<int32, [1]> var_6816 = const()[name = tensor<string, []>("op_6816"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_101_cast_fp16 = reduce_mean(axes = var_6816, keep_dims = var_6504, x = inputs_101_cast_fp16)[name = tensor<string, []>("channels_mean_101_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_101_cast_fp16 = sub(x = inputs_101_cast_fp16, y = channels_mean_101_cast_fp16)[name = tensor<string, []>("zero_mean_101_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_101_cast_fp16 = mul(x = zero_mean_101_cast_fp16, y = zero_mean_101_cast_fp16)[name = tensor<string, []>("zero_mean_sq_101_cast_fp16")];
            tensor<int32, [1]> var_6820 = const()[name = tensor<string, []>("op_6820"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_6821_cast_fp16 = reduce_mean(axes = var_6820, keep_dims = var_6504, x = zero_mean_sq_101_cast_fp16)[name = tensor<string, []>("op_6821_cast_fp16")];
            tensor<fp16, []> var_6822_to_fp16 = const()[name = tensor<string, []>("op_6822_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_6823_cast_fp16 = add(x = var_6821_cast_fp16, y = var_6822_to_fp16)[name = tensor<string, []>("op_6823_cast_fp16")];
            tensor<fp32, []> denom_101_epsilon_0 = const()[name = tensor<string, []>("denom_101_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_101_cast_fp16 = rsqrt(epsilon = denom_101_epsilon_0, x = var_6823_cast_fp16)[name = tensor<string, []>("denom_101_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_101_cast_fp16 = mul(x = zero_mean_101_cast_fp16, y = denom_101_cast_fp16)[name = tensor<string, []>("out_101_cast_fp16")];
            tensor<fp16, [1280]> input_501_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_501_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(370332224)))];
            tensor<fp16, [1280]> input_501_beta_0_to_fp16 = const()[name = tensor<string, []>("input_501_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(370334848)))];
            tensor<fp16, []> input_501_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_501_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_501_cast_fp16 = batch_norm(beta = input_501_beta_0_to_fp16, epsilon = input_501_epsilon_0_to_fp16, gamma = input_501_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_101_cast_fp16)[name = tensor<string, []>("input_501_cast_fp16")];
            tensor<int32, [2]> var_6837 = const()[name = tensor<string, []>("op_6837"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6839 = const()[name = tensor<string, []>("op_6839"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_337_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_337_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_337_pad_0 = const()[name = tensor<string, []>("pretrained_out_337_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_16_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(370337472))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(373614336))), name = tensor<string, []>("layers_16_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_16_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_16_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(373614464)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_337_cast_fp16 = conv(bias = layers_16_fc1_pretrained_bias_to_fp16, dilations = var_6839, groups = var_6503, pad = pretrained_out_337_pad_0, pad_type = pretrained_out_337_pad_type_0, strides = var_6837, weight = layers_16_fc1_pretrained_weight_to_fp16_palettized, x = input_501_cast_fp16)[name = tensor<string, []>("pretrained_out_337_cast_fp16")];
            tensor<int32, [2]> var_6843 = const()[name = tensor<string, []>("op_6843"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6845 = const()[name = tensor<string, []>("op_6845"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_503_pad_type_0 = const()[name = tensor<string, []>("input_503_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_503_pad_0 = const()[name = tensor<string, []>("input_503_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_16_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_16_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(373624768)))];
            tensor<fp16, [1, 16, 1, 1]> input_503_cast_fp16 = conv(dilations = var_6845, groups = var_6503, pad = input_503_pad_0, pad_type = input_503_pad_type_0, strides = var_6843, weight = layers_16_fc1_loraA_weight_to_fp16, x = input_501_cast_fp16)[name = tensor<string, []>("input_503_cast_fp16")];
            tensor<int32, [2]> var_6849 = const()[name = tensor<string, []>("op_6849"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6851 = const()[name = tensor<string, []>("op_6851"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_673_pad_type_0 = const()[name = tensor<string, []>("lora_out_673_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_673_pad_0 = const()[name = tensor<string, []>("lora_out_673_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_675_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_675_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(373665792)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_675_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_6851, groups = var_6503, pad = lora_out_673_pad_0, pad_type = lora_out_673_pad_type_0, strides = var_6849, weight = lora_out_675_weight_0_to_fp16, x = input_503_cast_fp16)[name = tensor<string, []>("lora_out_675_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_505_cast_fp16 = add(x = pretrained_out_337_cast_fp16, y = lora_out_675_cast_fp16)[name = tensor<string, []>("input_505_cast_fp16")];
            tensor<string, []> input_507_mode_0 = const()[name = tensor<string, []>("input_507_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_507_cast_fp16 = gelu(mode = input_507_mode_0, x = input_505_cast_fp16)[name = tensor<string, []>("input_507_cast_fp16")];
            tensor<int32, [2]> var_6863 = const()[name = tensor<string, []>("op_6863"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6865 = const()[name = tensor<string, []>("op_6865"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_339_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_339_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_339_pad_0 = const()[name = tensor<string, []>("pretrained_out_339_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_16_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(373829696))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(377106560))), name = tensor<string, []>("layers_16_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_16_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_16_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(377106688)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_339_cast_fp16 = conv(bias = layers_16_fc2_pretrained_bias_to_fp16, dilations = var_6865, groups = var_6503, pad = pretrained_out_339_pad_0, pad_type = pretrained_out_339_pad_type_0, strides = var_6863, weight = layers_16_fc2_pretrained_weight_to_fp16_palettized, x = input_507_cast_fp16)[name = tensor<string, []>("pretrained_out_339_cast_fp16")];
            tensor<int32, [2]> var_6869 = const()[name = tensor<string, []>("op_6869"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6871 = const()[name = tensor<string, []>("op_6871"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_509_pad_type_0 = const()[name = tensor<string, []>("input_509_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_509_pad_0 = const()[name = tensor<string, []>("input_509_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_16_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_16_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(377109312)))];
            tensor<fp16, [1, 16, 1, 1]> input_509_cast_fp16 = conv(dilations = var_6871, groups = var_6503, pad = input_509_pad_0, pad_type = input_509_pad_type_0, strides = var_6869, weight = layers_16_fc2_loraA_weight_to_fp16, x = input_507_cast_fp16)[name = tensor<string, []>("input_509_cast_fp16")];
            tensor<int32, [2]> var_6875 = const()[name = tensor<string, []>("op_6875"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6877 = const()[name = tensor<string, []>("op_6877"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_677_pad_type_0 = const()[name = tensor<string, []>("lora_out_677_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_677_pad_0 = const()[name = tensor<string, []>("lora_out_677_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_679_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_679_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(377273216)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_679_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_6877, groups = var_6503, pad = lora_out_677_pad_0, pad_type = lora_out_677_pad_type_0, strides = var_6875, weight = lora_out_679_weight_0_to_fp16, x = input_509_cast_fp16)[name = tensor<string, []>("lora_out_679_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_35_cast_fp16 = add(x = pretrained_out_339_cast_fp16, y = lora_out_679_cast_fp16)[name = tensor<string, []>("hidden_states_35_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_103_cast_fp16 = add(x = inputs_101_cast_fp16, y = hidden_states_35_cast_fp16)[name = tensor<string, []>("inputs_103_cast_fp16")];
            tensor<int32, []> var_6894 = const()[name = tensor<string, []>("op_6894"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_6901 = const()[name = tensor<string, []>("op_6901"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_6902 = const()[name = tensor<string, []>("op_6902"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_6914 = const()[name = tensor<string, []>("op_6914"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_103_cast_fp16 = reduce_mean(axes = var_6914, keep_dims = var_6902, x = inputs_103_cast_fp16)[name = tensor<string, []>("channels_mean_103_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_103_cast_fp16 = sub(x = inputs_103_cast_fp16, y = channels_mean_103_cast_fp16)[name = tensor<string, []>("zero_mean_103_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_103_cast_fp16 = mul(x = zero_mean_103_cast_fp16, y = zero_mean_103_cast_fp16)[name = tensor<string, []>("zero_mean_sq_103_cast_fp16")];
            tensor<int32, [1]> var_6918 = const()[name = tensor<string, []>("op_6918"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_6919_cast_fp16 = reduce_mean(axes = var_6918, keep_dims = var_6902, x = zero_mean_sq_103_cast_fp16)[name = tensor<string, []>("op_6919_cast_fp16")];
            tensor<fp16, []> var_6920_to_fp16 = const()[name = tensor<string, []>("op_6920_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_6921_cast_fp16 = add(x = var_6919_cast_fp16, y = var_6920_to_fp16)[name = tensor<string, []>("op_6921_cast_fp16")];
            tensor<fp32, []> denom_103_epsilon_0 = const()[name = tensor<string, []>("denom_103_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_103_cast_fp16 = rsqrt(epsilon = denom_103_epsilon_0, x = var_6921_cast_fp16)[name = tensor<string, []>("denom_103_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_103_cast_fp16 = mul(x = zero_mean_103_cast_fp16, y = denom_103_cast_fp16)[name = tensor<string, []>("out_103_cast_fp16")];
            tensor<fp16, [1280]> obj_239_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_239_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(377314240)))];
            tensor<fp16, [1280]> obj_239_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_239_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(377316864)))];
            tensor<fp16, []> obj_239_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_239_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_239_cast_fp16 = batch_norm(beta = obj_239_beta_0_to_fp16, epsilon = obj_239_epsilon_0_to_fp16, gamma = obj_239_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_103_cast_fp16)[name = tensor<string, []>("obj_239_cast_fp16")];
            tensor<int32, [2]> var_6939 = const()[name = tensor<string, []>("op_6939"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6941 = const()[name = tensor<string, []>("op_6941"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_341_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_341_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_341_pad_0 = const()[name = tensor<string, []>("pretrained_out_341_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_17_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(377319488))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(378138752))), name = tensor<string, []>("layers_17_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_17_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_17_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(378138880)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_341_cast_fp16 = conv(bias = layers_17_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_6941, groups = var_6901, pad = pretrained_out_341_pad_0, pad_type = pretrained_out_341_pad_type_0, strides = var_6939, weight = layers_17_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_239_cast_fp16)[name = tensor<string, []>("pretrained_out_341_cast_fp16")];
            tensor<int32, [2]> var_6945 = const()[name = tensor<string, []>("op_6945"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6947 = const()[name = tensor<string, []>("op_6947"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_511_pad_type_0 = const()[name = tensor<string, []>("input_511_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_511_pad_0 = const()[name = tensor<string, []>("input_511_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_17_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_17_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(378141504)))];
            tensor<fp16, [1, 16, 1, 1]> input_511_cast_fp16 = conv(dilations = var_6947, groups = var_6901, pad = input_511_pad_0, pad_type = input_511_pad_type_0, strides = var_6945, weight = layers_17_self_attn_q_proj_loraA_weight_to_fp16, x = obj_239_cast_fp16)[name = tensor<string, []>("input_511_cast_fp16")];
            tensor<int32, [2]> var_6951 = const()[name = tensor<string, []>("op_6951"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6953 = const()[name = tensor<string, []>("op_6953"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_681_pad_type_0 = const()[name = tensor<string, []>("lora_out_681_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_681_pad_0 = const()[name = tensor<string, []>("lora_out_681_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_683_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_683_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(378182528)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_683_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_6953, groups = var_6901, pad = lora_out_681_pad_0, pad_type = lora_out_681_pad_type_0, strides = var_6951, weight = lora_out_683_weight_0_to_fp16, x = input_511_cast_fp16)[name = tensor<string, []>("lora_out_683_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_69_cast_fp16 = add(x = pretrained_out_341_cast_fp16, y = lora_out_683_cast_fp16)[name = tensor<string, []>("query_69_cast_fp16")];
            tensor<int32, [2]> var_6963 = const()[name = tensor<string, []>("op_6963"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6965 = const()[name = tensor<string, []>("op_6965"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_343_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_343_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_343_pad_0 = const()[name = tensor<string, []>("pretrained_out_343_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_17_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(378223552))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(379042816))), name = tensor<string, []>("layers_17_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_343_cast_fp16 = conv(dilations = var_6965, groups = var_6901, pad = pretrained_out_343_pad_0, pad_type = pretrained_out_343_pad_type_0, strides = var_6963, weight = layers_17_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_239_cast_fp16)[name = tensor<string, []>("pretrained_out_343_cast_fp16")];
            tensor<int32, [2]> var_6969 = const()[name = tensor<string, []>("op_6969"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6971 = const()[name = tensor<string, []>("op_6971"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_513_pad_type_0 = const()[name = tensor<string, []>("input_513_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_513_pad_0 = const()[name = tensor<string, []>("input_513_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_17_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_17_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(379042944)))];
            tensor<fp16, [1, 16, 1, 1]> input_513_cast_fp16 = conv(dilations = var_6971, groups = var_6901, pad = input_513_pad_0, pad_type = input_513_pad_type_0, strides = var_6969, weight = layers_17_self_attn_k_proj_loraA_weight_to_fp16, x = obj_239_cast_fp16)[name = tensor<string, []>("input_513_cast_fp16")];
            tensor<int32, [2]> var_6975 = const()[name = tensor<string, []>("op_6975"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6977 = const()[name = tensor<string, []>("op_6977"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_685_pad_type_0 = const()[name = tensor<string, []>("lora_out_685_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_685_pad_0 = const()[name = tensor<string, []>("lora_out_685_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_687_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_687_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(379083968)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_687_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_6977, groups = var_6901, pad = lora_out_685_pad_0, pad_type = lora_out_685_pad_type_0, strides = var_6975, weight = lora_out_687_weight_0_to_fp16, x = input_513_cast_fp16)[name = tensor<string, []>("lora_out_687_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_35_cast_fp16 = add(x = pretrained_out_343_cast_fp16, y = lora_out_687_cast_fp16)[name = tensor<string, []>("current_key_35_cast_fp16")];
            tensor<int32, [2]> var_6988 = const()[name = tensor<string, []>("op_6988"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6990 = const()[name = tensor<string, []>("op_6990"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_345_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_345_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_345_pad_0 = const()[name = tensor<string, []>("pretrained_out_345_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_17_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(379124992))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(379944256))), name = tensor<string, []>("layers_17_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_17_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_17_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(379944384)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_345_cast_fp16 = conv(bias = layers_17_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_6990, groups = var_6901, pad = pretrained_out_345_pad_0, pad_type = pretrained_out_345_pad_type_0, strides = var_6988, weight = layers_17_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_239_cast_fp16)[name = tensor<string, []>("pretrained_out_345_cast_fp16")];
            tensor<int32, [2]> var_6994 = const()[name = tensor<string, []>("op_6994"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_6996 = const()[name = tensor<string, []>("op_6996"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_515_pad_type_0 = const()[name = tensor<string, []>("input_515_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_515_pad_0 = const()[name = tensor<string, []>("input_515_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_17_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_17_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(379947008)))];
            tensor<fp16, [1, 16, 1, 1]> input_515_cast_fp16 = conv(dilations = var_6996, groups = var_6901, pad = input_515_pad_0, pad_type = input_515_pad_type_0, strides = var_6994, weight = layers_17_self_attn_v_proj_loraA_weight_to_fp16, x = obj_239_cast_fp16)[name = tensor<string, []>("input_515_cast_fp16")];
            tensor<int32, [2]> var_7000 = const()[name = tensor<string, []>("op_7000"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7002 = const()[name = tensor<string, []>("op_7002"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_689_pad_type_0 = const()[name = tensor<string, []>("lora_out_689_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_689_pad_0 = const()[name = tensor<string, []>("lora_out_689_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_691_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_691_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(379988032)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_691_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_7002, groups = var_6901, pad = lora_out_689_pad_0, pad_type = lora_out_689_pad_type_0, strides = var_7000, weight = lora_out_691_weight_0_to_fp16, x = input_515_cast_fp16)[name = tensor<string, []>("lora_out_691_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_35_cast_fp16 = add(x = pretrained_out_345_cast_fp16, y = lora_out_691_cast_fp16)[name = tensor<string, []>("current_value_35_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_7012_cast_fp16 = mul(x = current_key_35_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_7012_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_7014_cast_fp16 = mul(x = var_103_cast_fp16_17, y = var_295_cast_fp16)[name = tensor<string, []>("op_7014_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_69_cast_fp16 = add(x = var_7012_cast_fp16, y = var_7014_cast_fp16)[name = tensor<string, []>("key_69_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_7016_cast_fp16 = mul(x = current_value_35_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_7016_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_7018_cast_fp16 = mul(x = var_138_cast_fp16_17, y = var_295_cast_fp16)[name = tensor<string, []>("op_7018_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_69_cast_fp16 = add(x = var_7016_cast_fp16, y = var_7018_cast_fp16)[name = tensor<string, []>("value_69_cast_fp16")];
            tensor<int32, [4]> var_7021 = const()[name = tensor<string, []>("op_7021"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_7022_cast_fp16 = reshape(shape = var_7021, x = query_69_cast_fp16)[name = tensor<string, []>("op_7022_cast_fp16")];
            tensor<fp16, []> var_7023_to_fp16 = const()[name = tensor<string, []>("op_7023_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_7024_cast_fp16 = mul(x = var_7022_cast_fp16, y = var_7023_to_fp16)[name = tensor<string, []>("op_7024_cast_fp16")];
            tensor<int32, [4]> var_7025 = const()[name = tensor<string, []>("op_7025"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_7026_cast_fp16 = reshape(shape = var_7025, x = key_69_cast_fp16)[name = tensor<string, []>("op_7026_cast_fp16")];
            tensor<bool, []> mh_w_103_transpose_x_0 = const()[name = tensor<string, []>("mh_w_103_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_103_transpose_y_0 = const()[name = tensor<string, []>("mh_w_103_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_103_cast_fp16 = matmul(transpose_x = mh_w_103_transpose_x_0, transpose_y = mh_w_103_transpose_y_0, x = var_7024_cast_fp16, y = var_7026_cast_fp16)[name = tensor<string, []>("mh_w_103_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_105_cast_fp16 = add(x = mh_w_103_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_105_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_7034_cast_fp16 = softmax(axis = var_6894, x = mh_w_105_cast_fp16)[name = tensor<string, []>("op_7034_cast_fp16")];
            tensor<int32, [4]> var_7035 = const()[name = tensor<string, []>("op_7035"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_7036_cast_fp16 = reshape(shape = var_7035, x = value_69_cast_fp16)[name = tensor<string, []>("op_7036_cast_fp16")];
            tensor<bool, []> attn_69_transpose_x_0 = const()[name = tensor<string, []>("attn_69_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_69_transpose_y_0 = const()[name = tensor<string, []>("attn_69_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_69_cast_fp16 = matmul(transpose_x = attn_69_transpose_x_0, transpose_y = attn_69_transpose_y_0, x = var_7036_cast_fp16, y = var_7034_cast_fp16)[name = tensor<string, []>("attn_69_cast_fp16")];
            tensor<int32, [4]> var_7039 = const()[name = tensor<string, []>("op_7039"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_517_cast_fp16 = reshape(shape = var_7039, x = attn_69_cast_fp16)[name = tensor<string, []>("input_517_cast_fp16")];
            tensor<int32, [2]> var_7046 = const()[name = tensor<string, []>("op_7046"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7048 = const()[name = tensor<string, []>("op_7048"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_347_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_347_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_347_pad_0 = const()[name = tensor<string, []>("pretrained_out_347_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_17_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(380029056))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(380848320))), name = tensor<string, []>("layers_17_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_17_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_17_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(380848448)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_347_cast_fp16 = conv(bias = layers_17_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_7048, groups = var_6901, pad = pretrained_out_347_pad_0, pad_type = pretrained_out_347_pad_type_0, strides = var_7046, weight = layers_17_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_517_cast_fp16)[name = tensor<string, []>("pretrained_out_347_cast_fp16")];
            tensor<int32, [2]> var_7052 = const()[name = tensor<string, []>("op_7052"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7054 = const()[name = tensor<string, []>("op_7054"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_519_pad_type_0 = const()[name = tensor<string, []>("input_519_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_519_pad_0 = const()[name = tensor<string, []>("input_519_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_17_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_17_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(380851072)))];
            tensor<fp16, [1, 16, 1, 1]> input_519_cast_fp16 = conv(dilations = var_7054, groups = var_6901, pad = input_519_pad_0, pad_type = input_519_pad_type_0, strides = var_7052, weight = layers_17_self_attn_o_proj_loraA_weight_to_fp16, x = input_517_cast_fp16)[name = tensor<string, []>("input_519_cast_fp16")];
            tensor<int32, [2]> var_7058 = const()[name = tensor<string, []>("op_7058"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7060 = const()[name = tensor<string, []>("op_7060"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_693_pad_type_0 = const()[name = tensor<string, []>("lora_out_693_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_693_pad_0 = const()[name = tensor<string, []>("lora_out_693_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_695_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_695_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(380892096)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_695_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_7060, groups = var_6901, pad = lora_out_693_pad_0, pad_type = lora_out_693_pad_type_0, strides = var_7058, weight = lora_out_695_weight_0_to_fp16, x = input_519_cast_fp16)[name = tensor<string, []>("lora_out_695_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_245_cast_fp16 = add(x = pretrained_out_347_cast_fp16, y = lora_out_695_cast_fp16)[name = tensor<string, []>("obj_245_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_105_cast_fp16 = add(x = inputs_103_cast_fp16, y = obj_245_cast_fp16)[name = tensor<string, []>("inputs_105_cast_fp16")];
            tensor<int32, [1]> var_7073 = const()[name = tensor<string, []>("op_7073"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_105_cast_fp16 = reduce_mean(axes = var_7073, keep_dims = var_6902, x = inputs_105_cast_fp16)[name = tensor<string, []>("channels_mean_105_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_105_cast_fp16 = sub(x = inputs_105_cast_fp16, y = channels_mean_105_cast_fp16)[name = tensor<string, []>("zero_mean_105_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_105_cast_fp16 = mul(x = zero_mean_105_cast_fp16, y = zero_mean_105_cast_fp16)[name = tensor<string, []>("zero_mean_sq_105_cast_fp16")];
            tensor<int32, [1]> var_7077 = const()[name = tensor<string, []>("op_7077"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_7078_cast_fp16 = reduce_mean(axes = var_7077, keep_dims = var_6902, x = zero_mean_sq_105_cast_fp16)[name = tensor<string, []>("op_7078_cast_fp16")];
            tensor<fp16, []> var_7079_to_fp16 = const()[name = tensor<string, []>("op_7079_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_7080_cast_fp16 = add(x = var_7078_cast_fp16, y = var_7079_to_fp16)[name = tensor<string, []>("op_7080_cast_fp16")];
            tensor<fp32, []> denom_105_epsilon_0 = const()[name = tensor<string, []>("denom_105_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_105_cast_fp16 = rsqrt(epsilon = denom_105_epsilon_0, x = var_7080_cast_fp16)[name = tensor<string, []>("denom_105_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_105_cast_fp16 = mul(x = zero_mean_105_cast_fp16, y = denom_105_cast_fp16)[name = tensor<string, []>("out_105_cast_fp16")];
            tensor<fp16, [1280]> obj_247_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_247_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(380933120)))];
            tensor<fp16, [1280]> obj_247_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_247_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(380935744)))];
            tensor<fp16, []> obj_247_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_247_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_247_cast_fp16 = batch_norm(beta = obj_247_beta_0_to_fp16, epsilon = obj_247_epsilon_0_to_fp16, gamma = obj_247_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_105_cast_fp16)[name = tensor<string, []>("obj_247_cast_fp16")];
            tensor<int32, [2]> var_7098 = const()[name = tensor<string, []>("op_7098"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7100 = const()[name = tensor<string, []>("op_7100"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_349_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_349_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_349_pad_0 = const()[name = tensor<string, []>("pretrained_out_349_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_17_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(380938368))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(381757632))), name = tensor<string, []>("layers_17_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_17_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_17_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(381757760)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_349_cast_fp16 = conv(bias = layers_17_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_7100, groups = var_6901, pad = pretrained_out_349_pad_0, pad_type = pretrained_out_349_pad_type_0, strides = var_7098, weight = layers_17_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_247_cast_fp16)[name = tensor<string, []>("pretrained_out_349_cast_fp16")];
            tensor<int32, [2]> var_7104 = const()[name = tensor<string, []>("op_7104"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7106 = const()[name = tensor<string, []>("op_7106"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_521_pad_type_0 = const()[name = tensor<string, []>("input_521_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_521_pad_0 = const()[name = tensor<string, []>("input_521_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_17_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_17_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(381760384)))];
            tensor<fp16, [1, 16, 1, 1]> input_521_cast_fp16 = conv(dilations = var_7106, groups = var_6901, pad = input_521_pad_0, pad_type = input_521_pad_type_0, strides = var_7104, weight = layers_17_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_247_cast_fp16)[name = tensor<string, []>("input_521_cast_fp16")];
            tensor<int32, [2]> var_7110 = const()[name = tensor<string, []>("op_7110"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7112 = const()[name = tensor<string, []>("op_7112"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_697_pad_type_0 = const()[name = tensor<string, []>("lora_out_697_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_697_pad_0 = const()[name = tensor<string, []>("lora_out_697_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_699_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_699_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(381801408)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_699_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_7112, groups = var_6901, pad = lora_out_697_pad_0, pad_type = lora_out_697_pad_type_0, strides = var_7110, weight = lora_out_699_weight_0_to_fp16, x = input_521_cast_fp16)[name = tensor<string, []>("lora_out_699_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_71_cast_fp16 = add(x = pretrained_out_349_cast_fp16, y = lora_out_699_cast_fp16)[name = tensor<string, []>("query_71_cast_fp16")];
            tensor<int32, [2]> var_7122 = const()[name = tensor<string, []>("op_7122"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7124 = const()[name = tensor<string, []>("op_7124"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_351_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_351_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_351_pad_0 = const()[name = tensor<string, []>("pretrained_out_351_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_17_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(381842432))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(382661696))), name = tensor<string, []>("layers_17_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_351_cast_fp16 = conv(dilations = var_7124, groups = var_6901, pad = pretrained_out_351_pad_0, pad_type = pretrained_out_351_pad_type_0, strides = var_7122, weight = layers_17_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_351_cast_fp16")];
            tensor<int32, [2]> var_7128 = const()[name = tensor<string, []>("op_7128"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7130 = const()[name = tensor<string, []>("op_7130"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_523_pad_type_0 = const()[name = tensor<string, []>("input_523_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_523_pad_0 = const()[name = tensor<string, []>("input_523_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_17_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_17_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(382661824)))];
            tensor<fp16, [1, 16, 1, 1500]> input_523_cast_fp16 = conv(dilations = var_7130, groups = var_6901, pad = input_523_pad_0, pad_type = input_523_pad_type_0, strides = var_7128, weight = layers_17_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_523_cast_fp16")];
            tensor<int32, [2]> var_7134 = const()[name = tensor<string, []>("op_7134"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7136 = const()[name = tensor<string, []>("op_7136"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_701_pad_type_0 = const()[name = tensor<string, []>("lora_out_701_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_701_pad_0 = const()[name = tensor<string, []>("lora_out_701_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_703_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_703_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(382702848)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_703_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_7136, groups = var_6901, pad = lora_out_701_pad_0, pad_type = lora_out_701_pad_type_0, strides = var_7134, weight = lora_out_703_weight_0_to_fp16, x = input_523_cast_fp16)[name = tensor<string, []>("lora_out_703_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_71_cast_fp16 = add(x = pretrained_out_351_cast_fp16, y = lora_out_703_cast_fp16)[name = tensor<string, []>("key_71_cast_fp16")];
            tensor<int32, [2]> var_7147 = const()[name = tensor<string, []>("op_7147"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7149 = const()[name = tensor<string, []>("op_7149"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_353_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_353_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_353_pad_0 = const()[name = tensor<string, []>("pretrained_out_353_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_17_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(382743872))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(383563136))), name = tensor<string, []>("layers_17_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_17_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_17_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(383563264)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_353_cast_fp16 = conv(bias = layers_17_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_7149, groups = var_6901, pad = pretrained_out_353_pad_0, pad_type = pretrained_out_353_pad_type_0, strides = var_7147, weight = layers_17_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_353_cast_fp16")];
            tensor<int32, [2]> var_7153 = const()[name = tensor<string, []>("op_7153"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7155 = const()[name = tensor<string, []>("op_7155"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_525_pad_type_0 = const()[name = tensor<string, []>("input_525_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_525_pad_0 = const()[name = tensor<string, []>("input_525_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_17_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_17_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(383565888)))];
            tensor<fp16, [1, 16, 1, 1500]> input_525_cast_fp16 = conv(dilations = var_7155, groups = var_6901, pad = input_525_pad_0, pad_type = input_525_pad_type_0, strides = var_7153, weight = layers_17_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_525_cast_fp16")];
            tensor<int32, [2]> var_7159 = const()[name = tensor<string, []>("op_7159"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7161 = const()[name = tensor<string, []>("op_7161"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_705_pad_type_0 = const()[name = tensor<string, []>("lora_out_705_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_705_pad_0 = const()[name = tensor<string, []>("lora_out_705_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_707_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_707_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(383606912)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_707_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_7161, groups = var_6901, pad = lora_out_705_pad_0, pad_type = lora_out_705_pad_type_0, strides = var_7159, weight = lora_out_707_weight_0_to_fp16, x = input_525_cast_fp16)[name = tensor<string, []>("lora_out_707_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_71_cast_fp16 = add(x = pretrained_out_353_cast_fp16, y = lora_out_707_cast_fp16)[name = tensor<string, []>("value_71_cast_fp16")];
            tensor<int32, [4]> var_7168 = const()[name = tensor<string, []>("op_7168"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_7169_cast_fp16 = reshape(shape = var_7168, x = query_71_cast_fp16)[name = tensor<string, []>("op_7169_cast_fp16")];
            tensor<fp16, []> var_7170_to_fp16 = const()[name = tensor<string, []>("op_7170_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_7171_cast_fp16 = mul(x = var_7169_cast_fp16, y = var_7170_to_fp16)[name = tensor<string, []>("op_7171_cast_fp16")];
            tensor<int32, [4]> var_7172 = const()[name = tensor<string, []>("op_7172"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_7173_cast_fp16 = reshape(shape = var_7172, x = key_71_cast_fp16)[name = tensor<string, []>("op_7173_cast_fp16")];
            tensor<bool, []> mh_w_107_transpose_x_0 = const()[name = tensor<string, []>("mh_w_107_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_107_transpose_y_0 = const()[name = tensor<string, []>("mh_w_107_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_107_cast_fp16 = matmul(transpose_x = mh_w_107_transpose_x_0, transpose_y = mh_w_107_transpose_y_0, x = var_7171_cast_fp16, y = var_7173_cast_fp16)[name = tensor<string, []>("mh_w_107_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_251_cast_fp16 = softmax(axis = var_6894, x = mh_w_107_cast_fp16)[name = tensor<string, []>("obj_251_cast_fp16")];
            tensor<int32, [4]> var_7177 = const()[name = tensor<string, []>("op_7177"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_7178_cast_fp16 = reshape(shape = var_7177, x = value_71_cast_fp16)[name = tensor<string, []>("op_7178_cast_fp16")];
            tensor<bool, []> attn_71_transpose_x_0 = const()[name = tensor<string, []>("attn_71_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_71_transpose_y_0 = const()[name = tensor<string, []>("attn_71_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_71_cast_fp16 = matmul(transpose_x = attn_71_transpose_x_0, transpose_y = attn_71_transpose_y_0, x = var_7178_cast_fp16, y = obj_251_cast_fp16)[name = tensor<string, []>("attn_71_cast_fp16")];
            tensor<int32, [4]> var_7181 = const()[name = tensor<string, []>("op_7181"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_527_cast_fp16 = reshape(shape = var_7181, x = attn_71_cast_fp16)[name = tensor<string, []>("input_527_cast_fp16")];
            tensor<int32, [2]> var_7188 = const()[name = tensor<string, []>("op_7188"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7190 = const()[name = tensor<string, []>("op_7190"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_355_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_355_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_355_pad_0 = const()[name = tensor<string, []>("pretrained_out_355_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_17_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(383647936))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(384467200))), name = tensor<string, []>("layers_17_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_17_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_17_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(384467328)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_355_cast_fp16 = conv(bias = layers_17_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_7190, groups = var_6901, pad = pretrained_out_355_pad_0, pad_type = pretrained_out_355_pad_type_0, strides = var_7188, weight = layers_17_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_527_cast_fp16)[name = tensor<string, []>("pretrained_out_355_cast_fp16")];
            tensor<int32, [2]> var_7194 = const()[name = tensor<string, []>("op_7194"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7196 = const()[name = tensor<string, []>("op_7196"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_529_pad_type_0 = const()[name = tensor<string, []>("input_529_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_529_pad_0 = const()[name = tensor<string, []>("input_529_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_17_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_17_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(384469952)))];
            tensor<fp16, [1, 16, 1, 1]> input_529_cast_fp16 = conv(dilations = var_7196, groups = var_6901, pad = input_529_pad_0, pad_type = input_529_pad_type_0, strides = var_7194, weight = layers_17_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_527_cast_fp16)[name = tensor<string, []>("input_529_cast_fp16")];
            tensor<int32, [2]> var_7200 = const()[name = tensor<string, []>("op_7200"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7202 = const()[name = tensor<string, []>("op_7202"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_709_pad_type_0 = const()[name = tensor<string, []>("lora_out_709_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_709_pad_0 = const()[name = tensor<string, []>("lora_out_709_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_711_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_711_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(384510976)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_711_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_7202, groups = var_6901, pad = lora_out_709_pad_0, pad_type = lora_out_709_pad_type_0, strides = var_7200, weight = lora_out_711_weight_0_to_fp16, x = input_529_cast_fp16)[name = tensor<string, []>("lora_out_711_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_249_cast_fp16 = add(x = pretrained_out_355_cast_fp16, y = lora_out_711_cast_fp16)[name = tensor<string, []>("obj_249_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_107_cast_fp16 = add(x = inputs_105_cast_fp16, y = obj_249_cast_fp16)[name = tensor<string, []>("inputs_107_cast_fp16")];
            tensor<int32, [1]> var_7214 = const()[name = tensor<string, []>("op_7214"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_107_cast_fp16 = reduce_mean(axes = var_7214, keep_dims = var_6902, x = inputs_107_cast_fp16)[name = tensor<string, []>("channels_mean_107_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_107_cast_fp16 = sub(x = inputs_107_cast_fp16, y = channels_mean_107_cast_fp16)[name = tensor<string, []>("zero_mean_107_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_107_cast_fp16 = mul(x = zero_mean_107_cast_fp16, y = zero_mean_107_cast_fp16)[name = tensor<string, []>("zero_mean_sq_107_cast_fp16")];
            tensor<int32, [1]> var_7218 = const()[name = tensor<string, []>("op_7218"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_7219_cast_fp16 = reduce_mean(axes = var_7218, keep_dims = var_6902, x = zero_mean_sq_107_cast_fp16)[name = tensor<string, []>("op_7219_cast_fp16")];
            tensor<fp16, []> var_7220_to_fp16 = const()[name = tensor<string, []>("op_7220_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_7221_cast_fp16 = add(x = var_7219_cast_fp16, y = var_7220_to_fp16)[name = tensor<string, []>("op_7221_cast_fp16")];
            tensor<fp32, []> denom_107_epsilon_0 = const()[name = tensor<string, []>("denom_107_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_107_cast_fp16 = rsqrt(epsilon = denom_107_epsilon_0, x = var_7221_cast_fp16)[name = tensor<string, []>("denom_107_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_107_cast_fp16 = mul(x = zero_mean_107_cast_fp16, y = denom_107_cast_fp16)[name = tensor<string, []>("out_107_cast_fp16")];
            tensor<fp16, [1280]> input_531_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_531_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(384552000)))];
            tensor<fp16, [1280]> input_531_beta_0_to_fp16 = const()[name = tensor<string, []>("input_531_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(384554624)))];
            tensor<fp16, []> input_531_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_531_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_531_cast_fp16 = batch_norm(beta = input_531_beta_0_to_fp16, epsilon = input_531_epsilon_0_to_fp16, gamma = input_531_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_107_cast_fp16)[name = tensor<string, []>("input_531_cast_fp16")];
            tensor<int32, [2]> var_7235 = const()[name = tensor<string, []>("op_7235"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7237 = const()[name = tensor<string, []>("op_7237"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_357_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_357_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_357_pad_0 = const()[name = tensor<string, []>("pretrained_out_357_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_17_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(384557248))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(387834112))), name = tensor<string, []>("layers_17_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_17_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_17_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(387834240)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_357_cast_fp16 = conv(bias = layers_17_fc1_pretrained_bias_to_fp16, dilations = var_7237, groups = var_6901, pad = pretrained_out_357_pad_0, pad_type = pretrained_out_357_pad_type_0, strides = var_7235, weight = layers_17_fc1_pretrained_weight_to_fp16_palettized, x = input_531_cast_fp16)[name = tensor<string, []>("pretrained_out_357_cast_fp16")];
            tensor<int32, [2]> var_7241 = const()[name = tensor<string, []>("op_7241"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7243 = const()[name = tensor<string, []>("op_7243"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_533_pad_type_0 = const()[name = tensor<string, []>("input_533_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_533_pad_0 = const()[name = tensor<string, []>("input_533_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_17_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_17_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(387844544)))];
            tensor<fp16, [1, 16, 1, 1]> input_533_cast_fp16 = conv(dilations = var_7243, groups = var_6901, pad = input_533_pad_0, pad_type = input_533_pad_type_0, strides = var_7241, weight = layers_17_fc1_loraA_weight_to_fp16, x = input_531_cast_fp16)[name = tensor<string, []>("input_533_cast_fp16")];
            tensor<int32, [2]> var_7247 = const()[name = tensor<string, []>("op_7247"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7249 = const()[name = tensor<string, []>("op_7249"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_713_pad_type_0 = const()[name = tensor<string, []>("lora_out_713_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_713_pad_0 = const()[name = tensor<string, []>("lora_out_713_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_715_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_715_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(387885568)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_715_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_7249, groups = var_6901, pad = lora_out_713_pad_0, pad_type = lora_out_713_pad_type_0, strides = var_7247, weight = lora_out_715_weight_0_to_fp16, x = input_533_cast_fp16)[name = tensor<string, []>("lora_out_715_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_535_cast_fp16 = add(x = pretrained_out_357_cast_fp16, y = lora_out_715_cast_fp16)[name = tensor<string, []>("input_535_cast_fp16")];
            tensor<string, []> input_537_mode_0 = const()[name = tensor<string, []>("input_537_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_537_cast_fp16 = gelu(mode = input_537_mode_0, x = input_535_cast_fp16)[name = tensor<string, []>("input_537_cast_fp16")];
            tensor<int32, [2]> var_7261 = const()[name = tensor<string, []>("op_7261"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7263 = const()[name = tensor<string, []>("op_7263"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_359_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_359_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_359_pad_0 = const()[name = tensor<string, []>("pretrained_out_359_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_17_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(388049472))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(391326336))), name = tensor<string, []>("layers_17_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_17_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_17_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(391326464)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_359_cast_fp16 = conv(bias = layers_17_fc2_pretrained_bias_to_fp16, dilations = var_7263, groups = var_6901, pad = pretrained_out_359_pad_0, pad_type = pretrained_out_359_pad_type_0, strides = var_7261, weight = layers_17_fc2_pretrained_weight_to_fp16_palettized, x = input_537_cast_fp16)[name = tensor<string, []>("pretrained_out_359_cast_fp16")];
            tensor<int32, [2]> var_7267 = const()[name = tensor<string, []>("op_7267"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7269 = const()[name = tensor<string, []>("op_7269"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_539_pad_type_0 = const()[name = tensor<string, []>("input_539_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_539_pad_0 = const()[name = tensor<string, []>("input_539_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_17_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_17_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(391329088)))];
            tensor<fp16, [1, 16, 1, 1]> input_539_cast_fp16 = conv(dilations = var_7269, groups = var_6901, pad = input_539_pad_0, pad_type = input_539_pad_type_0, strides = var_7267, weight = layers_17_fc2_loraA_weight_to_fp16, x = input_537_cast_fp16)[name = tensor<string, []>("input_539_cast_fp16")];
            tensor<int32, [2]> var_7273 = const()[name = tensor<string, []>("op_7273"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7275 = const()[name = tensor<string, []>("op_7275"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_717_pad_type_0 = const()[name = tensor<string, []>("lora_out_717_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_717_pad_0 = const()[name = tensor<string, []>("lora_out_717_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_719_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_719_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(391492992)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_719_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_7275, groups = var_6901, pad = lora_out_717_pad_0, pad_type = lora_out_717_pad_type_0, strides = var_7273, weight = lora_out_719_weight_0_to_fp16, x = input_539_cast_fp16)[name = tensor<string, []>("lora_out_719_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_37_cast_fp16 = add(x = pretrained_out_359_cast_fp16, y = lora_out_719_cast_fp16)[name = tensor<string, []>("hidden_states_37_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_109_cast_fp16 = add(x = inputs_107_cast_fp16, y = hidden_states_37_cast_fp16)[name = tensor<string, []>("inputs_109_cast_fp16")];
            tensor<int32, []> var_7292 = const()[name = tensor<string, []>("op_7292"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_7299 = const()[name = tensor<string, []>("op_7299"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_7300 = const()[name = tensor<string, []>("op_7300"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_7312 = const()[name = tensor<string, []>("op_7312"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_109_cast_fp16 = reduce_mean(axes = var_7312, keep_dims = var_7300, x = inputs_109_cast_fp16)[name = tensor<string, []>("channels_mean_109_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_109_cast_fp16 = sub(x = inputs_109_cast_fp16, y = channels_mean_109_cast_fp16)[name = tensor<string, []>("zero_mean_109_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_109_cast_fp16 = mul(x = zero_mean_109_cast_fp16, y = zero_mean_109_cast_fp16)[name = tensor<string, []>("zero_mean_sq_109_cast_fp16")];
            tensor<int32, [1]> var_7316 = const()[name = tensor<string, []>("op_7316"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_7317_cast_fp16 = reduce_mean(axes = var_7316, keep_dims = var_7300, x = zero_mean_sq_109_cast_fp16)[name = tensor<string, []>("op_7317_cast_fp16")];
            tensor<fp16, []> var_7318_to_fp16 = const()[name = tensor<string, []>("op_7318_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_7319_cast_fp16 = add(x = var_7317_cast_fp16, y = var_7318_to_fp16)[name = tensor<string, []>("op_7319_cast_fp16")];
            tensor<fp32, []> denom_109_epsilon_0 = const()[name = tensor<string, []>("denom_109_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_109_cast_fp16 = rsqrt(epsilon = denom_109_epsilon_0, x = var_7319_cast_fp16)[name = tensor<string, []>("denom_109_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_109_cast_fp16 = mul(x = zero_mean_109_cast_fp16, y = denom_109_cast_fp16)[name = tensor<string, []>("out_109_cast_fp16")];
            tensor<fp16, [1280]> obj_253_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_253_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(391534016)))];
            tensor<fp16, [1280]> obj_253_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_253_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(391536640)))];
            tensor<fp16, []> obj_253_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_253_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_253_cast_fp16 = batch_norm(beta = obj_253_beta_0_to_fp16, epsilon = obj_253_epsilon_0_to_fp16, gamma = obj_253_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_109_cast_fp16)[name = tensor<string, []>("obj_253_cast_fp16")];
            tensor<int32, [2]> var_7337 = const()[name = tensor<string, []>("op_7337"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7339 = const()[name = tensor<string, []>("op_7339"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_361_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_361_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_361_pad_0 = const()[name = tensor<string, []>("pretrained_out_361_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_18_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(391539264))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(392358528))), name = tensor<string, []>("layers_18_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_18_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_18_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(392358656)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_361_cast_fp16 = conv(bias = layers_18_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_7339, groups = var_7299, pad = pretrained_out_361_pad_0, pad_type = pretrained_out_361_pad_type_0, strides = var_7337, weight = layers_18_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_253_cast_fp16)[name = tensor<string, []>("pretrained_out_361_cast_fp16")];
            tensor<int32, [2]> var_7343 = const()[name = tensor<string, []>("op_7343"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7345 = const()[name = tensor<string, []>("op_7345"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_541_pad_type_0 = const()[name = tensor<string, []>("input_541_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_541_pad_0 = const()[name = tensor<string, []>("input_541_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_18_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_18_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(392361280)))];
            tensor<fp16, [1, 16, 1, 1]> input_541_cast_fp16 = conv(dilations = var_7345, groups = var_7299, pad = input_541_pad_0, pad_type = input_541_pad_type_0, strides = var_7343, weight = layers_18_self_attn_q_proj_loraA_weight_to_fp16, x = obj_253_cast_fp16)[name = tensor<string, []>("input_541_cast_fp16")];
            tensor<int32, [2]> var_7349 = const()[name = tensor<string, []>("op_7349"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7351 = const()[name = tensor<string, []>("op_7351"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_721_pad_type_0 = const()[name = tensor<string, []>("lora_out_721_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_721_pad_0 = const()[name = tensor<string, []>("lora_out_721_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_723_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_723_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(392402304)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_723_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_7351, groups = var_7299, pad = lora_out_721_pad_0, pad_type = lora_out_721_pad_type_0, strides = var_7349, weight = lora_out_723_weight_0_to_fp16, x = input_541_cast_fp16)[name = tensor<string, []>("lora_out_723_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_73_cast_fp16 = add(x = pretrained_out_361_cast_fp16, y = lora_out_723_cast_fp16)[name = tensor<string, []>("query_73_cast_fp16")];
            tensor<int32, [2]> var_7361 = const()[name = tensor<string, []>("op_7361"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7363 = const()[name = tensor<string, []>("op_7363"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_363_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_363_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_363_pad_0 = const()[name = tensor<string, []>("pretrained_out_363_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_18_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(392443328))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(393262592))), name = tensor<string, []>("layers_18_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_363_cast_fp16 = conv(dilations = var_7363, groups = var_7299, pad = pretrained_out_363_pad_0, pad_type = pretrained_out_363_pad_type_0, strides = var_7361, weight = layers_18_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_253_cast_fp16)[name = tensor<string, []>("pretrained_out_363_cast_fp16")];
            tensor<int32, [2]> var_7367 = const()[name = tensor<string, []>("op_7367"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7369 = const()[name = tensor<string, []>("op_7369"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_543_pad_type_0 = const()[name = tensor<string, []>("input_543_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_543_pad_0 = const()[name = tensor<string, []>("input_543_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_18_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_18_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(393262720)))];
            tensor<fp16, [1, 16, 1, 1]> input_543_cast_fp16 = conv(dilations = var_7369, groups = var_7299, pad = input_543_pad_0, pad_type = input_543_pad_type_0, strides = var_7367, weight = layers_18_self_attn_k_proj_loraA_weight_to_fp16, x = obj_253_cast_fp16)[name = tensor<string, []>("input_543_cast_fp16")];
            tensor<int32, [2]> var_7373 = const()[name = tensor<string, []>("op_7373"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7375 = const()[name = tensor<string, []>("op_7375"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_725_pad_type_0 = const()[name = tensor<string, []>("lora_out_725_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_725_pad_0 = const()[name = tensor<string, []>("lora_out_725_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_727_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_727_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(393303744)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_727_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_7375, groups = var_7299, pad = lora_out_725_pad_0, pad_type = lora_out_725_pad_type_0, strides = var_7373, weight = lora_out_727_weight_0_to_fp16, x = input_543_cast_fp16)[name = tensor<string, []>("lora_out_727_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_37_cast_fp16 = add(x = pretrained_out_363_cast_fp16, y = lora_out_727_cast_fp16)[name = tensor<string, []>("current_key_37_cast_fp16")];
            tensor<int32, [2]> var_7386 = const()[name = tensor<string, []>("op_7386"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7388 = const()[name = tensor<string, []>("op_7388"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_365_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_365_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_365_pad_0 = const()[name = tensor<string, []>("pretrained_out_365_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_18_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(393344768))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(394164032))), name = tensor<string, []>("layers_18_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_18_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_18_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(394164160)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_365_cast_fp16 = conv(bias = layers_18_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_7388, groups = var_7299, pad = pretrained_out_365_pad_0, pad_type = pretrained_out_365_pad_type_0, strides = var_7386, weight = layers_18_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_253_cast_fp16)[name = tensor<string, []>("pretrained_out_365_cast_fp16")];
            tensor<int32, [2]> var_7392 = const()[name = tensor<string, []>("op_7392"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7394 = const()[name = tensor<string, []>("op_7394"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_545_pad_type_0 = const()[name = tensor<string, []>("input_545_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_545_pad_0 = const()[name = tensor<string, []>("input_545_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_18_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_18_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(394166784)))];
            tensor<fp16, [1, 16, 1, 1]> input_545_cast_fp16 = conv(dilations = var_7394, groups = var_7299, pad = input_545_pad_0, pad_type = input_545_pad_type_0, strides = var_7392, weight = layers_18_self_attn_v_proj_loraA_weight_to_fp16, x = obj_253_cast_fp16)[name = tensor<string, []>("input_545_cast_fp16")];
            tensor<int32, [2]> var_7398 = const()[name = tensor<string, []>("op_7398"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7400 = const()[name = tensor<string, []>("op_7400"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_729_pad_type_0 = const()[name = tensor<string, []>("lora_out_729_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_729_pad_0 = const()[name = tensor<string, []>("lora_out_729_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_731_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_731_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(394207808)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_731_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_7400, groups = var_7299, pad = lora_out_729_pad_0, pad_type = lora_out_729_pad_type_0, strides = var_7398, weight = lora_out_731_weight_0_to_fp16, x = input_545_cast_fp16)[name = tensor<string, []>("lora_out_731_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_37_cast_fp16 = add(x = pretrained_out_365_cast_fp16, y = lora_out_731_cast_fp16)[name = tensor<string, []>("current_value_37_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_7410_cast_fp16 = mul(x = current_key_37_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_7410_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_7412_cast_fp16 = mul(x = var_103_cast_fp16_18, y = var_295_cast_fp16)[name = tensor<string, []>("op_7412_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_73_cast_fp16 = add(x = var_7410_cast_fp16, y = var_7412_cast_fp16)[name = tensor<string, []>("key_73_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_7414_cast_fp16 = mul(x = current_value_37_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_7414_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_7416_cast_fp16 = mul(x = var_138_cast_fp16_18, y = var_295_cast_fp16)[name = tensor<string, []>("op_7416_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_73_cast_fp16 = add(x = var_7414_cast_fp16, y = var_7416_cast_fp16)[name = tensor<string, []>("value_73_cast_fp16")];
            tensor<int32, [4]> var_7419 = const()[name = tensor<string, []>("op_7419"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_7420_cast_fp16 = reshape(shape = var_7419, x = query_73_cast_fp16)[name = tensor<string, []>("op_7420_cast_fp16")];
            tensor<fp16, []> var_7421_to_fp16 = const()[name = tensor<string, []>("op_7421_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_7422_cast_fp16 = mul(x = var_7420_cast_fp16, y = var_7421_to_fp16)[name = tensor<string, []>("op_7422_cast_fp16")];
            tensor<int32, [4]> var_7423 = const()[name = tensor<string, []>("op_7423"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_7424_cast_fp16 = reshape(shape = var_7423, x = key_73_cast_fp16)[name = tensor<string, []>("op_7424_cast_fp16")];
            tensor<bool, []> mh_w_109_transpose_x_0 = const()[name = tensor<string, []>("mh_w_109_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_109_transpose_y_0 = const()[name = tensor<string, []>("mh_w_109_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_109_cast_fp16 = matmul(transpose_x = mh_w_109_transpose_x_0, transpose_y = mh_w_109_transpose_y_0, x = var_7422_cast_fp16, y = var_7424_cast_fp16)[name = tensor<string, []>("mh_w_109_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_111_cast_fp16 = add(x = mh_w_109_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_111_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_7432_cast_fp16 = softmax(axis = var_7292, x = mh_w_111_cast_fp16)[name = tensor<string, []>("op_7432_cast_fp16")];
            tensor<int32, [4]> var_7433 = const()[name = tensor<string, []>("op_7433"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_7434_cast_fp16 = reshape(shape = var_7433, x = value_73_cast_fp16)[name = tensor<string, []>("op_7434_cast_fp16")];
            tensor<bool, []> attn_73_transpose_x_0 = const()[name = tensor<string, []>("attn_73_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_73_transpose_y_0 = const()[name = tensor<string, []>("attn_73_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_73_cast_fp16 = matmul(transpose_x = attn_73_transpose_x_0, transpose_y = attn_73_transpose_y_0, x = var_7434_cast_fp16, y = var_7432_cast_fp16)[name = tensor<string, []>("attn_73_cast_fp16")];
            tensor<int32, [4]> var_7437 = const()[name = tensor<string, []>("op_7437"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_547_cast_fp16 = reshape(shape = var_7437, x = attn_73_cast_fp16)[name = tensor<string, []>("input_547_cast_fp16")];
            tensor<int32, [2]> var_7444 = const()[name = tensor<string, []>("op_7444"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7446 = const()[name = tensor<string, []>("op_7446"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_367_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_367_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_367_pad_0 = const()[name = tensor<string, []>("pretrained_out_367_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_18_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(394248832))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(395068096))), name = tensor<string, []>("layers_18_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_18_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_18_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(395068224)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_367_cast_fp16 = conv(bias = layers_18_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_7446, groups = var_7299, pad = pretrained_out_367_pad_0, pad_type = pretrained_out_367_pad_type_0, strides = var_7444, weight = layers_18_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_547_cast_fp16)[name = tensor<string, []>("pretrained_out_367_cast_fp16")];
            tensor<int32, [2]> var_7450 = const()[name = tensor<string, []>("op_7450"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7452 = const()[name = tensor<string, []>("op_7452"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_549_pad_type_0 = const()[name = tensor<string, []>("input_549_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_549_pad_0 = const()[name = tensor<string, []>("input_549_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_18_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_18_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(395070848)))];
            tensor<fp16, [1, 16, 1, 1]> input_549_cast_fp16 = conv(dilations = var_7452, groups = var_7299, pad = input_549_pad_0, pad_type = input_549_pad_type_0, strides = var_7450, weight = layers_18_self_attn_o_proj_loraA_weight_to_fp16, x = input_547_cast_fp16)[name = tensor<string, []>("input_549_cast_fp16")];
            tensor<int32, [2]> var_7456 = const()[name = tensor<string, []>("op_7456"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7458 = const()[name = tensor<string, []>("op_7458"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_733_pad_type_0 = const()[name = tensor<string, []>("lora_out_733_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_733_pad_0 = const()[name = tensor<string, []>("lora_out_733_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_735_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_735_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(395111872)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_735_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_7458, groups = var_7299, pad = lora_out_733_pad_0, pad_type = lora_out_733_pad_type_0, strides = var_7456, weight = lora_out_735_weight_0_to_fp16, x = input_549_cast_fp16)[name = tensor<string, []>("lora_out_735_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_259_cast_fp16 = add(x = pretrained_out_367_cast_fp16, y = lora_out_735_cast_fp16)[name = tensor<string, []>("obj_259_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_111_cast_fp16 = add(x = inputs_109_cast_fp16, y = obj_259_cast_fp16)[name = tensor<string, []>("inputs_111_cast_fp16")];
            tensor<int32, [1]> var_7471 = const()[name = tensor<string, []>("op_7471"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_111_cast_fp16 = reduce_mean(axes = var_7471, keep_dims = var_7300, x = inputs_111_cast_fp16)[name = tensor<string, []>("channels_mean_111_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_111_cast_fp16 = sub(x = inputs_111_cast_fp16, y = channels_mean_111_cast_fp16)[name = tensor<string, []>("zero_mean_111_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_111_cast_fp16 = mul(x = zero_mean_111_cast_fp16, y = zero_mean_111_cast_fp16)[name = tensor<string, []>("zero_mean_sq_111_cast_fp16")];
            tensor<int32, [1]> var_7475 = const()[name = tensor<string, []>("op_7475"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_7476_cast_fp16 = reduce_mean(axes = var_7475, keep_dims = var_7300, x = zero_mean_sq_111_cast_fp16)[name = tensor<string, []>("op_7476_cast_fp16")];
            tensor<fp16, []> var_7477_to_fp16 = const()[name = tensor<string, []>("op_7477_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_7478_cast_fp16 = add(x = var_7476_cast_fp16, y = var_7477_to_fp16)[name = tensor<string, []>("op_7478_cast_fp16")];
            tensor<fp32, []> denom_111_epsilon_0 = const()[name = tensor<string, []>("denom_111_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_111_cast_fp16 = rsqrt(epsilon = denom_111_epsilon_0, x = var_7478_cast_fp16)[name = tensor<string, []>("denom_111_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_111_cast_fp16 = mul(x = zero_mean_111_cast_fp16, y = denom_111_cast_fp16)[name = tensor<string, []>("out_111_cast_fp16")];
            tensor<fp16, [1280]> obj_261_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_261_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(395152896)))];
            tensor<fp16, [1280]> obj_261_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_261_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(395155520)))];
            tensor<fp16, []> obj_261_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_261_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_261_cast_fp16 = batch_norm(beta = obj_261_beta_0_to_fp16, epsilon = obj_261_epsilon_0_to_fp16, gamma = obj_261_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_111_cast_fp16)[name = tensor<string, []>("obj_261_cast_fp16")];
            tensor<int32, [2]> var_7496 = const()[name = tensor<string, []>("op_7496"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7498 = const()[name = tensor<string, []>("op_7498"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_369_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_369_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_369_pad_0 = const()[name = tensor<string, []>("pretrained_out_369_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_18_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(395158144))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(395977408))), name = tensor<string, []>("layers_18_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_18_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_18_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(395977536)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_369_cast_fp16 = conv(bias = layers_18_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_7498, groups = var_7299, pad = pretrained_out_369_pad_0, pad_type = pretrained_out_369_pad_type_0, strides = var_7496, weight = layers_18_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_261_cast_fp16)[name = tensor<string, []>("pretrained_out_369_cast_fp16")];
            tensor<int32, [2]> var_7502 = const()[name = tensor<string, []>("op_7502"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7504 = const()[name = tensor<string, []>("op_7504"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_551_pad_type_0 = const()[name = tensor<string, []>("input_551_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_551_pad_0 = const()[name = tensor<string, []>("input_551_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_18_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_18_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(395980160)))];
            tensor<fp16, [1, 16, 1, 1]> input_551_cast_fp16 = conv(dilations = var_7504, groups = var_7299, pad = input_551_pad_0, pad_type = input_551_pad_type_0, strides = var_7502, weight = layers_18_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_261_cast_fp16)[name = tensor<string, []>("input_551_cast_fp16")];
            tensor<int32, [2]> var_7508 = const()[name = tensor<string, []>("op_7508"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7510 = const()[name = tensor<string, []>("op_7510"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_737_pad_type_0 = const()[name = tensor<string, []>("lora_out_737_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_737_pad_0 = const()[name = tensor<string, []>("lora_out_737_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_739_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_739_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(396021184)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_739_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_7510, groups = var_7299, pad = lora_out_737_pad_0, pad_type = lora_out_737_pad_type_0, strides = var_7508, weight = lora_out_739_weight_0_to_fp16, x = input_551_cast_fp16)[name = tensor<string, []>("lora_out_739_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_75_cast_fp16 = add(x = pretrained_out_369_cast_fp16, y = lora_out_739_cast_fp16)[name = tensor<string, []>("query_75_cast_fp16")];
            tensor<int32, [2]> var_7520 = const()[name = tensor<string, []>("op_7520"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7522 = const()[name = tensor<string, []>("op_7522"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_371_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_371_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_371_pad_0 = const()[name = tensor<string, []>("pretrained_out_371_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_18_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(396062208))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(396881472))), name = tensor<string, []>("layers_18_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_371_cast_fp16 = conv(dilations = var_7522, groups = var_7299, pad = pretrained_out_371_pad_0, pad_type = pretrained_out_371_pad_type_0, strides = var_7520, weight = layers_18_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_371_cast_fp16")];
            tensor<int32, [2]> var_7526 = const()[name = tensor<string, []>("op_7526"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7528 = const()[name = tensor<string, []>("op_7528"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_553_pad_type_0 = const()[name = tensor<string, []>("input_553_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_553_pad_0 = const()[name = tensor<string, []>("input_553_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_18_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_18_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(396881600)))];
            tensor<fp16, [1, 16, 1, 1500]> input_553_cast_fp16 = conv(dilations = var_7528, groups = var_7299, pad = input_553_pad_0, pad_type = input_553_pad_type_0, strides = var_7526, weight = layers_18_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_553_cast_fp16")];
            tensor<int32, [2]> var_7532 = const()[name = tensor<string, []>("op_7532"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7534 = const()[name = tensor<string, []>("op_7534"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_741_pad_type_0 = const()[name = tensor<string, []>("lora_out_741_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_741_pad_0 = const()[name = tensor<string, []>("lora_out_741_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_743_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_743_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(396922624)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_743_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_7534, groups = var_7299, pad = lora_out_741_pad_0, pad_type = lora_out_741_pad_type_0, strides = var_7532, weight = lora_out_743_weight_0_to_fp16, x = input_553_cast_fp16)[name = tensor<string, []>("lora_out_743_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_75_cast_fp16 = add(x = pretrained_out_371_cast_fp16, y = lora_out_743_cast_fp16)[name = tensor<string, []>("key_75_cast_fp16")];
            tensor<int32, [2]> var_7545 = const()[name = tensor<string, []>("op_7545"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7547 = const()[name = tensor<string, []>("op_7547"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_373_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_373_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_373_pad_0 = const()[name = tensor<string, []>("pretrained_out_373_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_18_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(396963648))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(397782912))), name = tensor<string, []>("layers_18_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_18_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_18_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(397783040)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_373_cast_fp16 = conv(bias = layers_18_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_7547, groups = var_7299, pad = pretrained_out_373_pad_0, pad_type = pretrained_out_373_pad_type_0, strides = var_7545, weight = layers_18_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_373_cast_fp16")];
            tensor<int32, [2]> var_7551 = const()[name = tensor<string, []>("op_7551"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7553 = const()[name = tensor<string, []>("op_7553"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_555_pad_type_0 = const()[name = tensor<string, []>("input_555_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_555_pad_0 = const()[name = tensor<string, []>("input_555_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_18_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_18_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(397785664)))];
            tensor<fp16, [1, 16, 1, 1500]> input_555_cast_fp16 = conv(dilations = var_7553, groups = var_7299, pad = input_555_pad_0, pad_type = input_555_pad_type_0, strides = var_7551, weight = layers_18_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_555_cast_fp16")];
            tensor<int32, [2]> var_7557 = const()[name = tensor<string, []>("op_7557"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7559 = const()[name = tensor<string, []>("op_7559"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_745_pad_type_0 = const()[name = tensor<string, []>("lora_out_745_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_745_pad_0 = const()[name = tensor<string, []>("lora_out_745_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_747_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_747_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(397826688)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_747_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_7559, groups = var_7299, pad = lora_out_745_pad_0, pad_type = lora_out_745_pad_type_0, strides = var_7557, weight = lora_out_747_weight_0_to_fp16, x = input_555_cast_fp16)[name = tensor<string, []>("lora_out_747_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_75_cast_fp16 = add(x = pretrained_out_373_cast_fp16, y = lora_out_747_cast_fp16)[name = tensor<string, []>("value_75_cast_fp16")];
            tensor<int32, [4]> var_7566 = const()[name = tensor<string, []>("op_7566"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_7567_cast_fp16 = reshape(shape = var_7566, x = query_75_cast_fp16)[name = tensor<string, []>("op_7567_cast_fp16")];
            tensor<fp16, []> var_7568_to_fp16 = const()[name = tensor<string, []>("op_7568_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_7569_cast_fp16 = mul(x = var_7567_cast_fp16, y = var_7568_to_fp16)[name = tensor<string, []>("op_7569_cast_fp16")];
            tensor<int32, [4]> var_7570 = const()[name = tensor<string, []>("op_7570"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_7571_cast_fp16 = reshape(shape = var_7570, x = key_75_cast_fp16)[name = tensor<string, []>("op_7571_cast_fp16")];
            tensor<bool, []> mh_w_113_transpose_x_0 = const()[name = tensor<string, []>("mh_w_113_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_113_transpose_y_0 = const()[name = tensor<string, []>("mh_w_113_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_113_cast_fp16 = matmul(transpose_x = mh_w_113_transpose_x_0, transpose_y = mh_w_113_transpose_y_0, x = var_7569_cast_fp16, y = var_7571_cast_fp16)[name = tensor<string, []>("mh_w_113_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_265_cast_fp16 = softmax(axis = var_7292, x = mh_w_113_cast_fp16)[name = tensor<string, []>("obj_265_cast_fp16")];
            tensor<int32, [4]> var_7575 = const()[name = tensor<string, []>("op_7575"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_7576_cast_fp16 = reshape(shape = var_7575, x = value_75_cast_fp16)[name = tensor<string, []>("op_7576_cast_fp16")];
            tensor<bool, []> attn_75_transpose_x_0 = const()[name = tensor<string, []>("attn_75_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_75_transpose_y_0 = const()[name = tensor<string, []>("attn_75_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_75_cast_fp16 = matmul(transpose_x = attn_75_transpose_x_0, transpose_y = attn_75_transpose_y_0, x = var_7576_cast_fp16, y = obj_265_cast_fp16)[name = tensor<string, []>("attn_75_cast_fp16")];
            tensor<int32, [4]> var_7579 = const()[name = tensor<string, []>("op_7579"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_557_cast_fp16 = reshape(shape = var_7579, x = attn_75_cast_fp16)[name = tensor<string, []>("input_557_cast_fp16")];
            tensor<int32, [2]> var_7586 = const()[name = tensor<string, []>("op_7586"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7588 = const()[name = tensor<string, []>("op_7588"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_375_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_375_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_375_pad_0 = const()[name = tensor<string, []>("pretrained_out_375_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_18_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(397867712))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(398686976))), name = tensor<string, []>("layers_18_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_18_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_18_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(398687104)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_375_cast_fp16 = conv(bias = layers_18_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_7588, groups = var_7299, pad = pretrained_out_375_pad_0, pad_type = pretrained_out_375_pad_type_0, strides = var_7586, weight = layers_18_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_557_cast_fp16)[name = tensor<string, []>("pretrained_out_375_cast_fp16")];
            tensor<int32, [2]> var_7592 = const()[name = tensor<string, []>("op_7592"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7594 = const()[name = tensor<string, []>("op_7594"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_559_pad_type_0 = const()[name = tensor<string, []>("input_559_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_559_pad_0 = const()[name = tensor<string, []>("input_559_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_18_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_18_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(398689728)))];
            tensor<fp16, [1, 16, 1, 1]> input_559_cast_fp16 = conv(dilations = var_7594, groups = var_7299, pad = input_559_pad_0, pad_type = input_559_pad_type_0, strides = var_7592, weight = layers_18_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_557_cast_fp16)[name = tensor<string, []>("input_559_cast_fp16")];
            tensor<int32, [2]> var_7598 = const()[name = tensor<string, []>("op_7598"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7600 = const()[name = tensor<string, []>("op_7600"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_749_pad_type_0 = const()[name = tensor<string, []>("lora_out_749_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_749_pad_0 = const()[name = tensor<string, []>("lora_out_749_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_751_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_751_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(398730752)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_751_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_7600, groups = var_7299, pad = lora_out_749_pad_0, pad_type = lora_out_749_pad_type_0, strides = var_7598, weight = lora_out_751_weight_0_to_fp16, x = input_559_cast_fp16)[name = tensor<string, []>("lora_out_751_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_263_cast_fp16 = add(x = pretrained_out_375_cast_fp16, y = lora_out_751_cast_fp16)[name = tensor<string, []>("obj_263_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_113_cast_fp16 = add(x = inputs_111_cast_fp16, y = obj_263_cast_fp16)[name = tensor<string, []>("inputs_113_cast_fp16")];
            tensor<int32, [1]> var_7609 = const()[name = tensor<string, []>("op_7609"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_113_cast_fp16 = reduce_mean(axes = var_7609, keep_dims = var_7300, x = inputs_113_cast_fp16)[name = tensor<string, []>("channels_mean_113_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_113_cast_fp16 = sub(x = inputs_113_cast_fp16, y = channels_mean_113_cast_fp16)[name = tensor<string, []>("zero_mean_113_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_113_cast_fp16 = mul(x = zero_mean_113_cast_fp16, y = zero_mean_113_cast_fp16)[name = tensor<string, []>("zero_mean_sq_113_cast_fp16")];
            tensor<int32, [1]> var_7613 = const()[name = tensor<string, []>("op_7613"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_7614_cast_fp16 = reduce_mean(axes = var_7613, keep_dims = var_7300, x = zero_mean_sq_113_cast_fp16)[name = tensor<string, []>("op_7614_cast_fp16")];
            tensor<fp16, []> var_7615_to_fp16 = const()[name = tensor<string, []>("op_7615_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_7616_cast_fp16 = add(x = var_7614_cast_fp16, y = var_7615_to_fp16)[name = tensor<string, []>("op_7616_cast_fp16")];
            tensor<fp32, []> denom_113_epsilon_0 = const()[name = tensor<string, []>("denom_113_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_113_cast_fp16 = rsqrt(epsilon = denom_113_epsilon_0, x = var_7616_cast_fp16)[name = tensor<string, []>("denom_113_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_113_cast_fp16 = mul(x = zero_mean_113_cast_fp16, y = denom_113_cast_fp16)[name = tensor<string, []>("out_113_cast_fp16")];
            tensor<fp16, [1280]> input_561_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_561_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(398771776)))];
            tensor<fp16, [1280]> input_561_beta_0_to_fp16 = const()[name = tensor<string, []>("input_561_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(398774400)))];
            tensor<fp16, []> input_561_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_561_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_561_cast_fp16 = batch_norm(beta = input_561_beta_0_to_fp16, epsilon = input_561_epsilon_0_to_fp16, gamma = input_561_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_113_cast_fp16)[name = tensor<string, []>("input_561_cast_fp16")];
            tensor<int32, [2]> var_7630 = const()[name = tensor<string, []>("op_7630"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7632 = const()[name = tensor<string, []>("op_7632"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_377_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_377_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_377_pad_0 = const()[name = tensor<string, []>("pretrained_out_377_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_18_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(398777024))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(402053888))), name = tensor<string, []>("layers_18_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_18_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_18_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(402054016)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_377_cast_fp16 = conv(bias = layers_18_fc1_pretrained_bias_to_fp16, dilations = var_7632, groups = var_7299, pad = pretrained_out_377_pad_0, pad_type = pretrained_out_377_pad_type_0, strides = var_7630, weight = layers_18_fc1_pretrained_weight_to_fp16_palettized, x = input_561_cast_fp16)[name = tensor<string, []>("pretrained_out_377_cast_fp16")];
            tensor<int32, [2]> var_7636 = const()[name = tensor<string, []>("op_7636"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7638 = const()[name = tensor<string, []>("op_7638"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_563_pad_type_0 = const()[name = tensor<string, []>("input_563_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_563_pad_0 = const()[name = tensor<string, []>("input_563_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_18_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_18_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(402064320)))];
            tensor<fp16, [1, 16, 1, 1]> input_563_cast_fp16 = conv(dilations = var_7638, groups = var_7299, pad = input_563_pad_0, pad_type = input_563_pad_type_0, strides = var_7636, weight = layers_18_fc1_loraA_weight_to_fp16, x = input_561_cast_fp16)[name = tensor<string, []>("input_563_cast_fp16")];
            tensor<int32, [2]> var_7642 = const()[name = tensor<string, []>("op_7642"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7644 = const()[name = tensor<string, []>("op_7644"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_753_pad_type_0 = const()[name = tensor<string, []>("lora_out_753_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_753_pad_0 = const()[name = tensor<string, []>("lora_out_753_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_755_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_755_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(402105344)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_755_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_7644, groups = var_7299, pad = lora_out_753_pad_0, pad_type = lora_out_753_pad_type_0, strides = var_7642, weight = lora_out_755_weight_0_to_fp16, x = input_563_cast_fp16)[name = tensor<string, []>("lora_out_755_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_565_cast_fp16 = add(x = pretrained_out_377_cast_fp16, y = lora_out_755_cast_fp16)[name = tensor<string, []>("input_565_cast_fp16")];
            tensor<string, []> input_567_mode_0 = const()[name = tensor<string, []>("input_567_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_567_cast_fp16 = gelu(mode = input_567_mode_0, x = input_565_cast_fp16)[name = tensor<string, []>("input_567_cast_fp16")];
            tensor<int32, [2]> var_7656 = const()[name = tensor<string, []>("op_7656"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7658 = const()[name = tensor<string, []>("op_7658"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_379_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_379_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_379_pad_0 = const()[name = tensor<string, []>("pretrained_out_379_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_18_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(402269248))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(405546112))), name = tensor<string, []>("layers_18_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_18_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_18_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(405546240)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_379_cast_fp16 = conv(bias = layers_18_fc2_pretrained_bias_to_fp16, dilations = var_7658, groups = var_7299, pad = pretrained_out_379_pad_0, pad_type = pretrained_out_379_pad_type_0, strides = var_7656, weight = layers_18_fc2_pretrained_weight_to_fp16_palettized, x = input_567_cast_fp16)[name = tensor<string, []>("pretrained_out_379_cast_fp16")];
            tensor<int32, [2]> var_7662 = const()[name = tensor<string, []>("op_7662"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7664 = const()[name = tensor<string, []>("op_7664"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_569_pad_type_0 = const()[name = tensor<string, []>("input_569_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_569_pad_0 = const()[name = tensor<string, []>("input_569_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_18_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_18_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(405548864)))];
            tensor<fp16, [1, 16, 1, 1]> input_569_cast_fp16 = conv(dilations = var_7664, groups = var_7299, pad = input_569_pad_0, pad_type = input_569_pad_type_0, strides = var_7662, weight = layers_18_fc2_loraA_weight_to_fp16, x = input_567_cast_fp16)[name = tensor<string, []>("input_569_cast_fp16")];
            tensor<int32, [2]> var_7668 = const()[name = tensor<string, []>("op_7668"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7670 = const()[name = tensor<string, []>("op_7670"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_757_pad_type_0 = const()[name = tensor<string, []>("lora_out_757_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_757_pad_0 = const()[name = tensor<string, []>("lora_out_757_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_759_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_759_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(405712768)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_759_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_7670, groups = var_7299, pad = lora_out_757_pad_0, pad_type = lora_out_757_pad_type_0, strides = var_7668, weight = lora_out_759_weight_0_to_fp16, x = input_569_cast_fp16)[name = tensor<string, []>("lora_out_759_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_39_cast_fp16 = add(x = pretrained_out_379_cast_fp16, y = lora_out_759_cast_fp16)[name = tensor<string, []>("hidden_states_39_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_115_cast_fp16 = add(x = inputs_113_cast_fp16, y = hidden_states_39_cast_fp16)[name = tensor<string, []>("inputs_115_cast_fp16")];
            tensor<int32, []> var_7686 = const()[name = tensor<string, []>("op_7686"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_7693 = const()[name = tensor<string, []>("op_7693"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_7694 = const()[name = tensor<string, []>("op_7694"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_7706 = const()[name = tensor<string, []>("op_7706"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_115_cast_fp16 = reduce_mean(axes = var_7706, keep_dims = var_7694, x = inputs_115_cast_fp16)[name = tensor<string, []>("channels_mean_115_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_115_cast_fp16 = sub(x = inputs_115_cast_fp16, y = channels_mean_115_cast_fp16)[name = tensor<string, []>("zero_mean_115_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_115_cast_fp16 = mul(x = zero_mean_115_cast_fp16, y = zero_mean_115_cast_fp16)[name = tensor<string, []>("zero_mean_sq_115_cast_fp16")];
            tensor<int32, [1]> var_7710 = const()[name = tensor<string, []>("op_7710"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_7711_cast_fp16 = reduce_mean(axes = var_7710, keep_dims = var_7694, x = zero_mean_sq_115_cast_fp16)[name = tensor<string, []>("op_7711_cast_fp16")];
            tensor<fp16, []> var_7712_to_fp16 = const()[name = tensor<string, []>("op_7712_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_7713_cast_fp16 = add(x = var_7711_cast_fp16, y = var_7712_to_fp16)[name = tensor<string, []>("op_7713_cast_fp16")];
            tensor<fp32, []> denom_115_epsilon_0 = const()[name = tensor<string, []>("denom_115_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_115_cast_fp16 = rsqrt(epsilon = denom_115_epsilon_0, x = var_7713_cast_fp16)[name = tensor<string, []>("denom_115_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_115_cast_fp16 = mul(x = zero_mean_115_cast_fp16, y = denom_115_cast_fp16)[name = tensor<string, []>("out_115_cast_fp16")];
            tensor<fp16, [1280]> obj_267_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_267_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(405753792)))];
            tensor<fp16, [1280]> obj_267_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_267_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(405756416)))];
            tensor<fp16, []> obj_267_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_267_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_267_cast_fp16 = batch_norm(beta = obj_267_beta_0_to_fp16, epsilon = obj_267_epsilon_0_to_fp16, gamma = obj_267_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_115_cast_fp16)[name = tensor<string, []>("obj_267_cast_fp16")];
            tensor<int32, [2]> var_7731 = const()[name = tensor<string, []>("op_7731"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7733 = const()[name = tensor<string, []>("op_7733"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_381_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_381_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_381_pad_0 = const()[name = tensor<string, []>("pretrained_out_381_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_19_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(405759040))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(406578304))), name = tensor<string, []>("layers_19_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_19_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_19_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(406578432)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_381_cast_fp16 = conv(bias = layers_19_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_7733, groups = var_7693, pad = pretrained_out_381_pad_0, pad_type = pretrained_out_381_pad_type_0, strides = var_7731, weight = layers_19_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_267_cast_fp16)[name = tensor<string, []>("pretrained_out_381_cast_fp16")];
            tensor<int32, [2]> var_7737 = const()[name = tensor<string, []>("op_7737"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7739 = const()[name = tensor<string, []>("op_7739"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_571_pad_type_0 = const()[name = tensor<string, []>("input_571_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_571_pad_0 = const()[name = tensor<string, []>("input_571_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_19_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_19_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(406581056)))];
            tensor<fp16, [1, 16, 1, 1]> input_571_cast_fp16 = conv(dilations = var_7739, groups = var_7693, pad = input_571_pad_0, pad_type = input_571_pad_type_0, strides = var_7737, weight = layers_19_self_attn_q_proj_loraA_weight_to_fp16, x = obj_267_cast_fp16)[name = tensor<string, []>("input_571_cast_fp16")];
            tensor<int32, [2]> var_7743 = const()[name = tensor<string, []>("op_7743"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7745 = const()[name = tensor<string, []>("op_7745"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_761_pad_type_0 = const()[name = tensor<string, []>("lora_out_761_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_761_pad_0 = const()[name = tensor<string, []>("lora_out_761_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_763_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_763_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(406622080)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_763_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_7745, groups = var_7693, pad = lora_out_761_pad_0, pad_type = lora_out_761_pad_type_0, strides = var_7743, weight = lora_out_763_weight_0_to_fp16, x = input_571_cast_fp16)[name = tensor<string, []>("lora_out_763_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_77_cast_fp16 = add(x = pretrained_out_381_cast_fp16, y = lora_out_763_cast_fp16)[name = tensor<string, []>("query_77_cast_fp16")];
            tensor<int32, [2]> var_7755 = const()[name = tensor<string, []>("op_7755"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7757 = const()[name = tensor<string, []>("op_7757"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_383_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_383_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_383_pad_0 = const()[name = tensor<string, []>("pretrained_out_383_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_19_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(406663104))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(407482368))), name = tensor<string, []>("layers_19_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_383_cast_fp16 = conv(dilations = var_7757, groups = var_7693, pad = pretrained_out_383_pad_0, pad_type = pretrained_out_383_pad_type_0, strides = var_7755, weight = layers_19_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_267_cast_fp16)[name = tensor<string, []>("pretrained_out_383_cast_fp16")];
            tensor<int32, [2]> var_7761 = const()[name = tensor<string, []>("op_7761"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7763 = const()[name = tensor<string, []>("op_7763"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_573_pad_type_0 = const()[name = tensor<string, []>("input_573_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_573_pad_0 = const()[name = tensor<string, []>("input_573_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_19_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_19_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(407482496)))];
            tensor<fp16, [1, 16, 1, 1]> input_573_cast_fp16 = conv(dilations = var_7763, groups = var_7693, pad = input_573_pad_0, pad_type = input_573_pad_type_0, strides = var_7761, weight = layers_19_self_attn_k_proj_loraA_weight_to_fp16, x = obj_267_cast_fp16)[name = tensor<string, []>("input_573_cast_fp16")];
            tensor<int32, [2]> var_7767 = const()[name = tensor<string, []>("op_7767"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7769 = const()[name = tensor<string, []>("op_7769"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_765_pad_type_0 = const()[name = tensor<string, []>("lora_out_765_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_765_pad_0 = const()[name = tensor<string, []>("lora_out_765_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_767_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_767_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(407523520)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_767_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_7769, groups = var_7693, pad = lora_out_765_pad_0, pad_type = lora_out_765_pad_type_0, strides = var_7767, weight = lora_out_767_weight_0_to_fp16, x = input_573_cast_fp16)[name = tensor<string, []>("lora_out_767_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_39_cast_fp16 = add(x = pretrained_out_383_cast_fp16, y = lora_out_767_cast_fp16)[name = tensor<string, []>("current_key_39_cast_fp16")];
            tensor<int32, [2]> var_7780 = const()[name = tensor<string, []>("op_7780"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7782 = const()[name = tensor<string, []>("op_7782"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_385_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_385_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_385_pad_0 = const()[name = tensor<string, []>("pretrained_out_385_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_19_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(407564544))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(408383808))), name = tensor<string, []>("layers_19_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_19_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_19_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(408383936)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_385_cast_fp16 = conv(bias = layers_19_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_7782, groups = var_7693, pad = pretrained_out_385_pad_0, pad_type = pretrained_out_385_pad_type_0, strides = var_7780, weight = layers_19_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_267_cast_fp16)[name = tensor<string, []>("pretrained_out_385_cast_fp16")];
            tensor<int32, [2]> var_7786 = const()[name = tensor<string, []>("op_7786"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7788 = const()[name = tensor<string, []>("op_7788"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_575_pad_type_0 = const()[name = tensor<string, []>("input_575_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_575_pad_0 = const()[name = tensor<string, []>("input_575_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_19_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_19_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(408386560)))];
            tensor<fp16, [1, 16, 1, 1]> input_575_cast_fp16 = conv(dilations = var_7788, groups = var_7693, pad = input_575_pad_0, pad_type = input_575_pad_type_0, strides = var_7786, weight = layers_19_self_attn_v_proj_loraA_weight_to_fp16, x = obj_267_cast_fp16)[name = tensor<string, []>("input_575_cast_fp16")];
            tensor<int32, [2]> var_7792 = const()[name = tensor<string, []>("op_7792"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7794 = const()[name = tensor<string, []>("op_7794"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_769_pad_type_0 = const()[name = tensor<string, []>("lora_out_769_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_769_pad_0 = const()[name = tensor<string, []>("lora_out_769_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_771_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_771_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(408427584)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_771_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_7794, groups = var_7693, pad = lora_out_769_pad_0, pad_type = lora_out_769_pad_type_0, strides = var_7792, weight = lora_out_771_weight_0_to_fp16, x = input_575_cast_fp16)[name = tensor<string, []>("lora_out_771_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_39_cast_fp16 = add(x = pretrained_out_385_cast_fp16, y = lora_out_771_cast_fp16)[name = tensor<string, []>("current_value_39_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_7804_cast_fp16 = mul(x = current_key_39_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_7804_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_7806_cast_fp16 = mul(x = var_103_cast_fp16_19, y = var_295_cast_fp16)[name = tensor<string, []>("op_7806_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_77_cast_fp16 = add(x = var_7804_cast_fp16, y = var_7806_cast_fp16)[name = tensor<string, []>("key_77_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_7808_cast_fp16 = mul(x = current_value_39_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_7808_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_7810_cast_fp16 = mul(x = var_138_cast_fp16_19, y = var_295_cast_fp16)[name = tensor<string, []>("op_7810_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_77_cast_fp16 = add(x = var_7808_cast_fp16, y = var_7810_cast_fp16)[name = tensor<string, []>("value_77_cast_fp16")];
            tensor<int32, [4]> var_7813 = const()[name = tensor<string, []>("op_7813"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_7814_cast_fp16 = reshape(shape = var_7813, x = query_77_cast_fp16)[name = tensor<string, []>("op_7814_cast_fp16")];
            tensor<fp16, []> var_7815_to_fp16 = const()[name = tensor<string, []>("op_7815_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_7816_cast_fp16 = mul(x = var_7814_cast_fp16, y = var_7815_to_fp16)[name = tensor<string, []>("op_7816_cast_fp16")];
            tensor<int32, [4]> var_7817 = const()[name = tensor<string, []>("op_7817"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_7818_cast_fp16 = reshape(shape = var_7817, x = key_77_cast_fp16)[name = tensor<string, []>("op_7818_cast_fp16")];
            tensor<bool, []> mh_w_115_transpose_x_0 = const()[name = tensor<string, []>("mh_w_115_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_115_transpose_y_0 = const()[name = tensor<string, []>("mh_w_115_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_115_cast_fp16 = matmul(transpose_x = mh_w_115_transpose_x_0, transpose_y = mh_w_115_transpose_y_0, x = var_7816_cast_fp16, y = var_7818_cast_fp16)[name = tensor<string, []>("mh_w_115_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_117_cast_fp16 = add(x = mh_w_115_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_117_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_7826_cast_fp16 = softmax(axis = var_7686, x = mh_w_117_cast_fp16)[name = tensor<string, []>("op_7826_cast_fp16")];
            tensor<int32, [4]> var_7827 = const()[name = tensor<string, []>("op_7827"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_7828_cast_fp16 = reshape(shape = var_7827, x = value_77_cast_fp16)[name = tensor<string, []>("op_7828_cast_fp16")];
            tensor<bool, []> attn_77_transpose_x_0 = const()[name = tensor<string, []>("attn_77_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_77_transpose_y_0 = const()[name = tensor<string, []>("attn_77_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_77_cast_fp16 = matmul(transpose_x = attn_77_transpose_x_0, transpose_y = attn_77_transpose_y_0, x = var_7828_cast_fp16, y = var_7826_cast_fp16)[name = tensor<string, []>("attn_77_cast_fp16")];
            tensor<int32, [4]> var_7831 = const()[name = tensor<string, []>("op_7831"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_577_cast_fp16 = reshape(shape = var_7831, x = attn_77_cast_fp16)[name = tensor<string, []>("input_577_cast_fp16")];
            tensor<int32, [2]> var_7838 = const()[name = tensor<string, []>("op_7838"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7840 = const()[name = tensor<string, []>("op_7840"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_387_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_387_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_387_pad_0 = const()[name = tensor<string, []>("pretrained_out_387_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_19_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(408468608))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(409287872))), name = tensor<string, []>("layers_19_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_19_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_19_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(409288000)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_387_cast_fp16 = conv(bias = layers_19_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_7840, groups = var_7693, pad = pretrained_out_387_pad_0, pad_type = pretrained_out_387_pad_type_0, strides = var_7838, weight = layers_19_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_577_cast_fp16)[name = tensor<string, []>("pretrained_out_387_cast_fp16")];
            tensor<int32, [2]> var_7844 = const()[name = tensor<string, []>("op_7844"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7846 = const()[name = tensor<string, []>("op_7846"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_579_pad_type_0 = const()[name = tensor<string, []>("input_579_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_579_pad_0 = const()[name = tensor<string, []>("input_579_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_19_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_19_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(409290624)))];
            tensor<fp16, [1, 16, 1, 1]> input_579_cast_fp16 = conv(dilations = var_7846, groups = var_7693, pad = input_579_pad_0, pad_type = input_579_pad_type_0, strides = var_7844, weight = layers_19_self_attn_o_proj_loraA_weight_to_fp16, x = input_577_cast_fp16)[name = tensor<string, []>("input_579_cast_fp16")];
            tensor<int32, [2]> var_7850 = const()[name = tensor<string, []>("op_7850"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7852 = const()[name = tensor<string, []>("op_7852"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_773_pad_type_0 = const()[name = tensor<string, []>("lora_out_773_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_773_pad_0 = const()[name = tensor<string, []>("lora_out_773_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_775_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_775_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(409331648)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_775_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_7852, groups = var_7693, pad = lora_out_773_pad_0, pad_type = lora_out_773_pad_type_0, strides = var_7850, weight = lora_out_775_weight_0_to_fp16, x = input_579_cast_fp16)[name = tensor<string, []>("lora_out_775_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_273_cast_fp16 = add(x = pretrained_out_387_cast_fp16, y = lora_out_775_cast_fp16)[name = tensor<string, []>("obj_273_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_117_cast_fp16 = add(x = inputs_115_cast_fp16, y = obj_273_cast_fp16)[name = tensor<string, []>("inputs_117_cast_fp16")];
            tensor<int32, [1]> var_7865 = const()[name = tensor<string, []>("op_7865"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_117_cast_fp16 = reduce_mean(axes = var_7865, keep_dims = var_7694, x = inputs_117_cast_fp16)[name = tensor<string, []>("channels_mean_117_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_117_cast_fp16 = sub(x = inputs_117_cast_fp16, y = channels_mean_117_cast_fp16)[name = tensor<string, []>("zero_mean_117_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_117_cast_fp16 = mul(x = zero_mean_117_cast_fp16, y = zero_mean_117_cast_fp16)[name = tensor<string, []>("zero_mean_sq_117_cast_fp16")];
            tensor<int32, [1]> var_7869 = const()[name = tensor<string, []>("op_7869"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_7870_cast_fp16 = reduce_mean(axes = var_7869, keep_dims = var_7694, x = zero_mean_sq_117_cast_fp16)[name = tensor<string, []>("op_7870_cast_fp16")];
            tensor<fp16, []> var_7871_to_fp16 = const()[name = tensor<string, []>("op_7871_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_7872_cast_fp16 = add(x = var_7870_cast_fp16, y = var_7871_to_fp16)[name = tensor<string, []>("op_7872_cast_fp16")];
            tensor<fp32, []> denom_117_epsilon_0 = const()[name = tensor<string, []>("denom_117_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_117_cast_fp16 = rsqrt(epsilon = denom_117_epsilon_0, x = var_7872_cast_fp16)[name = tensor<string, []>("denom_117_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_117_cast_fp16 = mul(x = zero_mean_117_cast_fp16, y = denom_117_cast_fp16)[name = tensor<string, []>("out_117_cast_fp16")];
            tensor<fp16, [1280]> obj_275_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_275_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(409372672)))];
            tensor<fp16, [1280]> obj_275_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_275_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(409375296)))];
            tensor<fp16, []> obj_275_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_275_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_275_cast_fp16 = batch_norm(beta = obj_275_beta_0_to_fp16, epsilon = obj_275_epsilon_0_to_fp16, gamma = obj_275_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_117_cast_fp16)[name = tensor<string, []>("obj_275_cast_fp16")];
            tensor<int32, [2]> var_7890 = const()[name = tensor<string, []>("op_7890"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7892 = const()[name = tensor<string, []>("op_7892"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_389_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_389_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_389_pad_0 = const()[name = tensor<string, []>("pretrained_out_389_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_19_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(409377920))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(410197184))), name = tensor<string, []>("layers_19_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_19_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_19_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(410197312)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_389_cast_fp16 = conv(bias = layers_19_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_7892, groups = var_7693, pad = pretrained_out_389_pad_0, pad_type = pretrained_out_389_pad_type_0, strides = var_7890, weight = layers_19_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_275_cast_fp16)[name = tensor<string, []>("pretrained_out_389_cast_fp16")];
            tensor<int32, [2]> var_7896 = const()[name = tensor<string, []>("op_7896"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7898 = const()[name = tensor<string, []>("op_7898"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_581_pad_type_0 = const()[name = tensor<string, []>("input_581_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_581_pad_0 = const()[name = tensor<string, []>("input_581_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_19_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_19_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(410199936)))];
            tensor<fp16, [1, 16, 1, 1]> input_581_cast_fp16 = conv(dilations = var_7898, groups = var_7693, pad = input_581_pad_0, pad_type = input_581_pad_type_0, strides = var_7896, weight = layers_19_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_275_cast_fp16)[name = tensor<string, []>("input_581_cast_fp16")];
            tensor<int32, [2]> var_7902 = const()[name = tensor<string, []>("op_7902"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7904 = const()[name = tensor<string, []>("op_7904"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_777_pad_type_0 = const()[name = tensor<string, []>("lora_out_777_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_777_pad_0 = const()[name = tensor<string, []>("lora_out_777_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_779_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_779_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(410240960)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_779_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_7904, groups = var_7693, pad = lora_out_777_pad_0, pad_type = lora_out_777_pad_type_0, strides = var_7902, weight = lora_out_779_weight_0_to_fp16, x = input_581_cast_fp16)[name = tensor<string, []>("lora_out_779_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_79_cast_fp16 = add(x = pretrained_out_389_cast_fp16, y = lora_out_779_cast_fp16)[name = tensor<string, []>("query_79_cast_fp16")];
            tensor<int32, [2]> var_7914 = const()[name = tensor<string, []>("op_7914"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7916 = const()[name = tensor<string, []>("op_7916"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_391_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_391_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_391_pad_0 = const()[name = tensor<string, []>("pretrained_out_391_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_19_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(410281984))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(411101248))), name = tensor<string, []>("layers_19_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_391_cast_fp16 = conv(dilations = var_7916, groups = var_7693, pad = pretrained_out_391_pad_0, pad_type = pretrained_out_391_pad_type_0, strides = var_7914, weight = layers_19_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_391_cast_fp16")];
            tensor<int32, [2]> var_7920 = const()[name = tensor<string, []>("op_7920"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7922 = const()[name = tensor<string, []>("op_7922"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_583_pad_type_0 = const()[name = tensor<string, []>("input_583_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_583_pad_0 = const()[name = tensor<string, []>("input_583_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_19_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_19_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(411101376)))];
            tensor<fp16, [1, 16, 1, 1500]> input_583_cast_fp16 = conv(dilations = var_7922, groups = var_7693, pad = input_583_pad_0, pad_type = input_583_pad_type_0, strides = var_7920, weight = layers_19_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_583_cast_fp16")];
            tensor<int32, [2]> var_7926 = const()[name = tensor<string, []>("op_7926"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7928 = const()[name = tensor<string, []>("op_7928"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_781_pad_type_0 = const()[name = tensor<string, []>("lora_out_781_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_781_pad_0 = const()[name = tensor<string, []>("lora_out_781_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_783_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_783_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(411142400)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_783_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_7928, groups = var_7693, pad = lora_out_781_pad_0, pad_type = lora_out_781_pad_type_0, strides = var_7926, weight = lora_out_783_weight_0_to_fp16, x = input_583_cast_fp16)[name = tensor<string, []>("lora_out_783_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_79_cast_fp16 = add(x = pretrained_out_391_cast_fp16, y = lora_out_783_cast_fp16)[name = tensor<string, []>("key_79_cast_fp16")];
            tensor<int32, [2]> var_7939 = const()[name = tensor<string, []>("op_7939"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7941 = const()[name = tensor<string, []>("op_7941"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_393_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_393_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_393_pad_0 = const()[name = tensor<string, []>("pretrained_out_393_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_19_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(411183424))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(412002688))), name = tensor<string, []>("layers_19_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_19_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_19_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(412002816)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_393_cast_fp16 = conv(bias = layers_19_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_7941, groups = var_7693, pad = pretrained_out_393_pad_0, pad_type = pretrained_out_393_pad_type_0, strides = var_7939, weight = layers_19_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_393_cast_fp16")];
            tensor<int32, [2]> var_7945 = const()[name = tensor<string, []>("op_7945"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7947 = const()[name = tensor<string, []>("op_7947"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_585_pad_type_0 = const()[name = tensor<string, []>("input_585_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_585_pad_0 = const()[name = tensor<string, []>("input_585_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_19_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_19_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(412005440)))];
            tensor<fp16, [1, 16, 1, 1500]> input_585_cast_fp16 = conv(dilations = var_7947, groups = var_7693, pad = input_585_pad_0, pad_type = input_585_pad_type_0, strides = var_7945, weight = layers_19_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_585_cast_fp16")];
            tensor<int32, [2]> var_7951 = const()[name = tensor<string, []>("op_7951"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7953 = const()[name = tensor<string, []>("op_7953"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_785_pad_type_0 = const()[name = tensor<string, []>("lora_out_785_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_785_pad_0 = const()[name = tensor<string, []>("lora_out_785_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_787_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_787_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(412046464)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_787_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_7953, groups = var_7693, pad = lora_out_785_pad_0, pad_type = lora_out_785_pad_type_0, strides = var_7951, weight = lora_out_787_weight_0_to_fp16, x = input_585_cast_fp16)[name = tensor<string, []>("lora_out_787_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_79_cast_fp16 = add(x = pretrained_out_393_cast_fp16, y = lora_out_787_cast_fp16)[name = tensor<string, []>("value_79_cast_fp16")];
            tensor<int32, [4]> var_7960 = const()[name = tensor<string, []>("op_7960"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_7961_cast_fp16 = reshape(shape = var_7960, x = query_79_cast_fp16)[name = tensor<string, []>("op_7961_cast_fp16")];
            tensor<fp16, []> var_7962_to_fp16 = const()[name = tensor<string, []>("op_7962_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_7963_cast_fp16 = mul(x = var_7961_cast_fp16, y = var_7962_to_fp16)[name = tensor<string, []>("op_7963_cast_fp16")];
            tensor<int32, [4]> var_7964 = const()[name = tensor<string, []>("op_7964"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_7965_cast_fp16 = reshape(shape = var_7964, x = key_79_cast_fp16)[name = tensor<string, []>("op_7965_cast_fp16")];
            tensor<bool, []> mh_w_119_transpose_x_0 = const()[name = tensor<string, []>("mh_w_119_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_119_transpose_y_0 = const()[name = tensor<string, []>("mh_w_119_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_119_cast_fp16 = matmul(transpose_x = mh_w_119_transpose_x_0, transpose_y = mh_w_119_transpose_y_0, x = var_7963_cast_fp16, y = var_7965_cast_fp16)[name = tensor<string, []>("mh_w_119_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_279_cast_fp16 = softmax(axis = var_7686, x = mh_w_119_cast_fp16)[name = tensor<string, []>("obj_279_cast_fp16")];
            tensor<int32, [4]> var_7969 = const()[name = tensor<string, []>("op_7969"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_7970_cast_fp16 = reshape(shape = var_7969, x = value_79_cast_fp16)[name = tensor<string, []>("op_7970_cast_fp16")];
            tensor<bool, []> attn_79_transpose_x_0 = const()[name = tensor<string, []>("attn_79_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_79_transpose_y_0 = const()[name = tensor<string, []>("attn_79_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_79_cast_fp16 = matmul(transpose_x = attn_79_transpose_x_0, transpose_y = attn_79_transpose_y_0, x = var_7970_cast_fp16, y = obj_279_cast_fp16)[name = tensor<string, []>("attn_79_cast_fp16")];
            tensor<int32, [4]> var_7973 = const()[name = tensor<string, []>("op_7973"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_587_cast_fp16 = reshape(shape = var_7973, x = attn_79_cast_fp16)[name = tensor<string, []>("input_587_cast_fp16")];
            tensor<int32, [2]> var_7980 = const()[name = tensor<string, []>("op_7980"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7982 = const()[name = tensor<string, []>("op_7982"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_395_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_395_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_395_pad_0 = const()[name = tensor<string, []>("pretrained_out_395_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_19_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(412087488))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(412906752))), name = tensor<string, []>("layers_19_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_19_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_19_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(412906880)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_395_cast_fp16 = conv(bias = layers_19_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_7982, groups = var_7693, pad = pretrained_out_395_pad_0, pad_type = pretrained_out_395_pad_type_0, strides = var_7980, weight = layers_19_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_587_cast_fp16)[name = tensor<string, []>("pretrained_out_395_cast_fp16")];
            tensor<int32, [2]> var_7986 = const()[name = tensor<string, []>("op_7986"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7988 = const()[name = tensor<string, []>("op_7988"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_589_pad_type_0 = const()[name = tensor<string, []>("input_589_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_589_pad_0 = const()[name = tensor<string, []>("input_589_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_19_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_19_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(412909504)))];
            tensor<fp16, [1, 16, 1, 1]> input_589_cast_fp16 = conv(dilations = var_7988, groups = var_7693, pad = input_589_pad_0, pad_type = input_589_pad_type_0, strides = var_7986, weight = layers_19_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_587_cast_fp16)[name = tensor<string, []>("input_589_cast_fp16")];
            tensor<int32, [2]> var_7992 = const()[name = tensor<string, []>("op_7992"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_7994 = const()[name = tensor<string, []>("op_7994"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_789_pad_type_0 = const()[name = tensor<string, []>("lora_out_789_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_789_pad_0 = const()[name = tensor<string, []>("lora_out_789_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_791_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_791_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(412950528)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_791_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_7994, groups = var_7693, pad = lora_out_789_pad_0, pad_type = lora_out_789_pad_type_0, strides = var_7992, weight = lora_out_791_weight_0_to_fp16, x = input_589_cast_fp16)[name = tensor<string, []>("lora_out_791_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_277_cast_fp16 = add(x = pretrained_out_395_cast_fp16, y = lora_out_791_cast_fp16)[name = tensor<string, []>("obj_277_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_119_cast_fp16 = add(x = inputs_117_cast_fp16, y = obj_277_cast_fp16)[name = tensor<string, []>("inputs_119_cast_fp16")];
            tensor<int32, [1]> var_8006 = const()[name = tensor<string, []>("op_8006"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_119_cast_fp16 = reduce_mean(axes = var_8006, keep_dims = var_7694, x = inputs_119_cast_fp16)[name = tensor<string, []>("channels_mean_119_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_119_cast_fp16 = sub(x = inputs_119_cast_fp16, y = channels_mean_119_cast_fp16)[name = tensor<string, []>("zero_mean_119_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_119_cast_fp16 = mul(x = zero_mean_119_cast_fp16, y = zero_mean_119_cast_fp16)[name = tensor<string, []>("zero_mean_sq_119_cast_fp16")];
            tensor<int32, [1]> var_8010 = const()[name = tensor<string, []>("op_8010"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_8011_cast_fp16 = reduce_mean(axes = var_8010, keep_dims = var_7694, x = zero_mean_sq_119_cast_fp16)[name = tensor<string, []>("op_8011_cast_fp16")];
            tensor<fp16, []> var_8012_to_fp16 = const()[name = tensor<string, []>("op_8012_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_8013_cast_fp16 = add(x = var_8011_cast_fp16, y = var_8012_to_fp16)[name = tensor<string, []>("op_8013_cast_fp16")];
            tensor<fp32, []> denom_119_epsilon_0 = const()[name = tensor<string, []>("denom_119_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_119_cast_fp16 = rsqrt(epsilon = denom_119_epsilon_0, x = var_8013_cast_fp16)[name = tensor<string, []>("denom_119_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_119_cast_fp16 = mul(x = zero_mean_119_cast_fp16, y = denom_119_cast_fp16)[name = tensor<string, []>("out_119_cast_fp16")];
            tensor<fp16, [1280]> input_591_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_591_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(412991552)))];
            tensor<fp16, [1280]> input_591_beta_0_to_fp16 = const()[name = tensor<string, []>("input_591_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(412994176)))];
            tensor<fp16, []> input_591_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_591_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_591_cast_fp16 = batch_norm(beta = input_591_beta_0_to_fp16, epsilon = input_591_epsilon_0_to_fp16, gamma = input_591_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_119_cast_fp16)[name = tensor<string, []>("input_591_cast_fp16")];
            tensor<int32, [2]> var_8027 = const()[name = tensor<string, []>("op_8027"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8029 = const()[name = tensor<string, []>("op_8029"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_397_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_397_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_397_pad_0 = const()[name = tensor<string, []>("pretrained_out_397_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_19_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(412996800))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(416273664))), name = tensor<string, []>("layers_19_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_19_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_19_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(416273792)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_397_cast_fp16 = conv(bias = layers_19_fc1_pretrained_bias_to_fp16, dilations = var_8029, groups = var_7693, pad = pretrained_out_397_pad_0, pad_type = pretrained_out_397_pad_type_0, strides = var_8027, weight = layers_19_fc1_pretrained_weight_to_fp16_palettized, x = input_591_cast_fp16)[name = tensor<string, []>("pretrained_out_397_cast_fp16")];
            tensor<int32, [2]> var_8033 = const()[name = tensor<string, []>("op_8033"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8035 = const()[name = tensor<string, []>("op_8035"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_593_pad_type_0 = const()[name = tensor<string, []>("input_593_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_593_pad_0 = const()[name = tensor<string, []>("input_593_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_19_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_19_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(416284096)))];
            tensor<fp16, [1, 16, 1, 1]> input_593_cast_fp16 = conv(dilations = var_8035, groups = var_7693, pad = input_593_pad_0, pad_type = input_593_pad_type_0, strides = var_8033, weight = layers_19_fc1_loraA_weight_to_fp16, x = input_591_cast_fp16)[name = tensor<string, []>("input_593_cast_fp16")];
            tensor<int32, [2]> var_8039 = const()[name = tensor<string, []>("op_8039"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8041 = const()[name = tensor<string, []>("op_8041"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_793_pad_type_0 = const()[name = tensor<string, []>("lora_out_793_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_793_pad_0 = const()[name = tensor<string, []>("lora_out_793_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_795_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_795_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(416325120)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_795_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_8041, groups = var_7693, pad = lora_out_793_pad_0, pad_type = lora_out_793_pad_type_0, strides = var_8039, weight = lora_out_795_weight_0_to_fp16, x = input_593_cast_fp16)[name = tensor<string, []>("lora_out_795_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_595_cast_fp16 = add(x = pretrained_out_397_cast_fp16, y = lora_out_795_cast_fp16)[name = tensor<string, []>("input_595_cast_fp16")];
            tensor<string, []> input_597_mode_0 = const()[name = tensor<string, []>("input_597_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_597_cast_fp16 = gelu(mode = input_597_mode_0, x = input_595_cast_fp16)[name = tensor<string, []>("input_597_cast_fp16")];
            tensor<int32, [2]> var_8053 = const()[name = tensor<string, []>("op_8053"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8055 = const()[name = tensor<string, []>("op_8055"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_399_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_399_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_399_pad_0 = const()[name = tensor<string, []>("pretrained_out_399_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_19_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(416489024))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(419765888))), name = tensor<string, []>("layers_19_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_19_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_19_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(419766016)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_399_cast_fp16 = conv(bias = layers_19_fc2_pretrained_bias_to_fp16, dilations = var_8055, groups = var_7693, pad = pretrained_out_399_pad_0, pad_type = pretrained_out_399_pad_type_0, strides = var_8053, weight = layers_19_fc2_pretrained_weight_to_fp16_palettized, x = input_597_cast_fp16)[name = tensor<string, []>("pretrained_out_399_cast_fp16")];
            tensor<int32, [2]> var_8059 = const()[name = tensor<string, []>("op_8059"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8061 = const()[name = tensor<string, []>("op_8061"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_599_pad_type_0 = const()[name = tensor<string, []>("input_599_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_599_pad_0 = const()[name = tensor<string, []>("input_599_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_19_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_19_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(419768640)))];
            tensor<fp16, [1, 16, 1, 1]> input_599_cast_fp16 = conv(dilations = var_8061, groups = var_7693, pad = input_599_pad_0, pad_type = input_599_pad_type_0, strides = var_8059, weight = layers_19_fc2_loraA_weight_to_fp16, x = input_597_cast_fp16)[name = tensor<string, []>("input_599_cast_fp16")];
            tensor<int32, [2]> var_8065 = const()[name = tensor<string, []>("op_8065"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8067 = const()[name = tensor<string, []>("op_8067"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_797_pad_type_0 = const()[name = tensor<string, []>("lora_out_797_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_797_pad_0 = const()[name = tensor<string, []>("lora_out_797_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_799_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_799_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(419932544)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_799_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_8067, groups = var_7693, pad = lora_out_797_pad_0, pad_type = lora_out_797_pad_type_0, strides = var_8065, weight = lora_out_799_weight_0_to_fp16, x = input_599_cast_fp16)[name = tensor<string, []>("lora_out_799_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_41_cast_fp16 = add(x = pretrained_out_399_cast_fp16, y = lora_out_799_cast_fp16)[name = tensor<string, []>("hidden_states_41_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_121_cast_fp16 = add(x = inputs_119_cast_fp16, y = hidden_states_41_cast_fp16)[name = tensor<string, []>("inputs_121_cast_fp16")];
            tensor<int32, []> var_8084 = const()[name = tensor<string, []>("op_8084"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_8091 = const()[name = tensor<string, []>("op_8091"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_8092 = const()[name = tensor<string, []>("op_8092"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_8104 = const()[name = tensor<string, []>("op_8104"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_121_cast_fp16 = reduce_mean(axes = var_8104, keep_dims = var_8092, x = inputs_121_cast_fp16)[name = tensor<string, []>("channels_mean_121_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_121_cast_fp16 = sub(x = inputs_121_cast_fp16, y = channels_mean_121_cast_fp16)[name = tensor<string, []>("zero_mean_121_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_121_cast_fp16 = mul(x = zero_mean_121_cast_fp16, y = zero_mean_121_cast_fp16)[name = tensor<string, []>("zero_mean_sq_121_cast_fp16")];
            tensor<int32, [1]> var_8108 = const()[name = tensor<string, []>("op_8108"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_8109_cast_fp16 = reduce_mean(axes = var_8108, keep_dims = var_8092, x = zero_mean_sq_121_cast_fp16)[name = tensor<string, []>("op_8109_cast_fp16")];
            tensor<fp16, []> var_8110_to_fp16 = const()[name = tensor<string, []>("op_8110_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_8111_cast_fp16 = add(x = var_8109_cast_fp16, y = var_8110_to_fp16)[name = tensor<string, []>("op_8111_cast_fp16")];
            tensor<fp32, []> denom_121_epsilon_0 = const()[name = tensor<string, []>("denom_121_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_121_cast_fp16 = rsqrt(epsilon = denom_121_epsilon_0, x = var_8111_cast_fp16)[name = tensor<string, []>("denom_121_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_121_cast_fp16 = mul(x = zero_mean_121_cast_fp16, y = denom_121_cast_fp16)[name = tensor<string, []>("out_121_cast_fp16")];
            tensor<fp16, [1280]> obj_281_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_281_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(419973568)))];
            tensor<fp16, [1280]> obj_281_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_281_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(419976192)))];
            tensor<fp16, []> obj_281_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_281_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_281_cast_fp16 = batch_norm(beta = obj_281_beta_0_to_fp16, epsilon = obj_281_epsilon_0_to_fp16, gamma = obj_281_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_121_cast_fp16)[name = tensor<string, []>("obj_281_cast_fp16")];
            tensor<int32, [2]> var_8129 = const()[name = tensor<string, []>("op_8129"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8131 = const()[name = tensor<string, []>("op_8131"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_401_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_401_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_401_pad_0 = const()[name = tensor<string, []>("pretrained_out_401_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_20_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(419978816))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(420798080))), name = tensor<string, []>("layers_20_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_20_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_20_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(420798208)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_401_cast_fp16 = conv(bias = layers_20_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_8131, groups = var_8091, pad = pretrained_out_401_pad_0, pad_type = pretrained_out_401_pad_type_0, strides = var_8129, weight = layers_20_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_281_cast_fp16)[name = tensor<string, []>("pretrained_out_401_cast_fp16")];
            tensor<int32, [2]> var_8135 = const()[name = tensor<string, []>("op_8135"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8137 = const()[name = tensor<string, []>("op_8137"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_601_pad_type_0 = const()[name = tensor<string, []>("input_601_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_601_pad_0 = const()[name = tensor<string, []>("input_601_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_20_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_20_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(420800832)))];
            tensor<fp16, [1, 16, 1, 1]> input_601_cast_fp16 = conv(dilations = var_8137, groups = var_8091, pad = input_601_pad_0, pad_type = input_601_pad_type_0, strides = var_8135, weight = layers_20_self_attn_q_proj_loraA_weight_to_fp16, x = obj_281_cast_fp16)[name = tensor<string, []>("input_601_cast_fp16")];
            tensor<int32, [2]> var_8141 = const()[name = tensor<string, []>("op_8141"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8143 = const()[name = tensor<string, []>("op_8143"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_801_pad_type_0 = const()[name = tensor<string, []>("lora_out_801_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_801_pad_0 = const()[name = tensor<string, []>("lora_out_801_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_803_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_803_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(420841856)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_803_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_8143, groups = var_8091, pad = lora_out_801_pad_0, pad_type = lora_out_801_pad_type_0, strides = var_8141, weight = lora_out_803_weight_0_to_fp16, x = input_601_cast_fp16)[name = tensor<string, []>("lora_out_803_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_81_cast_fp16 = add(x = pretrained_out_401_cast_fp16, y = lora_out_803_cast_fp16)[name = tensor<string, []>("query_81_cast_fp16")];
            tensor<int32, [2]> var_8153 = const()[name = tensor<string, []>("op_8153"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8155 = const()[name = tensor<string, []>("op_8155"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_403_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_403_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_403_pad_0 = const()[name = tensor<string, []>("pretrained_out_403_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_20_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(420882880))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(421702144))), name = tensor<string, []>("layers_20_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_403_cast_fp16 = conv(dilations = var_8155, groups = var_8091, pad = pretrained_out_403_pad_0, pad_type = pretrained_out_403_pad_type_0, strides = var_8153, weight = layers_20_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_281_cast_fp16)[name = tensor<string, []>("pretrained_out_403_cast_fp16")];
            tensor<int32, [2]> var_8159 = const()[name = tensor<string, []>("op_8159"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8161 = const()[name = tensor<string, []>("op_8161"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_603_pad_type_0 = const()[name = tensor<string, []>("input_603_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_603_pad_0 = const()[name = tensor<string, []>("input_603_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_20_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_20_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(421702272)))];
            tensor<fp16, [1, 16, 1, 1]> input_603_cast_fp16 = conv(dilations = var_8161, groups = var_8091, pad = input_603_pad_0, pad_type = input_603_pad_type_0, strides = var_8159, weight = layers_20_self_attn_k_proj_loraA_weight_to_fp16, x = obj_281_cast_fp16)[name = tensor<string, []>("input_603_cast_fp16")];
            tensor<int32, [2]> var_8165 = const()[name = tensor<string, []>("op_8165"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8167 = const()[name = tensor<string, []>("op_8167"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_805_pad_type_0 = const()[name = tensor<string, []>("lora_out_805_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_805_pad_0 = const()[name = tensor<string, []>("lora_out_805_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_807_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_807_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(421743296)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_807_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_8167, groups = var_8091, pad = lora_out_805_pad_0, pad_type = lora_out_805_pad_type_0, strides = var_8165, weight = lora_out_807_weight_0_to_fp16, x = input_603_cast_fp16)[name = tensor<string, []>("lora_out_807_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_41_cast_fp16 = add(x = pretrained_out_403_cast_fp16, y = lora_out_807_cast_fp16)[name = tensor<string, []>("current_key_41_cast_fp16")];
            tensor<int32, [2]> var_8178 = const()[name = tensor<string, []>("op_8178"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8180 = const()[name = tensor<string, []>("op_8180"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_405_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_405_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_405_pad_0 = const()[name = tensor<string, []>("pretrained_out_405_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_20_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(421784320))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(422603584))), name = tensor<string, []>("layers_20_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_20_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_20_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(422603712)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_405_cast_fp16 = conv(bias = layers_20_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_8180, groups = var_8091, pad = pretrained_out_405_pad_0, pad_type = pretrained_out_405_pad_type_0, strides = var_8178, weight = layers_20_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_281_cast_fp16)[name = tensor<string, []>("pretrained_out_405_cast_fp16")];
            tensor<int32, [2]> var_8184 = const()[name = tensor<string, []>("op_8184"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8186 = const()[name = tensor<string, []>("op_8186"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_605_pad_type_0 = const()[name = tensor<string, []>("input_605_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_605_pad_0 = const()[name = tensor<string, []>("input_605_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_20_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_20_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(422606336)))];
            tensor<fp16, [1, 16, 1, 1]> input_605_cast_fp16 = conv(dilations = var_8186, groups = var_8091, pad = input_605_pad_0, pad_type = input_605_pad_type_0, strides = var_8184, weight = layers_20_self_attn_v_proj_loraA_weight_to_fp16, x = obj_281_cast_fp16)[name = tensor<string, []>("input_605_cast_fp16")];
            tensor<int32, [2]> var_8190 = const()[name = tensor<string, []>("op_8190"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8192 = const()[name = tensor<string, []>("op_8192"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_809_pad_type_0 = const()[name = tensor<string, []>("lora_out_809_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_809_pad_0 = const()[name = tensor<string, []>("lora_out_809_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_811_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_811_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(422647360)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_811_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_8192, groups = var_8091, pad = lora_out_809_pad_0, pad_type = lora_out_809_pad_type_0, strides = var_8190, weight = lora_out_811_weight_0_to_fp16, x = input_605_cast_fp16)[name = tensor<string, []>("lora_out_811_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_41_cast_fp16 = add(x = pretrained_out_405_cast_fp16, y = lora_out_811_cast_fp16)[name = tensor<string, []>("current_value_41_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_8202_cast_fp16 = mul(x = current_key_41_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_8202_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_8204_cast_fp16 = mul(x = var_103_cast_fp16_20, y = var_295_cast_fp16)[name = tensor<string, []>("op_8204_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_81_cast_fp16 = add(x = var_8202_cast_fp16, y = var_8204_cast_fp16)[name = tensor<string, []>("key_81_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_8206_cast_fp16 = mul(x = current_value_41_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_8206_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_8208_cast_fp16 = mul(x = var_138_cast_fp16_20, y = var_295_cast_fp16)[name = tensor<string, []>("op_8208_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_81_cast_fp16 = add(x = var_8206_cast_fp16, y = var_8208_cast_fp16)[name = tensor<string, []>("value_81_cast_fp16")];
            tensor<int32, [4]> var_8211 = const()[name = tensor<string, []>("op_8211"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_8212_cast_fp16 = reshape(shape = var_8211, x = query_81_cast_fp16)[name = tensor<string, []>("op_8212_cast_fp16")];
            tensor<fp16, []> var_8213_to_fp16 = const()[name = tensor<string, []>("op_8213_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_8214_cast_fp16 = mul(x = var_8212_cast_fp16, y = var_8213_to_fp16)[name = tensor<string, []>("op_8214_cast_fp16")];
            tensor<int32, [4]> var_8215 = const()[name = tensor<string, []>("op_8215"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_8216_cast_fp16 = reshape(shape = var_8215, x = key_81_cast_fp16)[name = tensor<string, []>("op_8216_cast_fp16")];
            tensor<bool, []> mh_w_121_transpose_x_0 = const()[name = tensor<string, []>("mh_w_121_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_121_transpose_y_0 = const()[name = tensor<string, []>("mh_w_121_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_121_cast_fp16 = matmul(transpose_x = mh_w_121_transpose_x_0, transpose_y = mh_w_121_transpose_y_0, x = var_8214_cast_fp16, y = var_8216_cast_fp16)[name = tensor<string, []>("mh_w_121_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_123_cast_fp16 = add(x = mh_w_121_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_123_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_8224_cast_fp16 = softmax(axis = var_8084, x = mh_w_123_cast_fp16)[name = tensor<string, []>("op_8224_cast_fp16")];
            tensor<int32, [4]> var_8225 = const()[name = tensor<string, []>("op_8225"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_8226_cast_fp16 = reshape(shape = var_8225, x = value_81_cast_fp16)[name = tensor<string, []>("op_8226_cast_fp16")];
            tensor<bool, []> attn_81_transpose_x_0 = const()[name = tensor<string, []>("attn_81_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_81_transpose_y_0 = const()[name = tensor<string, []>("attn_81_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_81_cast_fp16 = matmul(transpose_x = attn_81_transpose_x_0, transpose_y = attn_81_transpose_y_0, x = var_8226_cast_fp16, y = var_8224_cast_fp16)[name = tensor<string, []>("attn_81_cast_fp16")];
            tensor<int32, [4]> var_8229 = const()[name = tensor<string, []>("op_8229"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_607_cast_fp16 = reshape(shape = var_8229, x = attn_81_cast_fp16)[name = tensor<string, []>("input_607_cast_fp16")];
            tensor<int32, [2]> var_8236 = const()[name = tensor<string, []>("op_8236"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8238 = const()[name = tensor<string, []>("op_8238"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_407_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_407_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_407_pad_0 = const()[name = tensor<string, []>("pretrained_out_407_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_20_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(422688384))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(423507648))), name = tensor<string, []>("layers_20_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_20_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_20_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(423507776)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_407_cast_fp16 = conv(bias = layers_20_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_8238, groups = var_8091, pad = pretrained_out_407_pad_0, pad_type = pretrained_out_407_pad_type_0, strides = var_8236, weight = layers_20_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_607_cast_fp16)[name = tensor<string, []>("pretrained_out_407_cast_fp16")];
            tensor<int32, [2]> var_8242 = const()[name = tensor<string, []>("op_8242"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8244 = const()[name = tensor<string, []>("op_8244"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_609_pad_type_0 = const()[name = tensor<string, []>("input_609_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_609_pad_0 = const()[name = tensor<string, []>("input_609_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_20_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_20_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(423510400)))];
            tensor<fp16, [1, 16, 1, 1]> input_609_cast_fp16 = conv(dilations = var_8244, groups = var_8091, pad = input_609_pad_0, pad_type = input_609_pad_type_0, strides = var_8242, weight = layers_20_self_attn_o_proj_loraA_weight_to_fp16, x = input_607_cast_fp16)[name = tensor<string, []>("input_609_cast_fp16")];
            tensor<int32, [2]> var_8248 = const()[name = tensor<string, []>("op_8248"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8250 = const()[name = tensor<string, []>("op_8250"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_813_pad_type_0 = const()[name = tensor<string, []>("lora_out_813_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_813_pad_0 = const()[name = tensor<string, []>("lora_out_813_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_815_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_815_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(423551424)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_815_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_8250, groups = var_8091, pad = lora_out_813_pad_0, pad_type = lora_out_813_pad_type_0, strides = var_8248, weight = lora_out_815_weight_0_to_fp16, x = input_609_cast_fp16)[name = tensor<string, []>("lora_out_815_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_287_cast_fp16 = add(x = pretrained_out_407_cast_fp16, y = lora_out_815_cast_fp16)[name = tensor<string, []>("obj_287_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_123_cast_fp16 = add(x = inputs_121_cast_fp16, y = obj_287_cast_fp16)[name = tensor<string, []>("inputs_123_cast_fp16")];
            tensor<int32, [1]> var_8263 = const()[name = tensor<string, []>("op_8263"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_123_cast_fp16 = reduce_mean(axes = var_8263, keep_dims = var_8092, x = inputs_123_cast_fp16)[name = tensor<string, []>("channels_mean_123_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_123_cast_fp16 = sub(x = inputs_123_cast_fp16, y = channels_mean_123_cast_fp16)[name = tensor<string, []>("zero_mean_123_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_123_cast_fp16 = mul(x = zero_mean_123_cast_fp16, y = zero_mean_123_cast_fp16)[name = tensor<string, []>("zero_mean_sq_123_cast_fp16")];
            tensor<int32, [1]> var_8267 = const()[name = tensor<string, []>("op_8267"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_8268_cast_fp16 = reduce_mean(axes = var_8267, keep_dims = var_8092, x = zero_mean_sq_123_cast_fp16)[name = tensor<string, []>("op_8268_cast_fp16")];
            tensor<fp16, []> var_8269_to_fp16 = const()[name = tensor<string, []>("op_8269_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_8270_cast_fp16 = add(x = var_8268_cast_fp16, y = var_8269_to_fp16)[name = tensor<string, []>("op_8270_cast_fp16")];
            tensor<fp32, []> denom_123_epsilon_0 = const()[name = tensor<string, []>("denom_123_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_123_cast_fp16 = rsqrt(epsilon = denom_123_epsilon_0, x = var_8270_cast_fp16)[name = tensor<string, []>("denom_123_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_123_cast_fp16 = mul(x = zero_mean_123_cast_fp16, y = denom_123_cast_fp16)[name = tensor<string, []>("out_123_cast_fp16")];
            tensor<fp16, [1280]> obj_289_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_289_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(423592448)))];
            tensor<fp16, [1280]> obj_289_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_289_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(423595072)))];
            tensor<fp16, []> obj_289_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_289_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_289_cast_fp16 = batch_norm(beta = obj_289_beta_0_to_fp16, epsilon = obj_289_epsilon_0_to_fp16, gamma = obj_289_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_123_cast_fp16)[name = tensor<string, []>("obj_289_cast_fp16")];
            tensor<int32, [2]> var_8288 = const()[name = tensor<string, []>("op_8288"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8290 = const()[name = tensor<string, []>("op_8290"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_409_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_409_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_409_pad_0 = const()[name = tensor<string, []>("pretrained_out_409_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_20_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(423597696))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(424416960))), name = tensor<string, []>("layers_20_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_20_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_20_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(424417088)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_409_cast_fp16 = conv(bias = layers_20_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_8290, groups = var_8091, pad = pretrained_out_409_pad_0, pad_type = pretrained_out_409_pad_type_0, strides = var_8288, weight = layers_20_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_289_cast_fp16)[name = tensor<string, []>("pretrained_out_409_cast_fp16")];
            tensor<int32, [2]> var_8294 = const()[name = tensor<string, []>("op_8294"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8296 = const()[name = tensor<string, []>("op_8296"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_611_pad_type_0 = const()[name = tensor<string, []>("input_611_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_611_pad_0 = const()[name = tensor<string, []>("input_611_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_20_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_20_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(424419712)))];
            tensor<fp16, [1, 16, 1, 1]> input_611_cast_fp16 = conv(dilations = var_8296, groups = var_8091, pad = input_611_pad_0, pad_type = input_611_pad_type_0, strides = var_8294, weight = layers_20_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_289_cast_fp16)[name = tensor<string, []>("input_611_cast_fp16")];
            tensor<int32, [2]> var_8300 = const()[name = tensor<string, []>("op_8300"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8302 = const()[name = tensor<string, []>("op_8302"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_817_pad_type_0 = const()[name = tensor<string, []>("lora_out_817_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_817_pad_0 = const()[name = tensor<string, []>("lora_out_817_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_819_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_819_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(424460736)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_819_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_8302, groups = var_8091, pad = lora_out_817_pad_0, pad_type = lora_out_817_pad_type_0, strides = var_8300, weight = lora_out_819_weight_0_to_fp16, x = input_611_cast_fp16)[name = tensor<string, []>("lora_out_819_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_83_cast_fp16 = add(x = pretrained_out_409_cast_fp16, y = lora_out_819_cast_fp16)[name = tensor<string, []>("query_83_cast_fp16")];
            tensor<int32, [2]> var_8312 = const()[name = tensor<string, []>("op_8312"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8314 = const()[name = tensor<string, []>("op_8314"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_411_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_411_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_411_pad_0 = const()[name = tensor<string, []>("pretrained_out_411_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_20_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(424501760))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(425321024))), name = tensor<string, []>("layers_20_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_411_cast_fp16 = conv(dilations = var_8314, groups = var_8091, pad = pretrained_out_411_pad_0, pad_type = pretrained_out_411_pad_type_0, strides = var_8312, weight = layers_20_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_411_cast_fp16")];
            tensor<int32, [2]> var_8318 = const()[name = tensor<string, []>("op_8318"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8320 = const()[name = tensor<string, []>("op_8320"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_613_pad_type_0 = const()[name = tensor<string, []>("input_613_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_613_pad_0 = const()[name = tensor<string, []>("input_613_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_20_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_20_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(425321152)))];
            tensor<fp16, [1, 16, 1, 1500]> input_613_cast_fp16 = conv(dilations = var_8320, groups = var_8091, pad = input_613_pad_0, pad_type = input_613_pad_type_0, strides = var_8318, weight = layers_20_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_613_cast_fp16")];
            tensor<int32, [2]> var_8324 = const()[name = tensor<string, []>("op_8324"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8326 = const()[name = tensor<string, []>("op_8326"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_821_pad_type_0 = const()[name = tensor<string, []>("lora_out_821_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_821_pad_0 = const()[name = tensor<string, []>("lora_out_821_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_823_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_823_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(425362176)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_823_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_8326, groups = var_8091, pad = lora_out_821_pad_0, pad_type = lora_out_821_pad_type_0, strides = var_8324, weight = lora_out_823_weight_0_to_fp16, x = input_613_cast_fp16)[name = tensor<string, []>("lora_out_823_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_83_cast_fp16 = add(x = pretrained_out_411_cast_fp16, y = lora_out_823_cast_fp16)[name = tensor<string, []>("key_83_cast_fp16")];
            tensor<int32, [2]> var_8337 = const()[name = tensor<string, []>("op_8337"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8339 = const()[name = tensor<string, []>("op_8339"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_413_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_413_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_413_pad_0 = const()[name = tensor<string, []>("pretrained_out_413_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_20_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(425403200))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(426222464))), name = tensor<string, []>("layers_20_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_20_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_20_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(426222592)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_413_cast_fp16 = conv(bias = layers_20_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_8339, groups = var_8091, pad = pretrained_out_413_pad_0, pad_type = pretrained_out_413_pad_type_0, strides = var_8337, weight = layers_20_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_413_cast_fp16")];
            tensor<int32, [2]> var_8343 = const()[name = tensor<string, []>("op_8343"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8345 = const()[name = tensor<string, []>("op_8345"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_615_pad_type_0 = const()[name = tensor<string, []>("input_615_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_615_pad_0 = const()[name = tensor<string, []>("input_615_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_20_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_20_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(426225216)))];
            tensor<fp16, [1, 16, 1, 1500]> input_615_cast_fp16 = conv(dilations = var_8345, groups = var_8091, pad = input_615_pad_0, pad_type = input_615_pad_type_0, strides = var_8343, weight = layers_20_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_615_cast_fp16")];
            tensor<int32, [2]> var_8349 = const()[name = tensor<string, []>("op_8349"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8351 = const()[name = tensor<string, []>("op_8351"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_825_pad_type_0 = const()[name = tensor<string, []>("lora_out_825_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_825_pad_0 = const()[name = tensor<string, []>("lora_out_825_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_827_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_827_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(426266240)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_827_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_8351, groups = var_8091, pad = lora_out_825_pad_0, pad_type = lora_out_825_pad_type_0, strides = var_8349, weight = lora_out_827_weight_0_to_fp16, x = input_615_cast_fp16)[name = tensor<string, []>("lora_out_827_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_83_cast_fp16 = add(x = pretrained_out_413_cast_fp16, y = lora_out_827_cast_fp16)[name = tensor<string, []>("value_83_cast_fp16")];
            tensor<int32, [4]> var_8358 = const()[name = tensor<string, []>("op_8358"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_8359_cast_fp16 = reshape(shape = var_8358, x = query_83_cast_fp16)[name = tensor<string, []>("op_8359_cast_fp16")];
            tensor<fp16, []> var_8360_to_fp16 = const()[name = tensor<string, []>("op_8360_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_8361_cast_fp16 = mul(x = var_8359_cast_fp16, y = var_8360_to_fp16)[name = tensor<string, []>("op_8361_cast_fp16")];
            tensor<int32, [4]> var_8362 = const()[name = tensor<string, []>("op_8362"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_8363_cast_fp16 = reshape(shape = var_8362, x = key_83_cast_fp16)[name = tensor<string, []>("op_8363_cast_fp16")];
            tensor<bool, []> mh_w_125_transpose_x_0 = const()[name = tensor<string, []>("mh_w_125_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_125_transpose_y_0 = const()[name = tensor<string, []>("mh_w_125_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_125_cast_fp16 = matmul(transpose_x = mh_w_125_transpose_x_0, transpose_y = mh_w_125_transpose_y_0, x = var_8361_cast_fp16, y = var_8363_cast_fp16)[name = tensor<string, []>("mh_w_125_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_293_cast_fp16 = softmax(axis = var_8084, x = mh_w_125_cast_fp16)[name = tensor<string, []>("obj_293_cast_fp16")];
            tensor<int32, [4]> var_8367 = const()[name = tensor<string, []>("op_8367"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_8368_cast_fp16 = reshape(shape = var_8367, x = value_83_cast_fp16)[name = tensor<string, []>("op_8368_cast_fp16")];
            tensor<bool, []> attn_83_transpose_x_0 = const()[name = tensor<string, []>("attn_83_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_83_transpose_y_0 = const()[name = tensor<string, []>("attn_83_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_83_cast_fp16 = matmul(transpose_x = attn_83_transpose_x_0, transpose_y = attn_83_transpose_y_0, x = var_8368_cast_fp16, y = obj_293_cast_fp16)[name = tensor<string, []>("attn_83_cast_fp16")];
            tensor<int32, [4]> var_8371 = const()[name = tensor<string, []>("op_8371"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_617_cast_fp16 = reshape(shape = var_8371, x = attn_83_cast_fp16)[name = tensor<string, []>("input_617_cast_fp16")];
            tensor<int32, [2]> var_8378 = const()[name = tensor<string, []>("op_8378"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8380 = const()[name = tensor<string, []>("op_8380"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_415_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_415_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_415_pad_0 = const()[name = tensor<string, []>("pretrained_out_415_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_20_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(426307264))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(427126528))), name = tensor<string, []>("layers_20_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_20_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_20_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(427126656)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_415_cast_fp16 = conv(bias = layers_20_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_8380, groups = var_8091, pad = pretrained_out_415_pad_0, pad_type = pretrained_out_415_pad_type_0, strides = var_8378, weight = layers_20_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_617_cast_fp16)[name = tensor<string, []>("pretrained_out_415_cast_fp16")];
            tensor<int32, [2]> var_8384 = const()[name = tensor<string, []>("op_8384"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8386 = const()[name = tensor<string, []>("op_8386"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_619_pad_type_0 = const()[name = tensor<string, []>("input_619_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_619_pad_0 = const()[name = tensor<string, []>("input_619_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_20_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_20_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(427129280)))];
            tensor<fp16, [1, 16, 1, 1]> input_619_cast_fp16 = conv(dilations = var_8386, groups = var_8091, pad = input_619_pad_0, pad_type = input_619_pad_type_0, strides = var_8384, weight = layers_20_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_617_cast_fp16)[name = tensor<string, []>("input_619_cast_fp16")];
            tensor<int32, [2]> var_8390 = const()[name = tensor<string, []>("op_8390"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8392 = const()[name = tensor<string, []>("op_8392"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_829_pad_type_0 = const()[name = tensor<string, []>("lora_out_829_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_829_pad_0 = const()[name = tensor<string, []>("lora_out_829_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_831_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_831_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(427170304)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_831_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_8392, groups = var_8091, pad = lora_out_829_pad_0, pad_type = lora_out_829_pad_type_0, strides = var_8390, weight = lora_out_831_weight_0_to_fp16, x = input_619_cast_fp16)[name = tensor<string, []>("lora_out_831_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_291_cast_fp16 = add(x = pretrained_out_415_cast_fp16, y = lora_out_831_cast_fp16)[name = tensor<string, []>("obj_291_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_125_cast_fp16 = add(x = inputs_123_cast_fp16, y = obj_291_cast_fp16)[name = tensor<string, []>("inputs_125_cast_fp16")];
            tensor<int32, [1]> var_8401 = const()[name = tensor<string, []>("op_8401"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_125_cast_fp16 = reduce_mean(axes = var_8401, keep_dims = var_8092, x = inputs_125_cast_fp16)[name = tensor<string, []>("channels_mean_125_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_125_cast_fp16 = sub(x = inputs_125_cast_fp16, y = channels_mean_125_cast_fp16)[name = tensor<string, []>("zero_mean_125_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_125_cast_fp16 = mul(x = zero_mean_125_cast_fp16, y = zero_mean_125_cast_fp16)[name = tensor<string, []>("zero_mean_sq_125_cast_fp16")];
            tensor<int32, [1]> var_8405 = const()[name = tensor<string, []>("op_8405"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_8406_cast_fp16 = reduce_mean(axes = var_8405, keep_dims = var_8092, x = zero_mean_sq_125_cast_fp16)[name = tensor<string, []>("op_8406_cast_fp16")];
            tensor<fp16, []> var_8407_to_fp16 = const()[name = tensor<string, []>("op_8407_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_8408_cast_fp16 = add(x = var_8406_cast_fp16, y = var_8407_to_fp16)[name = tensor<string, []>("op_8408_cast_fp16")];
            tensor<fp32, []> denom_125_epsilon_0 = const()[name = tensor<string, []>("denom_125_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_125_cast_fp16 = rsqrt(epsilon = denom_125_epsilon_0, x = var_8408_cast_fp16)[name = tensor<string, []>("denom_125_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_125_cast_fp16 = mul(x = zero_mean_125_cast_fp16, y = denom_125_cast_fp16)[name = tensor<string, []>("out_125_cast_fp16")];
            tensor<fp16, [1280]> input_621_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_621_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(427211328)))];
            tensor<fp16, [1280]> input_621_beta_0_to_fp16 = const()[name = tensor<string, []>("input_621_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(427213952)))];
            tensor<fp16, []> input_621_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_621_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_621_cast_fp16 = batch_norm(beta = input_621_beta_0_to_fp16, epsilon = input_621_epsilon_0_to_fp16, gamma = input_621_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_125_cast_fp16)[name = tensor<string, []>("input_621_cast_fp16")];
            tensor<int32, [2]> var_8422 = const()[name = tensor<string, []>("op_8422"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8424 = const()[name = tensor<string, []>("op_8424"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_417_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_417_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_417_pad_0 = const()[name = tensor<string, []>("pretrained_out_417_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_20_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(427216576))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(430493440))), name = tensor<string, []>("layers_20_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_20_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_20_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(430493568)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_417_cast_fp16 = conv(bias = layers_20_fc1_pretrained_bias_to_fp16, dilations = var_8424, groups = var_8091, pad = pretrained_out_417_pad_0, pad_type = pretrained_out_417_pad_type_0, strides = var_8422, weight = layers_20_fc1_pretrained_weight_to_fp16_palettized, x = input_621_cast_fp16)[name = tensor<string, []>("pretrained_out_417_cast_fp16")];
            tensor<int32, [2]> var_8428 = const()[name = tensor<string, []>("op_8428"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8430 = const()[name = tensor<string, []>("op_8430"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_623_pad_type_0 = const()[name = tensor<string, []>("input_623_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_623_pad_0 = const()[name = tensor<string, []>("input_623_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_20_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_20_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(430503872)))];
            tensor<fp16, [1, 16, 1, 1]> input_623_cast_fp16 = conv(dilations = var_8430, groups = var_8091, pad = input_623_pad_0, pad_type = input_623_pad_type_0, strides = var_8428, weight = layers_20_fc1_loraA_weight_to_fp16, x = input_621_cast_fp16)[name = tensor<string, []>("input_623_cast_fp16")];
            tensor<int32, [2]> var_8434 = const()[name = tensor<string, []>("op_8434"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8436 = const()[name = tensor<string, []>("op_8436"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_833_pad_type_0 = const()[name = tensor<string, []>("lora_out_833_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_833_pad_0 = const()[name = tensor<string, []>("lora_out_833_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_835_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_835_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(430544896)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_835_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_8436, groups = var_8091, pad = lora_out_833_pad_0, pad_type = lora_out_833_pad_type_0, strides = var_8434, weight = lora_out_835_weight_0_to_fp16, x = input_623_cast_fp16)[name = tensor<string, []>("lora_out_835_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_625_cast_fp16 = add(x = pretrained_out_417_cast_fp16, y = lora_out_835_cast_fp16)[name = tensor<string, []>("input_625_cast_fp16")];
            tensor<string, []> input_627_mode_0 = const()[name = tensor<string, []>("input_627_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_627_cast_fp16 = gelu(mode = input_627_mode_0, x = input_625_cast_fp16)[name = tensor<string, []>("input_627_cast_fp16")];
            tensor<int32, [2]> var_8448 = const()[name = tensor<string, []>("op_8448"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8450 = const()[name = tensor<string, []>("op_8450"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_419_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_419_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_419_pad_0 = const()[name = tensor<string, []>("pretrained_out_419_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_20_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(430708800))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(433985664))), name = tensor<string, []>("layers_20_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_20_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_20_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(433985792)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_419_cast_fp16 = conv(bias = layers_20_fc2_pretrained_bias_to_fp16, dilations = var_8450, groups = var_8091, pad = pretrained_out_419_pad_0, pad_type = pretrained_out_419_pad_type_0, strides = var_8448, weight = layers_20_fc2_pretrained_weight_to_fp16_palettized, x = input_627_cast_fp16)[name = tensor<string, []>("pretrained_out_419_cast_fp16")];
            tensor<int32, [2]> var_8454 = const()[name = tensor<string, []>("op_8454"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8456 = const()[name = tensor<string, []>("op_8456"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_629_pad_type_0 = const()[name = tensor<string, []>("input_629_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_629_pad_0 = const()[name = tensor<string, []>("input_629_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_20_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_20_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(433988416)))];
            tensor<fp16, [1, 16, 1, 1]> input_629_cast_fp16 = conv(dilations = var_8456, groups = var_8091, pad = input_629_pad_0, pad_type = input_629_pad_type_0, strides = var_8454, weight = layers_20_fc2_loraA_weight_to_fp16, x = input_627_cast_fp16)[name = tensor<string, []>("input_629_cast_fp16")];
            tensor<int32, [2]> var_8460 = const()[name = tensor<string, []>("op_8460"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8462 = const()[name = tensor<string, []>("op_8462"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_837_pad_type_0 = const()[name = tensor<string, []>("lora_out_837_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_837_pad_0 = const()[name = tensor<string, []>("lora_out_837_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_839_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_839_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(434152320)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_839_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_8462, groups = var_8091, pad = lora_out_837_pad_0, pad_type = lora_out_837_pad_type_0, strides = var_8460, weight = lora_out_839_weight_0_to_fp16, x = input_629_cast_fp16)[name = tensor<string, []>("lora_out_839_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_43_cast_fp16 = add(x = pretrained_out_419_cast_fp16, y = lora_out_839_cast_fp16)[name = tensor<string, []>("hidden_states_43_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_127_cast_fp16 = add(x = inputs_125_cast_fp16, y = hidden_states_43_cast_fp16)[name = tensor<string, []>("inputs_127_cast_fp16")];
            tensor<int32, []> var_8478 = const()[name = tensor<string, []>("op_8478"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_8485 = const()[name = tensor<string, []>("op_8485"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_8486 = const()[name = tensor<string, []>("op_8486"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_8498 = const()[name = tensor<string, []>("op_8498"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_127_cast_fp16 = reduce_mean(axes = var_8498, keep_dims = var_8486, x = inputs_127_cast_fp16)[name = tensor<string, []>("channels_mean_127_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_127_cast_fp16 = sub(x = inputs_127_cast_fp16, y = channels_mean_127_cast_fp16)[name = tensor<string, []>("zero_mean_127_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_127_cast_fp16 = mul(x = zero_mean_127_cast_fp16, y = zero_mean_127_cast_fp16)[name = tensor<string, []>("zero_mean_sq_127_cast_fp16")];
            tensor<int32, [1]> var_8502 = const()[name = tensor<string, []>("op_8502"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_8503_cast_fp16 = reduce_mean(axes = var_8502, keep_dims = var_8486, x = zero_mean_sq_127_cast_fp16)[name = tensor<string, []>("op_8503_cast_fp16")];
            tensor<fp16, []> var_8504_to_fp16 = const()[name = tensor<string, []>("op_8504_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_8505_cast_fp16 = add(x = var_8503_cast_fp16, y = var_8504_to_fp16)[name = tensor<string, []>("op_8505_cast_fp16")];
            tensor<fp32, []> denom_127_epsilon_0 = const()[name = tensor<string, []>("denom_127_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_127_cast_fp16 = rsqrt(epsilon = denom_127_epsilon_0, x = var_8505_cast_fp16)[name = tensor<string, []>("denom_127_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_127_cast_fp16 = mul(x = zero_mean_127_cast_fp16, y = denom_127_cast_fp16)[name = tensor<string, []>("out_127_cast_fp16")];
            tensor<fp16, [1280]> obj_295_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_295_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(434193344)))];
            tensor<fp16, [1280]> obj_295_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_295_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(434195968)))];
            tensor<fp16, []> obj_295_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_295_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_295_cast_fp16 = batch_norm(beta = obj_295_beta_0_to_fp16, epsilon = obj_295_epsilon_0_to_fp16, gamma = obj_295_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_127_cast_fp16)[name = tensor<string, []>("obj_295_cast_fp16")];
            tensor<int32, [2]> var_8523 = const()[name = tensor<string, []>("op_8523"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8525 = const()[name = tensor<string, []>("op_8525"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_421_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_421_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_421_pad_0 = const()[name = tensor<string, []>("pretrained_out_421_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_21_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(434198592))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(435017856))), name = tensor<string, []>("layers_21_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_21_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_21_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(435017984)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_421_cast_fp16 = conv(bias = layers_21_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_8525, groups = var_8485, pad = pretrained_out_421_pad_0, pad_type = pretrained_out_421_pad_type_0, strides = var_8523, weight = layers_21_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_295_cast_fp16)[name = tensor<string, []>("pretrained_out_421_cast_fp16")];
            tensor<int32, [2]> var_8529 = const()[name = tensor<string, []>("op_8529"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8531 = const()[name = tensor<string, []>("op_8531"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_631_pad_type_0 = const()[name = tensor<string, []>("input_631_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_631_pad_0 = const()[name = tensor<string, []>("input_631_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_21_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_21_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(435020608)))];
            tensor<fp16, [1, 16, 1, 1]> input_631_cast_fp16 = conv(dilations = var_8531, groups = var_8485, pad = input_631_pad_0, pad_type = input_631_pad_type_0, strides = var_8529, weight = layers_21_self_attn_q_proj_loraA_weight_to_fp16, x = obj_295_cast_fp16)[name = tensor<string, []>("input_631_cast_fp16")];
            tensor<int32, [2]> var_8535 = const()[name = tensor<string, []>("op_8535"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8537 = const()[name = tensor<string, []>("op_8537"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_841_pad_type_0 = const()[name = tensor<string, []>("lora_out_841_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_841_pad_0 = const()[name = tensor<string, []>("lora_out_841_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_843_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_843_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(435061632)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_843_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_8537, groups = var_8485, pad = lora_out_841_pad_0, pad_type = lora_out_841_pad_type_0, strides = var_8535, weight = lora_out_843_weight_0_to_fp16, x = input_631_cast_fp16)[name = tensor<string, []>("lora_out_843_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_85_cast_fp16 = add(x = pretrained_out_421_cast_fp16, y = lora_out_843_cast_fp16)[name = tensor<string, []>("query_85_cast_fp16")];
            tensor<int32, [2]> var_8547 = const()[name = tensor<string, []>("op_8547"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8549 = const()[name = tensor<string, []>("op_8549"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_423_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_423_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_423_pad_0 = const()[name = tensor<string, []>("pretrained_out_423_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_21_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(435102656))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(435921920))), name = tensor<string, []>("layers_21_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_423_cast_fp16 = conv(dilations = var_8549, groups = var_8485, pad = pretrained_out_423_pad_0, pad_type = pretrained_out_423_pad_type_0, strides = var_8547, weight = layers_21_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_295_cast_fp16)[name = tensor<string, []>("pretrained_out_423_cast_fp16")];
            tensor<int32, [2]> var_8553 = const()[name = tensor<string, []>("op_8553"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8555 = const()[name = tensor<string, []>("op_8555"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_633_pad_type_0 = const()[name = tensor<string, []>("input_633_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_633_pad_0 = const()[name = tensor<string, []>("input_633_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_21_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_21_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(435922048)))];
            tensor<fp16, [1, 16, 1, 1]> input_633_cast_fp16 = conv(dilations = var_8555, groups = var_8485, pad = input_633_pad_0, pad_type = input_633_pad_type_0, strides = var_8553, weight = layers_21_self_attn_k_proj_loraA_weight_to_fp16, x = obj_295_cast_fp16)[name = tensor<string, []>("input_633_cast_fp16")];
            tensor<int32, [2]> var_8559 = const()[name = tensor<string, []>("op_8559"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8561 = const()[name = tensor<string, []>("op_8561"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_845_pad_type_0 = const()[name = tensor<string, []>("lora_out_845_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_845_pad_0 = const()[name = tensor<string, []>("lora_out_845_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_847_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_847_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(435963072)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_847_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_8561, groups = var_8485, pad = lora_out_845_pad_0, pad_type = lora_out_845_pad_type_0, strides = var_8559, weight = lora_out_847_weight_0_to_fp16, x = input_633_cast_fp16)[name = tensor<string, []>("lora_out_847_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_43_cast_fp16 = add(x = pretrained_out_423_cast_fp16, y = lora_out_847_cast_fp16)[name = tensor<string, []>("current_key_43_cast_fp16")];
            tensor<int32, [2]> var_8572 = const()[name = tensor<string, []>("op_8572"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8574 = const()[name = tensor<string, []>("op_8574"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_425_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_425_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_425_pad_0 = const()[name = tensor<string, []>("pretrained_out_425_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_21_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(436004096))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(436823360))), name = tensor<string, []>("layers_21_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_21_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_21_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(436823488)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_425_cast_fp16 = conv(bias = layers_21_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_8574, groups = var_8485, pad = pretrained_out_425_pad_0, pad_type = pretrained_out_425_pad_type_0, strides = var_8572, weight = layers_21_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_295_cast_fp16)[name = tensor<string, []>("pretrained_out_425_cast_fp16")];
            tensor<int32, [2]> var_8578 = const()[name = tensor<string, []>("op_8578"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8580 = const()[name = tensor<string, []>("op_8580"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_635_pad_type_0 = const()[name = tensor<string, []>("input_635_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_635_pad_0 = const()[name = tensor<string, []>("input_635_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_21_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_21_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(436826112)))];
            tensor<fp16, [1, 16, 1, 1]> input_635_cast_fp16 = conv(dilations = var_8580, groups = var_8485, pad = input_635_pad_0, pad_type = input_635_pad_type_0, strides = var_8578, weight = layers_21_self_attn_v_proj_loraA_weight_to_fp16, x = obj_295_cast_fp16)[name = tensor<string, []>("input_635_cast_fp16")];
            tensor<int32, [2]> var_8584 = const()[name = tensor<string, []>("op_8584"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8586 = const()[name = tensor<string, []>("op_8586"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_849_pad_type_0 = const()[name = tensor<string, []>("lora_out_849_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_849_pad_0 = const()[name = tensor<string, []>("lora_out_849_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_851_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_851_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(436867136)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_851_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_8586, groups = var_8485, pad = lora_out_849_pad_0, pad_type = lora_out_849_pad_type_0, strides = var_8584, weight = lora_out_851_weight_0_to_fp16, x = input_635_cast_fp16)[name = tensor<string, []>("lora_out_851_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_43_cast_fp16 = add(x = pretrained_out_425_cast_fp16, y = lora_out_851_cast_fp16)[name = tensor<string, []>("current_value_43_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_8596_cast_fp16 = mul(x = current_key_43_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_8596_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_8598_cast_fp16 = mul(x = var_103_cast_fp16_21, y = var_295_cast_fp16)[name = tensor<string, []>("op_8598_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_85_cast_fp16 = add(x = var_8596_cast_fp16, y = var_8598_cast_fp16)[name = tensor<string, []>("key_85_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_8600_cast_fp16 = mul(x = current_value_43_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_8600_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_8602_cast_fp16 = mul(x = var_138_cast_fp16_21, y = var_295_cast_fp16)[name = tensor<string, []>("op_8602_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_85_cast_fp16 = add(x = var_8600_cast_fp16, y = var_8602_cast_fp16)[name = tensor<string, []>("value_85_cast_fp16")];
            tensor<int32, [4]> var_8605 = const()[name = tensor<string, []>("op_8605"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_8606_cast_fp16 = reshape(shape = var_8605, x = query_85_cast_fp16)[name = tensor<string, []>("op_8606_cast_fp16")];
            tensor<fp16, []> var_8607_to_fp16 = const()[name = tensor<string, []>("op_8607_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_8608_cast_fp16 = mul(x = var_8606_cast_fp16, y = var_8607_to_fp16)[name = tensor<string, []>("op_8608_cast_fp16")];
            tensor<int32, [4]> var_8609 = const()[name = tensor<string, []>("op_8609"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_8610_cast_fp16 = reshape(shape = var_8609, x = key_85_cast_fp16)[name = tensor<string, []>("op_8610_cast_fp16")];
            tensor<bool, []> mh_w_127_transpose_x_0 = const()[name = tensor<string, []>("mh_w_127_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_127_transpose_y_0 = const()[name = tensor<string, []>("mh_w_127_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_127_cast_fp16 = matmul(transpose_x = mh_w_127_transpose_x_0, transpose_y = mh_w_127_transpose_y_0, x = var_8608_cast_fp16, y = var_8610_cast_fp16)[name = tensor<string, []>("mh_w_127_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_129_cast_fp16 = add(x = mh_w_127_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_129_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_8618_cast_fp16 = softmax(axis = var_8478, x = mh_w_129_cast_fp16)[name = tensor<string, []>("op_8618_cast_fp16")];
            tensor<int32, [4]> var_8619 = const()[name = tensor<string, []>("op_8619"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_8620_cast_fp16 = reshape(shape = var_8619, x = value_85_cast_fp16)[name = tensor<string, []>("op_8620_cast_fp16")];
            tensor<bool, []> attn_85_transpose_x_0 = const()[name = tensor<string, []>("attn_85_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_85_transpose_y_0 = const()[name = tensor<string, []>("attn_85_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_85_cast_fp16 = matmul(transpose_x = attn_85_transpose_x_0, transpose_y = attn_85_transpose_y_0, x = var_8620_cast_fp16, y = var_8618_cast_fp16)[name = tensor<string, []>("attn_85_cast_fp16")];
            tensor<int32, [4]> var_8623 = const()[name = tensor<string, []>("op_8623"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_637_cast_fp16 = reshape(shape = var_8623, x = attn_85_cast_fp16)[name = tensor<string, []>("input_637_cast_fp16")];
            tensor<int32, [2]> var_8630 = const()[name = tensor<string, []>("op_8630"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8632 = const()[name = tensor<string, []>("op_8632"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_427_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_427_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_427_pad_0 = const()[name = tensor<string, []>("pretrained_out_427_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_21_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(436908160))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(437727424))), name = tensor<string, []>("layers_21_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_21_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_21_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(437727552)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_427_cast_fp16 = conv(bias = layers_21_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_8632, groups = var_8485, pad = pretrained_out_427_pad_0, pad_type = pretrained_out_427_pad_type_0, strides = var_8630, weight = layers_21_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_637_cast_fp16)[name = tensor<string, []>("pretrained_out_427_cast_fp16")];
            tensor<int32, [2]> var_8636 = const()[name = tensor<string, []>("op_8636"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8638 = const()[name = tensor<string, []>("op_8638"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_639_pad_type_0 = const()[name = tensor<string, []>("input_639_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_639_pad_0 = const()[name = tensor<string, []>("input_639_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_21_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_21_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(437730176)))];
            tensor<fp16, [1, 16, 1, 1]> input_639_cast_fp16 = conv(dilations = var_8638, groups = var_8485, pad = input_639_pad_0, pad_type = input_639_pad_type_0, strides = var_8636, weight = layers_21_self_attn_o_proj_loraA_weight_to_fp16, x = input_637_cast_fp16)[name = tensor<string, []>("input_639_cast_fp16")];
            tensor<int32, [2]> var_8642 = const()[name = tensor<string, []>("op_8642"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8644 = const()[name = tensor<string, []>("op_8644"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_853_pad_type_0 = const()[name = tensor<string, []>("lora_out_853_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_853_pad_0 = const()[name = tensor<string, []>("lora_out_853_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_855_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_855_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(437771200)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_855_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_8644, groups = var_8485, pad = lora_out_853_pad_0, pad_type = lora_out_853_pad_type_0, strides = var_8642, weight = lora_out_855_weight_0_to_fp16, x = input_639_cast_fp16)[name = tensor<string, []>("lora_out_855_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_301_cast_fp16 = add(x = pretrained_out_427_cast_fp16, y = lora_out_855_cast_fp16)[name = tensor<string, []>("obj_301_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_129_cast_fp16 = add(x = inputs_127_cast_fp16, y = obj_301_cast_fp16)[name = tensor<string, []>("inputs_129_cast_fp16")];
            tensor<int32, [1]> var_8657 = const()[name = tensor<string, []>("op_8657"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_129_cast_fp16 = reduce_mean(axes = var_8657, keep_dims = var_8486, x = inputs_129_cast_fp16)[name = tensor<string, []>("channels_mean_129_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_129_cast_fp16 = sub(x = inputs_129_cast_fp16, y = channels_mean_129_cast_fp16)[name = tensor<string, []>("zero_mean_129_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_129_cast_fp16 = mul(x = zero_mean_129_cast_fp16, y = zero_mean_129_cast_fp16)[name = tensor<string, []>("zero_mean_sq_129_cast_fp16")];
            tensor<int32, [1]> var_8661 = const()[name = tensor<string, []>("op_8661"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_8662_cast_fp16 = reduce_mean(axes = var_8661, keep_dims = var_8486, x = zero_mean_sq_129_cast_fp16)[name = tensor<string, []>("op_8662_cast_fp16")];
            tensor<fp16, []> var_8663_to_fp16 = const()[name = tensor<string, []>("op_8663_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_8664_cast_fp16 = add(x = var_8662_cast_fp16, y = var_8663_to_fp16)[name = tensor<string, []>("op_8664_cast_fp16")];
            tensor<fp32, []> denom_129_epsilon_0 = const()[name = tensor<string, []>("denom_129_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_129_cast_fp16 = rsqrt(epsilon = denom_129_epsilon_0, x = var_8664_cast_fp16)[name = tensor<string, []>("denom_129_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_129_cast_fp16 = mul(x = zero_mean_129_cast_fp16, y = denom_129_cast_fp16)[name = tensor<string, []>("out_129_cast_fp16")];
            tensor<fp16, [1280]> obj_303_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_303_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(437812224)))];
            tensor<fp16, [1280]> obj_303_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_303_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(437814848)))];
            tensor<fp16, []> obj_303_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_303_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_303_cast_fp16 = batch_norm(beta = obj_303_beta_0_to_fp16, epsilon = obj_303_epsilon_0_to_fp16, gamma = obj_303_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_129_cast_fp16)[name = tensor<string, []>("obj_303_cast_fp16")];
            tensor<int32, [2]> var_8682 = const()[name = tensor<string, []>("op_8682"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8684 = const()[name = tensor<string, []>("op_8684"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_429_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_429_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_429_pad_0 = const()[name = tensor<string, []>("pretrained_out_429_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_21_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(437817472))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(438636736))), name = tensor<string, []>("layers_21_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_21_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_21_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(438636864)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_429_cast_fp16 = conv(bias = layers_21_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_8684, groups = var_8485, pad = pretrained_out_429_pad_0, pad_type = pretrained_out_429_pad_type_0, strides = var_8682, weight = layers_21_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_303_cast_fp16)[name = tensor<string, []>("pretrained_out_429_cast_fp16")];
            tensor<int32, [2]> var_8688 = const()[name = tensor<string, []>("op_8688"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8690 = const()[name = tensor<string, []>("op_8690"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_641_pad_type_0 = const()[name = tensor<string, []>("input_641_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_641_pad_0 = const()[name = tensor<string, []>("input_641_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_21_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_21_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(438639488)))];
            tensor<fp16, [1, 16, 1, 1]> input_641_cast_fp16 = conv(dilations = var_8690, groups = var_8485, pad = input_641_pad_0, pad_type = input_641_pad_type_0, strides = var_8688, weight = layers_21_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_303_cast_fp16)[name = tensor<string, []>("input_641_cast_fp16")];
            tensor<int32, [2]> var_8694 = const()[name = tensor<string, []>("op_8694"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8696 = const()[name = tensor<string, []>("op_8696"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_857_pad_type_0 = const()[name = tensor<string, []>("lora_out_857_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_857_pad_0 = const()[name = tensor<string, []>("lora_out_857_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_859_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_859_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(438680512)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_859_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_8696, groups = var_8485, pad = lora_out_857_pad_0, pad_type = lora_out_857_pad_type_0, strides = var_8694, weight = lora_out_859_weight_0_to_fp16, x = input_641_cast_fp16)[name = tensor<string, []>("lora_out_859_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_87_cast_fp16 = add(x = pretrained_out_429_cast_fp16, y = lora_out_859_cast_fp16)[name = tensor<string, []>("query_87_cast_fp16")];
            tensor<int32, [2]> var_8706 = const()[name = tensor<string, []>("op_8706"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8708 = const()[name = tensor<string, []>("op_8708"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_431_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_431_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_431_pad_0 = const()[name = tensor<string, []>("pretrained_out_431_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_21_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(438721536))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(439540800))), name = tensor<string, []>("layers_21_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_431_cast_fp16 = conv(dilations = var_8708, groups = var_8485, pad = pretrained_out_431_pad_0, pad_type = pretrained_out_431_pad_type_0, strides = var_8706, weight = layers_21_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_431_cast_fp16")];
            tensor<int32, [2]> var_8712 = const()[name = tensor<string, []>("op_8712"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8714 = const()[name = tensor<string, []>("op_8714"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_643_pad_type_0 = const()[name = tensor<string, []>("input_643_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_643_pad_0 = const()[name = tensor<string, []>("input_643_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_21_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_21_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(439540928)))];
            tensor<fp16, [1, 16, 1, 1500]> input_643_cast_fp16 = conv(dilations = var_8714, groups = var_8485, pad = input_643_pad_0, pad_type = input_643_pad_type_0, strides = var_8712, weight = layers_21_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_643_cast_fp16")];
            tensor<int32, [2]> var_8718 = const()[name = tensor<string, []>("op_8718"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8720 = const()[name = tensor<string, []>("op_8720"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_861_pad_type_0 = const()[name = tensor<string, []>("lora_out_861_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_861_pad_0 = const()[name = tensor<string, []>("lora_out_861_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_863_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_863_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(439581952)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_863_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_8720, groups = var_8485, pad = lora_out_861_pad_0, pad_type = lora_out_861_pad_type_0, strides = var_8718, weight = lora_out_863_weight_0_to_fp16, x = input_643_cast_fp16)[name = tensor<string, []>("lora_out_863_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_87_cast_fp16 = add(x = pretrained_out_431_cast_fp16, y = lora_out_863_cast_fp16)[name = tensor<string, []>("key_87_cast_fp16")];
            tensor<int32, [2]> var_8731 = const()[name = tensor<string, []>("op_8731"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8733 = const()[name = tensor<string, []>("op_8733"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_433_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_433_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_433_pad_0 = const()[name = tensor<string, []>("pretrained_out_433_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_21_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(439622976))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(440442240))), name = tensor<string, []>("layers_21_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_21_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_21_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(440442368)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_433_cast_fp16 = conv(bias = layers_21_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_8733, groups = var_8485, pad = pretrained_out_433_pad_0, pad_type = pretrained_out_433_pad_type_0, strides = var_8731, weight = layers_21_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_433_cast_fp16")];
            tensor<int32, [2]> var_8737 = const()[name = tensor<string, []>("op_8737"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8739 = const()[name = tensor<string, []>("op_8739"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_645_pad_type_0 = const()[name = tensor<string, []>("input_645_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_645_pad_0 = const()[name = tensor<string, []>("input_645_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_21_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_21_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(440444992)))];
            tensor<fp16, [1, 16, 1, 1500]> input_645_cast_fp16 = conv(dilations = var_8739, groups = var_8485, pad = input_645_pad_0, pad_type = input_645_pad_type_0, strides = var_8737, weight = layers_21_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_645_cast_fp16")];
            tensor<int32, [2]> var_8743 = const()[name = tensor<string, []>("op_8743"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8745 = const()[name = tensor<string, []>("op_8745"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_865_pad_type_0 = const()[name = tensor<string, []>("lora_out_865_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_865_pad_0 = const()[name = tensor<string, []>("lora_out_865_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_867_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_867_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(440486016)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_867_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_8745, groups = var_8485, pad = lora_out_865_pad_0, pad_type = lora_out_865_pad_type_0, strides = var_8743, weight = lora_out_867_weight_0_to_fp16, x = input_645_cast_fp16)[name = tensor<string, []>("lora_out_867_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_87_cast_fp16 = add(x = pretrained_out_433_cast_fp16, y = lora_out_867_cast_fp16)[name = tensor<string, []>("value_87_cast_fp16")];
            tensor<int32, [4]> var_8752 = const()[name = tensor<string, []>("op_8752"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_8753_cast_fp16 = reshape(shape = var_8752, x = query_87_cast_fp16)[name = tensor<string, []>("op_8753_cast_fp16")];
            tensor<fp16, []> var_8754_to_fp16 = const()[name = tensor<string, []>("op_8754_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_8755_cast_fp16 = mul(x = var_8753_cast_fp16, y = var_8754_to_fp16)[name = tensor<string, []>("op_8755_cast_fp16")];
            tensor<int32, [4]> var_8756 = const()[name = tensor<string, []>("op_8756"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_8757_cast_fp16 = reshape(shape = var_8756, x = key_87_cast_fp16)[name = tensor<string, []>("op_8757_cast_fp16")];
            tensor<bool, []> mh_w_131_transpose_x_0 = const()[name = tensor<string, []>("mh_w_131_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_131_transpose_y_0 = const()[name = tensor<string, []>("mh_w_131_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_131_cast_fp16 = matmul(transpose_x = mh_w_131_transpose_x_0, transpose_y = mh_w_131_transpose_y_0, x = var_8755_cast_fp16, y = var_8757_cast_fp16)[name = tensor<string, []>("mh_w_131_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_307_cast_fp16 = softmax(axis = var_8478, x = mh_w_131_cast_fp16)[name = tensor<string, []>("obj_307_cast_fp16")];
            tensor<int32, [4]> var_8761 = const()[name = tensor<string, []>("op_8761"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_8762_cast_fp16 = reshape(shape = var_8761, x = value_87_cast_fp16)[name = tensor<string, []>("op_8762_cast_fp16")];
            tensor<bool, []> attn_87_transpose_x_0 = const()[name = tensor<string, []>("attn_87_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_87_transpose_y_0 = const()[name = tensor<string, []>("attn_87_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_87_cast_fp16 = matmul(transpose_x = attn_87_transpose_x_0, transpose_y = attn_87_transpose_y_0, x = var_8762_cast_fp16, y = obj_307_cast_fp16)[name = tensor<string, []>("attn_87_cast_fp16")];
            tensor<int32, [4]> var_8765 = const()[name = tensor<string, []>("op_8765"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_647_cast_fp16 = reshape(shape = var_8765, x = attn_87_cast_fp16)[name = tensor<string, []>("input_647_cast_fp16")];
            tensor<int32, [2]> var_8772 = const()[name = tensor<string, []>("op_8772"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8774 = const()[name = tensor<string, []>("op_8774"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_435_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_435_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_435_pad_0 = const()[name = tensor<string, []>("pretrained_out_435_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_21_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(440527040))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(441346304))), name = tensor<string, []>("layers_21_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_21_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_21_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(441346432)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_435_cast_fp16 = conv(bias = layers_21_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_8774, groups = var_8485, pad = pretrained_out_435_pad_0, pad_type = pretrained_out_435_pad_type_0, strides = var_8772, weight = layers_21_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_647_cast_fp16)[name = tensor<string, []>("pretrained_out_435_cast_fp16")];
            tensor<int32, [2]> var_8778 = const()[name = tensor<string, []>("op_8778"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8780 = const()[name = tensor<string, []>("op_8780"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_649_pad_type_0 = const()[name = tensor<string, []>("input_649_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_649_pad_0 = const()[name = tensor<string, []>("input_649_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_21_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_21_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(441349056)))];
            tensor<fp16, [1, 16, 1, 1]> input_649_cast_fp16 = conv(dilations = var_8780, groups = var_8485, pad = input_649_pad_0, pad_type = input_649_pad_type_0, strides = var_8778, weight = layers_21_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_647_cast_fp16)[name = tensor<string, []>("input_649_cast_fp16")];
            tensor<int32, [2]> var_8784 = const()[name = tensor<string, []>("op_8784"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8786 = const()[name = tensor<string, []>("op_8786"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_869_pad_type_0 = const()[name = tensor<string, []>("lora_out_869_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_869_pad_0 = const()[name = tensor<string, []>("lora_out_869_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_871_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_871_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(441390080)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_871_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_8786, groups = var_8485, pad = lora_out_869_pad_0, pad_type = lora_out_869_pad_type_0, strides = var_8784, weight = lora_out_871_weight_0_to_fp16, x = input_649_cast_fp16)[name = tensor<string, []>("lora_out_871_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_305_cast_fp16 = add(x = pretrained_out_435_cast_fp16, y = lora_out_871_cast_fp16)[name = tensor<string, []>("obj_305_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_131_cast_fp16 = add(x = inputs_129_cast_fp16, y = obj_305_cast_fp16)[name = tensor<string, []>("inputs_131_cast_fp16")];
            tensor<int32, [1]> var_8798 = const()[name = tensor<string, []>("op_8798"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_131_cast_fp16 = reduce_mean(axes = var_8798, keep_dims = var_8486, x = inputs_131_cast_fp16)[name = tensor<string, []>("channels_mean_131_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_131_cast_fp16 = sub(x = inputs_131_cast_fp16, y = channels_mean_131_cast_fp16)[name = tensor<string, []>("zero_mean_131_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_131_cast_fp16 = mul(x = zero_mean_131_cast_fp16, y = zero_mean_131_cast_fp16)[name = tensor<string, []>("zero_mean_sq_131_cast_fp16")];
            tensor<int32, [1]> var_8802 = const()[name = tensor<string, []>("op_8802"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_8803_cast_fp16 = reduce_mean(axes = var_8802, keep_dims = var_8486, x = zero_mean_sq_131_cast_fp16)[name = tensor<string, []>("op_8803_cast_fp16")];
            tensor<fp16, []> var_8804_to_fp16 = const()[name = tensor<string, []>("op_8804_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_8805_cast_fp16 = add(x = var_8803_cast_fp16, y = var_8804_to_fp16)[name = tensor<string, []>("op_8805_cast_fp16")];
            tensor<fp32, []> denom_131_epsilon_0 = const()[name = tensor<string, []>("denom_131_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_131_cast_fp16 = rsqrt(epsilon = denom_131_epsilon_0, x = var_8805_cast_fp16)[name = tensor<string, []>("denom_131_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_131_cast_fp16 = mul(x = zero_mean_131_cast_fp16, y = denom_131_cast_fp16)[name = tensor<string, []>("out_131_cast_fp16")];
            tensor<fp16, [1280]> input_651_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_651_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(441431104)))];
            tensor<fp16, [1280]> input_651_beta_0_to_fp16 = const()[name = tensor<string, []>("input_651_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(441433728)))];
            tensor<fp16, []> input_651_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_651_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_651_cast_fp16 = batch_norm(beta = input_651_beta_0_to_fp16, epsilon = input_651_epsilon_0_to_fp16, gamma = input_651_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_131_cast_fp16)[name = tensor<string, []>("input_651_cast_fp16")];
            tensor<int32, [2]> var_8819 = const()[name = tensor<string, []>("op_8819"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8821 = const()[name = tensor<string, []>("op_8821"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_437_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_437_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_437_pad_0 = const()[name = tensor<string, []>("pretrained_out_437_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_21_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(441436352))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(444713216))), name = tensor<string, []>("layers_21_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_21_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_21_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(444713344)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_437_cast_fp16 = conv(bias = layers_21_fc1_pretrained_bias_to_fp16, dilations = var_8821, groups = var_8485, pad = pretrained_out_437_pad_0, pad_type = pretrained_out_437_pad_type_0, strides = var_8819, weight = layers_21_fc1_pretrained_weight_to_fp16_palettized, x = input_651_cast_fp16)[name = tensor<string, []>("pretrained_out_437_cast_fp16")];
            tensor<int32, [2]> var_8825 = const()[name = tensor<string, []>("op_8825"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8827 = const()[name = tensor<string, []>("op_8827"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_653_pad_type_0 = const()[name = tensor<string, []>("input_653_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_653_pad_0 = const()[name = tensor<string, []>("input_653_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_21_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_21_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(444723648)))];
            tensor<fp16, [1, 16, 1, 1]> input_653_cast_fp16 = conv(dilations = var_8827, groups = var_8485, pad = input_653_pad_0, pad_type = input_653_pad_type_0, strides = var_8825, weight = layers_21_fc1_loraA_weight_to_fp16, x = input_651_cast_fp16)[name = tensor<string, []>("input_653_cast_fp16")];
            tensor<int32, [2]> var_8831 = const()[name = tensor<string, []>("op_8831"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8833 = const()[name = tensor<string, []>("op_8833"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_873_pad_type_0 = const()[name = tensor<string, []>("lora_out_873_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_873_pad_0 = const()[name = tensor<string, []>("lora_out_873_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_875_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_875_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(444764672)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_875_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_8833, groups = var_8485, pad = lora_out_873_pad_0, pad_type = lora_out_873_pad_type_0, strides = var_8831, weight = lora_out_875_weight_0_to_fp16, x = input_653_cast_fp16)[name = tensor<string, []>("lora_out_875_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_655_cast_fp16 = add(x = pretrained_out_437_cast_fp16, y = lora_out_875_cast_fp16)[name = tensor<string, []>("input_655_cast_fp16")];
            tensor<string, []> input_657_mode_0 = const()[name = tensor<string, []>("input_657_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_657_cast_fp16 = gelu(mode = input_657_mode_0, x = input_655_cast_fp16)[name = tensor<string, []>("input_657_cast_fp16")];
            tensor<int32, [2]> var_8845 = const()[name = tensor<string, []>("op_8845"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8847 = const()[name = tensor<string, []>("op_8847"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_439_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_439_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_439_pad_0 = const()[name = tensor<string, []>("pretrained_out_439_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_21_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(444928576))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(448205440))), name = tensor<string, []>("layers_21_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_21_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_21_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(448205568)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_439_cast_fp16 = conv(bias = layers_21_fc2_pretrained_bias_to_fp16, dilations = var_8847, groups = var_8485, pad = pretrained_out_439_pad_0, pad_type = pretrained_out_439_pad_type_0, strides = var_8845, weight = layers_21_fc2_pretrained_weight_to_fp16_palettized, x = input_657_cast_fp16)[name = tensor<string, []>("pretrained_out_439_cast_fp16")];
            tensor<int32, [2]> var_8851 = const()[name = tensor<string, []>("op_8851"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8853 = const()[name = tensor<string, []>("op_8853"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_659_pad_type_0 = const()[name = tensor<string, []>("input_659_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_659_pad_0 = const()[name = tensor<string, []>("input_659_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_21_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_21_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(448208192)))];
            tensor<fp16, [1, 16, 1, 1]> input_659_cast_fp16 = conv(dilations = var_8853, groups = var_8485, pad = input_659_pad_0, pad_type = input_659_pad_type_0, strides = var_8851, weight = layers_21_fc2_loraA_weight_to_fp16, x = input_657_cast_fp16)[name = tensor<string, []>("input_659_cast_fp16")];
            tensor<int32, [2]> var_8857 = const()[name = tensor<string, []>("op_8857"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8859 = const()[name = tensor<string, []>("op_8859"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_877_pad_type_0 = const()[name = tensor<string, []>("lora_out_877_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_877_pad_0 = const()[name = tensor<string, []>("lora_out_877_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_879_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_879_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(448372096)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_879_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_8859, groups = var_8485, pad = lora_out_877_pad_0, pad_type = lora_out_877_pad_type_0, strides = var_8857, weight = lora_out_879_weight_0_to_fp16, x = input_659_cast_fp16)[name = tensor<string, []>("lora_out_879_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_45_cast_fp16 = add(x = pretrained_out_439_cast_fp16, y = lora_out_879_cast_fp16)[name = tensor<string, []>("hidden_states_45_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_133_cast_fp16 = add(x = inputs_131_cast_fp16, y = hidden_states_45_cast_fp16)[name = tensor<string, []>("inputs_133_cast_fp16")];
            tensor<int32, []> var_8876 = const()[name = tensor<string, []>("op_8876"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_8883 = const()[name = tensor<string, []>("op_8883"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_8884 = const()[name = tensor<string, []>("op_8884"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_8896 = const()[name = tensor<string, []>("op_8896"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_133_cast_fp16 = reduce_mean(axes = var_8896, keep_dims = var_8884, x = inputs_133_cast_fp16)[name = tensor<string, []>("channels_mean_133_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_133_cast_fp16 = sub(x = inputs_133_cast_fp16, y = channels_mean_133_cast_fp16)[name = tensor<string, []>("zero_mean_133_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_133_cast_fp16 = mul(x = zero_mean_133_cast_fp16, y = zero_mean_133_cast_fp16)[name = tensor<string, []>("zero_mean_sq_133_cast_fp16")];
            tensor<int32, [1]> var_8900 = const()[name = tensor<string, []>("op_8900"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_8901_cast_fp16 = reduce_mean(axes = var_8900, keep_dims = var_8884, x = zero_mean_sq_133_cast_fp16)[name = tensor<string, []>("op_8901_cast_fp16")];
            tensor<fp16, []> var_8902_to_fp16 = const()[name = tensor<string, []>("op_8902_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_8903_cast_fp16 = add(x = var_8901_cast_fp16, y = var_8902_to_fp16)[name = tensor<string, []>("op_8903_cast_fp16")];
            tensor<fp32, []> denom_133_epsilon_0 = const()[name = tensor<string, []>("denom_133_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_133_cast_fp16 = rsqrt(epsilon = denom_133_epsilon_0, x = var_8903_cast_fp16)[name = tensor<string, []>("denom_133_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_133_cast_fp16 = mul(x = zero_mean_133_cast_fp16, y = denom_133_cast_fp16)[name = tensor<string, []>("out_133_cast_fp16")];
            tensor<fp16, [1280]> obj_309_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_309_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(448413120)))];
            tensor<fp16, [1280]> obj_309_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_309_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(448415744)))];
            tensor<fp16, []> obj_309_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_309_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_309_cast_fp16 = batch_norm(beta = obj_309_beta_0_to_fp16, epsilon = obj_309_epsilon_0_to_fp16, gamma = obj_309_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_133_cast_fp16)[name = tensor<string, []>("obj_309_cast_fp16")];
            tensor<int32, [2]> var_8921 = const()[name = tensor<string, []>("op_8921"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8923 = const()[name = tensor<string, []>("op_8923"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_441_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_441_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_441_pad_0 = const()[name = tensor<string, []>("pretrained_out_441_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_22_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(448418368))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(449237632))), name = tensor<string, []>("layers_22_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_22_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_22_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(449237760)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_441_cast_fp16 = conv(bias = layers_22_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_8923, groups = var_8883, pad = pretrained_out_441_pad_0, pad_type = pretrained_out_441_pad_type_0, strides = var_8921, weight = layers_22_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_309_cast_fp16)[name = tensor<string, []>("pretrained_out_441_cast_fp16")];
            tensor<int32, [2]> var_8927 = const()[name = tensor<string, []>("op_8927"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8929 = const()[name = tensor<string, []>("op_8929"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_661_pad_type_0 = const()[name = tensor<string, []>("input_661_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_661_pad_0 = const()[name = tensor<string, []>("input_661_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_22_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_22_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(449240384)))];
            tensor<fp16, [1, 16, 1, 1]> input_661_cast_fp16 = conv(dilations = var_8929, groups = var_8883, pad = input_661_pad_0, pad_type = input_661_pad_type_0, strides = var_8927, weight = layers_22_self_attn_q_proj_loraA_weight_to_fp16, x = obj_309_cast_fp16)[name = tensor<string, []>("input_661_cast_fp16")];
            tensor<int32, [2]> var_8933 = const()[name = tensor<string, []>("op_8933"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8935 = const()[name = tensor<string, []>("op_8935"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_881_pad_type_0 = const()[name = tensor<string, []>("lora_out_881_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_881_pad_0 = const()[name = tensor<string, []>("lora_out_881_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_883_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_883_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(449281408)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_883_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_8935, groups = var_8883, pad = lora_out_881_pad_0, pad_type = lora_out_881_pad_type_0, strides = var_8933, weight = lora_out_883_weight_0_to_fp16, x = input_661_cast_fp16)[name = tensor<string, []>("lora_out_883_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_89_cast_fp16 = add(x = pretrained_out_441_cast_fp16, y = lora_out_883_cast_fp16)[name = tensor<string, []>("query_89_cast_fp16")];
            tensor<int32, [2]> var_8945 = const()[name = tensor<string, []>("op_8945"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8947 = const()[name = tensor<string, []>("op_8947"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_443_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_443_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_443_pad_0 = const()[name = tensor<string, []>("pretrained_out_443_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_22_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(449322432))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(450141696))), name = tensor<string, []>("layers_22_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_443_cast_fp16 = conv(dilations = var_8947, groups = var_8883, pad = pretrained_out_443_pad_0, pad_type = pretrained_out_443_pad_type_0, strides = var_8945, weight = layers_22_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_309_cast_fp16)[name = tensor<string, []>("pretrained_out_443_cast_fp16")];
            tensor<int32, [2]> var_8951 = const()[name = tensor<string, []>("op_8951"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8953 = const()[name = tensor<string, []>("op_8953"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_663_pad_type_0 = const()[name = tensor<string, []>("input_663_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_663_pad_0 = const()[name = tensor<string, []>("input_663_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_22_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_22_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(450141824)))];
            tensor<fp16, [1, 16, 1, 1]> input_663_cast_fp16 = conv(dilations = var_8953, groups = var_8883, pad = input_663_pad_0, pad_type = input_663_pad_type_0, strides = var_8951, weight = layers_22_self_attn_k_proj_loraA_weight_to_fp16, x = obj_309_cast_fp16)[name = tensor<string, []>("input_663_cast_fp16")];
            tensor<int32, [2]> var_8957 = const()[name = tensor<string, []>("op_8957"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8959 = const()[name = tensor<string, []>("op_8959"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_885_pad_type_0 = const()[name = tensor<string, []>("lora_out_885_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_885_pad_0 = const()[name = tensor<string, []>("lora_out_885_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_887_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_887_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(450182848)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_887_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_8959, groups = var_8883, pad = lora_out_885_pad_0, pad_type = lora_out_885_pad_type_0, strides = var_8957, weight = lora_out_887_weight_0_to_fp16, x = input_663_cast_fp16)[name = tensor<string, []>("lora_out_887_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_45_cast_fp16 = add(x = pretrained_out_443_cast_fp16, y = lora_out_887_cast_fp16)[name = tensor<string, []>("current_key_45_cast_fp16")];
            tensor<int32, [2]> var_8970 = const()[name = tensor<string, []>("op_8970"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8972 = const()[name = tensor<string, []>("op_8972"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_445_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_445_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_445_pad_0 = const()[name = tensor<string, []>("pretrained_out_445_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_22_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(450223872))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(451043136))), name = tensor<string, []>("layers_22_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_22_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_22_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(451043264)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_445_cast_fp16 = conv(bias = layers_22_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_8972, groups = var_8883, pad = pretrained_out_445_pad_0, pad_type = pretrained_out_445_pad_type_0, strides = var_8970, weight = layers_22_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_309_cast_fp16)[name = tensor<string, []>("pretrained_out_445_cast_fp16")];
            tensor<int32, [2]> var_8976 = const()[name = tensor<string, []>("op_8976"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8978 = const()[name = tensor<string, []>("op_8978"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_665_pad_type_0 = const()[name = tensor<string, []>("input_665_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_665_pad_0 = const()[name = tensor<string, []>("input_665_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_22_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_22_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(451045888)))];
            tensor<fp16, [1, 16, 1, 1]> input_665_cast_fp16 = conv(dilations = var_8978, groups = var_8883, pad = input_665_pad_0, pad_type = input_665_pad_type_0, strides = var_8976, weight = layers_22_self_attn_v_proj_loraA_weight_to_fp16, x = obj_309_cast_fp16)[name = tensor<string, []>("input_665_cast_fp16")];
            tensor<int32, [2]> var_8982 = const()[name = tensor<string, []>("op_8982"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_8984 = const()[name = tensor<string, []>("op_8984"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_889_pad_type_0 = const()[name = tensor<string, []>("lora_out_889_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_889_pad_0 = const()[name = tensor<string, []>("lora_out_889_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_891_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_891_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(451086912)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_891_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_8984, groups = var_8883, pad = lora_out_889_pad_0, pad_type = lora_out_889_pad_type_0, strides = var_8982, weight = lora_out_891_weight_0_to_fp16, x = input_665_cast_fp16)[name = tensor<string, []>("lora_out_891_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_45_cast_fp16 = add(x = pretrained_out_445_cast_fp16, y = lora_out_891_cast_fp16)[name = tensor<string, []>("current_value_45_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_8994_cast_fp16 = mul(x = current_key_45_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_8994_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_8996_cast_fp16 = mul(x = var_103_cast_fp16_22, y = var_295_cast_fp16)[name = tensor<string, []>("op_8996_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_89_cast_fp16 = add(x = var_8994_cast_fp16, y = var_8996_cast_fp16)[name = tensor<string, []>("key_89_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_8998_cast_fp16 = mul(x = current_value_45_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_8998_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_9000_cast_fp16 = mul(x = var_138_cast_fp16_22, y = var_295_cast_fp16)[name = tensor<string, []>("op_9000_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_89_cast_fp16 = add(x = var_8998_cast_fp16, y = var_9000_cast_fp16)[name = tensor<string, []>("value_89_cast_fp16")];
            tensor<int32, [4]> var_9003 = const()[name = tensor<string, []>("op_9003"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_9004_cast_fp16 = reshape(shape = var_9003, x = query_89_cast_fp16)[name = tensor<string, []>("op_9004_cast_fp16")];
            tensor<fp16, []> var_9005_to_fp16 = const()[name = tensor<string, []>("op_9005_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_9006_cast_fp16 = mul(x = var_9004_cast_fp16, y = var_9005_to_fp16)[name = tensor<string, []>("op_9006_cast_fp16")];
            tensor<int32, [4]> var_9007 = const()[name = tensor<string, []>("op_9007"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_9008_cast_fp16 = reshape(shape = var_9007, x = key_89_cast_fp16)[name = tensor<string, []>("op_9008_cast_fp16")];
            tensor<bool, []> mh_w_133_transpose_x_0 = const()[name = tensor<string, []>("mh_w_133_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_133_transpose_y_0 = const()[name = tensor<string, []>("mh_w_133_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_133_cast_fp16 = matmul(transpose_x = mh_w_133_transpose_x_0, transpose_y = mh_w_133_transpose_y_0, x = var_9006_cast_fp16, y = var_9008_cast_fp16)[name = tensor<string, []>("mh_w_133_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_135_cast_fp16 = add(x = mh_w_133_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_135_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_9016_cast_fp16 = softmax(axis = var_8876, x = mh_w_135_cast_fp16)[name = tensor<string, []>("op_9016_cast_fp16")];
            tensor<int32, [4]> var_9017 = const()[name = tensor<string, []>("op_9017"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_9018_cast_fp16 = reshape(shape = var_9017, x = value_89_cast_fp16)[name = tensor<string, []>("op_9018_cast_fp16")];
            tensor<bool, []> attn_89_transpose_x_0 = const()[name = tensor<string, []>("attn_89_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_89_transpose_y_0 = const()[name = tensor<string, []>("attn_89_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_89_cast_fp16 = matmul(transpose_x = attn_89_transpose_x_0, transpose_y = attn_89_transpose_y_0, x = var_9018_cast_fp16, y = var_9016_cast_fp16)[name = tensor<string, []>("attn_89_cast_fp16")];
            tensor<int32, [4]> var_9021 = const()[name = tensor<string, []>("op_9021"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_667_cast_fp16 = reshape(shape = var_9021, x = attn_89_cast_fp16)[name = tensor<string, []>("input_667_cast_fp16")];
            tensor<int32, [2]> var_9028 = const()[name = tensor<string, []>("op_9028"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9030 = const()[name = tensor<string, []>("op_9030"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_447_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_447_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_447_pad_0 = const()[name = tensor<string, []>("pretrained_out_447_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_22_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(451127936))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(451947200))), name = tensor<string, []>("layers_22_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_22_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_22_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(451947328)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_447_cast_fp16 = conv(bias = layers_22_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_9030, groups = var_8883, pad = pretrained_out_447_pad_0, pad_type = pretrained_out_447_pad_type_0, strides = var_9028, weight = layers_22_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_667_cast_fp16)[name = tensor<string, []>("pretrained_out_447_cast_fp16")];
            tensor<int32, [2]> var_9034 = const()[name = tensor<string, []>("op_9034"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9036 = const()[name = tensor<string, []>("op_9036"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_669_pad_type_0 = const()[name = tensor<string, []>("input_669_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_669_pad_0 = const()[name = tensor<string, []>("input_669_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_22_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_22_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(451949952)))];
            tensor<fp16, [1, 16, 1, 1]> input_669_cast_fp16 = conv(dilations = var_9036, groups = var_8883, pad = input_669_pad_0, pad_type = input_669_pad_type_0, strides = var_9034, weight = layers_22_self_attn_o_proj_loraA_weight_to_fp16, x = input_667_cast_fp16)[name = tensor<string, []>("input_669_cast_fp16")];
            tensor<int32, [2]> var_9040 = const()[name = tensor<string, []>("op_9040"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9042 = const()[name = tensor<string, []>("op_9042"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_893_pad_type_0 = const()[name = tensor<string, []>("lora_out_893_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_893_pad_0 = const()[name = tensor<string, []>("lora_out_893_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_895_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_895_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(451990976)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_895_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_9042, groups = var_8883, pad = lora_out_893_pad_0, pad_type = lora_out_893_pad_type_0, strides = var_9040, weight = lora_out_895_weight_0_to_fp16, x = input_669_cast_fp16)[name = tensor<string, []>("lora_out_895_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_315_cast_fp16 = add(x = pretrained_out_447_cast_fp16, y = lora_out_895_cast_fp16)[name = tensor<string, []>("obj_315_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_135_cast_fp16 = add(x = inputs_133_cast_fp16, y = obj_315_cast_fp16)[name = tensor<string, []>("inputs_135_cast_fp16")];
            tensor<int32, [1]> var_9055 = const()[name = tensor<string, []>("op_9055"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_135_cast_fp16 = reduce_mean(axes = var_9055, keep_dims = var_8884, x = inputs_135_cast_fp16)[name = tensor<string, []>("channels_mean_135_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_135_cast_fp16 = sub(x = inputs_135_cast_fp16, y = channels_mean_135_cast_fp16)[name = tensor<string, []>("zero_mean_135_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_135_cast_fp16 = mul(x = zero_mean_135_cast_fp16, y = zero_mean_135_cast_fp16)[name = tensor<string, []>("zero_mean_sq_135_cast_fp16")];
            tensor<int32, [1]> var_9059 = const()[name = tensor<string, []>("op_9059"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_9060_cast_fp16 = reduce_mean(axes = var_9059, keep_dims = var_8884, x = zero_mean_sq_135_cast_fp16)[name = tensor<string, []>("op_9060_cast_fp16")];
            tensor<fp16, []> var_9061_to_fp16 = const()[name = tensor<string, []>("op_9061_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_9062_cast_fp16 = add(x = var_9060_cast_fp16, y = var_9061_to_fp16)[name = tensor<string, []>("op_9062_cast_fp16")];
            tensor<fp32, []> denom_135_epsilon_0 = const()[name = tensor<string, []>("denom_135_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_135_cast_fp16 = rsqrt(epsilon = denom_135_epsilon_0, x = var_9062_cast_fp16)[name = tensor<string, []>("denom_135_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_135_cast_fp16 = mul(x = zero_mean_135_cast_fp16, y = denom_135_cast_fp16)[name = tensor<string, []>("out_135_cast_fp16")];
            tensor<fp16, [1280]> obj_317_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_317_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(452032000)))];
            tensor<fp16, [1280]> obj_317_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_317_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(452034624)))];
            tensor<fp16, []> obj_317_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_317_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_317_cast_fp16 = batch_norm(beta = obj_317_beta_0_to_fp16, epsilon = obj_317_epsilon_0_to_fp16, gamma = obj_317_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_135_cast_fp16)[name = tensor<string, []>("obj_317_cast_fp16")];
            tensor<int32, [2]> var_9080 = const()[name = tensor<string, []>("op_9080"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9082 = const()[name = tensor<string, []>("op_9082"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_449_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_449_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_449_pad_0 = const()[name = tensor<string, []>("pretrained_out_449_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_22_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(452037248))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(452856512))), name = tensor<string, []>("layers_22_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_22_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_22_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(452856640)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_449_cast_fp16 = conv(bias = layers_22_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_9082, groups = var_8883, pad = pretrained_out_449_pad_0, pad_type = pretrained_out_449_pad_type_0, strides = var_9080, weight = layers_22_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_317_cast_fp16)[name = tensor<string, []>("pretrained_out_449_cast_fp16")];
            tensor<int32, [2]> var_9086 = const()[name = tensor<string, []>("op_9086"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9088 = const()[name = tensor<string, []>("op_9088"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_671_pad_type_0 = const()[name = tensor<string, []>("input_671_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_671_pad_0 = const()[name = tensor<string, []>("input_671_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_22_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_22_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(452859264)))];
            tensor<fp16, [1, 16, 1, 1]> input_671_cast_fp16 = conv(dilations = var_9088, groups = var_8883, pad = input_671_pad_0, pad_type = input_671_pad_type_0, strides = var_9086, weight = layers_22_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_317_cast_fp16)[name = tensor<string, []>("input_671_cast_fp16")];
            tensor<int32, [2]> var_9092 = const()[name = tensor<string, []>("op_9092"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9094 = const()[name = tensor<string, []>("op_9094"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_897_pad_type_0 = const()[name = tensor<string, []>("lora_out_897_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_897_pad_0 = const()[name = tensor<string, []>("lora_out_897_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_899_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_899_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(452900288)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_899_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_9094, groups = var_8883, pad = lora_out_897_pad_0, pad_type = lora_out_897_pad_type_0, strides = var_9092, weight = lora_out_899_weight_0_to_fp16, x = input_671_cast_fp16)[name = tensor<string, []>("lora_out_899_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_91_cast_fp16 = add(x = pretrained_out_449_cast_fp16, y = lora_out_899_cast_fp16)[name = tensor<string, []>("query_91_cast_fp16")];
            tensor<int32, [2]> var_9104 = const()[name = tensor<string, []>("op_9104"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9106 = const()[name = tensor<string, []>("op_9106"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_451_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_451_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_451_pad_0 = const()[name = tensor<string, []>("pretrained_out_451_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_22_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(452941312))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(453760576))), name = tensor<string, []>("layers_22_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_451_cast_fp16 = conv(dilations = var_9106, groups = var_8883, pad = pretrained_out_451_pad_0, pad_type = pretrained_out_451_pad_type_0, strides = var_9104, weight = layers_22_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_451_cast_fp16")];
            tensor<int32, [2]> var_9110 = const()[name = tensor<string, []>("op_9110"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9112 = const()[name = tensor<string, []>("op_9112"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_673_pad_type_0 = const()[name = tensor<string, []>("input_673_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_673_pad_0 = const()[name = tensor<string, []>("input_673_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_22_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_22_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(453760704)))];
            tensor<fp16, [1, 16, 1, 1500]> input_673_cast_fp16 = conv(dilations = var_9112, groups = var_8883, pad = input_673_pad_0, pad_type = input_673_pad_type_0, strides = var_9110, weight = layers_22_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_673_cast_fp16")];
            tensor<int32, [2]> var_9116 = const()[name = tensor<string, []>("op_9116"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9118 = const()[name = tensor<string, []>("op_9118"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_901_pad_type_0 = const()[name = tensor<string, []>("lora_out_901_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_901_pad_0 = const()[name = tensor<string, []>("lora_out_901_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_903_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_903_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(453801728)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_903_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_9118, groups = var_8883, pad = lora_out_901_pad_0, pad_type = lora_out_901_pad_type_0, strides = var_9116, weight = lora_out_903_weight_0_to_fp16, x = input_673_cast_fp16)[name = tensor<string, []>("lora_out_903_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_91_cast_fp16 = add(x = pretrained_out_451_cast_fp16, y = lora_out_903_cast_fp16)[name = tensor<string, []>("key_91_cast_fp16")];
            tensor<int32, [2]> var_9129 = const()[name = tensor<string, []>("op_9129"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9131 = const()[name = tensor<string, []>("op_9131"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_453_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_453_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_453_pad_0 = const()[name = tensor<string, []>("pretrained_out_453_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_22_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(453842752))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(454662016))), name = tensor<string, []>("layers_22_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_22_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_22_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(454662144)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_453_cast_fp16 = conv(bias = layers_22_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_9131, groups = var_8883, pad = pretrained_out_453_pad_0, pad_type = pretrained_out_453_pad_type_0, strides = var_9129, weight = layers_22_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_453_cast_fp16")];
            tensor<int32, [2]> var_9135 = const()[name = tensor<string, []>("op_9135"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9137 = const()[name = tensor<string, []>("op_9137"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_675_pad_type_0 = const()[name = tensor<string, []>("input_675_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_675_pad_0 = const()[name = tensor<string, []>("input_675_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_22_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_22_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(454664768)))];
            tensor<fp16, [1, 16, 1, 1500]> input_675_cast_fp16 = conv(dilations = var_9137, groups = var_8883, pad = input_675_pad_0, pad_type = input_675_pad_type_0, strides = var_9135, weight = layers_22_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_675_cast_fp16")];
            tensor<int32, [2]> var_9141 = const()[name = tensor<string, []>("op_9141"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9143 = const()[name = tensor<string, []>("op_9143"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_905_pad_type_0 = const()[name = tensor<string, []>("lora_out_905_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_905_pad_0 = const()[name = tensor<string, []>("lora_out_905_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_907_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_907_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(454705792)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_907_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_9143, groups = var_8883, pad = lora_out_905_pad_0, pad_type = lora_out_905_pad_type_0, strides = var_9141, weight = lora_out_907_weight_0_to_fp16, x = input_675_cast_fp16)[name = tensor<string, []>("lora_out_907_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_91_cast_fp16 = add(x = pretrained_out_453_cast_fp16, y = lora_out_907_cast_fp16)[name = tensor<string, []>("value_91_cast_fp16")];
            tensor<int32, [4]> var_9150 = const()[name = tensor<string, []>("op_9150"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_9151_cast_fp16 = reshape(shape = var_9150, x = query_91_cast_fp16)[name = tensor<string, []>("op_9151_cast_fp16")];
            tensor<fp16, []> var_9152_to_fp16 = const()[name = tensor<string, []>("op_9152_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_9153_cast_fp16 = mul(x = var_9151_cast_fp16, y = var_9152_to_fp16)[name = tensor<string, []>("op_9153_cast_fp16")];
            tensor<int32, [4]> var_9154 = const()[name = tensor<string, []>("op_9154"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_9155_cast_fp16 = reshape(shape = var_9154, x = key_91_cast_fp16)[name = tensor<string, []>("op_9155_cast_fp16")];
            tensor<bool, []> mh_w_137_transpose_x_0 = const()[name = tensor<string, []>("mh_w_137_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_137_transpose_y_0 = const()[name = tensor<string, []>("mh_w_137_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_137_cast_fp16 = matmul(transpose_x = mh_w_137_transpose_x_0, transpose_y = mh_w_137_transpose_y_0, x = var_9153_cast_fp16, y = var_9155_cast_fp16)[name = tensor<string, []>("mh_w_137_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_321_cast_fp16 = softmax(axis = var_8876, x = mh_w_137_cast_fp16)[name = tensor<string, []>("obj_321_cast_fp16")];
            tensor<int32, [4]> var_9159 = const()[name = tensor<string, []>("op_9159"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_9160_cast_fp16 = reshape(shape = var_9159, x = value_91_cast_fp16)[name = tensor<string, []>("op_9160_cast_fp16")];
            tensor<bool, []> attn_91_transpose_x_0 = const()[name = tensor<string, []>("attn_91_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_91_transpose_y_0 = const()[name = tensor<string, []>("attn_91_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_91_cast_fp16 = matmul(transpose_x = attn_91_transpose_x_0, transpose_y = attn_91_transpose_y_0, x = var_9160_cast_fp16, y = obj_321_cast_fp16)[name = tensor<string, []>("attn_91_cast_fp16")];
            tensor<int32, [4]> var_9163 = const()[name = tensor<string, []>("op_9163"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_677_cast_fp16 = reshape(shape = var_9163, x = attn_91_cast_fp16)[name = tensor<string, []>("input_677_cast_fp16")];
            tensor<int32, [2]> var_9170 = const()[name = tensor<string, []>("op_9170"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9172 = const()[name = tensor<string, []>("op_9172"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_455_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_455_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_455_pad_0 = const()[name = tensor<string, []>("pretrained_out_455_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_22_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(454746816))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(455566080))), name = tensor<string, []>("layers_22_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_22_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_22_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(455566208)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_455_cast_fp16 = conv(bias = layers_22_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_9172, groups = var_8883, pad = pretrained_out_455_pad_0, pad_type = pretrained_out_455_pad_type_0, strides = var_9170, weight = layers_22_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_677_cast_fp16)[name = tensor<string, []>("pretrained_out_455_cast_fp16")];
            tensor<int32, [2]> var_9176 = const()[name = tensor<string, []>("op_9176"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9178 = const()[name = tensor<string, []>("op_9178"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_679_pad_type_0 = const()[name = tensor<string, []>("input_679_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_679_pad_0 = const()[name = tensor<string, []>("input_679_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_22_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_22_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(455568832)))];
            tensor<fp16, [1, 16, 1, 1]> input_679_cast_fp16 = conv(dilations = var_9178, groups = var_8883, pad = input_679_pad_0, pad_type = input_679_pad_type_0, strides = var_9176, weight = layers_22_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_677_cast_fp16)[name = tensor<string, []>("input_679_cast_fp16")];
            tensor<int32, [2]> var_9182 = const()[name = tensor<string, []>("op_9182"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9184 = const()[name = tensor<string, []>("op_9184"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_909_pad_type_0 = const()[name = tensor<string, []>("lora_out_909_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_909_pad_0 = const()[name = tensor<string, []>("lora_out_909_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_911_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_911_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(455609856)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_911_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_9184, groups = var_8883, pad = lora_out_909_pad_0, pad_type = lora_out_909_pad_type_0, strides = var_9182, weight = lora_out_911_weight_0_to_fp16, x = input_679_cast_fp16)[name = tensor<string, []>("lora_out_911_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_319_cast_fp16 = add(x = pretrained_out_455_cast_fp16, y = lora_out_911_cast_fp16)[name = tensor<string, []>("obj_319_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_137_cast_fp16 = add(x = inputs_135_cast_fp16, y = obj_319_cast_fp16)[name = tensor<string, []>("inputs_137_cast_fp16")];
            tensor<int32, [1]> var_9193 = const()[name = tensor<string, []>("op_9193"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_137_cast_fp16 = reduce_mean(axes = var_9193, keep_dims = var_8884, x = inputs_137_cast_fp16)[name = tensor<string, []>("channels_mean_137_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_137_cast_fp16 = sub(x = inputs_137_cast_fp16, y = channels_mean_137_cast_fp16)[name = tensor<string, []>("zero_mean_137_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_137_cast_fp16 = mul(x = zero_mean_137_cast_fp16, y = zero_mean_137_cast_fp16)[name = tensor<string, []>("zero_mean_sq_137_cast_fp16")];
            tensor<int32, [1]> var_9197 = const()[name = tensor<string, []>("op_9197"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_9198_cast_fp16 = reduce_mean(axes = var_9197, keep_dims = var_8884, x = zero_mean_sq_137_cast_fp16)[name = tensor<string, []>("op_9198_cast_fp16")];
            tensor<fp16, []> var_9199_to_fp16 = const()[name = tensor<string, []>("op_9199_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_9200_cast_fp16 = add(x = var_9198_cast_fp16, y = var_9199_to_fp16)[name = tensor<string, []>("op_9200_cast_fp16")];
            tensor<fp32, []> denom_137_epsilon_0 = const()[name = tensor<string, []>("denom_137_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_137_cast_fp16 = rsqrt(epsilon = denom_137_epsilon_0, x = var_9200_cast_fp16)[name = tensor<string, []>("denom_137_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_137_cast_fp16 = mul(x = zero_mean_137_cast_fp16, y = denom_137_cast_fp16)[name = tensor<string, []>("out_137_cast_fp16")];
            tensor<fp16, [1280]> input_681_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_681_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(455650880)))];
            tensor<fp16, [1280]> input_681_beta_0_to_fp16 = const()[name = tensor<string, []>("input_681_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(455653504)))];
            tensor<fp16, []> input_681_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_681_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_681_cast_fp16 = batch_norm(beta = input_681_beta_0_to_fp16, epsilon = input_681_epsilon_0_to_fp16, gamma = input_681_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_137_cast_fp16)[name = tensor<string, []>("input_681_cast_fp16")];
            tensor<int32, [2]> var_9214 = const()[name = tensor<string, []>("op_9214"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9216 = const()[name = tensor<string, []>("op_9216"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_457_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_457_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_457_pad_0 = const()[name = tensor<string, []>("pretrained_out_457_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_22_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(455656128))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(458932992))), name = tensor<string, []>("layers_22_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_22_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_22_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(458933120)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_457_cast_fp16 = conv(bias = layers_22_fc1_pretrained_bias_to_fp16, dilations = var_9216, groups = var_8883, pad = pretrained_out_457_pad_0, pad_type = pretrained_out_457_pad_type_0, strides = var_9214, weight = layers_22_fc1_pretrained_weight_to_fp16_palettized, x = input_681_cast_fp16)[name = tensor<string, []>("pretrained_out_457_cast_fp16")];
            tensor<int32, [2]> var_9220 = const()[name = tensor<string, []>("op_9220"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9222 = const()[name = tensor<string, []>("op_9222"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_683_pad_type_0 = const()[name = tensor<string, []>("input_683_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_683_pad_0 = const()[name = tensor<string, []>("input_683_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_22_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_22_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(458943424)))];
            tensor<fp16, [1, 16, 1, 1]> input_683_cast_fp16 = conv(dilations = var_9222, groups = var_8883, pad = input_683_pad_0, pad_type = input_683_pad_type_0, strides = var_9220, weight = layers_22_fc1_loraA_weight_to_fp16, x = input_681_cast_fp16)[name = tensor<string, []>("input_683_cast_fp16")];
            tensor<int32, [2]> var_9226 = const()[name = tensor<string, []>("op_9226"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9228 = const()[name = tensor<string, []>("op_9228"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_913_pad_type_0 = const()[name = tensor<string, []>("lora_out_913_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_913_pad_0 = const()[name = tensor<string, []>("lora_out_913_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_915_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_915_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(458984448)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_915_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_9228, groups = var_8883, pad = lora_out_913_pad_0, pad_type = lora_out_913_pad_type_0, strides = var_9226, weight = lora_out_915_weight_0_to_fp16, x = input_683_cast_fp16)[name = tensor<string, []>("lora_out_915_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_685_cast_fp16 = add(x = pretrained_out_457_cast_fp16, y = lora_out_915_cast_fp16)[name = tensor<string, []>("input_685_cast_fp16")];
            tensor<string, []> input_687_mode_0 = const()[name = tensor<string, []>("input_687_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_687_cast_fp16 = gelu(mode = input_687_mode_0, x = input_685_cast_fp16)[name = tensor<string, []>("input_687_cast_fp16")];
            tensor<int32, [2]> var_9240 = const()[name = tensor<string, []>("op_9240"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9242 = const()[name = tensor<string, []>("op_9242"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_459_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_459_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_459_pad_0 = const()[name = tensor<string, []>("pretrained_out_459_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_22_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(459148352))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(462425216))), name = tensor<string, []>("layers_22_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_22_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_22_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(462425344)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_459_cast_fp16 = conv(bias = layers_22_fc2_pretrained_bias_to_fp16, dilations = var_9242, groups = var_8883, pad = pretrained_out_459_pad_0, pad_type = pretrained_out_459_pad_type_0, strides = var_9240, weight = layers_22_fc2_pretrained_weight_to_fp16_palettized, x = input_687_cast_fp16)[name = tensor<string, []>("pretrained_out_459_cast_fp16")];
            tensor<int32, [2]> var_9246 = const()[name = tensor<string, []>("op_9246"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9248 = const()[name = tensor<string, []>("op_9248"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_689_pad_type_0 = const()[name = tensor<string, []>("input_689_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_689_pad_0 = const()[name = tensor<string, []>("input_689_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_22_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_22_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(462427968)))];
            tensor<fp16, [1, 16, 1, 1]> input_689_cast_fp16 = conv(dilations = var_9248, groups = var_8883, pad = input_689_pad_0, pad_type = input_689_pad_type_0, strides = var_9246, weight = layers_22_fc2_loraA_weight_to_fp16, x = input_687_cast_fp16)[name = tensor<string, []>("input_689_cast_fp16")];
            tensor<int32, [2]> var_9252 = const()[name = tensor<string, []>("op_9252"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9254 = const()[name = tensor<string, []>("op_9254"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_917_pad_type_0 = const()[name = tensor<string, []>("lora_out_917_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_917_pad_0 = const()[name = tensor<string, []>("lora_out_917_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_919_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_919_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(462591872)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_919_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_9254, groups = var_8883, pad = lora_out_917_pad_0, pad_type = lora_out_917_pad_type_0, strides = var_9252, weight = lora_out_919_weight_0_to_fp16, x = input_689_cast_fp16)[name = tensor<string, []>("lora_out_919_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_47_cast_fp16 = add(x = pretrained_out_459_cast_fp16, y = lora_out_919_cast_fp16)[name = tensor<string, []>("hidden_states_47_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_139_cast_fp16 = add(x = inputs_137_cast_fp16, y = hidden_states_47_cast_fp16)[name = tensor<string, []>("inputs_139_cast_fp16")];
            tensor<int32, []> var_9270 = const()[name = tensor<string, []>("op_9270"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_9277 = const()[name = tensor<string, []>("op_9277"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_9278 = const()[name = tensor<string, []>("op_9278"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_9290 = const()[name = tensor<string, []>("op_9290"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_139_cast_fp16 = reduce_mean(axes = var_9290, keep_dims = var_9278, x = inputs_139_cast_fp16)[name = tensor<string, []>("channels_mean_139_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_139_cast_fp16 = sub(x = inputs_139_cast_fp16, y = channels_mean_139_cast_fp16)[name = tensor<string, []>("zero_mean_139_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_139_cast_fp16 = mul(x = zero_mean_139_cast_fp16, y = zero_mean_139_cast_fp16)[name = tensor<string, []>("zero_mean_sq_139_cast_fp16")];
            tensor<int32, [1]> var_9294 = const()[name = tensor<string, []>("op_9294"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_9295_cast_fp16 = reduce_mean(axes = var_9294, keep_dims = var_9278, x = zero_mean_sq_139_cast_fp16)[name = tensor<string, []>("op_9295_cast_fp16")];
            tensor<fp16, []> var_9296_to_fp16 = const()[name = tensor<string, []>("op_9296_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_9297_cast_fp16 = add(x = var_9295_cast_fp16, y = var_9296_to_fp16)[name = tensor<string, []>("op_9297_cast_fp16")];
            tensor<fp32, []> denom_139_epsilon_0 = const()[name = tensor<string, []>("denom_139_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_139_cast_fp16 = rsqrt(epsilon = denom_139_epsilon_0, x = var_9297_cast_fp16)[name = tensor<string, []>("denom_139_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_139_cast_fp16 = mul(x = zero_mean_139_cast_fp16, y = denom_139_cast_fp16)[name = tensor<string, []>("out_139_cast_fp16")];
            tensor<fp16, [1280]> obj_323_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_323_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(462632896)))];
            tensor<fp16, [1280]> obj_323_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_323_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(462635520)))];
            tensor<fp16, []> obj_323_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_323_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_323_cast_fp16 = batch_norm(beta = obj_323_beta_0_to_fp16, epsilon = obj_323_epsilon_0_to_fp16, gamma = obj_323_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_139_cast_fp16)[name = tensor<string, []>("obj_323_cast_fp16")];
            tensor<int32, [2]> var_9315 = const()[name = tensor<string, []>("op_9315"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9317 = const()[name = tensor<string, []>("op_9317"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_461_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_461_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_461_pad_0 = const()[name = tensor<string, []>("pretrained_out_461_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_23_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(462638144))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(463457408))), name = tensor<string, []>("layers_23_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_23_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_23_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(463457536)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_461_cast_fp16 = conv(bias = layers_23_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_9317, groups = var_9277, pad = pretrained_out_461_pad_0, pad_type = pretrained_out_461_pad_type_0, strides = var_9315, weight = layers_23_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_323_cast_fp16)[name = tensor<string, []>("pretrained_out_461_cast_fp16")];
            tensor<int32, [2]> var_9321 = const()[name = tensor<string, []>("op_9321"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9323 = const()[name = tensor<string, []>("op_9323"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_691_pad_type_0 = const()[name = tensor<string, []>("input_691_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_691_pad_0 = const()[name = tensor<string, []>("input_691_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_23_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_23_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(463460160)))];
            tensor<fp16, [1, 16, 1, 1]> input_691_cast_fp16 = conv(dilations = var_9323, groups = var_9277, pad = input_691_pad_0, pad_type = input_691_pad_type_0, strides = var_9321, weight = layers_23_self_attn_q_proj_loraA_weight_to_fp16, x = obj_323_cast_fp16)[name = tensor<string, []>("input_691_cast_fp16")];
            tensor<int32, [2]> var_9327 = const()[name = tensor<string, []>("op_9327"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9329 = const()[name = tensor<string, []>("op_9329"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_921_pad_type_0 = const()[name = tensor<string, []>("lora_out_921_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_921_pad_0 = const()[name = tensor<string, []>("lora_out_921_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_923_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_923_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(463501184)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_923_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_9329, groups = var_9277, pad = lora_out_921_pad_0, pad_type = lora_out_921_pad_type_0, strides = var_9327, weight = lora_out_923_weight_0_to_fp16, x = input_691_cast_fp16)[name = tensor<string, []>("lora_out_923_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_93_cast_fp16 = add(x = pretrained_out_461_cast_fp16, y = lora_out_923_cast_fp16)[name = tensor<string, []>("query_93_cast_fp16")];
            tensor<int32, [2]> var_9339 = const()[name = tensor<string, []>("op_9339"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9341 = const()[name = tensor<string, []>("op_9341"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_463_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_463_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_463_pad_0 = const()[name = tensor<string, []>("pretrained_out_463_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_23_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(463542208))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(464361472))), name = tensor<string, []>("layers_23_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_463_cast_fp16 = conv(dilations = var_9341, groups = var_9277, pad = pretrained_out_463_pad_0, pad_type = pretrained_out_463_pad_type_0, strides = var_9339, weight = layers_23_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_323_cast_fp16)[name = tensor<string, []>("pretrained_out_463_cast_fp16")];
            tensor<int32, [2]> var_9345 = const()[name = tensor<string, []>("op_9345"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9347 = const()[name = tensor<string, []>("op_9347"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_693_pad_type_0 = const()[name = tensor<string, []>("input_693_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_693_pad_0 = const()[name = tensor<string, []>("input_693_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_23_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_23_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(464361600)))];
            tensor<fp16, [1, 16, 1, 1]> input_693_cast_fp16 = conv(dilations = var_9347, groups = var_9277, pad = input_693_pad_0, pad_type = input_693_pad_type_0, strides = var_9345, weight = layers_23_self_attn_k_proj_loraA_weight_to_fp16, x = obj_323_cast_fp16)[name = tensor<string, []>("input_693_cast_fp16")];
            tensor<int32, [2]> var_9351 = const()[name = tensor<string, []>("op_9351"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9353 = const()[name = tensor<string, []>("op_9353"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_925_pad_type_0 = const()[name = tensor<string, []>("lora_out_925_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_925_pad_0 = const()[name = tensor<string, []>("lora_out_925_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_927_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_927_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(464402624)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_927_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_9353, groups = var_9277, pad = lora_out_925_pad_0, pad_type = lora_out_925_pad_type_0, strides = var_9351, weight = lora_out_927_weight_0_to_fp16, x = input_693_cast_fp16)[name = tensor<string, []>("lora_out_927_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_47_cast_fp16 = add(x = pretrained_out_463_cast_fp16, y = lora_out_927_cast_fp16)[name = tensor<string, []>("current_key_47_cast_fp16")];
            tensor<int32, [2]> var_9364 = const()[name = tensor<string, []>("op_9364"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9366 = const()[name = tensor<string, []>("op_9366"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_465_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_465_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_465_pad_0 = const()[name = tensor<string, []>("pretrained_out_465_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_23_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(464443648))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(465262912))), name = tensor<string, []>("layers_23_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_23_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_23_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(465263040)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_465_cast_fp16 = conv(bias = layers_23_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_9366, groups = var_9277, pad = pretrained_out_465_pad_0, pad_type = pretrained_out_465_pad_type_0, strides = var_9364, weight = layers_23_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_323_cast_fp16)[name = tensor<string, []>("pretrained_out_465_cast_fp16")];
            tensor<int32, [2]> var_9370 = const()[name = tensor<string, []>("op_9370"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9372 = const()[name = tensor<string, []>("op_9372"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_695_pad_type_0 = const()[name = tensor<string, []>("input_695_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_695_pad_0 = const()[name = tensor<string, []>("input_695_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_23_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_23_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(465265664)))];
            tensor<fp16, [1, 16, 1, 1]> input_695_cast_fp16 = conv(dilations = var_9372, groups = var_9277, pad = input_695_pad_0, pad_type = input_695_pad_type_0, strides = var_9370, weight = layers_23_self_attn_v_proj_loraA_weight_to_fp16, x = obj_323_cast_fp16)[name = tensor<string, []>("input_695_cast_fp16")];
            tensor<int32, [2]> var_9376 = const()[name = tensor<string, []>("op_9376"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9378 = const()[name = tensor<string, []>("op_9378"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_929_pad_type_0 = const()[name = tensor<string, []>("lora_out_929_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_929_pad_0 = const()[name = tensor<string, []>("lora_out_929_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_931_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_931_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(465306688)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_931_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_9378, groups = var_9277, pad = lora_out_929_pad_0, pad_type = lora_out_929_pad_type_0, strides = var_9376, weight = lora_out_931_weight_0_to_fp16, x = input_695_cast_fp16)[name = tensor<string, []>("lora_out_931_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_47_cast_fp16 = add(x = pretrained_out_465_cast_fp16, y = lora_out_931_cast_fp16)[name = tensor<string, []>("current_value_47_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_9388_cast_fp16 = mul(x = current_key_47_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_9388_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_9390_cast_fp16 = mul(x = var_103_cast_fp16_23, y = var_295_cast_fp16)[name = tensor<string, []>("op_9390_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_93_cast_fp16 = add(x = var_9388_cast_fp16, y = var_9390_cast_fp16)[name = tensor<string, []>("key_93_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_9392_cast_fp16 = mul(x = current_value_47_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_9392_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_9394_cast_fp16 = mul(x = var_138_cast_fp16_23, y = var_295_cast_fp16)[name = tensor<string, []>("op_9394_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_93_cast_fp16 = add(x = var_9392_cast_fp16, y = var_9394_cast_fp16)[name = tensor<string, []>("value_93_cast_fp16")];
            tensor<int32, [4]> var_9397 = const()[name = tensor<string, []>("op_9397"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_9398_cast_fp16 = reshape(shape = var_9397, x = query_93_cast_fp16)[name = tensor<string, []>("op_9398_cast_fp16")];
            tensor<fp16, []> var_9399_to_fp16 = const()[name = tensor<string, []>("op_9399_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_9400_cast_fp16 = mul(x = var_9398_cast_fp16, y = var_9399_to_fp16)[name = tensor<string, []>("op_9400_cast_fp16")];
            tensor<int32, [4]> var_9401 = const()[name = tensor<string, []>("op_9401"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_9402_cast_fp16 = reshape(shape = var_9401, x = key_93_cast_fp16)[name = tensor<string, []>("op_9402_cast_fp16")];
            tensor<bool, []> mh_w_139_transpose_x_0 = const()[name = tensor<string, []>("mh_w_139_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_139_transpose_y_0 = const()[name = tensor<string, []>("mh_w_139_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_139_cast_fp16 = matmul(transpose_x = mh_w_139_transpose_x_0, transpose_y = mh_w_139_transpose_y_0, x = var_9400_cast_fp16, y = var_9402_cast_fp16)[name = tensor<string, []>("mh_w_139_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_141_cast_fp16 = add(x = mh_w_139_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_141_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_9410_cast_fp16 = softmax(axis = var_9270, x = mh_w_141_cast_fp16)[name = tensor<string, []>("op_9410_cast_fp16")];
            tensor<int32, [4]> var_9411 = const()[name = tensor<string, []>("op_9411"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_9412_cast_fp16 = reshape(shape = var_9411, x = value_93_cast_fp16)[name = tensor<string, []>("op_9412_cast_fp16")];
            tensor<bool, []> attn_93_transpose_x_0 = const()[name = tensor<string, []>("attn_93_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_93_transpose_y_0 = const()[name = tensor<string, []>("attn_93_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_93_cast_fp16 = matmul(transpose_x = attn_93_transpose_x_0, transpose_y = attn_93_transpose_y_0, x = var_9412_cast_fp16, y = var_9410_cast_fp16)[name = tensor<string, []>("attn_93_cast_fp16")];
            tensor<int32, [4]> var_9415 = const()[name = tensor<string, []>("op_9415"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_697_cast_fp16 = reshape(shape = var_9415, x = attn_93_cast_fp16)[name = tensor<string, []>("input_697_cast_fp16")];
            tensor<int32, [2]> var_9422 = const()[name = tensor<string, []>("op_9422"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9424 = const()[name = tensor<string, []>("op_9424"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_467_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_467_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_467_pad_0 = const()[name = tensor<string, []>("pretrained_out_467_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_23_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(465347712))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(466166976))), name = tensor<string, []>("layers_23_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_23_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_23_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(466167104)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_467_cast_fp16 = conv(bias = layers_23_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_9424, groups = var_9277, pad = pretrained_out_467_pad_0, pad_type = pretrained_out_467_pad_type_0, strides = var_9422, weight = layers_23_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_697_cast_fp16)[name = tensor<string, []>("pretrained_out_467_cast_fp16")];
            tensor<int32, [2]> var_9428 = const()[name = tensor<string, []>("op_9428"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9430 = const()[name = tensor<string, []>("op_9430"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_699_pad_type_0 = const()[name = tensor<string, []>("input_699_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_699_pad_0 = const()[name = tensor<string, []>("input_699_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_23_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_23_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(466169728)))];
            tensor<fp16, [1, 16, 1, 1]> input_699_cast_fp16 = conv(dilations = var_9430, groups = var_9277, pad = input_699_pad_0, pad_type = input_699_pad_type_0, strides = var_9428, weight = layers_23_self_attn_o_proj_loraA_weight_to_fp16, x = input_697_cast_fp16)[name = tensor<string, []>("input_699_cast_fp16")];
            tensor<int32, [2]> var_9434 = const()[name = tensor<string, []>("op_9434"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9436 = const()[name = tensor<string, []>("op_9436"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_933_pad_type_0 = const()[name = tensor<string, []>("lora_out_933_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_933_pad_0 = const()[name = tensor<string, []>("lora_out_933_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_935_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_935_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(466210752)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_935_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_9436, groups = var_9277, pad = lora_out_933_pad_0, pad_type = lora_out_933_pad_type_0, strides = var_9434, weight = lora_out_935_weight_0_to_fp16, x = input_699_cast_fp16)[name = tensor<string, []>("lora_out_935_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_329_cast_fp16 = add(x = pretrained_out_467_cast_fp16, y = lora_out_935_cast_fp16)[name = tensor<string, []>("obj_329_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_141_cast_fp16 = add(x = inputs_139_cast_fp16, y = obj_329_cast_fp16)[name = tensor<string, []>("inputs_141_cast_fp16")];
            tensor<int32, [1]> var_9449 = const()[name = tensor<string, []>("op_9449"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_141_cast_fp16 = reduce_mean(axes = var_9449, keep_dims = var_9278, x = inputs_141_cast_fp16)[name = tensor<string, []>("channels_mean_141_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_141_cast_fp16 = sub(x = inputs_141_cast_fp16, y = channels_mean_141_cast_fp16)[name = tensor<string, []>("zero_mean_141_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_141_cast_fp16 = mul(x = zero_mean_141_cast_fp16, y = zero_mean_141_cast_fp16)[name = tensor<string, []>("zero_mean_sq_141_cast_fp16")];
            tensor<int32, [1]> var_9453 = const()[name = tensor<string, []>("op_9453"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_9454_cast_fp16 = reduce_mean(axes = var_9453, keep_dims = var_9278, x = zero_mean_sq_141_cast_fp16)[name = tensor<string, []>("op_9454_cast_fp16")];
            tensor<fp16, []> var_9455_to_fp16 = const()[name = tensor<string, []>("op_9455_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_9456_cast_fp16 = add(x = var_9454_cast_fp16, y = var_9455_to_fp16)[name = tensor<string, []>("op_9456_cast_fp16")];
            tensor<fp32, []> denom_141_epsilon_0 = const()[name = tensor<string, []>("denom_141_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_141_cast_fp16 = rsqrt(epsilon = denom_141_epsilon_0, x = var_9456_cast_fp16)[name = tensor<string, []>("denom_141_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_141_cast_fp16 = mul(x = zero_mean_141_cast_fp16, y = denom_141_cast_fp16)[name = tensor<string, []>("out_141_cast_fp16")];
            tensor<fp16, [1280]> obj_331_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_331_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(466251776)))];
            tensor<fp16, [1280]> obj_331_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_331_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(466254400)))];
            tensor<fp16, []> obj_331_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_331_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_331_cast_fp16 = batch_norm(beta = obj_331_beta_0_to_fp16, epsilon = obj_331_epsilon_0_to_fp16, gamma = obj_331_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_141_cast_fp16)[name = tensor<string, []>("obj_331_cast_fp16")];
            tensor<int32, [2]> var_9474 = const()[name = tensor<string, []>("op_9474"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9476 = const()[name = tensor<string, []>("op_9476"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_469_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_469_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_469_pad_0 = const()[name = tensor<string, []>("pretrained_out_469_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_23_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(466257024))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(467076288))), name = tensor<string, []>("layers_23_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_23_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_23_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(467076416)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_469_cast_fp16 = conv(bias = layers_23_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_9476, groups = var_9277, pad = pretrained_out_469_pad_0, pad_type = pretrained_out_469_pad_type_0, strides = var_9474, weight = layers_23_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_331_cast_fp16)[name = tensor<string, []>("pretrained_out_469_cast_fp16")];
            tensor<int32, [2]> var_9480 = const()[name = tensor<string, []>("op_9480"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9482 = const()[name = tensor<string, []>("op_9482"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_701_pad_type_0 = const()[name = tensor<string, []>("input_701_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_701_pad_0 = const()[name = tensor<string, []>("input_701_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_23_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_23_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(467079040)))];
            tensor<fp16, [1, 16, 1, 1]> input_701_cast_fp16 = conv(dilations = var_9482, groups = var_9277, pad = input_701_pad_0, pad_type = input_701_pad_type_0, strides = var_9480, weight = layers_23_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_331_cast_fp16)[name = tensor<string, []>("input_701_cast_fp16")];
            tensor<int32, [2]> var_9486 = const()[name = tensor<string, []>("op_9486"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9488 = const()[name = tensor<string, []>("op_9488"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_937_pad_type_0 = const()[name = tensor<string, []>("lora_out_937_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_937_pad_0 = const()[name = tensor<string, []>("lora_out_937_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_939_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_939_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(467120064)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_939_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_9488, groups = var_9277, pad = lora_out_937_pad_0, pad_type = lora_out_937_pad_type_0, strides = var_9486, weight = lora_out_939_weight_0_to_fp16, x = input_701_cast_fp16)[name = tensor<string, []>("lora_out_939_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_95_cast_fp16 = add(x = pretrained_out_469_cast_fp16, y = lora_out_939_cast_fp16)[name = tensor<string, []>("query_95_cast_fp16")];
            tensor<int32, [2]> var_9498 = const()[name = tensor<string, []>("op_9498"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9500 = const()[name = tensor<string, []>("op_9500"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_471_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_471_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_471_pad_0 = const()[name = tensor<string, []>("pretrained_out_471_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_23_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(467161088))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(467980352))), name = tensor<string, []>("layers_23_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_471_cast_fp16 = conv(dilations = var_9500, groups = var_9277, pad = pretrained_out_471_pad_0, pad_type = pretrained_out_471_pad_type_0, strides = var_9498, weight = layers_23_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_471_cast_fp16")];
            tensor<int32, [2]> var_9504 = const()[name = tensor<string, []>("op_9504"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9506 = const()[name = tensor<string, []>("op_9506"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_703_pad_type_0 = const()[name = tensor<string, []>("input_703_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_703_pad_0 = const()[name = tensor<string, []>("input_703_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_23_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_23_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(467980480)))];
            tensor<fp16, [1, 16, 1, 1500]> input_703_cast_fp16 = conv(dilations = var_9506, groups = var_9277, pad = input_703_pad_0, pad_type = input_703_pad_type_0, strides = var_9504, weight = layers_23_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_703_cast_fp16")];
            tensor<int32, [2]> var_9510 = const()[name = tensor<string, []>("op_9510"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9512 = const()[name = tensor<string, []>("op_9512"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_941_pad_type_0 = const()[name = tensor<string, []>("lora_out_941_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_941_pad_0 = const()[name = tensor<string, []>("lora_out_941_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_943_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_943_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(468021504)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_943_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_9512, groups = var_9277, pad = lora_out_941_pad_0, pad_type = lora_out_941_pad_type_0, strides = var_9510, weight = lora_out_943_weight_0_to_fp16, x = input_703_cast_fp16)[name = tensor<string, []>("lora_out_943_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_95_cast_fp16 = add(x = pretrained_out_471_cast_fp16, y = lora_out_943_cast_fp16)[name = tensor<string, []>("key_95_cast_fp16")];
            tensor<int32, [2]> var_9523 = const()[name = tensor<string, []>("op_9523"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9525 = const()[name = tensor<string, []>("op_9525"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_473_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_473_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_473_pad_0 = const()[name = tensor<string, []>("pretrained_out_473_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_23_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(468062528))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(468881792))), name = tensor<string, []>("layers_23_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_23_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_23_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(468881920)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_473_cast_fp16 = conv(bias = layers_23_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_9525, groups = var_9277, pad = pretrained_out_473_pad_0, pad_type = pretrained_out_473_pad_type_0, strides = var_9523, weight = layers_23_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_473_cast_fp16")];
            tensor<int32, [2]> var_9529 = const()[name = tensor<string, []>("op_9529"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9531 = const()[name = tensor<string, []>("op_9531"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_705_pad_type_0 = const()[name = tensor<string, []>("input_705_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_705_pad_0 = const()[name = tensor<string, []>("input_705_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_23_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_23_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(468884544)))];
            tensor<fp16, [1, 16, 1, 1500]> input_705_cast_fp16 = conv(dilations = var_9531, groups = var_9277, pad = input_705_pad_0, pad_type = input_705_pad_type_0, strides = var_9529, weight = layers_23_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_705_cast_fp16")];
            tensor<int32, [2]> var_9535 = const()[name = tensor<string, []>("op_9535"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9537 = const()[name = tensor<string, []>("op_9537"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_945_pad_type_0 = const()[name = tensor<string, []>("lora_out_945_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_945_pad_0 = const()[name = tensor<string, []>("lora_out_945_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_947_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_947_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(468925568)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_947_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_9537, groups = var_9277, pad = lora_out_945_pad_0, pad_type = lora_out_945_pad_type_0, strides = var_9535, weight = lora_out_947_weight_0_to_fp16, x = input_705_cast_fp16)[name = tensor<string, []>("lora_out_947_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_95_cast_fp16 = add(x = pretrained_out_473_cast_fp16, y = lora_out_947_cast_fp16)[name = tensor<string, []>("value_95_cast_fp16")];
            tensor<int32, [4]> var_9544 = const()[name = tensor<string, []>("op_9544"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_9545_cast_fp16 = reshape(shape = var_9544, x = query_95_cast_fp16)[name = tensor<string, []>("op_9545_cast_fp16")];
            tensor<fp16, []> var_9546_to_fp16 = const()[name = tensor<string, []>("op_9546_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_9547_cast_fp16 = mul(x = var_9545_cast_fp16, y = var_9546_to_fp16)[name = tensor<string, []>("op_9547_cast_fp16")];
            tensor<int32, [4]> var_9548 = const()[name = tensor<string, []>("op_9548"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_9549_cast_fp16 = reshape(shape = var_9548, x = key_95_cast_fp16)[name = tensor<string, []>("op_9549_cast_fp16")];
            tensor<bool, []> mh_w_143_transpose_x_0 = const()[name = tensor<string, []>("mh_w_143_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_143_transpose_y_0 = const()[name = tensor<string, []>("mh_w_143_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_143_cast_fp16 = matmul(transpose_x = mh_w_143_transpose_x_0, transpose_y = mh_w_143_transpose_y_0, x = var_9547_cast_fp16, y = var_9549_cast_fp16)[name = tensor<string, []>("mh_w_143_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_335_cast_fp16 = softmax(axis = var_9270, x = mh_w_143_cast_fp16)[name = tensor<string, []>("obj_335_cast_fp16")];
            tensor<int32, [4]> var_9553 = const()[name = tensor<string, []>("op_9553"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_9554_cast_fp16 = reshape(shape = var_9553, x = value_95_cast_fp16)[name = tensor<string, []>("op_9554_cast_fp16")];
            tensor<bool, []> attn_95_transpose_x_0 = const()[name = tensor<string, []>("attn_95_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_95_transpose_y_0 = const()[name = tensor<string, []>("attn_95_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_95_cast_fp16 = matmul(transpose_x = attn_95_transpose_x_0, transpose_y = attn_95_transpose_y_0, x = var_9554_cast_fp16, y = obj_335_cast_fp16)[name = tensor<string, []>("attn_95_cast_fp16")];
            tensor<int32, [4]> var_9557 = const()[name = tensor<string, []>("op_9557"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_707_cast_fp16 = reshape(shape = var_9557, x = attn_95_cast_fp16)[name = tensor<string, []>("input_707_cast_fp16")];
            tensor<int32, [2]> var_9564 = const()[name = tensor<string, []>("op_9564"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9566 = const()[name = tensor<string, []>("op_9566"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_475_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_475_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_475_pad_0 = const()[name = tensor<string, []>("pretrained_out_475_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_23_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(468966592))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(469785856))), name = tensor<string, []>("layers_23_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_23_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_23_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(469785984)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_475_cast_fp16 = conv(bias = layers_23_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_9566, groups = var_9277, pad = pretrained_out_475_pad_0, pad_type = pretrained_out_475_pad_type_0, strides = var_9564, weight = layers_23_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_707_cast_fp16)[name = tensor<string, []>("pretrained_out_475_cast_fp16")];
            tensor<int32, [2]> var_9570 = const()[name = tensor<string, []>("op_9570"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9572 = const()[name = tensor<string, []>("op_9572"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_709_pad_type_0 = const()[name = tensor<string, []>("input_709_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_709_pad_0 = const()[name = tensor<string, []>("input_709_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_23_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_23_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(469788608)))];
            tensor<fp16, [1, 16, 1, 1]> input_709_cast_fp16 = conv(dilations = var_9572, groups = var_9277, pad = input_709_pad_0, pad_type = input_709_pad_type_0, strides = var_9570, weight = layers_23_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_707_cast_fp16)[name = tensor<string, []>("input_709_cast_fp16")];
            tensor<int32, [2]> var_9576 = const()[name = tensor<string, []>("op_9576"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9578 = const()[name = tensor<string, []>("op_9578"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_949_pad_type_0 = const()[name = tensor<string, []>("lora_out_949_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_949_pad_0 = const()[name = tensor<string, []>("lora_out_949_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_951_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_951_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(469829632)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_951_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_9578, groups = var_9277, pad = lora_out_949_pad_0, pad_type = lora_out_949_pad_type_0, strides = var_9576, weight = lora_out_951_weight_0_to_fp16, x = input_709_cast_fp16)[name = tensor<string, []>("lora_out_951_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_333_cast_fp16 = add(x = pretrained_out_475_cast_fp16, y = lora_out_951_cast_fp16)[name = tensor<string, []>("obj_333_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_143_cast_fp16 = add(x = inputs_141_cast_fp16, y = obj_333_cast_fp16)[name = tensor<string, []>("inputs_143_cast_fp16")];
            tensor<int32, [1]> var_9587 = const()[name = tensor<string, []>("op_9587"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_143_cast_fp16 = reduce_mean(axes = var_9587, keep_dims = var_9278, x = inputs_143_cast_fp16)[name = tensor<string, []>("channels_mean_143_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_143_cast_fp16 = sub(x = inputs_143_cast_fp16, y = channels_mean_143_cast_fp16)[name = tensor<string, []>("zero_mean_143_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_143_cast_fp16 = mul(x = zero_mean_143_cast_fp16, y = zero_mean_143_cast_fp16)[name = tensor<string, []>("zero_mean_sq_143_cast_fp16")];
            tensor<int32, [1]> var_9591 = const()[name = tensor<string, []>("op_9591"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_9592_cast_fp16 = reduce_mean(axes = var_9591, keep_dims = var_9278, x = zero_mean_sq_143_cast_fp16)[name = tensor<string, []>("op_9592_cast_fp16")];
            tensor<fp16, []> var_9593_to_fp16 = const()[name = tensor<string, []>("op_9593_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_9594_cast_fp16 = add(x = var_9592_cast_fp16, y = var_9593_to_fp16)[name = tensor<string, []>("op_9594_cast_fp16")];
            tensor<fp32, []> denom_143_epsilon_0 = const()[name = tensor<string, []>("denom_143_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_143_cast_fp16 = rsqrt(epsilon = denom_143_epsilon_0, x = var_9594_cast_fp16)[name = tensor<string, []>("denom_143_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_143_cast_fp16 = mul(x = zero_mean_143_cast_fp16, y = denom_143_cast_fp16)[name = tensor<string, []>("out_143_cast_fp16")];
            tensor<fp16, [1280]> input_711_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_711_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(469870656)))];
            tensor<fp16, [1280]> input_711_beta_0_to_fp16 = const()[name = tensor<string, []>("input_711_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(469873280)))];
            tensor<fp16, []> input_711_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_711_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_711_cast_fp16 = batch_norm(beta = input_711_beta_0_to_fp16, epsilon = input_711_epsilon_0_to_fp16, gamma = input_711_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_143_cast_fp16)[name = tensor<string, []>("input_711_cast_fp16")];
            tensor<int32, [2]> var_9608 = const()[name = tensor<string, []>("op_9608"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9610 = const()[name = tensor<string, []>("op_9610"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_477_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_477_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_477_pad_0 = const()[name = tensor<string, []>("pretrained_out_477_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_23_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(469875904))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(473152768))), name = tensor<string, []>("layers_23_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_23_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_23_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(473152896)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_477_cast_fp16 = conv(bias = layers_23_fc1_pretrained_bias_to_fp16, dilations = var_9610, groups = var_9277, pad = pretrained_out_477_pad_0, pad_type = pretrained_out_477_pad_type_0, strides = var_9608, weight = layers_23_fc1_pretrained_weight_to_fp16_palettized, x = input_711_cast_fp16)[name = tensor<string, []>("pretrained_out_477_cast_fp16")];
            tensor<int32, [2]> var_9614 = const()[name = tensor<string, []>("op_9614"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9616 = const()[name = tensor<string, []>("op_9616"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_713_pad_type_0 = const()[name = tensor<string, []>("input_713_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_713_pad_0 = const()[name = tensor<string, []>("input_713_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_23_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_23_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(473163200)))];
            tensor<fp16, [1, 16, 1, 1]> input_713_cast_fp16 = conv(dilations = var_9616, groups = var_9277, pad = input_713_pad_0, pad_type = input_713_pad_type_0, strides = var_9614, weight = layers_23_fc1_loraA_weight_to_fp16, x = input_711_cast_fp16)[name = tensor<string, []>("input_713_cast_fp16")];
            tensor<int32, [2]> var_9620 = const()[name = tensor<string, []>("op_9620"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9622 = const()[name = tensor<string, []>("op_9622"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_953_pad_type_0 = const()[name = tensor<string, []>("lora_out_953_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_953_pad_0 = const()[name = tensor<string, []>("lora_out_953_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_955_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_955_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(473204224)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_955_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_9622, groups = var_9277, pad = lora_out_953_pad_0, pad_type = lora_out_953_pad_type_0, strides = var_9620, weight = lora_out_955_weight_0_to_fp16, x = input_713_cast_fp16)[name = tensor<string, []>("lora_out_955_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_715_cast_fp16 = add(x = pretrained_out_477_cast_fp16, y = lora_out_955_cast_fp16)[name = tensor<string, []>("input_715_cast_fp16")];
            tensor<string, []> input_717_mode_0 = const()[name = tensor<string, []>("input_717_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_717_cast_fp16 = gelu(mode = input_717_mode_0, x = input_715_cast_fp16)[name = tensor<string, []>("input_717_cast_fp16")];
            tensor<int32, [2]> var_9634 = const()[name = tensor<string, []>("op_9634"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9636 = const()[name = tensor<string, []>("op_9636"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_479_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_479_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_479_pad_0 = const()[name = tensor<string, []>("pretrained_out_479_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_23_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(473368128))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(476644992))), name = tensor<string, []>("layers_23_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_23_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_23_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(476645120)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_479_cast_fp16 = conv(bias = layers_23_fc2_pretrained_bias_to_fp16, dilations = var_9636, groups = var_9277, pad = pretrained_out_479_pad_0, pad_type = pretrained_out_479_pad_type_0, strides = var_9634, weight = layers_23_fc2_pretrained_weight_to_fp16_palettized, x = input_717_cast_fp16)[name = tensor<string, []>("pretrained_out_479_cast_fp16")];
            tensor<int32, [2]> var_9640 = const()[name = tensor<string, []>("op_9640"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9642 = const()[name = tensor<string, []>("op_9642"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_719_pad_type_0 = const()[name = tensor<string, []>("input_719_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_719_pad_0 = const()[name = tensor<string, []>("input_719_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_23_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_23_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(476647744)))];
            tensor<fp16, [1, 16, 1, 1]> input_719_cast_fp16 = conv(dilations = var_9642, groups = var_9277, pad = input_719_pad_0, pad_type = input_719_pad_type_0, strides = var_9640, weight = layers_23_fc2_loraA_weight_to_fp16, x = input_717_cast_fp16)[name = tensor<string, []>("input_719_cast_fp16")];
            tensor<int32, [2]> var_9646 = const()[name = tensor<string, []>("op_9646"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9648 = const()[name = tensor<string, []>("op_9648"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_957_pad_type_0 = const()[name = tensor<string, []>("lora_out_957_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_957_pad_0 = const()[name = tensor<string, []>("lora_out_957_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_959_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_959_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(476811648)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_959_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_9648, groups = var_9277, pad = lora_out_957_pad_0, pad_type = lora_out_957_pad_type_0, strides = var_9646, weight = lora_out_959_weight_0_to_fp16, x = input_719_cast_fp16)[name = tensor<string, []>("lora_out_959_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_49_cast_fp16 = add(x = pretrained_out_479_cast_fp16, y = lora_out_959_cast_fp16)[name = tensor<string, []>("hidden_states_49_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_145_cast_fp16 = add(x = inputs_143_cast_fp16, y = hidden_states_49_cast_fp16)[name = tensor<string, []>("inputs_145_cast_fp16")];
            tensor<int32, []> var_9664 = const()[name = tensor<string, []>("op_9664"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_9671 = const()[name = tensor<string, []>("op_9671"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_9672 = const()[name = tensor<string, []>("op_9672"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_9684 = const()[name = tensor<string, []>("op_9684"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_145_cast_fp16 = reduce_mean(axes = var_9684, keep_dims = var_9672, x = inputs_145_cast_fp16)[name = tensor<string, []>("channels_mean_145_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_145_cast_fp16 = sub(x = inputs_145_cast_fp16, y = channels_mean_145_cast_fp16)[name = tensor<string, []>("zero_mean_145_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_145_cast_fp16 = mul(x = zero_mean_145_cast_fp16, y = zero_mean_145_cast_fp16)[name = tensor<string, []>("zero_mean_sq_145_cast_fp16")];
            tensor<int32, [1]> var_9688 = const()[name = tensor<string, []>("op_9688"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_9689_cast_fp16 = reduce_mean(axes = var_9688, keep_dims = var_9672, x = zero_mean_sq_145_cast_fp16)[name = tensor<string, []>("op_9689_cast_fp16")];
            tensor<fp16, []> var_9690_to_fp16 = const()[name = tensor<string, []>("op_9690_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_9691_cast_fp16 = add(x = var_9689_cast_fp16, y = var_9690_to_fp16)[name = tensor<string, []>("op_9691_cast_fp16")];
            tensor<fp32, []> denom_145_epsilon_0 = const()[name = tensor<string, []>("denom_145_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_145_cast_fp16 = rsqrt(epsilon = denom_145_epsilon_0, x = var_9691_cast_fp16)[name = tensor<string, []>("denom_145_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_145_cast_fp16 = mul(x = zero_mean_145_cast_fp16, y = denom_145_cast_fp16)[name = tensor<string, []>("out_145_cast_fp16")];
            tensor<fp16, [1280]> obj_337_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_337_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(476852672)))];
            tensor<fp16, [1280]> obj_337_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_337_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(476855296)))];
            tensor<fp16, []> obj_337_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_337_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_337_cast_fp16 = batch_norm(beta = obj_337_beta_0_to_fp16, epsilon = obj_337_epsilon_0_to_fp16, gamma = obj_337_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_145_cast_fp16)[name = tensor<string, []>("obj_337_cast_fp16")];
            tensor<int32, [2]> var_9709 = const()[name = tensor<string, []>("op_9709"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9711 = const()[name = tensor<string, []>("op_9711"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_481_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_481_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_481_pad_0 = const()[name = tensor<string, []>("pretrained_out_481_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_24_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(476857920))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(477677184))), name = tensor<string, []>("layers_24_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_24_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_24_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(477677312)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_481_cast_fp16 = conv(bias = layers_24_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_9711, groups = var_9671, pad = pretrained_out_481_pad_0, pad_type = pretrained_out_481_pad_type_0, strides = var_9709, weight = layers_24_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_337_cast_fp16)[name = tensor<string, []>("pretrained_out_481_cast_fp16")];
            tensor<int32, [2]> var_9715 = const()[name = tensor<string, []>("op_9715"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9717 = const()[name = tensor<string, []>("op_9717"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_721_pad_type_0 = const()[name = tensor<string, []>("input_721_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_721_pad_0 = const()[name = tensor<string, []>("input_721_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_24_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_24_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(477679936)))];
            tensor<fp16, [1, 16, 1, 1]> input_721_cast_fp16 = conv(dilations = var_9717, groups = var_9671, pad = input_721_pad_0, pad_type = input_721_pad_type_0, strides = var_9715, weight = layers_24_self_attn_q_proj_loraA_weight_to_fp16, x = obj_337_cast_fp16)[name = tensor<string, []>("input_721_cast_fp16")];
            tensor<int32, [2]> var_9721 = const()[name = tensor<string, []>("op_9721"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9723 = const()[name = tensor<string, []>("op_9723"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_961_pad_type_0 = const()[name = tensor<string, []>("lora_out_961_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_961_pad_0 = const()[name = tensor<string, []>("lora_out_961_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_963_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_963_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(477720960)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_963_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_9723, groups = var_9671, pad = lora_out_961_pad_0, pad_type = lora_out_961_pad_type_0, strides = var_9721, weight = lora_out_963_weight_0_to_fp16, x = input_721_cast_fp16)[name = tensor<string, []>("lora_out_963_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_97_cast_fp16 = add(x = pretrained_out_481_cast_fp16, y = lora_out_963_cast_fp16)[name = tensor<string, []>("query_97_cast_fp16")];
            tensor<int32, [2]> var_9733 = const()[name = tensor<string, []>("op_9733"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9735 = const()[name = tensor<string, []>("op_9735"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_483_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_483_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_483_pad_0 = const()[name = tensor<string, []>("pretrained_out_483_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_24_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(477761984))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(478581248))), name = tensor<string, []>("layers_24_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_483_cast_fp16 = conv(dilations = var_9735, groups = var_9671, pad = pretrained_out_483_pad_0, pad_type = pretrained_out_483_pad_type_0, strides = var_9733, weight = layers_24_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_337_cast_fp16)[name = tensor<string, []>("pretrained_out_483_cast_fp16")];
            tensor<int32, [2]> var_9739 = const()[name = tensor<string, []>("op_9739"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9741 = const()[name = tensor<string, []>("op_9741"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_723_pad_type_0 = const()[name = tensor<string, []>("input_723_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_723_pad_0 = const()[name = tensor<string, []>("input_723_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_24_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_24_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(478581376)))];
            tensor<fp16, [1, 16, 1, 1]> input_723_cast_fp16 = conv(dilations = var_9741, groups = var_9671, pad = input_723_pad_0, pad_type = input_723_pad_type_0, strides = var_9739, weight = layers_24_self_attn_k_proj_loraA_weight_to_fp16, x = obj_337_cast_fp16)[name = tensor<string, []>("input_723_cast_fp16")];
            tensor<int32, [2]> var_9745 = const()[name = tensor<string, []>("op_9745"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9747 = const()[name = tensor<string, []>("op_9747"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_965_pad_type_0 = const()[name = tensor<string, []>("lora_out_965_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_965_pad_0 = const()[name = tensor<string, []>("lora_out_965_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_967_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_967_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(478622400)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_967_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_9747, groups = var_9671, pad = lora_out_965_pad_0, pad_type = lora_out_965_pad_type_0, strides = var_9745, weight = lora_out_967_weight_0_to_fp16, x = input_723_cast_fp16)[name = tensor<string, []>("lora_out_967_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_49_cast_fp16 = add(x = pretrained_out_483_cast_fp16, y = lora_out_967_cast_fp16)[name = tensor<string, []>("current_key_49_cast_fp16")];
            tensor<int32, [2]> var_9758 = const()[name = tensor<string, []>("op_9758"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9760 = const()[name = tensor<string, []>("op_9760"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_485_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_485_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_485_pad_0 = const()[name = tensor<string, []>("pretrained_out_485_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_24_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(478663424))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(479482688))), name = tensor<string, []>("layers_24_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_24_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_24_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(479482816)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_485_cast_fp16 = conv(bias = layers_24_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_9760, groups = var_9671, pad = pretrained_out_485_pad_0, pad_type = pretrained_out_485_pad_type_0, strides = var_9758, weight = layers_24_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_337_cast_fp16)[name = tensor<string, []>("pretrained_out_485_cast_fp16")];
            tensor<int32, [2]> var_9764 = const()[name = tensor<string, []>("op_9764"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9766 = const()[name = tensor<string, []>("op_9766"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_725_pad_type_0 = const()[name = tensor<string, []>("input_725_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_725_pad_0 = const()[name = tensor<string, []>("input_725_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_24_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_24_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(479485440)))];
            tensor<fp16, [1, 16, 1, 1]> input_725_cast_fp16 = conv(dilations = var_9766, groups = var_9671, pad = input_725_pad_0, pad_type = input_725_pad_type_0, strides = var_9764, weight = layers_24_self_attn_v_proj_loraA_weight_to_fp16, x = obj_337_cast_fp16)[name = tensor<string, []>("input_725_cast_fp16")];
            tensor<int32, [2]> var_9770 = const()[name = tensor<string, []>("op_9770"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9772 = const()[name = tensor<string, []>("op_9772"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_969_pad_type_0 = const()[name = tensor<string, []>("lora_out_969_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_969_pad_0 = const()[name = tensor<string, []>("lora_out_969_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_971_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_971_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(479526464)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_971_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_9772, groups = var_9671, pad = lora_out_969_pad_0, pad_type = lora_out_969_pad_type_0, strides = var_9770, weight = lora_out_971_weight_0_to_fp16, x = input_725_cast_fp16)[name = tensor<string, []>("lora_out_971_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_49_cast_fp16 = add(x = pretrained_out_485_cast_fp16, y = lora_out_971_cast_fp16)[name = tensor<string, []>("current_value_49_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_9782_cast_fp16 = mul(x = current_key_49_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_9782_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_9784_cast_fp16 = mul(x = var_103_cast_fp16_24, y = var_295_cast_fp16)[name = tensor<string, []>("op_9784_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_97_cast_fp16 = add(x = var_9782_cast_fp16, y = var_9784_cast_fp16)[name = tensor<string, []>("key_97_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_9786_cast_fp16 = mul(x = current_value_49_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_9786_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_9788_cast_fp16 = mul(x = var_138_cast_fp16_24, y = var_295_cast_fp16)[name = tensor<string, []>("op_9788_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_97_cast_fp16 = add(x = var_9786_cast_fp16, y = var_9788_cast_fp16)[name = tensor<string, []>("value_97_cast_fp16")];
            tensor<int32, [4]> var_9791 = const()[name = tensor<string, []>("op_9791"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_9792_cast_fp16 = reshape(shape = var_9791, x = query_97_cast_fp16)[name = tensor<string, []>("op_9792_cast_fp16")];
            tensor<fp16, []> var_9793_to_fp16 = const()[name = tensor<string, []>("op_9793_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_9794_cast_fp16 = mul(x = var_9792_cast_fp16, y = var_9793_to_fp16)[name = tensor<string, []>("op_9794_cast_fp16")];
            tensor<int32, [4]> var_9795 = const()[name = tensor<string, []>("op_9795"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_9796_cast_fp16 = reshape(shape = var_9795, x = key_97_cast_fp16)[name = tensor<string, []>("op_9796_cast_fp16")];
            tensor<bool, []> mh_w_145_transpose_x_0 = const()[name = tensor<string, []>("mh_w_145_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_145_transpose_y_0 = const()[name = tensor<string, []>("mh_w_145_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_145_cast_fp16 = matmul(transpose_x = mh_w_145_transpose_x_0, transpose_y = mh_w_145_transpose_y_0, x = var_9794_cast_fp16, y = var_9796_cast_fp16)[name = tensor<string, []>("mh_w_145_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_147_cast_fp16 = add(x = mh_w_145_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_147_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_9804_cast_fp16 = softmax(axis = var_9664, x = mh_w_147_cast_fp16)[name = tensor<string, []>("op_9804_cast_fp16")];
            tensor<int32, [4]> var_9805 = const()[name = tensor<string, []>("op_9805"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_9806_cast_fp16 = reshape(shape = var_9805, x = value_97_cast_fp16)[name = tensor<string, []>("op_9806_cast_fp16")];
            tensor<bool, []> attn_97_transpose_x_0 = const()[name = tensor<string, []>("attn_97_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_97_transpose_y_0 = const()[name = tensor<string, []>("attn_97_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_97_cast_fp16 = matmul(transpose_x = attn_97_transpose_x_0, transpose_y = attn_97_transpose_y_0, x = var_9806_cast_fp16, y = var_9804_cast_fp16)[name = tensor<string, []>("attn_97_cast_fp16")];
            tensor<int32, [4]> var_9809 = const()[name = tensor<string, []>("op_9809"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_727_cast_fp16 = reshape(shape = var_9809, x = attn_97_cast_fp16)[name = tensor<string, []>("input_727_cast_fp16")];
            tensor<int32, [2]> var_9816 = const()[name = tensor<string, []>("op_9816"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9818 = const()[name = tensor<string, []>("op_9818"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_487_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_487_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_487_pad_0 = const()[name = tensor<string, []>("pretrained_out_487_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_24_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(479567488))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(480386752))), name = tensor<string, []>("layers_24_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_24_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_24_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(480386880)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_487_cast_fp16 = conv(bias = layers_24_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_9818, groups = var_9671, pad = pretrained_out_487_pad_0, pad_type = pretrained_out_487_pad_type_0, strides = var_9816, weight = layers_24_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_727_cast_fp16)[name = tensor<string, []>("pretrained_out_487_cast_fp16")];
            tensor<int32, [2]> var_9822 = const()[name = tensor<string, []>("op_9822"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9824 = const()[name = tensor<string, []>("op_9824"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_729_pad_type_0 = const()[name = tensor<string, []>("input_729_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_729_pad_0 = const()[name = tensor<string, []>("input_729_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_24_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_24_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(480389504)))];
            tensor<fp16, [1, 16, 1, 1]> input_729_cast_fp16 = conv(dilations = var_9824, groups = var_9671, pad = input_729_pad_0, pad_type = input_729_pad_type_0, strides = var_9822, weight = layers_24_self_attn_o_proj_loraA_weight_to_fp16, x = input_727_cast_fp16)[name = tensor<string, []>("input_729_cast_fp16")];
            tensor<int32, [2]> var_9828 = const()[name = tensor<string, []>("op_9828"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9830 = const()[name = tensor<string, []>("op_9830"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_973_pad_type_0 = const()[name = tensor<string, []>("lora_out_973_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_973_pad_0 = const()[name = tensor<string, []>("lora_out_973_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_975_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_975_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(480430528)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_975_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_9830, groups = var_9671, pad = lora_out_973_pad_0, pad_type = lora_out_973_pad_type_0, strides = var_9828, weight = lora_out_975_weight_0_to_fp16, x = input_729_cast_fp16)[name = tensor<string, []>("lora_out_975_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_343_cast_fp16 = add(x = pretrained_out_487_cast_fp16, y = lora_out_975_cast_fp16)[name = tensor<string, []>("obj_343_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_147_cast_fp16 = add(x = inputs_145_cast_fp16, y = obj_343_cast_fp16)[name = tensor<string, []>("inputs_147_cast_fp16")];
            tensor<int32, [1]> var_9843 = const()[name = tensor<string, []>("op_9843"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_147_cast_fp16 = reduce_mean(axes = var_9843, keep_dims = var_9672, x = inputs_147_cast_fp16)[name = tensor<string, []>("channels_mean_147_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_147_cast_fp16 = sub(x = inputs_147_cast_fp16, y = channels_mean_147_cast_fp16)[name = tensor<string, []>("zero_mean_147_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_147_cast_fp16 = mul(x = zero_mean_147_cast_fp16, y = zero_mean_147_cast_fp16)[name = tensor<string, []>("zero_mean_sq_147_cast_fp16")];
            tensor<int32, [1]> var_9847 = const()[name = tensor<string, []>("op_9847"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_9848_cast_fp16 = reduce_mean(axes = var_9847, keep_dims = var_9672, x = zero_mean_sq_147_cast_fp16)[name = tensor<string, []>("op_9848_cast_fp16")];
            tensor<fp16, []> var_9849_to_fp16 = const()[name = tensor<string, []>("op_9849_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_9850_cast_fp16 = add(x = var_9848_cast_fp16, y = var_9849_to_fp16)[name = tensor<string, []>("op_9850_cast_fp16")];
            tensor<fp32, []> denom_147_epsilon_0 = const()[name = tensor<string, []>("denom_147_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_147_cast_fp16 = rsqrt(epsilon = denom_147_epsilon_0, x = var_9850_cast_fp16)[name = tensor<string, []>("denom_147_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_147_cast_fp16 = mul(x = zero_mean_147_cast_fp16, y = denom_147_cast_fp16)[name = tensor<string, []>("out_147_cast_fp16")];
            tensor<fp16, [1280]> obj_345_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_345_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(480471552)))];
            tensor<fp16, [1280]> obj_345_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_345_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(480474176)))];
            tensor<fp16, []> obj_345_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_345_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_345_cast_fp16 = batch_norm(beta = obj_345_beta_0_to_fp16, epsilon = obj_345_epsilon_0_to_fp16, gamma = obj_345_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_147_cast_fp16)[name = tensor<string, []>("obj_345_cast_fp16")];
            tensor<int32, [2]> var_9868 = const()[name = tensor<string, []>("op_9868"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9870 = const()[name = tensor<string, []>("op_9870"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_489_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_489_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_489_pad_0 = const()[name = tensor<string, []>("pretrained_out_489_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_24_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(480476800))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(481296064))), name = tensor<string, []>("layers_24_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_24_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_24_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(481296192)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_489_cast_fp16 = conv(bias = layers_24_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_9870, groups = var_9671, pad = pretrained_out_489_pad_0, pad_type = pretrained_out_489_pad_type_0, strides = var_9868, weight = layers_24_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_345_cast_fp16)[name = tensor<string, []>("pretrained_out_489_cast_fp16")];
            tensor<int32, [2]> var_9874 = const()[name = tensor<string, []>("op_9874"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9876 = const()[name = tensor<string, []>("op_9876"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_731_pad_type_0 = const()[name = tensor<string, []>("input_731_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_731_pad_0 = const()[name = tensor<string, []>("input_731_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_24_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_24_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(481298816)))];
            tensor<fp16, [1, 16, 1, 1]> input_731_cast_fp16 = conv(dilations = var_9876, groups = var_9671, pad = input_731_pad_0, pad_type = input_731_pad_type_0, strides = var_9874, weight = layers_24_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_345_cast_fp16)[name = tensor<string, []>("input_731_cast_fp16")];
            tensor<int32, [2]> var_9880 = const()[name = tensor<string, []>("op_9880"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9882 = const()[name = tensor<string, []>("op_9882"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_977_pad_type_0 = const()[name = tensor<string, []>("lora_out_977_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_977_pad_0 = const()[name = tensor<string, []>("lora_out_977_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_979_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_979_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(481339840)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_979_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_9882, groups = var_9671, pad = lora_out_977_pad_0, pad_type = lora_out_977_pad_type_0, strides = var_9880, weight = lora_out_979_weight_0_to_fp16, x = input_731_cast_fp16)[name = tensor<string, []>("lora_out_979_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_99_cast_fp16 = add(x = pretrained_out_489_cast_fp16, y = lora_out_979_cast_fp16)[name = tensor<string, []>("query_99_cast_fp16")];
            tensor<int32, [2]> var_9892 = const()[name = tensor<string, []>("op_9892"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9894 = const()[name = tensor<string, []>("op_9894"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_491_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_491_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_491_pad_0 = const()[name = tensor<string, []>("pretrained_out_491_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_24_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(481380864))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(482200128))), name = tensor<string, []>("layers_24_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_491_cast_fp16 = conv(dilations = var_9894, groups = var_9671, pad = pretrained_out_491_pad_0, pad_type = pretrained_out_491_pad_type_0, strides = var_9892, weight = layers_24_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_491_cast_fp16")];
            tensor<int32, [2]> var_9898 = const()[name = tensor<string, []>("op_9898"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9900 = const()[name = tensor<string, []>("op_9900"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_733_pad_type_0 = const()[name = tensor<string, []>("input_733_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_733_pad_0 = const()[name = tensor<string, []>("input_733_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_24_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_24_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(482200256)))];
            tensor<fp16, [1, 16, 1, 1500]> input_733_cast_fp16 = conv(dilations = var_9900, groups = var_9671, pad = input_733_pad_0, pad_type = input_733_pad_type_0, strides = var_9898, weight = layers_24_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_733_cast_fp16")];
            tensor<int32, [2]> var_9904 = const()[name = tensor<string, []>("op_9904"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9906 = const()[name = tensor<string, []>("op_9906"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_981_pad_type_0 = const()[name = tensor<string, []>("lora_out_981_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_981_pad_0 = const()[name = tensor<string, []>("lora_out_981_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_983_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_983_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(482241280)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_983_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_9906, groups = var_9671, pad = lora_out_981_pad_0, pad_type = lora_out_981_pad_type_0, strides = var_9904, weight = lora_out_983_weight_0_to_fp16, x = input_733_cast_fp16)[name = tensor<string, []>("lora_out_983_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_99_cast_fp16 = add(x = pretrained_out_491_cast_fp16, y = lora_out_983_cast_fp16)[name = tensor<string, []>("key_99_cast_fp16")];
            tensor<int32, [2]> var_9917 = const()[name = tensor<string, []>("op_9917"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9919 = const()[name = tensor<string, []>("op_9919"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_493_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_493_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_493_pad_0 = const()[name = tensor<string, []>("pretrained_out_493_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_24_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(482282304))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(483101568))), name = tensor<string, []>("layers_24_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_24_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_24_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(483101696)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_493_cast_fp16 = conv(bias = layers_24_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_9919, groups = var_9671, pad = pretrained_out_493_pad_0, pad_type = pretrained_out_493_pad_type_0, strides = var_9917, weight = layers_24_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_493_cast_fp16")];
            tensor<int32, [2]> var_9923 = const()[name = tensor<string, []>("op_9923"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9925 = const()[name = tensor<string, []>("op_9925"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_735_pad_type_0 = const()[name = tensor<string, []>("input_735_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_735_pad_0 = const()[name = tensor<string, []>("input_735_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_24_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_24_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(483104320)))];
            tensor<fp16, [1, 16, 1, 1500]> input_735_cast_fp16 = conv(dilations = var_9925, groups = var_9671, pad = input_735_pad_0, pad_type = input_735_pad_type_0, strides = var_9923, weight = layers_24_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_735_cast_fp16")];
            tensor<int32, [2]> var_9929 = const()[name = tensor<string, []>("op_9929"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9931 = const()[name = tensor<string, []>("op_9931"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_985_pad_type_0 = const()[name = tensor<string, []>("lora_out_985_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_985_pad_0 = const()[name = tensor<string, []>("lora_out_985_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_987_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_987_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(483145344)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_987_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_9931, groups = var_9671, pad = lora_out_985_pad_0, pad_type = lora_out_985_pad_type_0, strides = var_9929, weight = lora_out_987_weight_0_to_fp16, x = input_735_cast_fp16)[name = tensor<string, []>("lora_out_987_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_99_cast_fp16 = add(x = pretrained_out_493_cast_fp16, y = lora_out_987_cast_fp16)[name = tensor<string, []>("value_99_cast_fp16")];
            tensor<int32, [4]> var_9938 = const()[name = tensor<string, []>("op_9938"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_9939_cast_fp16 = reshape(shape = var_9938, x = query_99_cast_fp16)[name = tensor<string, []>("op_9939_cast_fp16")];
            tensor<fp16, []> var_9940_to_fp16 = const()[name = tensor<string, []>("op_9940_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_9941_cast_fp16 = mul(x = var_9939_cast_fp16, y = var_9940_to_fp16)[name = tensor<string, []>("op_9941_cast_fp16")];
            tensor<int32, [4]> var_9942 = const()[name = tensor<string, []>("op_9942"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_9943_cast_fp16 = reshape(shape = var_9942, x = key_99_cast_fp16)[name = tensor<string, []>("op_9943_cast_fp16")];
            tensor<bool, []> mh_w_149_transpose_x_0 = const()[name = tensor<string, []>("mh_w_149_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_149_transpose_y_0 = const()[name = tensor<string, []>("mh_w_149_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_149_cast_fp16 = matmul(transpose_x = mh_w_149_transpose_x_0, transpose_y = mh_w_149_transpose_y_0, x = var_9941_cast_fp16, y = var_9943_cast_fp16)[name = tensor<string, []>("mh_w_149_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_349_cast_fp16 = softmax(axis = var_9664, x = mh_w_149_cast_fp16)[name = tensor<string, []>("obj_349_cast_fp16")];
            tensor<int32, [4]> var_9947 = const()[name = tensor<string, []>("op_9947"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_9948_cast_fp16 = reshape(shape = var_9947, x = value_99_cast_fp16)[name = tensor<string, []>("op_9948_cast_fp16")];
            tensor<bool, []> attn_99_transpose_x_0 = const()[name = tensor<string, []>("attn_99_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_99_transpose_y_0 = const()[name = tensor<string, []>("attn_99_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_99_cast_fp16 = matmul(transpose_x = attn_99_transpose_x_0, transpose_y = attn_99_transpose_y_0, x = var_9948_cast_fp16, y = obj_349_cast_fp16)[name = tensor<string, []>("attn_99_cast_fp16")];
            tensor<int32, [4]> var_9951 = const()[name = tensor<string, []>("op_9951"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_737_cast_fp16 = reshape(shape = var_9951, x = attn_99_cast_fp16)[name = tensor<string, []>("input_737_cast_fp16")];
            tensor<int32, [2]> var_9958 = const()[name = tensor<string, []>("op_9958"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9960 = const()[name = tensor<string, []>("op_9960"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_495_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_495_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_495_pad_0 = const()[name = tensor<string, []>("pretrained_out_495_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_24_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(483186368))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(484005632))), name = tensor<string, []>("layers_24_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_24_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_24_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(484005760)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_495_cast_fp16 = conv(bias = layers_24_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_9960, groups = var_9671, pad = pretrained_out_495_pad_0, pad_type = pretrained_out_495_pad_type_0, strides = var_9958, weight = layers_24_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_737_cast_fp16)[name = tensor<string, []>("pretrained_out_495_cast_fp16")];
            tensor<int32, [2]> var_9964 = const()[name = tensor<string, []>("op_9964"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9966 = const()[name = tensor<string, []>("op_9966"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_739_pad_type_0 = const()[name = tensor<string, []>("input_739_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_739_pad_0 = const()[name = tensor<string, []>("input_739_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_24_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_24_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(484008384)))];
            tensor<fp16, [1, 16, 1, 1]> input_739_cast_fp16 = conv(dilations = var_9966, groups = var_9671, pad = input_739_pad_0, pad_type = input_739_pad_type_0, strides = var_9964, weight = layers_24_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_737_cast_fp16)[name = tensor<string, []>("input_739_cast_fp16")];
            tensor<int32, [2]> var_9970 = const()[name = tensor<string, []>("op_9970"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_9972 = const()[name = tensor<string, []>("op_9972"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_989_pad_type_0 = const()[name = tensor<string, []>("lora_out_989_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_989_pad_0 = const()[name = tensor<string, []>("lora_out_989_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_991_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_991_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(484049408)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_991_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_9972, groups = var_9671, pad = lora_out_989_pad_0, pad_type = lora_out_989_pad_type_0, strides = var_9970, weight = lora_out_991_weight_0_to_fp16, x = input_739_cast_fp16)[name = tensor<string, []>("lora_out_991_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_347_cast_fp16 = add(x = pretrained_out_495_cast_fp16, y = lora_out_991_cast_fp16)[name = tensor<string, []>("obj_347_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_149_cast_fp16 = add(x = inputs_147_cast_fp16, y = obj_347_cast_fp16)[name = tensor<string, []>("inputs_149_cast_fp16")];
            tensor<int32, [1]> var_9984 = const()[name = tensor<string, []>("op_9984"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_149_cast_fp16 = reduce_mean(axes = var_9984, keep_dims = var_9672, x = inputs_149_cast_fp16)[name = tensor<string, []>("channels_mean_149_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_149_cast_fp16 = sub(x = inputs_149_cast_fp16, y = channels_mean_149_cast_fp16)[name = tensor<string, []>("zero_mean_149_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_149_cast_fp16 = mul(x = zero_mean_149_cast_fp16, y = zero_mean_149_cast_fp16)[name = tensor<string, []>("zero_mean_sq_149_cast_fp16")];
            tensor<int32, [1]> var_9988 = const()[name = tensor<string, []>("op_9988"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_9989_cast_fp16 = reduce_mean(axes = var_9988, keep_dims = var_9672, x = zero_mean_sq_149_cast_fp16)[name = tensor<string, []>("op_9989_cast_fp16")];
            tensor<fp16, []> var_9990_to_fp16 = const()[name = tensor<string, []>("op_9990_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_9991_cast_fp16 = add(x = var_9989_cast_fp16, y = var_9990_to_fp16)[name = tensor<string, []>("op_9991_cast_fp16")];
            tensor<fp32, []> denom_149_epsilon_0 = const()[name = tensor<string, []>("denom_149_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_149_cast_fp16 = rsqrt(epsilon = denom_149_epsilon_0, x = var_9991_cast_fp16)[name = tensor<string, []>("denom_149_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_149_cast_fp16 = mul(x = zero_mean_149_cast_fp16, y = denom_149_cast_fp16)[name = tensor<string, []>("out_149_cast_fp16")];
            tensor<fp16, [1280]> input_741_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_741_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(484090432)))];
            tensor<fp16, [1280]> input_741_beta_0_to_fp16 = const()[name = tensor<string, []>("input_741_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(484093056)))];
            tensor<fp16, []> input_741_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_741_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_741_cast_fp16 = batch_norm(beta = input_741_beta_0_to_fp16, epsilon = input_741_epsilon_0_to_fp16, gamma = input_741_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_149_cast_fp16)[name = tensor<string, []>("input_741_cast_fp16")];
            tensor<int32, [2]> var_10005 = const()[name = tensor<string, []>("op_10005"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10007 = const()[name = tensor<string, []>("op_10007"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_497_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_497_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_497_pad_0 = const()[name = tensor<string, []>("pretrained_out_497_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_24_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(484095680))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(487372544))), name = tensor<string, []>("layers_24_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_24_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_24_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(487372672)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_497_cast_fp16 = conv(bias = layers_24_fc1_pretrained_bias_to_fp16, dilations = var_10007, groups = var_9671, pad = pretrained_out_497_pad_0, pad_type = pretrained_out_497_pad_type_0, strides = var_10005, weight = layers_24_fc1_pretrained_weight_to_fp16_palettized, x = input_741_cast_fp16)[name = tensor<string, []>("pretrained_out_497_cast_fp16")];
            tensor<int32, [2]> var_10011 = const()[name = tensor<string, []>("op_10011"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10013 = const()[name = tensor<string, []>("op_10013"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_743_pad_type_0 = const()[name = tensor<string, []>("input_743_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_743_pad_0 = const()[name = tensor<string, []>("input_743_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_24_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_24_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(487382976)))];
            tensor<fp16, [1, 16, 1, 1]> input_743_cast_fp16 = conv(dilations = var_10013, groups = var_9671, pad = input_743_pad_0, pad_type = input_743_pad_type_0, strides = var_10011, weight = layers_24_fc1_loraA_weight_to_fp16, x = input_741_cast_fp16)[name = tensor<string, []>("input_743_cast_fp16")];
            tensor<int32, [2]> var_10017 = const()[name = tensor<string, []>("op_10017"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10019 = const()[name = tensor<string, []>("op_10019"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_993_pad_type_0 = const()[name = tensor<string, []>("lora_out_993_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_993_pad_0 = const()[name = tensor<string, []>("lora_out_993_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_995_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_995_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(487424000)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_995_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_10019, groups = var_9671, pad = lora_out_993_pad_0, pad_type = lora_out_993_pad_type_0, strides = var_10017, weight = lora_out_995_weight_0_to_fp16, x = input_743_cast_fp16)[name = tensor<string, []>("lora_out_995_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_745_cast_fp16 = add(x = pretrained_out_497_cast_fp16, y = lora_out_995_cast_fp16)[name = tensor<string, []>("input_745_cast_fp16")];
            tensor<string, []> input_747_mode_0 = const()[name = tensor<string, []>("input_747_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_747_cast_fp16 = gelu(mode = input_747_mode_0, x = input_745_cast_fp16)[name = tensor<string, []>("input_747_cast_fp16")];
            tensor<int32, [2]> var_10031 = const()[name = tensor<string, []>("op_10031"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10033 = const()[name = tensor<string, []>("op_10033"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_499_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_499_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_499_pad_0 = const()[name = tensor<string, []>("pretrained_out_499_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_24_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(487587904))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(490864768))), name = tensor<string, []>("layers_24_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_24_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_24_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(490864896)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_499_cast_fp16 = conv(bias = layers_24_fc2_pretrained_bias_to_fp16, dilations = var_10033, groups = var_9671, pad = pretrained_out_499_pad_0, pad_type = pretrained_out_499_pad_type_0, strides = var_10031, weight = layers_24_fc2_pretrained_weight_to_fp16_palettized, x = input_747_cast_fp16)[name = tensor<string, []>("pretrained_out_499_cast_fp16")];
            tensor<int32, [2]> var_10037 = const()[name = tensor<string, []>("op_10037"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10039 = const()[name = tensor<string, []>("op_10039"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_749_pad_type_0 = const()[name = tensor<string, []>("input_749_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_749_pad_0 = const()[name = tensor<string, []>("input_749_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_24_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_24_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(490867520)))];
            tensor<fp16, [1, 16, 1, 1]> input_749_cast_fp16 = conv(dilations = var_10039, groups = var_9671, pad = input_749_pad_0, pad_type = input_749_pad_type_0, strides = var_10037, weight = layers_24_fc2_loraA_weight_to_fp16, x = input_747_cast_fp16)[name = tensor<string, []>("input_749_cast_fp16")];
            tensor<int32, [2]> var_10043 = const()[name = tensor<string, []>("op_10043"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10045 = const()[name = tensor<string, []>("op_10045"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_997_pad_type_0 = const()[name = tensor<string, []>("lora_out_997_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_997_pad_0 = const()[name = tensor<string, []>("lora_out_997_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_999_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_999_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(491031424)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_999_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_10045, groups = var_9671, pad = lora_out_997_pad_0, pad_type = lora_out_997_pad_type_0, strides = var_10043, weight = lora_out_999_weight_0_to_fp16, x = input_749_cast_fp16)[name = tensor<string, []>("lora_out_999_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_51_cast_fp16 = add(x = pretrained_out_499_cast_fp16, y = lora_out_999_cast_fp16)[name = tensor<string, []>("hidden_states_51_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_151_cast_fp16 = add(x = inputs_149_cast_fp16, y = hidden_states_51_cast_fp16)[name = tensor<string, []>("inputs_151_cast_fp16")];
            tensor<int32, []> var_10062 = const()[name = tensor<string, []>("op_10062"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_10069 = const()[name = tensor<string, []>("op_10069"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_10070 = const()[name = tensor<string, []>("op_10070"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_10082 = const()[name = tensor<string, []>("op_10082"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_151_cast_fp16 = reduce_mean(axes = var_10082, keep_dims = var_10070, x = inputs_151_cast_fp16)[name = tensor<string, []>("channels_mean_151_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_151_cast_fp16 = sub(x = inputs_151_cast_fp16, y = channels_mean_151_cast_fp16)[name = tensor<string, []>("zero_mean_151_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_151_cast_fp16 = mul(x = zero_mean_151_cast_fp16, y = zero_mean_151_cast_fp16)[name = tensor<string, []>("zero_mean_sq_151_cast_fp16")];
            tensor<int32, [1]> var_10086 = const()[name = tensor<string, []>("op_10086"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_10087_cast_fp16 = reduce_mean(axes = var_10086, keep_dims = var_10070, x = zero_mean_sq_151_cast_fp16)[name = tensor<string, []>("op_10087_cast_fp16")];
            tensor<fp16, []> var_10088_to_fp16 = const()[name = tensor<string, []>("op_10088_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_10089_cast_fp16 = add(x = var_10087_cast_fp16, y = var_10088_to_fp16)[name = tensor<string, []>("op_10089_cast_fp16")];
            tensor<fp32, []> denom_151_epsilon_0 = const()[name = tensor<string, []>("denom_151_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_151_cast_fp16 = rsqrt(epsilon = denom_151_epsilon_0, x = var_10089_cast_fp16)[name = tensor<string, []>("denom_151_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_151_cast_fp16 = mul(x = zero_mean_151_cast_fp16, y = denom_151_cast_fp16)[name = tensor<string, []>("out_151_cast_fp16")];
            tensor<fp16, [1280]> obj_351_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_351_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(491072448)))];
            tensor<fp16, [1280]> obj_351_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_351_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(491075072)))];
            tensor<fp16, []> obj_351_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_351_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_351_cast_fp16 = batch_norm(beta = obj_351_beta_0_to_fp16, epsilon = obj_351_epsilon_0_to_fp16, gamma = obj_351_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_151_cast_fp16)[name = tensor<string, []>("obj_351_cast_fp16")];
            tensor<int32, [2]> var_10107 = const()[name = tensor<string, []>("op_10107"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10109 = const()[name = tensor<string, []>("op_10109"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_501_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_501_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_501_pad_0 = const()[name = tensor<string, []>("pretrained_out_501_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_25_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(491077696))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(491896960))), name = tensor<string, []>("layers_25_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_25_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_25_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(491897088)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_501_cast_fp16 = conv(bias = layers_25_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_10109, groups = var_10069, pad = pretrained_out_501_pad_0, pad_type = pretrained_out_501_pad_type_0, strides = var_10107, weight = layers_25_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_351_cast_fp16)[name = tensor<string, []>("pretrained_out_501_cast_fp16")];
            tensor<int32, [2]> var_10113 = const()[name = tensor<string, []>("op_10113"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10115 = const()[name = tensor<string, []>("op_10115"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_751_pad_type_0 = const()[name = tensor<string, []>("input_751_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_751_pad_0 = const()[name = tensor<string, []>("input_751_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_25_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_25_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(491899712)))];
            tensor<fp16, [1, 16, 1, 1]> input_751_cast_fp16 = conv(dilations = var_10115, groups = var_10069, pad = input_751_pad_0, pad_type = input_751_pad_type_0, strides = var_10113, weight = layers_25_self_attn_q_proj_loraA_weight_to_fp16, x = obj_351_cast_fp16)[name = tensor<string, []>("input_751_cast_fp16")];
            tensor<int32, [2]> var_10119 = const()[name = tensor<string, []>("op_10119"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10121 = const()[name = tensor<string, []>("op_10121"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1001_pad_type_0 = const()[name = tensor<string, []>("lora_out_1001_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1001_pad_0 = const()[name = tensor<string, []>("lora_out_1001_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1003_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1003_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(491940736)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1003_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_10121, groups = var_10069, pad = lora_out_1001_pad_0, pad_type = lora_out_1001_pad_type_0, strides = var_10119, weight = lora_out_1003_weight_0_to_fp16, x = input_751_cast_fp16)[name = tensor<string, []>("lora_out_1003_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_101_cast_fp16 = add(x = pretrained_out_501_cast_fp16, y = lora_out_1003_cast_fp16)[name = tensor<string, []>("query_101_cast_fp16")];
            tensor<int32, [2]> var_10131 = const()[name = tensor<string, []>("op_10131"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10133 = const()[name = tensor<string, []>("op_10133"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_503_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_503_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_503_pad_0 = const()[name = tensor<string, []>("pretrained_out_503_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_25_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(491981760))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(492801024))), name = tensor<string, []>("layers_25_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_503_cast_fp16 = conv(dilations = var_10133, groups = var_10069, pad = pretrained_out_503_pad_0, pad_type = pretrained_out_503_pad_type_0, strides = var_10131, weight = layers_25_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_351_cast_fp16)[name = tensor<string, []>("pretrained_out_503_cast_fp16")];
            tensor<int32, [2]> var_10137 = const()[name = tensor<string, []>("op_10137"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10139 = const()[name = tensor<string, []>("op_10139"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_753_pad_type_0 = const()[name = tensor<string, []>("input_753_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_753_pad_0 = const()[name = tensor<string, []>("input_753_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_25_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_25_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(492801152)))];
            tensor<fp16, [1, 16, 1, 1]> input_753_cast_fp16 = conv(dilations = var_10139, groups = var_10069, pad = input_753_pad_0, pad_type = input_753_pad_type_0, strides = var_10137, weight = layers_25_self_attn_k_proj_loraA_weight_to_fp16, x = obj_351_cast_fp16)[name = tensor<string, []>("input_753_cast_fp16")];
            tensor<int32, [2]> var_10143 = const()[name = tensor<string, []>("op_10143"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10145 = const()[name = tensor<string, []>("op_10145"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1005_pad_type_0 = const()[name = tensor<string, []>("lora_out_1005_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1005_pad_0 = const()[name = tensor<string, []>("lora_out_1005_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1007_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1007_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(492842176)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1007_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_10145, groups = var_10069, pad = lora_out_1005_pad_0, pad_type = lora_out_1005_pad_type_0, strides = var_10143, weight = lora_out_1007_weight_0_to_fp16, x = input_753_cast_fp16)[name = tensor<string, []>("lora_out_1007_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_51_cast_fp16 = add(x = pretrained_out_503_cast_fp16, y = lora_out_1007_cast_fp16)[name = tensor<string, []>("current_key_51_cast_fp16")];
            tensor<int32, [2]> var_10156 = const()[name = tensor<string, []>("op_10156"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10158 = const()[name = tensor<string, []>("op_10158"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_505_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_505_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_505_pad_0 = const()[name = tensor<string, []>("pretrained_out_505_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_25_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(492883200))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(493702464))), name = tensor<string, []>("layers_25_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_25_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_25_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(493702592)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_505_cast_fp16 = conv(bias = layers_25_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_10158, groups = var_10069, pad = pretrained_out_505_pad_0, pad_type = pretrained_out_505_pad_type_0, strides = var_10156, weight = layers_25_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_351_cast_fp16)[name = tensor<string, []>("pretrained_out_505_cast_fp16")];
            tensor<int32, [2]> var_10162 = const()[name = tensor<string, []>("op_10162"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10164 = const()[name = tensor<string, []>("op_10164"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_755_pad_type_0 = const()[name = tensor<string, []>("input_755_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_755_pad_0 = const()[name = tensor<string, []>("input_755_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_25_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_25_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(493705216)))];
            tensor<fp16, [1, 16, 1, 1]> input_755_cast_fp16 = conv(dilations = var_10164, groups = var_10069, pad = input_755_pad_0, pad_type = input_755_pad_type_0, strides = var_10162, weight = layers_25_self_attn_v_proj_loraA_weight_to_fp16, x = obj_351_cast_fp16)[name = tensor<string, []>("input_755_cast_fp16")];
            tensor<int32, [2]> var_10168 = const()[name = tensor<string, []>("op_10168"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10170 = const()[name = tensor<string, []>("op_10170"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1009_pad_type_0 = const()[name = tensor<string, []>("lora_out_1009_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1009_pad_0 = const()[name = tensor<string, []>("lora_out_1009_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1011_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1011_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(493746240)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1011_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_10170, groups = var_10069, pad = lora_out_1009_pad_0, pad_type = lora_out_1009_pad_type_0, strides = var_10168, weight = lora_out_1011_weight_0_to_fp16, x = input_755_cast_fp16)[name = tensor<string, []>("lora_out_1011_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_51_cast_fp16 = add(x = pretrained_out_505_cast_fp16, y = lora_out_1011_cast_fp16)[name = tensor<string, []>("current_value_51_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_10180_cast_fp16 = mul(x = current_key_51_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_10180_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_10182_cast_fp16 = mul(x = var_103_cast_fp16_25, y = var_295_cast_fp16)[name = tensor<string, []>("op_10182_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_101_cast_fp16 = add(x = var_10180_cast_fp16, y = var_10182_cast_fp16)[name = tensor<string, []>("key_101_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_10184_cast_fp16 = mul(x = current_value_51_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_10184_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_10186_cast_fp16 = mul(x = var_138_cast_fp16_25, y = var_295_cast_fp16)[name = tensor<string, []>("op_10186_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_101_cast_fp16 = add(x = var_10184_cast_fp16, y = var_10186_cast_fp16)[name = tensor<string, []>("value_101_cast_fp16")];
            tensor<int32, [4]> var_10189 = const()[name = tensor<string, []>("op_10189"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_10190_cast_fp16 = reshape(shape = var_10189, x = query_101_cast_fp16)[name = tensor<string, []>("op_10190_cast_fp16")];
            tensor<fp16, []> var_10191_to_fp16 = const()[name = tensor<string, []>("op_10191_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_10192_cast_fp16 = mul(x = var_10190_cast_fp16, y = var_10191_to_fp16)[name = tensor<string, []>("op_10192_cast_fp16")];
            tensor<int32, [4]> var_10193 = const()[name = tensor<string, []>("op_10193"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_10194_cast_fp16 = reshape(shape = var_10193, x = key_101_cast_fp16)[name = tensor<string, []>("op_10194_cast_fp16")];
            tensor<bool, []> mh_w_151_transpose_x_0 = const()[name = tensor<string, []>("mh_w_151_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_151_transpose_y_0 = const()[name = tensor<string, []>("mh_w_151_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_151_cast_fp16 = matmul(transpose_x = mh_w_151_transpose_x_0, transpose_y = mh_w_151_transpose_y_0, x = var_10192_cast_fp16, y = var_10194_cast_fp16)[name = tensor<string, []>("mh_w_151_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_153_cast_fp16 = add(x = mh_w_151_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_153_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_10202_cast_fp16 = softmax(axis = var_10062, x = mh_w_153_cast_fp16)[name = tensor<string, []>("op_10202_cast_fp16")];
            tensor<int32, [4]> var_10203 = const()[name = tensor<string, []>("op_10203"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_10204_cast_fp16 = reshape(shape = var_10203, x = value_101_cast_fp16)[name = tensor<string, []>("op_10204_cast_fp16")];
            tensor<bool, []> attn_101_transpose_x_0 = const()[name = tensor<string, []>("attn_101_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_101_transpose_y_0 = const()[name = tensor<string, []>("attn_101_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_101_cast_fp16 = matmul(transpose_x = attn_101_transpose_x_0, transpose_y = attn_101_transpose_y_0, x = var_10204_cast_fp16, y = var_10202_cast_fp16)[name = tensor<string, []>("attn_101_cast_fp16")];
            tensor<int32, [4]> var_10207 = const()[name = tensor<string, []>("op_10207"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_757_cast_fp16 = reshape(shape = var_10207, x = attn_101_cast_fp16)[name = tensor<string, []>("input_757_cast_fp16")];
            tensor<int32, [2]> var_10214 = const()[name = tensor<string, []>("op_10214"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10216 = const()[name = tensor<string, []>("op_10216"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_507_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_507_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_507_pad_0 = const()[name = tensor<string, []>("pretrained_out_507_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_25_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(493787264))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(494606528))), name = tensor<string, []>("layers_25_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_25_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_25_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(494606656)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_507_cast_fp16 = conv(bias = layers_25_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_10216, groups = var_10069, pad = pretrained_out_507_pad_0, pad_type = pretrained_out_507_pad_type_0, strides = var_10214, weight = layers_25_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_757_cast_fp16)[name = tensor<string, []>("pretrained_out_507_cast_fp16")];
            tensor<int32, [2]> var_10220 = const()[name = tensor<string, []>("op_10220"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10222 = const()[name = tensor<string, []>("op_10222"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_759_pad_type_0 = const()[name = tensor<string, []>("input_759_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_759_pad_0 = const()[name = tensor<string, []>("input_759_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_25_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_25_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(494609280)))];
            tensor<fp16, [1, 16, 1, 1]> input_759_cast_fp16 = conv(dilations = var_10222, groups = var_10069, pad = input_759_pad_0, pad_type = input_759_pad_type_0, strides = var_10220, weight = layers_25_self_attn_o_proj_loraA_weight_to_fp16, x = input_757_cast_fp16)[name = tensor<string, []>("input_759_cast_fp16")];
            tensor<int32, [2]> var_10226 = const()[name = tensor<string, []>("op_10226"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10228 = const()[name = tensor<string, []>("op_10228"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1013_pad_type_0 = const()[name = tensor<string, []>("lora_out_1013_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1013_pad_0 = const()[name = tensor<string, []>("lora_out_1013_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1015_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1015_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(494650304)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1015_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_10228, groups = var_10069, pad = lora_out_1013_pad_0, pad_type = lora_out_1013_pad_type_0, strides = var_10226, weight = lora_out_1015_weight_0_to_fp16, x = input_759_cast_fp16)[name = tensor<string, []>("lora_out_1015_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_357_cast_fp16 = add(x = pretrained_out_507_cast_fp16, y = lora_out_1015_cast_fp16)[name = tensor<string, []>("obj_357_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_153_cast_fp16 = add(x = inputs_151_cast_fp16, y = obj_357_cast_fp16)[name = tensor<string, []>("inputs_153_cast_fp16")];
            tensor<int32, [1]> var_10241 = const()[name = tensor<string, []>("op_10241"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_153_cast_fp16 = reduce_mean(axes = var_10241, keep_dims = var_10070, x = inputs_153_cast_fp16)[name = tensor<string, []>("channels_mean_153_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_153_cast_fp16 = sub(x = inputs_153_cast_fp16, y = channels_mean_153_cast_fp16)[name = tensor<string, []>("zero_mean_153_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_153_cast_fp16 = mul(x = zero_mean_153_cast_fp16, y = zero_mean_153_cast_fp16)[name = tensor<string, []>("zero_mean_sq_153_cast_fp16")];
            tensor<int32, [1]> var_10245 = const()[name = tensor<string, []>("op_10245"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_10246_cast_fp16 = reduce_mean(axes = var_10245, keep_dims = var_10070, x = zero_mean_sq_153_cast_fp16)[name = tensor<string, []>("op_10246_cast_fp16")];
            tensor<fp16, []> var_10247_to_fp16 = const()[name = tensor<string, []>("op_10247_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_10248_cast_fp16 = add(x = var_10246_cast_fp16, y = var_10247_to_fp16)[name = tensor<string, []>("op_10248_cast_fp16")];
            tensor<fp32, []> denom_153_epsilon_0 = const()[name = tensor<string, []>("denom_153_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_153_cast_fp16 = rsqrt(epsilon = denom_153_epsilon_0, x = var_10248_cast_fp16)[name = tensor<string, []>("denom_153_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_153_cast_fp16 = mul(x = zero_mean_153_cast_fp16, y = denom_153_cast_fp16)[name = tensor<string, []>("out_153_cast_fp16")];
            tensor<fp16, [1280]> obj_359_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_359_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(494691328)))];
            tensor<fp16, [1280]> obj_359_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_359_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(494693952)))];
            tensor<fp16, []> obj_359_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_359_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_359_cast_fp16 = batch_norm(beta = obj_359_beta_0_to_fp16, epsilon = obj_359_epsilon_0_to_fp16, gamma = obj_359_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_153_cast_fp16)[name = tensor<string, []>("obj_359_cast_fp16")];
            tensor<int32, [2]> var_10266 = const()[name = tensor<string, []>("op_10266"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10268 = const()[name = tensor<string, []>("op_10268"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_509_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_509_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_509_pad_0 = const()[name = tensor<string, []>("pretrained_out_509_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_25_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(494696576))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(495515840))), name = tensor<string, []>("layers_25_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_25_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_25_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(495515968)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_509_cast_fp16 = conv(bias = layers_25_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_10268, groups = var_10069, pad = pretrained_out_509_pad_0, pad_type = pretrained_out_509_pad_type_0, strides = var_10266, weight = layers_25_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_359_cast_fp16)[name = tensor<string, []>("pretrained_out_509_cast_fp16")];
            tensor<int32, [2]> var_10272 = const()[name = tensor<string, []>("op_10272"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10274 = const()[name = tensor<string, []>("op_10274"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_761_pad_type_0 = const()[name = tensor<string, []>("input_761_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_761_pad_0 = const()[name = tensor<string, []>("input_761_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_25_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_25_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(495518592)))];
            tensor<fp16, [1, 16, 1, 1]> input_761_cast_fp16 = conv(dilations = var_10274, groups = var_10069, pad = input_761_pad_0, pad_type = input_761_pad_type_0, strides = var_10272, weight = layers_25_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_359_cast_fp16)[name = tensor<string, []>("input_761_cast_fp16")];
            tensor<int32, [2]> var_10278 = const()[name = tensor<string, []>("op_10278"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10280 = const()[name = tensor<string, []>("op_10280"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1017_pad_type_0 = const()[name = tensor<string, []>("lora_out_1017_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1017_pad_0 = const()[name = tensor<string, []>("lora_out_1017_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1019_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1019_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(495559616)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1019_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_10280, groups = var_10069, pad = lora_out_1017_pad_0, pad_type = lora_out_1017_pad_type_0, strides = var_10278, weight = lora_out_1019_weight_0_to_fp16, x = input_761_cast_fp16)[name = tensor<string, []>("lora_out_1019_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_103_cast_fp16 = add(x = pretrained_out_509_cast_fp16, y = lora_out_1019_cast_fp16)[name = tensor<string, []>("query_103_cast_fp16")];
            tensor<int32, [2]> var_10290 = const()[name = tensor<string, []>("op_10290"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10292 = const()[name = tensor<string, []>("op_10292"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_511_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_511_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_511_pad_0 = const()[name = tensor<string, []>("pretrained_out_511_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_25_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(495600640))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(496419904))), name = tensor<string, []>("layers_25_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_511_cast_fp16 = conv(dilations = var_10292, groups = var_10069, pad = pretrained_out_511_pad_0, pad_type = pretrained_out_511_pad_type_0, strides = var_10290, weight = layers_25_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_511_cast_fp16")];
            tensor<int32, [2]> var_10296 = const()[name = tensor<string, []>("op_10296"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10298 = const()[name = tensor<string, []>("op_10298"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_763_pad_type_0 = const()[name = tensor<string, []>("input_763_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_763_pad_0 = const()[name = tensor<string, []>("input_763_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_25_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_25_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(496420032)))];
            tensor<fp16, [1, 16, 1, 1500]> input_763_cast_fp16 = conv(dilations = var_10298, groups = var_10069, pad = input_763_pad_0, pad_type = input_763_pad_type_0, strides = var_10296, weight = layers_25_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_763_cast_fp16")];
            tensor<int32, [2]> var_10302 = const()[name = tensor<string, []>("op_10302"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10304 = const()[name = tensor<string, []>("op_10304"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1021_pad_type_0 = const()[name = tensor<string, []>("lora_out_1021_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1021_pad_0 = const()[name = tensor<string, []>("lora_out_1021_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1023_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1023_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(496461056)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_1023_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_10304, groups = var_10069, pad = lora_out_1021_pad_0, pad_type = lora_out_1021_pad_type_0, strides = var_10302, weight = lora_out_1023_weight_0_to_fp16, x = input_763_cast_fp16)[name = tensor<string, []>("lora_out_1023_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_103_cast_fp16 = add(x = pretrained_out_511_cast_fp16, y = lora_out_1023_cast_fp16)[name = tensor<string, []>("key_103_cast_fp16")];
            tensor<int32, [2]> var_10315 = const()[name = tensor<string, []>("op_10315"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10317 = const()[name = tensor<string, []>("op_10317"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_513_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_513_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_513_pad_0 = const()[name = tensor<string, []>("pretrained_out_513_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_25_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(496502080))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(497321344))), name = tensor<string, []>("layers_25_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_25_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_25_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(497321472)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_513_cast_fp16 = conv(bias = layers_25_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_10317, groups = var_10069, pad = pretrained_out_513_pad_0, pad_type = pretrained_out_513_pad_type_0, strides = var_10315, weight = layers_25_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_513_cast_fp16")];
            tensor<int32, [2]> var_10321 = const()[name = tensor<string, []>("op_10321"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10323 = const()[name = tensor<string, []>("op_10323"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_765_pad_type_0 = const()[name = tensor<string, []>("input_765_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_765_pad_0 = const()[name = tensor<string, []>("input_765_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_25_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_25_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(497324096)))];
            tensor<fp16, [1, 16, 1, 1500]> input_765_cast_fp16 = conv(dilations = var_10323, groups = var_10069, pad = input_765_pad_0, pad_type = input_765_pad_type_0, strides = var_10321, weight = layers_25_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_765_cast_fp16")];
            tensor<int32, [2]> var_10327 = const()[name = tensor<string, []>("op_10327"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10329 = const()[name = tensor<string, []>("op_10329"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1025_pad_type_0 = const()[name = tensor<string, []>("lora_out_1025_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1025_pad_0 = const()[name = tensor<string, []>("lora_out_1025_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1027_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1027_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(497365120)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_1027_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_10329, groups = var_10069, pad = lora_out_1025_pad_0, pad_type = lora_out_1025_pad_type_0, strides = var_10327, weight = lora_out_1027_weight_0_to_fp16, x = input_765_cast_fp16)[name = tensor<string, []>("lora_out_1027_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_103_cast_fp16 = add(x = pretrained_out_513_cast_fp16, y = lora_out_1027_cast_fp16)[name = tensor<string, []>("value_103_cast_fp16")];
            tensor<int32, [4]> var_10336 = const()[name = tensor<string, []>("op_10336"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_10337_cast_fp16 = reshape(shape = var_10336, x = query_103_cast_fp16)[name = tensor<string, []>("op_10337_cast_fp16")];
            tensor<fp16, []> var_10338_to_fp16 = const()[name = tensor<string, []>("op_10338_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_10339_cast_fp16 = mul(x = var_10337_cast_fp16, y = var_10338_to_fp16)[name = tensor<string, []>("op_10339_cast_fp16")];
            tensor<int32, [4]> var_10340 = const()[name = tensor<string, []>("op_10340"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_10341_cast_fp16 = reshape(shape = var_10340, x = key_103_cast_fp16)[name = tensor<string, []>("op_10341_cast_fp16")];
            tensor<bool, []> mh_w_155_transpose_x_0 = const()[name = tensor<string, []>("mh_w_155_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_155_transpose_y_0 = const()[name = tensor<string, []>("mh_w_155_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_155_cast_fp16 = matmul(transpose_x = mh_w_155_transpose_x_0, transpose_y = mh_w_155_transpose_y_0, x = var_10339_cast_fp16, y = var_10341_cast_fp16)[name = tensor<string, []>("mh_w_155_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_363_cast_fp16 = softmax(axis = var_10062, x = mh_w_155_cast_fp16)[name = tensor<string, []>("obj_363_cast_fp16")];
            tensor<int32, [4]> var_10345 = const()[name = tensor<string, []>("op_10345"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_10346_cast_fp16 = reshape(shape = var_10345, x = value_103_cast_fp16)[name = tensor<string, []>("op_10346_cast_fp16")];
            tensor<bool, []> attn_103_transpose_x_0 = const()[name = tensor<string, []>("attn_103_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_103_transpose_y_0 = const()[name = tensor<string, []>("attn_103_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_103_cast_fp16 = matmul(transpose_x = attn_103_transpose_x_0, transpose_y = attn_103_transpose_y_0, x = var_10346_cast_fp16, y = obj_363_cast_fp16)[name = tensor<string, []>("attn_103_cast_fp16")];
            tensor<int32, [4]> var_10349 = const()[name = tensor<string, []>("op_10349"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_767_cast_fp16 = reshape(shape = var_10349, x = attn_103_cast_fp16)[name = tensor<string, []>("input_767_cast_fp16")];
            tensor<int32, [2]> var_10356 = const()[name = tensor<string, []>("op_10356"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10358 = const()[name = tensor<string, []>("op_10358"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_515_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_515_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_515_pad_0 = const()[name = tensor<string, []>("pretrained_out_515_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_25_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(497406144))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(498225408))), name = tensor<string, []>("layers_25_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_25_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_25_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(498225536)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_515_cast_fp16 = conv(bias = layers_25_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_10358, groups = var_10069, pad = pretrained_out_515_pad_0, pad_type = pretrained_out_515_pad_type_0, strides = var_10356, weight = layers_25_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_767_cast_fp16)[name = tensor<string, []>("pretrained_out_515_cast_fp16")];
            tensor<int32, [2]> var_10362 = const()[name = tensor<string, []>("op_10362"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10364 = const()[name = tensor<string, []>("op_10364"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_769_pad_type_0 = const()[name = tensor<string, []>("input_769_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_769_pad_0 = const()[name = tensor<string, []>("input_769_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_25_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_25_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(498228160)))];
            tensor<fp16, [1, 16, 1, 1]> input_769_cast_fp16 = conv(dilations = var_10364, groups = var_10069, pad = input_769_pad_0, pad_type = input_769_pad_type_0, strides = var_10362, weight = layers_25_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_767_cast_fp16)[name = tensor<string, []>("input_769_cast_fp16")];
            tensor<int32, [2]> var_10368 = const()[name = tensor<string, []>("op_10368"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10370 = const()[name = tensor<string, []>("op_10370"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1029_pad_type_0 = const()[name = tensor<string, []>("lora_out_1029_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1029_pad_0 = const()[name = tensor<string, []>("lora_out_1029_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1031_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1031_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(498269184)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1031_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_10370, groups = var_10069, pad = lora_out_1029_pad_0, pad_type = lora_out_1029_pad_type_0, strides = var_10368, weight = lora_out_1031_weight_0_to_fp16, x = input_769_cast_fp16)[name = tensor<string, []>("lora_out_1031_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_361_cast_fp16 = add(x = pretrained_out_515_cast_fp16, y = lora_out_1031_cast_fp16)[name = tensor<string, []>("obj_361_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_155_cast_fp16 = add(x = inputs_153_cast_fp16, y = obj_361_cast_fp16)[name = tensor<string, []>("inputs_155_cast_fp16")];
            tensor<int32, [1]> var_10382 = const()[name = tensor<string, []>("op_10382"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_155_cast_fp16 = reduce_mean(axes = var_10382, keep_dims = var_10070, x = inputs_155_cast_fp16)[name = tensor<string, []>("channels_mean_155_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_155_cast_fp16 = sub(x = inputs_155_cast_fp16, y = channels_mean_155_cast_fp16)[name = tensor<string, []>("zero_mean_155_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_155_cast_fp16 = mul(x = zero_mean_155_cast_fp16, y = zero_mean_155_cast_fp16)[name = tensor<string, []>("zero_mean_sq_155_cast_fp16")];
            tensor<int32, [1]> var_10386 = const()[name = tensor<string, []>("op_10386"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_10387_cast_fp16 = reduce_mean(axes = var_10386, keep_dims = var_10070, x = zero_mean_sq_155_cast_fp16)[name = tensor<string, []>("op_10387_cast_fp16")];
            tensor<fp16, []> var_10388_to_fp16 = const()[name = tensor<string, []>("op_10388_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_10389_cast_fp16 = add(x = var_10387_cast_fp16, y = var_10388_to_fp16)[name = tensor<string, []>("op_10389_cast_fp16")];
            tensor<fp32, []> denom_155_epsilon_0 = const()[name = tensor<string, []>("denom_155_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_155_cast_fp16 = rsqrt(epsilon = denom_155_epsilon_0, x = var_10389_cast_fp16)[name = tensor<string, []>("denom_155_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_155_cast_fp16 = mul(x = zero_mean_155_cast_fp16, y = denom_155_cast_fp16)[name = tensor<string, []>("out_155_cast_fp16")];
            tensor<fp16, [1280]> input_771_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_771_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(498310208)))];
            tensor<fp16, [1280]> input_771_beta_0_to_fp16 = const()[name = tensor<string, []>("input_771_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(498312832)))];
            tensor<fp16, []> input_771_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_771_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_771_cast_fp16 = batch_norm(beta = input_771_beta_0_to_fp16, epsilon = input_771_epsilon_0_to_fp16, gamma = input_771_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_155_cast_fp16)[name = tensor<string, []>("input_771_cast_fp16")];
            tensor<int32, [2]> var_10403 = const()[name = tensor<string, []>("op_10403"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10405 = const()[name = tensor<string, []>("op_10405"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_517_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_517_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_517_pad_0 = const()[name = tensor<string, []>("pretrained_out_517_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_25_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(498315456))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(501592320))), name = tensor<string, []>("layers_25_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_25_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_25_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(501592448)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_517_cast_fp16 = conv(bias = layers_25_fc1_pretrained_bias_to_fp16, dilations = var_10405, groups = var_10069, pad = pretrained_out_517_pad_0, pad_type = pretrained_out_517_pad_type_0, strides = var_10403, weight = layers_25_fc1_pretrained_weight_to_fp16_palettized, x = input_771_cast_fp16)[name = tensor<string, []>("pretrained_out_517_cast_fp16")];
            tensor<int32, [2]> var_10409 = const()[name = tensor<string, []>("op_10409"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10411 = const()[name = tensor<string, []>("op_10411"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_773_pad_type_0 = const()[name = tensor<string, []>("input_773_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_773_pad_0 = const()[name = tensor<string, []>("input_773_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_25_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_25_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(501602752)))];
            tensor<fp16, [1, 16, 1, 1]> input_773_cast_fp16 = conv(dilations = var_10411, groups = var_10069, pad = input_773_pad_0, pad_type = input_773_pad_type_0, strides = var_10409, weight = layers_25_fc1_loraA_weight_to_fp16, x = input_771_cast_fp16)[name = tensor<string, []>("input_773_cast_fp16")];
            tensor<int32, [2]> var_10415 = const()[name = tensor<string, []>("op_10415"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10417 = const()[name = tensor<string, []>("op_10417"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1033_pad_type_0 = const()[name = tensor<string, []>("lora_out_1033_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1033_pad_0 = const()[name = tensor<string, []>("lora_out_1033_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_1035_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1035_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(501643776)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_1035_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_10417, groups = var_10069, pad = lora_out_1033_pad_0, pad_type = lora_out_1033_pad_type_0, strides = var_10415, weight = lora_out_1035_weight_0_to_fp16, x = input_773_cast_fp16)[name = tensor<string, []>("lora_out_1035_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_775_cast_fp16 = add(x = pretrained_out_517_cast_fp16, y = lora_out_1035_cast_fp16)[name = tensor<string, []>("input_775_cast_fp16")];
            tensor<string, []> input_777_mode_0 = const()[name = tensor<string, []>("input_777_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_777_cast_fp16 = gelu(mode = input_777_mode_0, x = input_775_cast_fp16)[name = tensor<string, []>("input_777_cast_fp16")];
            tensor<int32, [2]> var_10429 = const()[name = tensor<string, []>("op_10429"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10431 = const()[name = tensor<string, []>("op_10431"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_519_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_519_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_519_pad_0 = const()[name = tensor<string, []>("pretrained_out_519_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_25_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(501807680))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(505084544))), name = tensor<string, []>("layers_25_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_25_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_25_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(505084672)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_519_cast_fp16 = conv(bias = layers_25_fc2_pretrained_bias_to_fp16, dilations = var_10431, groups = var_10069, pad = pretrained_out_519_pad_0, pad_type = pretrained_out_519_pad_type_0, strides = var_10429, weight = layers_25_fc2_pretrained_weight_to_fp16_palettized, x = input_777_cast_fp16)[name = tensor<string, []>("pretrained_out_519_cast_fp16")];
            tensor<int32, [2]> var_10435 = const()[name = tensor<string, []>("op_10435"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10437 = const()[name = tensor<string, []>("op_10437"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_779_pad_type_0 = const()[name = tensor<string, []>("input_779_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_779_pad_0 = const()[name = tensor<string, []>("input_779_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_25_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_25_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(505087296)))];
            tensor<fp16, [1, 16, 1, 1]> input_779_cast_fp16 = conv(dilations = var_10437, groups = var_10069, pad = input_779_pad_0, pad_type = input_779_pad_type_0, strides = var_10435, weight = layers_25_fc2_loraA_weight_to_fp16, x = input_777_cast_fp16)[name = tensor<string, []>("input_779_cast_fp16")];
            tensor<int32, [2]> var_10441 = const()[name = tensor<string, []>("op_10441"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10443 = const()[name = tensor<string, []>("op_10443"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1037_pad_type_0 = const()[name = tensor<string, []>("lora_out_1037_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1037_pad_0 = const()[name = tensor<string, []>("lora_out_1037_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1039_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1039_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(505251200)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1039_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_10443, groups = var_10069, pad = lora_out_1037_pad_0, pad_type = lora_out_1037_pad_type_0, strides = var_10441, weight = lora_out_1039_weight_0_to_fp16, x = input_779_cast_fp16)[name = tensor<string, []>("lora_out_1039_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_53_cast_fp16 = add(x = pretrained_out_519_cast_fp16, y = lora_out_1039_cast_fp16)[name = tensor<string, []>("hidden_states_53_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_157_cast_fp16 = add(x = inputs_155_cast_fp16, y = hidden_states_53_cast_fp16)[name = tensor<string, []>("inputs_157_cast_fp16")];
            tensor<int32, []> var_10460 = const()[name = tensor<string, []>("op_10460"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_10467 = const()[name = tensor<string, []>("op_10467"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_10468 = const()[name = tensor<string, []>("op_10468"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_10480 = const()[name = tensor<string, []>("op_10480"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_157_cast_fp16 = reduce_mean(axes = var_10480, keep_dims = var_10468, x = inputs_157_cast_fp16)[name = tensor<string, []>("channels_mean_157_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_157_cast_fp16 = sub(x = inputs_157_cast_fp16, y = channels_mean_157_cast_fp16)[name = tensor<string, []>("zero_mean_157_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_157_cast_fp16 = mul(x = zero_mean_157_cast_fp16, y = zero_mean_157_cast_fp16)[name = tensor<string, []>("zero_mean_sq_157_cast_fp16")];
            tensor<int32, [1]> var_10484 = const()[name = tensor<string, []>("op_10484"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_10485_cast_fp16 = reduce_mean(axes = var_10484, keep_dims = var_10468, x = zero_mean_sq_157_cast_fp16)[name = tensor<string, []>("op_10485_cast_fp16")];
            tensor<fp16, []> var_10486_to_fp16 = const()[name = tensor<string, []>("op_10486_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_10487_cast_fp16 = add(x = var_10485_cast_fp16, y = var_10486_to_fp16)[name = tensor<string, []>("op_10487_cast_fp16")];
            tensor<fp32, []> denom_157_epsilon_0 = const()[name = tensor<string, []>("denom_157_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_157_cast_fp16 = rsqrt(epsilon = denom_157_epsilon_0, x = var_10487_cast_fp16)[name = tensor<string, []>("denom_157_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_157_cast_fp16 = mul(x = zero_mean_157_cast_fp16, y = denom_157_cast_fp16)[name = tensor<string, []>("out_157_cast_fp16")];
            tensor<fp16, [1280]> obj_365_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_365_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(505292224)))];
            tensor<fp16, [1280]> obj_365_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_365_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(505294848)))];
            tensor<fp16, []> obj_365_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_365_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_365_cast_fp16 = batch_norm(beta = obj_365_beta_0_to_fp16, epsilon = obj_365_epsilon_0_to_fp16, gamma = obj_365_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_157_cast_fp16)[name = tensor<string, []>("obj_365_cast_fp16")];
            tensor<int32, [2]> var_10505 = const()[name = tensor<string, []>("op_10505"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10507 = const()[name = tensor<string, []>("op_10507"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_521_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_521_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_521_pad_0 = const()[name = tensor<string, []>("pretrained_out_521_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_26_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(505297472))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(506116736))), name = tensor<string, []>("layers_26_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_26_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_26_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(506116864)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_521_cast_fp16 = conv(bias = layers_26_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_10507, groups = var_10467, pad = pretrained_out_521_pad_0, pad_type = pretrained_out_521_pad_type_0, strides = var_10505, weight = layers_26_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_365_cast_fp16)[name = tensor<string, []>("pretrained_out_521_cast_fp16")];
            tensor<int32, [2]> var_10511 = const()[name = tensor<string, []>("op_10511"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10513 = const()[name = tensor<string, []>("op_10513"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_781_pad_type_0 = const()[name = tensor<string, []>("input_781_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_781_pad_0 = const()[name = tensor<string, []>("input_781_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_26_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_26_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(506119488)))];
            tensor<fp16, [1, 16, 1, 1]> input_781_cast_fp16 = conv(dilations = var_10513, groups = var_10467, pad = input_781_pad_0, pad_type = input_781_pad_type_0, strides = var_10511, weight = layers_26_self_attn_q_proj_loraA_weight_to_fp16, x = obj_365_cast_fp16)[name = tensor<string, []>("input_781_cast_fp16")];
            tensor<int32, [2]> var_10517 = const()[name = tensor<string, []>("op_10517"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10519 = const()[name = tensor<string, []>("op_10519"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1041_pad_type_0 = const()[name = tensor<string, []>("lora_out_1041_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1041_pad_0 = const()[name = tensor<string, []>("lora_out_1041_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1043_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1043_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(506160512)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1043_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_10519, groups = var_10467, pad = lora_out_1041_pad_0, pad_type = lora_out_1041_pad_type_0, strides = var_10517, weight = lora_out_1043_weight_0_to_fp16, x = input_781_cast_fp16)[name = tensor<string, []>("lora_out_1043_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_105_cast_fp16 = add(x = pretrained_out_521_cast_fp16, y = lora_out_1043_cast_fp16)[name = tensor<string, []>("query_105_cast_fp16")];
            tensor<int32, [2]> var_10529 = const()[name = tensor<string, []>("op_10529"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10531 = const()[name = tensor<string, []>("op_10531"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_523_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_523_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_523_pad_0 = const()[name = tensor<string, []>("pretrained_out_523_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_26_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(506201536))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(507020800))), name = tensor<string, []>("layers_26_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_523_cast_fp16 = conv(dilations = var_10531, groups = var_10467, pad = pretrained_out_523_pad_0, pad_type = pretrained_out_523_pad_type_0, strides = var_10529, weight = layers_26_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_365_cast_fp16)[name = tensor<string, []>("pretrained_out_523_cast_fp16")];
            tensor<int32, [2]> var_10535 = const()[name = tensor<string, []>("op_10535"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10537 = const()[name = tensor<string, []>("op_10537"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_783_pad_type_0 = const()[name = tensor<string, []>("input_783_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_783_pad_0 = const()[name = tensor<string, []>("input_783_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_26_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_26_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(507020928)))];
            tensor<fp16, [1, 16, 1, 1]> input_783_cast_fp16 = conv(dilations = var_10537, groups = var_10467, pad = input_783_pad_0, pad_type = input_783_pad_type_0, strides = var_10535, weight = layers_26_self_attn_k_proj_loraA_weight_to_fp16, x = obj_365_cast_fp16)[name = tensor<string, []>("input_783_cast_fp16")];
            tensor<int32, [2]> var_10541 = const()[name = tensor<string, []>("op_10541"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10543 = const()[name = tensor<string, []>("op_10543"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1045_pad_type_0 = const()[name = tensor<string, []>("lora_out_1045_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1045_pad_0 = const()[name = tensor<string, []>("lora_out_1045_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1047_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1047_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(507061952)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1047_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_10543, groups = var_10467, pad = lora_out_1045_pad_0, pad_type = lora_out_1045_pad_type_0, strides = var_10541, weight = lora_out_1047_weight_0_to_fp16, x = input_783_cast_fp16)[name = tensor<string, []>("lora_out_1047_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_53_cast_fp16 = add(x = pretrained_out_523_cast_fp16, y = lora_out_1047_cast_fp16)[name = tensor<string, []>("current_key_53_cast_fp16")];
            tensor<int32, [2]> var_10554 = const()[name = tensor<string, []>("op_10554"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10556 = const()[name = tensor<string, []>("op_10556"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_525_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_525_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_525_pad_0 = const()[name = tensor<string, []>("pretrained_out_525_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_26_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(507102976))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(507922240))), name = tensor<string, []>("layers_26_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_26_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_26_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(507922368)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_525_cast_fp16 = conv(bias = layers_26_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_10556, groups = var_10467, pad = pretrained_out_525_pad_0, pad_type = pretrained_out_525_pad_type_0, strides = var_10554, weight = layers_26_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_365_cast_fp16)[name = tensor<string, []>("pretrained_out_525_cast_fp16")];
            tensor<int32, [2]> var_10560 = const()[name = tensor<string, []>("op_10560"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10562 = const()[name = tensor<string, []>("op_10562"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_785_pad_type_0 = const()[name = tensor<string, []>("input_785_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_785_pad_0 = const()[name = tensor<string, []>("input_785_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_26_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_26_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(507924992)))];
            tensor<fp16, [1, 16, 1, 1]> input_785_cast_fp16 = conv(dilations = var_10562, groups = var_10467, pad = input_785_pad_0, pad_type = input_785_pad_type_0, strides = var_10560, weight = layers_26_self_attn_v_proj_loraA_weight_to_fp16, x = obj_365_cast_fp16)[name = tensor<string, []>("input_785_cast_fp16")];
            tensor<int32, [2]> var_10566 = const()[name = tensor<string, []>("op_10566"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10568 = const()[name = tensor<string, []>("op_10568"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1049_pad_type_0 = const()[name = tensor<string, []>("lora_out_1049_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1049_pad_0 = const()[name = tensor<string, []>("lora_out_1049_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1051_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1051_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(507966016)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1051_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_10568, groups = var_10467, pad = lora_out_1049_pad_0, pad_type = lora_out_1049_pad_type_0, strides = var_10566, weight = lora_out_1051_weight_0_to_fp16, x = input_785_cast_fp16)[name = tensor<string, []>("lora_out_1051_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_53_cast_fp16 = add(x = pretrained_out_525_cast_fp16, y = lora_out_1051_cast_fp16)[name = tensor<string, []>("current_value_53_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_10578_cast_fp16 = mul(x = current_key_53_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_10578_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_10580_cast_fp16 = mul(x = var_103_cast_fp16_26, y = var_295_cast_fp16)[name = tensor<string, []>("op_10580_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_105_cast_fp16 = add(x = var_10578_cast_fp16, y = var_10580_cast_fp16)[name = tensor<string, []>("key_105_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_10582_cast_fp16 = mul(x = current_value_53_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_10582_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_10584_cast_fp16 = mul(x = var_138_cast_fp16_26, y = var_295_cast_fp16)[name = tensor<string, []>("op_10584_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_105_cast_fp16 = add(x = var_10582_cast_fp16, y = var_10584_cast_fp16)[name = tensor<string, []>("value_105_cast_fp16")];
            tensor<int32, [4]> var_10587 = const()[name = tensor<string, []>("op_10587"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_10588_cast_fp16 = reshape(shape = var_10587, x = query_105_cast_fp16)[name = tensor<string, []>("op_10588_cast_fp16")];
            tensor<fp16, []> var_10589_to_fp16 = const()[name = tensor<string, []>("op_10589_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_10590_cast_fp16 = mul(x = var_10588_cast_fp16, y = var_10589_to_fp16)[name = tensor<string, []>("op_10590_cast_fp16")];
            tensor<int32, [4]> var_10591 = const()[name = tensor<string, []>("op_10591"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_10592_cast_fp16 = reshape(shape = var_10591, x = key_105_cast_fp16)[name = tensor<string, []>("op_10592_cast_fp16")];
            tensor<bool, []> mh_w_157_transpose_x_0 = const()[name = tensor<string, []>("mh_w_157_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_157_transpose_y_0 = const()[name = tensor<string, []>("mh_w_157_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_157_cast_fp16 = matmul(transpose_x = mh_w_157_transpose_x_0, transpose_y = mh_w_157_transpose_y_0, x = var_10590_cast_fp16, y = var_10592_cast_fp16)[name = tensor<string, []>("mh_w_157_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_159_cast_fp16 = add(x = mh_w_157_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_159_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_10600_cast_fp16 = softmax(axis = var_10460, x = mh_w_159_cast_fp16)[name = tensor<string, []>("op_10600_cast_fp16")];
            tensor<int32, [4]> var_10601 = const()[name = tensor<string, []>("op_10601"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_10602_cast_fp16 = reshape(shape = var_10601, x = value_105_cast_fp16)[name = tensor<string, []>("op_10602_cast_fp16")];
            tensor<bool, []> attn_105_transpose_x_0 = const()[name = tensor<string, []>("attn_105_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_105_transpose_y_0 = const()[name = tensor<string, []>("attn_105_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_105_cast_fp16 = matmul(transpose_x = attn_105_transpose_x_0, transpose_y = attn_105_transpose_y_0, x = var_10602_cast_fp16, y = var_10600_cast_fp16)[name = tensor<string, []>("attn_105_cast_fp16")];
            tensor<int32, [4]> var_10605 = const()[name = tensor<string, []>("op_10605"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_787_cast_fp16 = reshape(shape = var_10605, x = attn_105_cast_fp16)[name = tensor<string, []>("input_787_cast_fp16")];
            tensor<int32, [2]> var_10612 = const()[name = tensor<string, []>("op_10612"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10614 = const()[name = tensor<string, []>("op_10614"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_527_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_527_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_527_pad_0 = const()[name = tensor<string, []>("pretrained_out_527_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_26_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(508007040))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(508826304))), name = tensor<string, []>("layers_26_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_26_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_26_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(508826432)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_527_cast_fp16 = conv(bias = layers_26_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_10614, groups = var_10467, pad = pretrained_out_527_pad_0, pad_type = pretrained_out_527_pad_type_0, strides = var_10612, weight = layers_26_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_787_cast_fp16)[name = tensor<string, []>("pretrained_out_527_cast_fp16")];
            tensor<int32, [2]> var_10618 = const()[name = tensor<string, []>("op_10618"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10620 = const()[name = tensor<string, []>("op_10620"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_789_pad_type_0 = const()[name = tensor<string, []>("input_789_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_789_pad_0 = const()[name = tensor<string, []>("input_789_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_26_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_26_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(508829056)))];
            tensor<fp16, [1, 16, 1, 1]> input_789_cast_fp16 = conv(dilations = var_10620, groups = var_10467, pad = input_789_pad_0, pad_type = input_789_pad_type_0, strides = var_10618, weight = layers_26_self_attn_o_proj_loraA_weight_to_fp16, x = input_787_cast_fp16)[name = tensor<string, []>("input_789_cast_fp16")];
            tensor<int32, [2]> var_10624 = const()[name = tensor<string, []>("op_10624"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10626 = const()[name = tensor<string, []>("op_10626"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1053_pad_type_0 = const()[name = tensor<string, []>("lora_out_1053_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1053_pad_0 = const()[name = tensor<string, []>("lora_out_1053_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1055_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1055_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(508870080)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1055_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_10626, groups = var_10467, pad = lora_out_1053_pad_0, pad_type = lora_out_1053_pad_type_0, strides = var_10624, weight = lora_out_1055_weight_0_to_fp16, x = input_789_cast_fp16)[name = tensor<string, []>("lora_out_1055_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_371_cast_fp16 = add(x = pretrained_out_527_cast_fp16, y = lora_out_1055_cast_fp16)[name = tensor<string, []>("obj_371_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_159_cast_fp16 = add(x = inputs_157_cast_fp16, y = obj_371_cast_fp16)[name = tensor<string, []>("inputs_159_cast_fp16")];
            tensor<int32, [1]> var_10639 = const()[name = tensor<string, []>("op_10639"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_159_cast_fp16 = reduce_mean(axes = var_10639, keep_dims = var_10468, x = inputs_159_cast_fp16)[name = tensor<string, []>("channels_mean_159_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_159_cast_fp16 = sub(x = inputs_159_cast_fp16, y = channels_mean_159_cast_fp16)[name = tensor<string, []>("zero_mean_159_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_159_cast_fp16 = mul(x = zero_mean_159_cast_fp16, y = zero_mean_159_cast_fp16)[name = tensor<string, []>("zero_mean_sq_159_cast_fp16")];
            tensor<int32, [1]> var_10643 = const()[name = tensor<string, []>("op_10643"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_10644_cast_fp16 = reduce_mean(axes = var_10643, keep_dims = var_10468, x = zero_mean_sq_159_cast_fp16)[name = tensor<string, []>("op_10644_cast_fp16")];
            tensor<fp16, []> var_10645_to_fp16 = const()[name = tensor<string, []>("op_10645_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_10646_cast_fp16 = add(x = var_10644_cast_fp16, y = var_10645_to_fp16)[name = tensor<string, []>("op_10646_cast_fp16")];
            tensor<fp32, []> denom_159_epsilon_0 = const()[name = tensor<string, []>("denom_159_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_159_cast_fp16 = rsqrt(epsilon = denom_159_epsilon_0, x = var_10646_cast_fp16)[name = tensor<string, []>("denom_159_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_159_cast_fp16 = mul(x = zero_mean_159_cast_fp16, y = denom_159_cast_fp16)[name = tensor<string, []>("out_159_cast_fp16")];
            tensor<fp16, [1280]> obj_373_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_373_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(508911104)))];
            tensor<fp16, [1280]> obj_373_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_373_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(508913728)))];
            tensor<fp16, []> obj_373_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_373_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_373_cast_fp16 = batch_norm(beta = obj_373_beta_0_to_fp16, epsilon = obj_373_epsilon_0_to_fp16, gamma = obj_373_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_159_cast_fp16)[name = tensor<string, []>("obj_373_cast_fp16")];
            tensor<int32, [2]> var_10664 = const()[name = tensor<string, []>("op_10664"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10666 = const()[name = tensor<string, []>("op_10666"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_529_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_529_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_529_pad_0 = const()[name = tensor<string, []>("pretrained_out_529_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_26_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(508916352))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(509735616))), name = tensor<string, []>("layers_26_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_26_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_26_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(509735744)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_529_cast_fp16 = conv(bias = layers_26_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_10666, groups = var_10467, pad = pretrained_out_529_pad_0, pad_type = pretrained_out_529_pad_type_0, strides = var_10664, weight = layers_26_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_373_cast_fp16)[name = tensor<string, []>("pretrained_out_529_cast_fp16")];
            tensor<int32, [2]> var_10670 = const()[name = tensor<string, []>("op_10670"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10672 = const()[name = tensor<string, []>("op_10672"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_791_pad_type_0 = const()[name = tensor<string, []>("input_791_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_791_pad_0 = const()[name = tensor<string, []>("input_791_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_26_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_26_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(509738368)))];
            tensor<fp16, [1, 16, 1, 1]> input_791_cast_fp16 = conv(dilations = var_10672, groups = var_10467, pad = input_791_pad_0, pad_type = input_791_pad_type_0, strides = var_10670, weight = layers_26_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_373_cast_fp16)[name = tensor<string, []>("input_791_cast_fp16")];
            tensor<int32, [2]> var_10676 = const()[name = tensor<string, []>("op_10676"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10678 = const()[name = tensor<string, []>("op_10678"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1057_pad_type_0 = const()[name = tensor<string, []>("lora_out_1057_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1057_pad_0 = const()[name = tensor<string, []>("lora_out_1057_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1059_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1059_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(509779392)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1059_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_10678, groups = var_10467, pad = lora_out_1057_pad_0, pad_type = lora_out_1057_pad_type_0, strides = var_10676, weight = lora_out_1059_weight_0_to_fp16, x = input_791_cast_fp16)[name = tensor<string, []>("lora_out_1059_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_107_cast_fp16 = add(x = pretrained_out_529_cast_fp16, y = lora_out_1059_cast_fp16)[name = tensor<string, []>("query_107_cast_fp16")];
            tensor<int32, [2]> var_10688 = const()[name = tensor<string, []>("op_10688"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10690 = const()[name = tensor<string, []>("op_10690"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_531_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_531_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_531_pad_0 = const()[name = tensor<string, []>("pretrained_out_531_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_26_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(509820416))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(510639680))), name = tensor<string, []>("layers_26_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_531_cast_fp16 = conv(dilations = var_10690, groups = var_10467, pad = pretrained_out_531_pad_0, pad_type = pretrained_out_531_pad_type_0, strides = var_10688, weight = layers_26_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_531_cast_fp16")];
            tensor<int32, [2]> var_10694 = const()[name = tensor<string, []>("op_10694"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10696 = const()[name = tensor<string, []>("op_10696"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_793_pad_type_0 = const()[name = tensor<string, []>("input_793_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_793_pad_0 = const()[name = tensor<string, []>("input_793_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_26_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_26_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(510639808)))];
            tensor<fp16, [1, 16, 1, 1500]> input_793_cast_fp16 = conv(dilations = var_10696, groups = var_10467, pad = input_793_pad_0, pad_type = input_793_pad_type_0, strides = var_10694, weight = layers_26_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_793_cast_fp16")];
            tensor<int32, [2]> var_10700 = const()[name = tensor<string, []>("op_10700"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10702 = const()[name = tensor<string, []>("op_10702"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1061_pad_type_0 = const()[name = tensor<string, []>("lora_out_1061_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1061_pad_0 = const()[name = tensor<string, []>("lora_out_1061_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1063_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1063_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(510680832)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_1063_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_10702, groups = var_10467, pad = lora_out_1061_pad_0, pad_type = lora_out_1061_pad_type_0, strides = var_10700, weight = lora_out_1063_weight_0_to_fp16, x = input_793_cast_fp16)[name = tensor<string, []>("lora_out_1063_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_107_cast_fp16 = add(x = pretrained_out_531_cast_fp16, y = lora_out_1063_cast_fp16)[name = tensor<string, []>("key_107_cast_fp16")];
            tensor<int32, [2]> var_10713 = const()[name = tensor<string, []>("op_10713"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10715 = const()[name = tensor<string, []>("op_10715"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_533_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_533_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_533_pad_0 = const()[name = tensor<string, []>("pretrained_out_533_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_26_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(510721856))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(511541120))), name = tensor<string, []>("layers_26_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_26_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_26_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(511541248)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_533_cast_fp16 = conv(bias = layers_26_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_10715, groups = var_10467, pad = pretrained_out_533_pad_0, pad_type = pretrained_out_533_pad_type_0, strides = var_10713, weight = layers_26_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_533_cast_fp16")];
            tensor<int32, [2]> var_10719 = const()[name = tensor<string, []>("op_10719"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10721 = const()[name = tensor<string, []>("op_10721"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_795_pad_type_0 = const()[name = tensor<string, []>("input_795_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_795_pad_0 = const()[name = tensor<string, []>("input_795_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_26_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_26_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(511543872)))];
            tensor<fp16, [1, 16, 1, 1500]> input_795_cast_fp16 = conv(dilations = var_10721, groups = var_10467, pad = input_795_pad_0, pad_type = input_795_pad_type_0, strides = var_10719, weight = layers_26_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_795_cast_fp16")];
            tensor<int32, [2]> var_10725 = const()[name = tensor<string, []>("op_10725"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10727 = const()[name = tensor<string, []>("op_10727"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1065_pad_type_0 = const()[name = tensor<string, []>("lora_out_1065_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1065_pad_0 = const()[name = tensor<string, []>("lora_out_1065_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1067_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1067_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(511584896)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_1067_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_10727, groups = var_10467, pad = lora_out_1065_pad_0, pad_type = lora_out_1065_pad_type_0, strides = var_10725, weight = lora_out_1067_weight_0_to_fp16, x = input_795_cast_fp16)[name = tensor<string, []>("lora_out_1067_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_107_cast_fp16 = add(x = pretrained_out_533_cast_fp16, y = lora_out_1067_cast_fp16)[name = tensor<string, []>("value_107_cast_fp16")];
            tensor<int32, [4]> var_10734 = const()[name = tensor<string, []>("op_10734"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_10735_cast_fp16 = reshape(shape = var_10734, x = query_107_cast_fp16)[name = tensor<string, []>("op_10735_cast_fp16")];
            tensor<fp16, []> var_10736_to_fp16 = const()[name = tensor<string, []>("op_10736_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_10737_cast_fp16 = mul(x = var_10735_cast_fp16, y = var_10736_to_fp16)[name = tensor<string, []>("op_10737_cast_fp16")];
            tensor<int32, [4]> var_10738 = const()[name = tensor<string, []>("op_10738"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_10739_cast_fp16 = reshape(shape = var_10738, x = key_107_cast_fp16)[name = tensor<string, []>("op_10739_cast_fp16")];
            tensor<bool, []> mh_w_161_transpose_x_0 = const()[name = tensor<string, []>("mh_w_161_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_161_transpose_y_0 = const()[name = tensor<string, []>("mh_w_161_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_161_cast_fp16 = matmul(transpose_x = mh_w_161_transpose_x_0, transpose_y = mh_w_161_transpose_y_0, x = var_10737_cast_fp16, y = var_10739_cast_fp16)[name = tensor<string, []>("mh_w_161_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_377_cast_fp16 = softmax(axis = var_10460, x = mh_w_161_cast_fp16)[name = tensor<string, []>("obj_377_cast_fp16")];
            tensor<int32, [4]> var_10743 = const()[name = tensor<string, []>("op_10743"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_10744_cast_fp16 = reshape(shape = var_10743, x = value_107_cast_fp16)[name = tensor<string, []>("op_10744_cast_fp16")];
            tensor<bool, []> attn_107_transpose_x_0 = const()[name = tensor<string, []>("attn_107_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_107_transpose_y_0 = const()[name = tensor<string, []>("attn_107_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_107_cast_fp16 = matmul(transpose_x = attn_107_transpose_x_0, transpose_y = attn_107_transpose_y_0, x = var_10744_cast_fp16, y = obj_377_cast_fp16)[name = tensor<string, []>("attn_107_cast_fp16")];
            tensor<int32, [4]> var_10747 = const()[name = tensor<string, []>("op_10747"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_797_cast_fp16 = reshape(shape = var_10747, x = attn_107_cast_fp16)[name = tensor<string, []>("input_797_cast_fp16")];
            tensor<int32, [2]> var_10754 = const()[name = tensor<string, []>("op_10754"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10756 = const()[name = tensor<string, []>("op_10756"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_535_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_535_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_535_pad_0 = const()[name = tensor<string, []>("pretrained_out_535_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_26_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(511625920))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(512445184))), name = tensor<string, []>("layers_26_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_26_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_26_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(512445312)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_535_cast_fp16 = conv(bias = layers_26_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_10756, groups = var_10467, pad = pretrained_out_535_pad_0, pad_type = pretrained_out_535_pad_type_0, strides = var_10754, weight = layers_26_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_797_cast_fp16)[name = tensor<string, []>("pretrained_out_535_cast_fp16")];
            tensor<int32, [2]> var_10760 = const()[name = tensor<string, []>("op_10760"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10762 = const()[name = tensor<string, []>("op_10762"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_799_pad_type_0 = const()[name = tensor<string, []>("input_799_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_799_pad_0 = const()[name = tensor<string, []>("input_799_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_26_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_26_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(512447936)))];
            tensor<fp16, [1, 16, 1, 1]> input_799_cast_fp16 = conv(dilations = var_10762, groups = var_10467, pad = input_799_pad_0, pad_type = input_799_pad_type_0, strides = var_10760, weight = layers_26_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_797_cast_fp16)[name = tensor<string, []>("input_799_cast_fp16")];
            tensor<int32, [2]> var_10766 = const()[name = tensor<string, []>("op_10766"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10768 = const()[name = tensor<string, []>("op_10768"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1069_pad_type_0 = const()[name = tensor<string, []>("lora_out_1069_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1069_pad_0 = const()[name = tensor<string, []>("lora_out_1069_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1071_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1071_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(512488960)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1071_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_10768, groups = var_10467, pad = lora_out_1069_pad_0, pad_type = lora_out_1069_pad_type_0, strides = var_10766, weight = lora_out_1071_weight_0_to_fp16, x = input_799_cast_fp16)[name = tensor<string, []>("lora_out_1071_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_375_cast_fp16 = add(x = pretrained_out_535_cast_fp16, y = lora_out_1071_cast_fp16)[name = tensor<string, []>("obj_375_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_161_cast_fp16 = add(x = inputs_159_cast_fp16, y = obj_375_cast_fp16)[name = tensor<string, []>("inputs_161_cast_fp16")];
            tensor<int32, [1]> var_10777 = const()[name = tensor<string, []>("op_10777"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_161_cast_fp16 = reduce_mean(axes = var_10777, keep_dims = var_10468, x = inputs_161_cast_fp16)[name = tensor<string, []>("channels_mean_161_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_161_cast_fp16 = sub(x = inputs_161_cast_fp16, y = channels_mean_161_cast_fp16)[name = tensor<string, []>("zero_mean_161_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_161_cast_fp16 = mul(x = zero_mean_161_cast_fp16, y = zero_mean_161_cast_fp16)[name = tensor<string, []>("zero_mean_sq_161_cast_fp16")];
            tensor<int32, [1]> var_10781 = const()[name = tensor<string, []>("op_10781"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_10782_cast_fp16 = reduce_mean(axes = var_10781, keep_dims = var_10468, x = zero_mean_sq_161_cast_fp16)[name = tensor<string, []>("op_10782_cast_fp16")];
            tensor<fp16, []> var_10783_to_fp16 = const()[name = tensor<string, []>("op_10783_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_10784_cast_fp16 = add(x = var_10782_cast_fp16, y = var_10783_to_fp16)[name = tensor<string, []>("op_10784_cast_fp16")];
            tensor<fp32, []> denom_161_epsilon_0 = const()[name = tensor<string, []>("denom_161_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_161_cast_fp16 = rsqrt(epsilon = denom_161_epsilon_0, x = var_10784_cast_fp16)[name = tensor<string, []>("denom_161_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_161_cast_fp16 = mul(x = zero_mean_161_cast_fp16, y = denom_161_cast_fp16)[name = tensor<string, []>("out_161_cast_fp16")];
            tensor<fp16, [1280]> input_801_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_801_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(512529984)))];
            tensor<fp16, [1280]> input_801_beta_0_to_fp16 = const()[name = tensor<string, []>("input_801_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(512532608)))];
            tensor<fp16, []> input_801_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_801_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_801_cast_fp16 = batch_norm(beta = input_801_beta_0_to_fp16, epsilon = input_801_epsilon_0_to_fp16, gamma = input_801_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_161_cast_fp16)[name = tensor<string, []>("input_801_cast_fp16")];
            tensor<int32, [2]> var_10798 = const()[name = tensor<string, []>("op_10798"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10800 = const()[name = tensor<string, []>("op_10800"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_537_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_537_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_537_pad_0 = const()[name = tensor<string, []>("pretrained_out_537_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_26_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(512535232))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(515812096))), name = tensor<string, []>("layers_26_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_26_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_26_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(515812224)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_537_cast_fp16 = conv(bias = layers_26_fc1_pretrained_bias_to_fp16, dilations = var_10800, groups = var_10467, pad = pretrained_out_537_pad_0, pad_type = pretrained_out_537_pad_type_0, strides = var_10798, weight = layers_26_fc1_pretrained_weight_to_fp16_palettized, x = input_801_cast_fp16)[name = tensor<string, []>("pretrained_out_537_cast_fp16")];
            tensor<int32, [2]> var_10804 = const()[name = tensor<string, []>("op_10804"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10806 = const()[name = tensor<string, []>("op_10806"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_803_pad_type_0 = const()[name = tensor<string, []>("input_803_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_803_pad_0 = const()[name = tensor<string, []>("input_803_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_26_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_26_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(515822528)))];
            tensor<fp16, [1, 16, 1, 1]> input_803_cast_fp16 = conv(dilations = var_10806, groups = var_10467, pad = input_803_pad_0, pad_type = input_803_pad_type_0, strides = var_10804, weight = layers_26_fc1_loraA_weight_to_fp16, x = input_801_cast_fp16)[name = tensor<string, []>("input_803_cast_fp16")];
            tensor<int32, [2]> var_10810 = const()[name = tensor<string, []>("op_10810"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10812 = const()[name = tensor<string, []>("op_10812"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1073_pad_type_0 = const()[name = tensor<string, []>("lora_out_1073_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1073_pad_0 = const()[name = tensor<string, []>("lora_out_1073_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_1075_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1075_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(515863552)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_1075_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_10812, groups = var_10467, pad = lora_out_1073_pad_0, pad_type = lora_out_1073_pad_type_0, strides = var_10810, weight = lora_out_1075_weight_0_to_fp16, x = input_803_cast_fp16)[name = tensor<string, []>("lora_out_1075_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_805_cast_fp16 = add(x = pretrained_out_537_cast_fp16, y = lora_out_1075_cast_fp16)[name = tensor<string, []>("input_805_cast_fp16")];
            tensor<string, []> input_807_mode_0 = const()[name = tensor<string, []>("input_807_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_807_cast_fp16 = gelu(mode = input_807_mode_0, x = input_805_cast_fp16)[name = tensor<string, []>("input_807_cast_fp16")];
            tensor<int32, [2]> var_10824 = const()[name = tensor<string, []>("op_10824"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10826 = const()[name = tensor<string, []>("op_10826"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_539_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_539_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_539_pad_0 = const()[name = tensor<string, []>("pretrained_out_539_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_26_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(516027456))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(519304320))), name = tensor<string, []>("layers_26_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_26_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_26_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(519304448)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_539_cast_fp16 = conv(bias = layers_26_fc2_pretrained_bias_to_fp16, dilations = var_10826, groups = var_10467, pad = pretrained_out_539_pad_0, pad_type = pretrained_out_539_pad_type_0, strides = var_10824, weight = layers_26_fc2_pretrained_weight_to_fp16_palettized, x = input_807_cast_fp16)[name = tensor<string, []>("pretrained_out_539_cast_fp16")];
            tensor<int32, [2]> var_10830 = const()[name = tensor<string, []>("op_10830"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10832 = const()[name = tensor<string, []>("op_10832"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_809_pad_type_0 = const()[name = tensor<string, []>("input_809_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_809_pad_0 = const()[name = tensor<string, []>("input_809_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_26_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_26_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(519307072)))];
            tensor<fp16, [1, 16, 1, 1]> input_809_cast_fp16 = conv(dilations = var_10832, groups = var_10467, pad = input_809_pad_0, pad_type = input_809_pad_type_0, strides = var_10830, weight = layers_26_fc2_loraA_weight_to_fp16, x = input_807_cast_fp16)[name = tensor<string, []>("input_809_cast_fp16")];
            tensor<int32, [2]> var_10836 = const()[name = tensor<string, []>("op_10836"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10838 = const()[name = tensor<string, []>("op_10838"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1077_pad_type_0 = const()[name = tensor<string, []>("lora_out_1077_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1077_pad_0 = const()[name = tensor<string, []>("lora_out_1077_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1079_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1079_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(519470976)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1079_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_10838, groups = var_10467, pad = lora_out_1077_pad_0, pad_type = lora_out_1077_pad_type_0, strides = var_10836, weight = lora_out_1079_weight_0_to_fp16, x = input_809_cast_fp16)[name = tensor<string, []>("lora_out_1079_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_55_cast_fp16 = add(x = pretrained_out_539_cast_fp16, y = lora_out_1079_cast_fp16)[name = tensor<string, []>("hidden_states_55_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_163_cast_fp16 = add(x = inputs_161_cast_fp16, y = hidden_states_55_cast_fp16)[name = tensor<string, []>("inputs_163_cast_fp16")];
            tensor<int32, []> var_10854 = const()[name = tensor<string, []>("op_10854"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_10861 = const()[name = tensor<string, []>("op_10861"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_10862 = const()[name = tensor<string, []>("op_10862"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_10874 = const()[name = tensor<string, []>("op_10874"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_163_cast_fp16 = reduce_mean(axes = var_10874, keep_dims = var_10862, x = inputs_163_cast_fp16)[name = tensor<string, []>("channels_mean_163_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_163_cast_fp16 = sub(x = inputs_163_cast_fp16, y = channels_mean_163_cast_fp16)[name = tensor<string, []>("zero_mean_163_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_163_cast_fp16 = mul(x = zero_mean_163_cast_fp16, y = zero_mean_163_cast_fp16)[name = tensor<string, []>("zero_mean_sq_163_cast_fp16")];
            tensor<int32, [1]> var_10878 = const()[name = tensor<string, []>("op_10878"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_10879_cast_fp16 = reduce_mean(axes = var_10878, keep_dims = var_10862, x = zero_mean_sq_163_cast_fp16)[name = tensor<string, []>("op_10879_cast_fp16")];
            tensor<fp16, []> var_10880_to_fp16 = const()[name = tensor<string, []>("op_10880_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_10881_cast_fp16 = add(x = var_10879_cast_fp16, y = var_10880_to_fp16)[name = tensor<string, []>("op_10881_cast_fp16")];
            tensor<fp32, []> denom_163_epsilon_0 = const()[name = tensor<string, []>("denom_163_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_163_cast_fp16 = rsqrt(epsilon = denom_163_epsilon_0, x = var_10881_cast_fp16)[name = tensor<string, []>("denom_163_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_163_cast_fp16 = mul(x = zero_mean_163_cast_fp16, y = denom_163_cast_fp16)[name = tensor<string, []>("out_163_cast_fp16")];
            tensor<fp16, [1280]> obj_379_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_379_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(519512000)))];
            tensor<fp16, [1280]> obj_379_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_379_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(519514624)))];
            tensor<fp16, []> obj_379_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_379_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_379_cast_fp16 = batch_norm(beta = obj_379_beta_0_to_fp16, epsilon = obj_379_epsilon_0_to_fp16, gamma = obj_379_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_163_cast_fp16)[name = tensor<string, []>("obj_379_cast_fp16")];
            tensor<int32, [2]> var_10899 = const()[name = tensor<string, []>("op_10899"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10901 = const()[name = tensor<string, []>("op_10901"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_541_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_541_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_541_pad_0 = const()[name = tensor<string, []>("pretrained_out_541_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_27_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(519517248))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(520336512))), name = tensor<string, []>("layers_27_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_27_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_27_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(520336640)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_541_cast_fp16 = conv(bias = layers_27_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_10901, groups = var_10861, pad = pretrained_out_541_pad_0, pad_type = pretrained_out_541_pad_type_0, strides = var_10899, weight = layers_27_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_379_cast_fp16)[name = tensor<string, []>("pretrained_out_541_cast_fp16")];
            tensor<int32, [2]> var_10905 = const()[name = tensor<string, []>("op_10905"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10907 = const()[name = tensor<string, []>("op_10907"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_811_pad_type_0 = const()[name = tensor<string, []>("input_811_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_811_pad_0 = const()[name = tensor<string, []>("input_811_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_27_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_27_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(520339264)))];
            tensor<fp16, [1, 16, 1, 1]> input_811_cast_fp16 = conv(dilations = var_10907, groups = var_10861, pad = input_811_pad_0, pad_type = input_811_pad_type_0, strides = var_10905, weight = layers_27_self_attn_q_proj_loraA_weight_to_fp16, x = obj_379_cast_fp16)[name = tensor<string, []>("input_811_cast_fp16")];
            tensor<int32, [2]> var_10911 = const()[name = tensor<string, []>("op_10911"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10913 = const()[name = tensor<string, []>("op_10913"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1081_pad_type_0 = const()[name = tensor<string, []>("lora_out_1081_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1081_pad_0 = const()[name = tensor<string, []>("lora_out_1081_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1083_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1083_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(520380288)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1083_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_10913, groups = var_10861, pad = lora_out_1081_pad_0, pad_type = lora_out_1081_pad_type_0, strides = var_10911, weight = lora_out_1083_weight_0_to_fp16, x = input_811_cast_fp16)[name = tensor<string, []>("lora_out_1083_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_109_cast_fp16 = add(x = pretrained_out_541_cast_fp16, y = lora_out_1083_cast_fp16)[name = tensor<string, []>("query_109_cast_fp16")];
            tensor<int32, [2]> var_10923 = const()[name = tensor<string, []>("op_10923"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10925 = const()[name = tensor<string, []>("op_10925"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_543_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_543_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_543_pad_0 = const()[name = tensor<string, []>("pretrained_out_543_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_27_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(520421312))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(521240576))), name = tensor<string, []>("layers_27_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_543_cast_fp16 = conv(dilations = var_10925, groups = var_10861, pad = pretrained_out_543_pad_0, pad_type = pretrained_out_543_pad_type_0, strides = var_10923, weight = layers_27_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_379_cast_fp16)[name = tensor<string, []>("pretrained_out_543_cast_fp16")];
            tensor<int32, [2]> var_10929 = const()[name = tensor<string, []>("op_10929"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10931 = const()[name = tensor<string, []>("op_10931"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_813_pad_type_0 = const()[name = tensor<string, []>("input_813_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_813_pad_0 = const()[name = tensor<string, []>("input_813_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_27_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_27_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(521240704)))];
            tensor<fp16, [1, 16, 1, 1]> input_813_cast_fp16 = conv(dilations = var_10931, groups = var_10861, pad = input_813_pad_0, pad_type = input_813_pad_type_0, strides = var_10929, weight = layers_27_self_attn_k_proj_loraA_weight_to_fp16, x = obj_379_cast_fp16)[name = tensor<string, []>("input_813_cast_fp16")];
            tensor<int32, [2]> var_10935 = const()[name = tensor<string, []>("op_10935"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10937 = const()[name = tensor<string, []>("op_10937"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1085_pad_type_0 = const()[name = tensor<string, []>("lora_out_1085_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1085_pad_0 = const()[name = tensor<string, []>("lora_out_1085_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1087_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1087_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(521281728)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1087_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_10937, groups = var_10861, pad = lora_out_1085_pad_0, pad_type = lora_out_1085_pad_type_0, strides = var_10935, weight = lora_out_1087_weight_0_to_fp16, x = input_813_cast_fp16)[name = tensor<string, []>("lora_out_1087_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_55_cast_fp16 = add(x = pretrained_out_543_cast_fp16, y = lora_out_1087_cast_fp16)[name = tensor<string, []>("current_key_55_cast_fp16")];
            tensor<int32, [2]> var_10948 = const()[name = tensor<string, []>("op_10948"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10950 = const()[name = tensor<string, []>("op_10950"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_545_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_545_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_545_pad_0 = const()[name = tensor<string, []>("pretrained_out_545_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_27_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(521322752))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(522142016))), name = tensor<string, []>("layers_27_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_27_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_27_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(522142144)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_545_cast_fp16 = conv(bias = layers_27_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_10950, groups = var_10861, pad = pretrained_out_545_pad_0, pad_type = pretrained_out_545_pad_type_0, strides = var_10948, weight = layers_27_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_379_cast_fp16)[name = tensor<string, []>("pretrained_out_545_cast_fp16")];
            tensor<int32, [2]> var_10954 = const()[name = tensor<string, []>("op_10954"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10956 = const()[name = tensor<string, []>("op_10956"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_815_pad_type_0 = const()[name = tensor<string, []>("input_815_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_815_pad_0 = const()[name = tensor<string, []>("input_815_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_27_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_27_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(522144768)))];
            tensor<fp16, [1, 16, 1, 1]> input_815_cast_fp16 = conv(dilations = var_10956, groups = var_10861, pad = input_815_pad_0, pad_type = input_815_pad_type_0, strides = var_10954, weight = layers_27_self_attn_v_proj_loraA_weight_to_fp16, x = obj_379_cast_fp16)[name = tensor<string, []>("input_815_cast_fp16")];
            tensor<int32, [2]> var_10960 = const()[name = tensor<string, []>("op_10960"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_10962 = const()[name = tensor<string, []>("op_10962"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1089_pad_type_0 = const()[name = tensor<string, []>("lora_out_1089_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1089_pad_0 = const()[name = tensor<string, []>("lora_out_1089_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1091_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1091_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(522185792)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1091_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_10962, groups = var_10861, pad = lora_out_1089_pad_0, pad_type = lora_out_1089_pad_type_0, strides = var_10960, weight = lora_out_1091_weight_0_to_fp16, x = input_815_cast_fp16)[name = tensor<string, []>("lora_out_1091_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_55_cast_fp16 = add(x = pretrained_out_545_cast_fp16, y = lora_out_1091_cast_fp16)[name = tensor<string, []>("current_value_55_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_10972_cast_fp16 = mul(x = current_key_55_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_10972_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_10974_cast_fp16 = mul(x = var_103_cast_fp16_27, y = var_295_cast_fp16)[name = tensor<string, []>("op_10974_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_109_cast_fp16 = add(x = var_10972_cast_fp16, y = var_10974_cast_fp16)[name = tensor<string, []>("key_109_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_10976_cast_fp16 = mul(x = current_value_55_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_10976_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_10978_cast_fp16 = mul(x = var_138_cast_fp16_27, y = var_295_cast_fp16)[name = tensor<string, []>("op_10978_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_109_cast_fp16 = add(x = var_10976_cast_fp16, y = var_10978_cast_fp16)[name = tensor<string, []>("value_109_cast_fp16")];
            tensor<int32, [4]> var_10981 = const()[name = tensor<string, []>("op_10981"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_10982_cast_fp16 = reshape(shape = var_10981, x = query_109_cast_fp16)[name = tensor<string, []>("op_10982_cast_fp16")];
            tensor<fp16, []> var_10983_to_fp16 = const()[name = tensor<string, []>("op_10983_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_10984_cast_fp16 = mul(x = var_10982_cast_fp16, y = var_10983_to_fp16)[name = tensor<string, []>("op_10984_cast_fp16")];
            tensor<int32, [4]> var_10985 = const()[name = tensor<string, []>("op_10985"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_10986_cast_fp16 = reshape(shape = var_10985, x = key_109_cast_fp16)[name = tensor<string, []>("op_10986_cast_fp16")];
            tensor<bool, []> mh_w_163_transpose_x_0 = const()[name = tensor<string, []>("mh_w_163_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_163_transpose_y_0 = const()[name = tensor<string, []>("mh_w_163_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_163_cast_fp16 = matmul(transpose_x = mh_w_163_transpose_x_0, transpose_y = mh_w_163_transpose_y_0, x = var_10984_cast_fp16, y = var_10986_cast_fp16)[name = tensor<string, []>("mh_w_163_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_165_cast_fp16 = add(x = mh_w_163_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_165_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_10994_cast_fp16 = softmax(axis = var_10854, x = mh_w_165_cast_fp16)[name = tensor<string, []>("op_10994_cast_fp16")];
            tensor<int32, [4]> var_10995 = const()[name = tensor<string, []>("op_10995"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_10996_cast_fp16 = reshape(shape = var_10995, x = value_109_cast_fp16)[name = tensor<string, []>("op_10996_cast_fp16")];
            tensor<bool, []> attn_109_transpose_x_0 = const()[name = tensor<string, []>("attn_109_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_109_transpose_y_0 = const()[name = tensor<string, []>("attn_109_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_109_cast_fp16 = matmul(transpose_x = attn_109_transpose_x_0, transpose_y = attn_109_transpose_y_0, x = var_10996_cast_fp16, y = var_10994_cast_fp16)[name = tensor<string, []>("attn_109_cast_fp16")];
            tensor<int32, [4]> var_10999 = const()[name = tensor<string, []>("op_10999"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_817_cast_fp16 = reshape(shape = var_10999, x = attn_109_cast_fp16)[name = tensor<string, []>("input_817_cast_fp16")];
            tensor<int32, [2]> var_11006 = const()[name = tensor<string, []>("op_11006"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11008 = const()[name = tensor<string, []>("op_11008"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_547_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_547_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_547_pad_0 = const()[name = tensor<string, []>("pretrained_out_547_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_27_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(522226816))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(523046080))), name = tensor<string, []>("layers_27_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_27_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_27_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(523046208)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_547_cast_fp16 = conv(bias = layers_27_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_11008, groups = var_10861, pad = pretrained_out_547_pad_0, pad_type = pretrained_out_547_pad_type_0, strides = var_11006, weight = layers_27_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_817_cast_fp16)[name = tensor<string, []>("pretrained_out_547_cast_fp16")];
            tensor<int32, [2]> var_11012 = const()[name = tensor<string, []>("op_11012"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11014 = const()[name = tensor<string, []>("op_11014"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_819_pad_type_0 = const()[name = tensor<string, []>("input_819_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_819_pad_0 = const()[name = tensor<string, []>("input_819_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_27_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_27_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(523048832)))];
            tensor<fp16, [1, 16, 1, 1]> input_819_cast_fp16 = conv(dilations = var_11014, groups = var_10861, pad = input_819_pad_0, pad_type = input_819_pad_type_0, strides = var_11012, weight = layers_27_self_attn_o_proj_loraA_weight_to_fp16, x = input_817_cast_fp16)[name = tensor<string, []>("input_819_cast_fp16")];
            tensor<int32, [2]> var_11018 = const()[name = tensor<string, []>("op_11018"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11020 = const()[name = tensor<string, []>("op_11020"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1093_pad_type_0 = const()[name = tensor<string, []>("lora_out_1093_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1093_pad_0 = const()[name = tensor<string, []>("lora_out_1093_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1095_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1095_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(523089856)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1095_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_11020, groups = var_10861, pad = lora_out_1093_pad_0, pad_type = lora_out_1093_pad_type_0, strides = var_11018, weight = lora_out_1095_weight_0_to_fp16, x = input_819_cast_fp16)[name = tensor<string, []>("lora_out_1095_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_385_cast_fp16 = add(x = pretrained_out_547_cast_fp16, y = lora_out_1095_cast_fp16)[name = tensor<string, []>("obj_385_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_165_cast_fp16 = add(x = inputs_163_cast_fp16, y = obj_385_cast_fp16)[name = tensor<string, []>("inputs_165_cast_fp16")];
            tensor<int32, [1]> var_11033 = const()[name = tensor<string, []>("op_11033"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_165_cast_fp16 = reduce_mean(axes = var_11033, keep_dims = var_10862, x = inputs_165_cast_fp16)[name = tensor<string, []>("channels_mean_165_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_165_cast_fp16 = sub(x = inputs_165_cast_fp16, y = channels_mean_165_cast_fp16)[name = tensor<string, []>("zero_mean_165_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_165_cast_fp16 = mul(x = zero_mean_165_cast_fp16, y = zero_mean_165_cast_fp16)[name = tensor<string, []>("zero_mean_sq_165_cast_fp16")];
            tensor<int32, [1]> var_11037 = const()[name = tensor<string, []>("op_11037"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_11038_cast_fp16 = reduce_mean(axes = var_11037, keep_dims = var_10862, x = zero_mean_sq_165_cast_fp16)[name = tensor<string, []>("op_11038_cast_fp16")];
            tensor<fp16, []> var_11039_to_fp16 = const()[name = tensor<string, []>("op_11039_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_11040_cast_fp16 = add(x = var_11038_cast_fp16, y = var_11039_to_fp16)[name = tensor<string, []>("op_11040_cast_fp16")];
            tensor<fp32, []> denom_165_epsilon_0 = const()[name = tensor<string, []>("denom_165_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_165_cast_fp16 = rsqrt(epsilon = denom_165_epsilon_0, x = var_11040_cast_fp16)[name = tensor<string, []>("denom_165_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_165_cast_fp16 = mul(x = zero_mean_165_cast_fp16, y = denom_165_cast_fp16)[name = tensor<string, []>("out_165_cast_fp16")];
            tensor<fp16, [1280]> obj_387_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_387_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(523130880)))];
            tensor<fp16, [1280]> obj_387_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_387_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(523133504)))];
            tensor<fp16, []> obj_387_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_387_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_387_cast_fp16 = batch_norm(beta = obj_387_beta_0_to_fp16, epsilon = obj_387_epsilon_0_to_fp16, gamma = obj_387_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_165_cast_fp16)[name = tensor<string, []>("obj_387_cast_fp16")];
            tensor<int32, [2]> var_11058 = const()[name = tensor<string, []>("op_11058"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11060 = const()[name = tensor<string, []>("op_11060"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_549_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_549_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_549_pad_0 = const()[name = tensor<string, []>("pretrained_out_549_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_27_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(523136128))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(523955392))), name = tensor<string, []>("layers_27_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_27_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_27_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(523955520)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_549_cast_fp16 = conv(bias = layers_27_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_11060, groups = var_10861, pad = pretrained_out_549_pad_0, pad_type = pretrained_out_549_pad_type_0, strides = var_11058, weight = layers_27_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_387_cast_fp16)[name = tensor<string, []>("pretrained_out_549_cast_fp16")];
            tensor<int32, [2]> var_11064 = const()[name = tensor<string, []>("op_11064"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11066 = const()[name = tensor<string, []>("op_11066"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_821_pad_type_0 = const()[name = tensor<string, []>("input_821_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_821_pad_0 = const()[name = tensor<string, []>("input_821_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_27_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_27_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(523958144)))];
            tensor<fp16, [1, 16, 1, 1]> input_821_cast_fp16 = conv(dilations = var_11066, groups = var_10861, pad = input_821_pad_0, pad_type = input_821_pad_type_0, strides = var_11064, weight = layers_27_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_387_cast_fp16)[name = tensor<string, []>("input_821_cast_fp16")];
            tensor<int32, [2]> var_11070 = const()[name = tensor<string, []>("op_11070"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11072 = const()[name = tensor<string, []>("op_11072"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1097_pad_type_0 = const()[name = tensor<string, []>("lora_out_1097_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1097_pad_0 = const()[name = tensor<string, []>("lora_out_1097_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1099_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1099_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(523999168)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1099_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_11072, groups = var_10861, pad = lora_out_1097_pad_0, pad_type = lora_out_1097_pad_type_0, strides = var_11070, weight = lora_out_1099_weight_0_to_fp16, x = input_821_cast_fp16)[name = tensor<string, []>("lora_out_1099_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_111_cast_fp16 = add(x = pretrained_out_549_cast_fp16, y = lora_out_1099_cast_fp16)[name = tensor<string, []>("query_111_cast_fp16")];
            tensor<int32, [2]> var_11082 = const()[name = tensor<string, []>("op_11082"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11084 = const()[name = tensor<string, []>("op_11084"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_551_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_551_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_551_pad_0 = const()[name = tensor<string, []>("pretrained_out_551_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_27_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(524040192))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(524859456))), name = tensor<string, []>("layers_27_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_551_cast_fp16 = conv(dilations = var_11084, groups = var_10861, pad = pretrained_out_551_pad_0, pad_type = pretrained_out_551_pad_type_0, strides = var_11082, weight = layers_27_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_551_cast_fp16")];
            tensor<int32, [2]> var_11088 = const()[name = tensor<string, []>("op_11088"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11090 = const()[name = tensor<string, []>("op_11090"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_823_pad_type_0 = const()[name = tensor<string, []>("input_823_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_823_pad_0 = const()[name = tensor<string, []>("input_823_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_27_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_27_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(524859584)))];
            tensor<fp16, [1, 16, 1, 1500]> input_823_cast_fp16 = conv(dilations = var_11090, groups = var_10861, pad = input_823_pad_0, pad_type = input_823_pad_type_0, strides = var_11088, weight = layers_27_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_823_cast_fp16")];
            tensor<int32, [2]> var_11094 = const()[name = tensor<string, []>("op_11094"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11096 = const()[name = tensor<string, []>("op_11096"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1101_pad_type_0 = const()[name = tensor<string, []>("lora_out_1101_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1101_pad_0 = const()[name = tensor<string, []>("lora_out_1101_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1103_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1103_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(524900608)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_1103_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_11096, groups = var_10861, pad = lora_out_1101_pad_0, pad_type = lora_out_1101_pad_type_0, strides = var_11094, weight = lora_out_1103_weight_0_to_fp16, x = input_823_cast_fp16)[name = tensor<string, []>("lora_out_1103_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_111_cast_fp16 = add(x = pretrained_out_551_cast_fp16, y = lora_out_1103_cast_fp16)[name = tensor<string, []>("key_111_cast_fp16")];
            tensor<int32, [2]> var_11107 = const()[name = tensor<string, []>("op_11107"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11109 = const()[name = tensor<string, []>("op_11109"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_553_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_553_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_553_pad_0 = const()[name = tensor<string, []>("pretrained_out_553_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_27_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(524941632))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(525760896))), name = tensor<string, []>("layers_27_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_27_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_27_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(525761024)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_553_cast_fp16 = conv(bias = layers_27_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_11109, groups = var_10861, pad = pretrained_out_553_pad_0, pad_type = pretrained_out_553_pad_type_0, strides = var_11107, weight = layers_27_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_553_cast_fp16")];
            tensor<int32, [2]> var_11113 = const()[name = tensor<string, []>("op_11113"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11115 = const()[name = tensor<string, []>("op_11115"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_825_pad_type_0 = const()[name = tensor<string, []>("input_825_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_825_pad_0 = const()[name = tensor<string, []>("input_825_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_27_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_27_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(525763648)))];
            tensor<fp16, [1, 16, 1, 1500]> input_825_cast_fp16 = conv(dilations = var_11115, groups = var_10861, pad = input_825_pad_0, pad_type = input_825_pad_type_0, strides = var_11113, weight = layers_27_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_825_cast_fp16")];
            tensor<int32, [2]> var_11119 = const()[name = tensor<string, []>("op_11119"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11121 = const()[name = tensor<string, []>("op_11121"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1105_pad_type_0 = const()[name = tensor<string, []>("lora_out_1105_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1105_pad_0 = const()[name = tensor<string, []>("lora_out_1105_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1107_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1107_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(525804672)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_1107_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_11121, groups = var_10861, pad = lora_out_1105_pad_0, pad_type = lora_out_1105_pad_type_0, strides = var_11119, weight = lora_out_1107_weight_0_to_fp16, x = input_825_cast_fp16)[name = tensor<string, []>("lora_out_1107_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_111_cast_fp16 = add(x = pretrained_out_553_cast_fp16, y = lora_out_1107_cast_fp16)[name = tensor<string, []>("value_111_cast_fp16")];
            tensor<int32, [4]> var_11128 = const()[name = tensor<string, []>("op_11128"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_11129_cast_fp16 = reshape(shape = var_11128, x = query_111_cast_fp16)[name = tensor<string, []>("op_11129_cast_fp16")];
            tensor<fp16, []> var_11130_to_fp16 = const()[name = tensor<string, []>("op_11130_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_11131_cast_fp16 = mul(x = var_11129_cast_fp16, y = var_11130_to_fp16)[name = tensor<string, []>("op_11131_cast_fp16")];
            tensor<int32, [4]> var_11132 = const()[name = tensor<string, []>("op_11132"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_11133_cast_fp16 = reshape(shape = var_11132, x = key_111_cast_fp16)[name = tensor<string, []>("op_11133_cast_fp16")];
            tensor<bool, []> mh_w_167_transpose_x_0 = const()[name = tensor<string, []>("mh_w_167_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_167_transpose_y_0 = const()[name = tensor<string, []>("mh_w_167_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_167_cast_fp16 = matmul(transpose_x = mh_w_167_transpose_x_0, transpose_y = mh_w_167_transpose_y_0, x = var_11131_cast_fp16, y = var_11133_cast_fp16)[name = tensor<string, []>("mh_w_167_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_391_cast_fp16 = softmax(axis = var_10854, x = mh_w_167_cast_fp16)[name = tensor<string, []>("obj_391_cast_fp16")];
            tensor<int32, [4]> var_11137 = const()[name = tensor<string, []>("op_11137"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_11138_cast_fp16 = reshape(shape = var_11137, x = value_111_cast_fp16)[name = tensor<string, []>("op_11138_cast_fp16")];
            tensor<bool, []> attn_111_transpose_x_0 = const()[name = tensor<string, []>("attn_111_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_111_transpose_y_0 = const()[name = tensor<string, []>("attn_111_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_111_cast_fp16 = matmul(transpose_x = attn_111_transpose_x_0, transpose_y = attn_111_transpose_y_0, x = var_11138_cast_fp16, y = obj_391_cast_fp16)[name = tensor<string, []>("attn_111_cast_fp16")];
            tensor<int32, [4]> var_11141 = const()[name = tensor<string, []>("op_11141"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_827_cast_fp16 = reshape(shape = var_11141, x = attn_111_cast_fp16)[name = tensor<string, []>("input_827_cast_fp16")];
            tensor<int32, [2]> var_11148 = const()[name = tensor<string, []>("op_11148"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11150 = const()[name = tensor<string, []>("op_11150"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_555_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_555_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_555_pad_0 = const()[name = tensor<string, []>("pretrained_out_555_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_27_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(525845696))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(526664960))), name = tensor<string, []>("layers_27_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_27_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_27_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(526665088)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_555_cast_fp16 = conv(bias = layers_27_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_11150, groups = var_10861, pad = pretrained_out_555_pad_0, pad_type = pretrained_out_555_pad_type_0, strides = var_11148, weight = layers_27_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_827_cast_fp16)[name = tensor<string, []>("pretrained_out_555_cast_fp16")];
            tensor<int32, [2]> var_11154 = const()[name = tensor<string, []>("op_11154"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11156 = const()[name = tensor<string, []>("op_11156"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_829_pad_type_0 = const()[name = tensor<string, []>("input_829_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_829_pad_0 = const()[name = tensor<string, []>("input_829_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_27_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_27_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(526667712)))];
            tensor<fp16, [1, 16, 1, 1]> input_829_cast_fp16 = conv(dilations = var_11156, groups = var_10861, pad = input_829_pad_0, pad_type = input_829_pad_type_0, strides = var_11154, weight = layers_27_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_827_cast_fp16)[name = tensor<string, []>("input_829_cast_fp16")];
            tensor<int32, [2]> var_11160 = const()[name = tensor<string, []>("op_11160"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11162 = const()[name = tensor<string, []>("op_11162"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1109_pad_type_0 = const()[name = tensor<string, []>("lora_out_1109_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1109_pad_0 = const()[name = tensor<string, []>("lora_out_1109_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1111_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1111_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(526708736)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1111_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_11162, groups = var_10861, pad = lora_out_1109_pad_0, pad_type = lora_out_1109_pad_type_0, strides = var_11160, weight = lora_out_1111_weight_0_to_fp16, x = input_829_cast_fp16)[name = tensor<string, []>("lora_out_1111_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_389_cast_fp16 = add(x = pretrained_out_555_cast_fp16, y = lora_out_1111_cast_fp16)[name = tensor<string, []>("obj_389_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_167_cast_fp16 = add(x = inputs_165_cast_fp16, y = obj_389_cast_fp16)[name = tensor<string, []>("inputs_167_cast_fp16")];
            tensor<int32, [1]> var_11171 = const()[name = tensor<string, []>("op_11171"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_167_cast_fp16 = reduce_mean(axes = var_11171, keep_dims = var_10862, x = inputs_167_cast_fp16)[name = tensor<string, []>("channels_mean_167_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_167_cast_fp16 = sub(x = inputs_167_cast_fp16, y = channels_mean_167_cast_fp16)[name = tensor<string, []>("zero_mean_167_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_167_cast_fp16 = mul(x = zero_mean_167_cast_fp16, y = zero_mean_167_cast_fp16)[name = tensor<string, []>("zero_mean_sq_167_cast_fp16")];
            tensor<int32, [1]> var_11175 = const()[name = tensor<string, []>("op_11175"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_11176_cast_fp16 = reduce_mean(axes = var_11175, keep_dims = var_10862, x = zero_mean_sq_167_cast_fp16)[name = tensor<string, []>("op_11176_cast_fp16")];
            tensor<fp16, []> var_11177_to_fp16 = const()[name = tensor<string, []>("op_11177_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_11178_cast_fp16 = add(x = var_11176_cast_fp16, y = var_11177_to_fp16)[name = tensor<string, []>("op_11178_cast_fp16")];
            tensor<fp32, []> denom_167_epsilon_0 = const()[name = tensor<string, []>("denom_167_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_167_cast_fp16 = rsqrt(epsilon = denom_167_epsilon_0, x = var_11178_cast_fp16)[name = tensor<string, []>("denom_167_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_167_cast_fp16 = mul(x = zero_mean_167_cast_fp16, y = denom_167_cast_fp16)[name = tensor<string, []>("out_167_cast_fp16")];
            tensor<fp16, [1280]> input_831_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_831_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(526749760)))];
            tensor<fp16, [1280]> input_831_beta_0_to_fp16 = const()[name = tensor<string, []>("input_831_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(526752384)))];
            tensor<fp16, []> input_831_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_831_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_831_cast_fp16 = batch_norm(beta = input_831_beta_0_to_fp16, epsilon = input_831_epsilon_0_to_fp16, gamma = input_831_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_167_cast_fp16)[name = tensor<string, []>("input_831_cast_fp16")];
            tensor<int32, [2]> var_11192 = const()[name = tensor<string, []>("op_11192"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11194 = const()[name = tensor<string, []>("op_11194"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_557_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_557_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_557_pad_0 = const()[name = tensor<string, []>("pretrained_out_557_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_27_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(526755008))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(530031872))), name = tensor<string, []>("layers_27_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_27_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_27_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(530032000)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_557_cast_fp16 = conv(bias = layers_27_fc1_pretrained_bias_to_fp16, dilations = var_11194, groups = var_10861, pad = pretrained_out_557_pad_0, pad_type = pretrained_out_557_pad_type_0, strides = var_11192, weight = layers_27_fc1_pretrained_weight_to_fp16_palettized, x = input_831_cast_fp16)[name = tensor<string, []>("pretrained_out_557_cast_fp16")];
            tensor<int32, [2]> var_11198 = const()[name = tensor<string, []>("op_11198"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11200 = const()[name = tensor<string, []>("op_11200"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_833_pad_type_0 = const()[name = tensor<string, []>("input_833_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_833_pad_0 = const()[name = tensor<string, []>("input_833_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_27_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_27_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(530042304)))];
            tensor<fp16, [1, 16, 1, 1]> input_833_cast_fp16 = conv(dilations = var_11200, groups = var_10861, pad = input_833_pad_0, pad_type = input_833_pad_type_0, strides = var_11198, weight = layers_27_fc1_loraA_weight_to_fp16, x = input_831_cast_fp16)[name = tensor<string, []>("input_833_cast_fp16")];
            tensor<int32, [2]> var_11204 = const()[name = tensor<string, []>("op_11204"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11206 = const()[name = tensor<string, []>("op_11206"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1113_pad_type_0 = const()[name = tensor<string, []>("lora_out_1113_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1113_pad_0 = const()[name = tensor<string, []>("lora_out_1113_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_1115_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1115_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(530083328)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_1115_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_11206, groups = var_10861, pad = lora_out_1113_pad_0, pad_type = lora_out_1113_pad_type_0, strides = var_11204, weight = lora_out_1115_weight_0_to_fp16, x = input_833_cast_fp16)[name = tensor<string, []>("lora_out_1115_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_835_cast_fp16 = add(x = pretrained_out_557_cast_fp16, y = lora_out_1115_cast_fp16)[name = tensor<string, []>("input_835_cast_fp16")];
            tensor<string, []> input_837_mode_0 = const()[name = tensor<string, []>("input_837_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_837_cast_fp16 = gelu(mode = input_837_mode_0, x = input_835_cast_fp16)[name = tensor<string, []>("input_837_cast_fp16")];
            tensor<int32, [2]> var_11218 = const()[name = tensor<string, []>("op_11218"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11220 = const()[name = tensor<string, []>("op_11220"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_559_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_559_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_559_pad_0 = const()[name = tensor<string, []>("pretrained_out_559_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_27_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(530247232))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(533524096))), name = tensor<string, []>("layers_27_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_27_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_27_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(533524224)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_559_cast_fp16 = conv(bias = layers_27_fc2_pretrained_bias_to_fp16, dilations = var_11220, groups = var_10861, pad = pretrained_out_559_pad_0, pad_type = pretrained_out_559_pad_type_0, strides = var_11218, weight = layers_27_fc2_pretrained_weight_to_fp16_palettized, x = input_837_cast_fp16)[name = tensor<string, []>("pretrained_out_559_cast_fp16")];
            tensor<int32, [2]> var_11224 = const()[name = tensor<string, []>("op_11224"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11226 = const()[name = tensor<string, []>("op_11226"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_839_pad_type_0 = const()[name = tensor<string, []>("input_839_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_839_pad_0 = const()[name = tensor<string, []>("input_839_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_27_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_27_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(533526848)))];
            tensor<fp16, [1, 16, 1, 1]> input_839_cast_fp16 = conv(dilations = var_11226, groups = var_10861, pad = input_839_pad_0, pad_type = input_839_pad_type_0, strides = var_11224, weight = layers_27_fc2_loraA_weight_to_fp16, x = input_837_cast_fp16)[name = tensor<string, []>("input_839_cast_fp16")];
            tensor<int32, [2]> var_11230 = const()[name = tensor<string, []>("op_11230"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11232 = const()[name = tensor<string, []>("op_11232"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1117_pad_type_0 = const()[name = tensor<string, []>("lora_out_1117_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1117_pad_0 = const()[name = tensor<string, []>("lora_out_1117_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1119_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1119_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(533690752)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1119_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_11232, groups = var_10861, pad = lora_out_1117_pad_0, pad_type = lora_out_1117_pad_type_0, strides = var_11230, weight = lora_out_1119_weight_0_to_fp16, x = input_839_cast_fp16)[name = tensor<string, []>("lora_out_1119_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_57_cast_fp16 = add(x = pretrained_out_559_cast_fp16, y = lora_out_1119_cast_fp16)[name = tensor<string, []>("hidden_states_57_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_169_cast_fp16 = add(x = inputs_167_cast_fp16, y = hidden_states_57_cast_fp16)[name = tensor<string, []>("inputs_169_cast_fp16")];
            tensor<int32, []> var_11248 = const()[name = tensor<string, []>("op_11248"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_11255 = const()[name = tensor<string, []>("op_11255"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_11256 = const()[name = tensor<string, []>("op_11256"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_11268 = const()[name = tensor<string, []>("op_11268"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_169_cast_fp16 = reduce_mean(axes = var_11268, keep_dims = var_11256, x = inputs_169_cast_fp16)[name = tensor<string, []>("channels_mean_169_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_169_cast_fp16 = sub(x = inputs_169_cast_fp16, y = channels_mean_169_cast_fp16)[name = tensor<string, []>("zero_mean_169_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_169_cast_fp16 = mul(x = zero_mean_169_cast_fp16, y = zero_mean_169_cast_fp16)[name = tensor<string, []>("zero_mean_sq_169_cast_fp16")];
            tensor<int32, [1]> var_11272 = const()[name = tensor<string, []>("op_11272"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_11273_cast_fp16 = reduce_mean(axes = var_11272, keep_dims = var_11256, x = zero_mean_sq_169_cast_fp16)[name = tensor<string, []>("op_11273_cast_fp16")];
            tensor<fp16, []> var_11274_to_fp16 = const()[name = tensor<string, []>("op_11274_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_11275_cast_fp16 = add(x = var_11273_cast_fp16, y = var_11274_to_fp16)[name = tensor<string, []>("op_11275_cast_fp16")];
            tensor<fp32, []> denom_169_epsilon_0 = const()[name = tensor<string, []>("denom_169_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_169_cast_fp16 = rsqrt(epsilon = denom_169_epsilon_0, x = var_11275_cast_fp16)[name = tensor<string, []>("denom_169_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_169_cast_fp16 = mul(x = zero_mean_169_cast_fp16, y = denom_169_cast_fp16)[name = tensor<string, []>("out_169_cast_fp16")];
            tensor<fp16, [1280]> obj_393_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_393_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(533731776)))];
            tensor<fp16, [1280]> obj_393_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_393_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(533734400)))];
            tensor<fp16, []> obj_393_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_393_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_393_cast_fp16 = batch_norm(beta = obj_393_beta_0_to_fp16, epsilon = obj_393_epsilon_0_to_fp16, gamma = obj_393_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_169_cast_fp16)[name = tensor<string, []>("obj_393_cast_fp16")];
            tensor<int32, [2]> var_11293 = const()[name = tensor<string, []>("op_11293"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11295 = const()[name = tensor<string, []>("op_11295"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_561_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_561_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_561_pad_0 = const()[name = tensor<string, []>("pretrained_out_561_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_28_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(533737024))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(534556288))), name = tensor<string, []>("layers_28_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_28_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_28_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(534556416)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_561_cast_fp16 = conv(bias = layers_28_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_11295, groups = var_11255, pad = pretrained_out_561_pad_0, pad_type = pretrained_out_561_pad_type_0, strides = var_11293, weight = layers_28_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_393_cast_fp16)[name = tensor<string, []>("pretrained_out_561_cast_fp16")];
            tensor<int32, [2]> var_11299 = const()[name = tensor<string, []>("op_11299"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11301 = const()[name = tensor<string, []>("op_11301"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_841_pad_type_0 = const()[name = tensor<string, []>("input_841_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_841_pad_0 = const()[name = tensor<string, []>("input_841_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_28_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_28_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(534559040)))];
            tensor<fp16, [1, 16, 1, 1]> input_841_cast_fp16 = conv(dilations = var_11301, groups = var_11255, pad = input_841_pad_0, pad_type = input_841_pad_type_0, strides = var_11299, weight = layers_28_self_attn_q_proj_loraA_weight_to_fp16, x = obj_393_cast_fp16)[name = tensor<string, []>("input_841_cast_fp16")];
            tensor<int32, [2]> var_11305 = const()[name = tensor<string, []>("op_11305"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11307 = const()[name = tensor<string, []>("op_11307"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1121_pad_type_0 = const()[name = tensor<string, []>("lora_out_1121_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1121_pad_0 = const()[name = tensor<string, []>("lora_out_1121_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1123_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1123_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(534600064)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1123_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_11307, groups = var_11255, pad = lora_out_1121_pad_0, pad_type = lora_out_1121_pad_type_0, strides = var_11305, weight = lora_out_1123_weight_0_to_fp16, x = input_841_cast_fp16)[name = tensor<string, []>("lora_out_1123_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_113_cast_fp16 = add(x = pretrained_out_561_cast_fp16, y = lora_out_1123_cast_fp16)[name = tensor<string, []>("query_113_cast_fp16")];
            tensor<int32, [2]> var_11317 = const()[name = tensor<string, []>("op_11317"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11319 = const()[name = tensor<string, []>("op_11319"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_563_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_563_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_563_pad_0 = const()[name = tensor<string, []>("pretrained_out_563_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_28_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(534641088))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(535460352))), name = tensor<string, []>("layers_28_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_563_cast_fp16 = conv(dilations = var_11319, groups = var_11255, pad = pretrained_out_563_pad_0, pad_type = pretrained_out_563_pad_type_0, strides = var_11317, weight = layers_28_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_393_cast_fp16)[name = tensor<string, []>("pretrained_out_563_cast_fp16")];
            tensor<int32, [2]> var_11323 = const()[name = tensor<string, []>("op_11323"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11325 = const()[name = tensor<string, []>("op_11325"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_843_pad_type_0 = const()[name = tensor<string, []>("input_843_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_843_pad_0 = const()[name = tensor<string, []>("input_843_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_28_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_28_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(535460480)))];
            tensor<fp16, [1, 16, 1, 1]> input_843_cast_fp16 = conv(dilations = var_11325, groups = var_11255, pad = input_843_pad_0, pad_type = input_843_pad_type_0, strides = var_11323, weight = layers_28_self_attn_k_proj_loraA_weight_to_fp16, x = obj_393_cast_fp16)[name = tensor<string, []>("input_843_cast_fp16")];
            tensor<int32, [2]> var_11329 = const()[name = tensor<string, []>("op_11329"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11331 = const()[name = tensor<string, []>("op_11331"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1125_pad_type_0 = const()[name = tensor<string, []>("lora_out_1125_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1125_pad_0 = const()[name = tensor<string, []>("lora_out_1125_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1127_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1127_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(535501504)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1127_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_11331, groups = var_11255, pad = lora_out_1125_pad_0, pad_type = lora_out_1125_pad_type_0, strides = var_11329, weight = lora_out_1127_weight_0_to_fp16, x = input_843_cast_fp16)[name = tensor<string, []>("lora_out_1127_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_57_cast_fp16 = add(x = pretrained_out_563_cast_fp16, y = lora_out_1127_cast_fp16)[name = tensor<string, []>("current_key_57_cast_fp16")];
            tensor<int32, [2]> var_11342 = const()[name = tensor<string, []>("op_11342"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11344 = const()[name = tensor<string, []>("op_11344"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_565_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_565_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_565_pad_0 = const()[name = tensor<string, []>("pretrained_out_565_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_28_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(535542528))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(536361792))), name = tensor<string, []>("layers_28_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_28_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_28_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(536361920)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_565_cast_fp16 = conv(bias = layers_28_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_11344, groups = var_11255, pad = pretrained_out_565_pad_0, pad_type = pretrained_out_565_pad_type_0, strides = var_11342, weight = layers_28_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_393_cast_fp16)[name = tensor<string, []>("pretrained_out_565_cast_fp16")];
            tensor<int32, [2]> var_11348 = const()[name = tensor<string, []>("op_11348"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11350 = const()[name = tensor<string, []>("op_11350"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_845_pad_type_0 = const()[name = tensor<string, []>("input_845_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_845_pad_0 = const()[name = tensor<string, []>("input_845_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_28_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_28_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(536364544)))];
            tensor<fp16, [1, 16, 1, 1]> input_845_cast_fp16 = conv(dilations = var_11350, groups = var_11255, pad = input_845_pad_0, pad_type = input_845_pad_type_0, strides = var_11348, weight = layers_28_self_attn_v_proj_loraA_weight_to_fp16, x = obj_393_cast_fp16)[name = tensor<string, []>("input_845_cast_fp16")];
            tensor<int32, [2]> var_11354 = const()[name = tensor<string, []>("op_11354"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11356 = const()[name = tensor<string, []>("op_11356"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1129_pad_type_0 = const()[name = tensor<string, []>("lora_out_1129_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1129_pad_0 = const()[name = tensor<string, []>("lora_out_1129_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1131_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1131_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(536405568)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1131_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_11356, groups = var_11255, pad = lora_out_1129_pad_0, pad_type = lora_out_1129_pad_type_0, strides = var_11354, weight = lora_out_1131_weight_0_to_fp16, x = input_845_cast_fp16)[name = tensor<string, []>("lora_out_1131_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_57_cast_fp16 = add(x = pretrained_out_565_cast_fp16, y = lora_out_1131_cast_fp16)[name = tensor<string, []>("current_value_57_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_11366_cast_fp16 = mul(x = current_key_57_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_11366_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_11368_cast_fp16 = mul(x = var_103_cast_fp16_28, y = var_295_cast_fp16)[name = tensor<string, []>("op_11368_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_113_cast_fp16 = add(x = var_11366_cast_fp16, y = var_11368_cast_fp16)[name = tensor<string, []>("key_113_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_11370_cast_fp16 = mul(x = current_value_57_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_11370_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_11372_cast_fp16 = mul(x = var_138_cast_fp16_28, y = var_295_cast_fp16)[name = tensor<string, []>("op_11372_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_113_cast_fp16 = add(x = var_11370_cast_fp16, y = var_11372_cast_fp16)[name = tensor<string, []>("value_113_cast_fp16")];
            tensor<int32, [4]> var_11375 = const()[name = tensor<string, []>("op_11375"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_11376_cast_fp16 = reshape(shape = var_11375, x = query_113_cast_fp16)[name = tensor<string, []>("op_11376_cast_fp16")];
            tensor<fp16, []> var_11377_to_fp16 = const()[name = tensor<string, []>("op_11377_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_11378_cast_fp16 = mul(x = var_11376_cast_fp16, y = var_11377_to_fp16)[name = tensor<string, []>("op_11378_cast_fp16")];
            tensor<int32, [4]> var_11379 = const()[name = tensor<string, []>("op_11379"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_11380_cast_fp16 = reshape(shape = var_11379, x = key_113_cast_fp16)[name = tensor<string, []>("op_11380_cast_fp16")];
            tensor<bool, []> mh_w_169_transpose_x_0 = const()[name = tensor<string, []>("mh_w_169_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_169_transpose_y_0 = const()[name = tensor<string, []>("mh_w_169_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_169_cast_fp16 = matmul(transpose_x = mh_w_169_transpose_x_0, transpose_y = mh_w_169_transpose_y_0, x = var_11378_cast_fp16, y = var_11380_cast_fp16)[name = tensor<string, []>("mh_w_169_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_171_cast_fp16 = add(x = mh_w_169_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_171_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_11388_cast_fp16 = softmax(axis = var_11248, x = mh_w_171_cast_fp16)[name = tensor<string, []>("op_11388_cast_fp16")];
            tensor<int32, [4]> var_11389 = const()[name = tensor<string, []>("op_11389"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_11390_cast_fp16 = reshape(shape = var_11389, x = value_113_cast_fp16)[name = tensor<string, []>("op_11390_cast_fp16")];
            tensor<bool, []> attn_113_transpose_x_0 = const()[name = tensor<string, []>("attn_113_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_113_transpose_y_0 = const()[name = tensor<string, []>("attn_113_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_113_cast_fp16 = matmul(transpose_x = attn_113_transpose_x_0, transpose_y = attn_113_transpose_y_0, x = var_11390_cast_fp16, y = var_11388_cast_fp16)[name = tensor<string, []>("attn_113_cast_fp16")];
            tensor<int32, [4]> var_11393 = const()[name = tensor<string, []>("op_11393"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_847_cast_fp16 = reshape(shape = var_11393, x = attn_113_cast_fp16)[name = tensor<string, []>("input_847_cast_fp16")];
            tensor<int32, [2]> var_11400 = const()[name = tensor<string, []>("op_11400"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11402 = const()[name = tensor<string, []>("op_11402"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_567_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_567_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_567_pad_0 = const()[name = tensor<string, []>("pretrained_out_567_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_28_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(536446592))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(537265856))), name = tensor<string, []>("layers_28_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_28_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_28_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(537265984)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_567_cast_fp16 = conv(bias = layers_28_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_11402, groups = var_11255, pad = pretrained_out_567_pad_0, pad_type = pretrained_out_567_pad_type_0, strides = var_11400, weight = layers_28_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_847_cast_fp16)[name = tensor<string, []>("pretrained_out_567_cast_fp16")];
            tensor<int32, [2]> var_11406 = const()[name = tensor<string, []>("op_11406"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11408 = const()[name = tensor<string, []>("op_11408"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_849_pad_type_0 = const()[name = tensor<string, []>("input_849_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_849_pad_0 = const()[name = tensor<string, []>("input_849_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_28_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_28_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(537268608)))];
            tensor<fp16, [1, 16, 1, 1]> input_849_cast_fp16 = conv(dilations = var_11408, groups = var_11255, pad = input_849_pad_0, pad_type = input_849_pad_type_0, strides = var_11406, weight = layers_28_self_attn_o_proj_loraA_weight_to_fp16, x = input_847_cast_fp16)[name = tensor<string, []>("input_849_cast_fp16")];
            tensor<int32, [2]> var_11412 = const()[name = tensor<string, []>("op_11412"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11414 = const()[name = tensor<string, []>("op_11414"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1133_pad_type_0 = const()[name = tensor<string, []>("lora_out_1133_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1133_pad_0 = const()[name = tensor<string, []>("lora_out_1133_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1135_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1135_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(537309632)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1135_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_11414, groups = var_11255, pad = lora_out_1133_pad_0, pad_type = lora_out_1133_pad_type_0, strides = var_11412, weight = lora_out_1135_weight_0_to_fp16, x = input_849_cast_fp16)[name = tensor<string, []>("lora_out_1135_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_399_cast_fp16 = add(x = pretrained_out_567_cast_fp16, y = lora_out_1135_cast_fp16)[name = tensor<string, []>("obj_399_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_171_cast_fp16 = add(x = inputs_169_cast_fp16, y = obj_399_cast_fp16)[name = tensor<string, []>("inputs_171_cast_fp16")];
            tensor<int32, [1]> var_11427 = const()[name = tensor<string, []>("op_11427"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_171_cast_fp16 = reduce_mean(axes = var_11427, keep_dims = var_11256, x = inputs_171_cast_fp16)[name = tensor<string, []>("channels_mean_171_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_171_cast_fp16 = sub(x = inputs_171_cast_fp16, y = channels_mean_171_cast_fp16)[name = tensor<string, []>("zero_mean_171_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_171_cast_fp16 = mul(x = zero_mean_171_cast_fp16, y = zero_mean_171_cast_fp16)[name = tensor<string, []>("zero_mean_sq_171_cast_fp16")];
            tensor<int32, [1]> var_11431 = const()[name = tensor<string, []>("op_11431"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_11432_cast_fp16 = reduce_mean(axes = var_11431, keep_dims = var_11256, x = zero_mean_sq_171_cast_fp16)[name = tensor<string, []>("op_11432_cast_fp16")];
            tensor<fp16, []> var_11433_to_fp16 = const()[name = tensor<string, []>("op_11433_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_11434_cast_fp16 = add(x = var_11432_cast_fp16, y = var_11433_to_fp16)[name = tensor<string, []>("op_11434_cast_fp16")];
            tensor<fp32, []> denom_171_epsilon_0 = const()[name = tensor<string, []>("denom_171_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_171_cast_fp16 = rsqrt(epsilon = denom_171_epsilon_0, x = var_11434_cast_fp16)[name = tensor<string, []>("denom_171_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_171_cast_fp16 = mul(x = zero_mean_171_cast_fp16, y = denom_171_cast_fp16)[name = tensor<string, []>("out_171_cast_fp16")];
            tensor<fp16, [1280]> obj_401_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_401_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(537350656)))];
            tensor<fp16, [1280]> obj_401_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_401_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(537353280)))];
            tensor<fp16, []> obj_401_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_401_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_401_cast_fp16 = batch_norm(beta = obj_401_beta_0_to_fp16, epsilon = obj_401_epsilon_0_to_fp16, gamma = obj_401_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_171_cast_fp16)[name = tensor<string, []>("obj_401_cast_fp16")];
            tensor<int32, [2]> var_11452 = const()[name = tensor<string, []>("op_11452"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11454 = const()[name = tensor<string, []>("op_11454"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_569_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_569_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_569_pad_0 = const()[name = tensor<string, []>("pretrained_out_569_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_28_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(537355904))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(538175168))), name = tensor<string, []>("layers_28_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_28_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_28_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(538175296)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_569_cast_fp16 = conv(bias = layers_28_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_11454, groups = var_11255, pad = pretrained_out_569_pad_0, pad_type = pretrained_out_569_pad_type_0, strides = var_11452, weight = layers_28_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_401_cast_fp16)[name = tensor<string, []>("pretrained_out_569_cast_fp16")];
            tensor<int32, [2]> var_11458 = const()[name = tensor<string, []>("op_11458"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11460 = const()[name = tensor<string, []>("op_11460"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_851_pad_type_0 = const()[name = tensor<string, []>("input_851_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_851_pad_0 = const()[name = tensor<string, []>("input_851_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_28_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_28_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(538177920)))];
            tensor<fp16, [1, 16, 1, 1]> input_851_cast_fp16 = conv(dilations = var_11460, groups = var_11255, pad = input_851_pad_0, pad_type = input_851_pad_type_0, strides = var_11458, weight = layers_28_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_401_cast_fp16)[name = tensor<string, []>("input_851_cast_fp16")];
            tensor<int32, [2]> var_11464 = const()[name = tensor<string, []>("op_11464"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11466 = const()[name = tensor<string, []>("op_11466"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1137_pad_type_0 = const()[name = tensor<string, []>("lora_out_1137_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1137_pad_0 = const()[name = tensor<string, []>("lora_out_1137_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1139_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1139_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(538218944)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1139_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_11466, groups = var_11255, pad = lora_out_1137_pad_0, pad_type = lora_out_1137_pad_type_0, strides = var_11464, weight = lora_out_1139_weight_0_to_fp16, x = input_851_cast_fp16)[name = tensor<string, []>("lora_out_1139_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_115_cast_fp16 = add(x = pretrained_out_569_cast_fp16, y = lora_out_1139_cast_fp16)[name = tensor<string, []>("query_115_cast_fp16")];
            tensor<int32, [2]> var_11476 = const()[name = tensor<string, []>("op_11476"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11478 = const()[name = tensor<string, []>("op_11478"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_571_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_571_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_571_pad_0 = const()[name = tensor<string, []>("pretrained_out_571_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_28_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(538259968))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(539079232))), name = tensor<string, []>("layers_28_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_571_cast_fp16 = conv(dilations = var_11478, groups = var_11255, pad = pretrained_out_571_pad_0, pad_type = pretrained_out_571_pad_type_0, strides = var_11476, weight = layers_28_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_571_cast_fp16")];
            tensor<int32, [2]> var_11482 = const()[name = tensor<string, []>("op_11482"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11484 = const()[name = tensor<string, []>("op_11484"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_853_pad_type_0 = const()[name = tensor<string, []>("input_853_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_853_pad_0 = const()[name = tensor<string, []>("input_853_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_28_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_28_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(539079360)))];
            tensor<fp16, [1, 16, 1, 1500]> input_853_cast_fp16 = conv(dilations = var_11484, groups = var_11255, pad = input_853_pad_0, pad_type = input_853_pad_type_0, strides = var_11482, weight = layers_28_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_853_cast_fp16")];
            tensor<int32, [2]> var_11488 = const()[name = tensor<string, []>("op_11488"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11490 = const()[name = tensor<string, []>("op_11490"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1141_pad_type_0 = const()[name = tensor<string, []>("lora_out_1141_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1141_pad_0 = const()[name = tensor<string, []>("lora_out_1141_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1143_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1143_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(539120384)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_1143_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_11490, groups = var_11255, pad = lora_out_1141_pad_0, pad_type = lora_out_1141_pad_type_0, strides = var_11488, weight = lora_out_1143_weight_0_to_fp16, x = input_853_cast_fp16)[name = tensor<string, []>("lora_out_1143_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_115_cast_fp16 = add(x = pretrained_out_571_cast_fp16, y = lora_out_1143_cast_fp16)[name = tensor<string, []>("key_115_cast_fp16")];
            tensor<int32, [2]> var_11501 = const()[name = tensor<string, []>("op_11501"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11503 = const()[name = tensor<string, []>("op_11503"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_573_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_573_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_573_pad_0 = const()[name = tensor<string, []>("pretrained_out_573_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_28_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(539161408))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(539980672))), name = tensor<string, []>("layers_28_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_28_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_28_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(539980800)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_573_cast_fp16 = conv(bias = layers_28_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_11503, groups = var_11255, pad = pretrained_out_573_pad_0, pad_type = pretrained_out_573_pad_type_0, strides = var_11501, weight = layers_28_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_573_cast_fp16")];
            tensor<int32, [2]> var_11507 = const()[name = tensor<string, []>("op_11507"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11509 = const()[name = tensor<string, []>("op_11509"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_855_pad_type_0 = const()[name = tensor<string, []>("input_855_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_855_pad_0 = const()[name = tensor<string, []>("input_855_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_28_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_28_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(539983424)))];
            tensor<fp16, [1, 16, 1, 1500]> input_855_cast_fp16 = conv(dilations = var_11509, groups = var_11255, pad = input_855_pad_0, pad_type = input_855_pad_type_0, strides = var_11507, weight = layers_28_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_855_cast_fp16")];
            tensor<int32, [2]> var_11513 = const()[name = tensor<string, []>("op_11513"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11515 = const()[name = tensor<string, []>("op_11515"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1145_pad_type_0 = const()[name = tensor<string, []>("lora_out_1145_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1145_pad_0 = const()[name = tensor<string, []>("lora_out_1145_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1147_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1147_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(540024448)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_1147_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_11515, groups = var_11255, pad = lora_out_1145_pad_0, pad_type = lora_out_1145_pad_type_0, strides = var_11513, weight = lora_out_1147_weight_0_to_fp16, x = input_855_cast_fp16)[name = tensor<string, []>("lora_out_1147_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_115_cast_fp16 = add(x = pretrained_out_573_cast_fp16, y = lora_out_1147_cast_fp16)[name = tensor<string, []>("value_115_cast_fp16")];
            tensor<int32, [4]> var_11522 = const()[name = tensor<string, []>("op_11522"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_11523_cast_fp16 = reshape(shape = var_11522, x = query_115_cast_fp16)[name = tensor<string, []>("op_11523_cast_fp16")];
            tensor<fp16, []> var_11524_to_fp16 = const()[name = tensor<string, []>("op_11524_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_11525_cast_fp16 = mul(x = var_11523_cast_fp16, y = var_11524_to_fp16)[name = tensor<string, []>("op_11525_cast_fp16")];
            tensor<int32, [4]> var_11526 = const()[name = tensor<string, []>("op_11526"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_11527_cast_fp16 = reshape(shape = var_11526, x = key_115_cast_fp16)[name = tensor<string, []>("op_11527_cast_fp16")];
            tensor<bool, []> mh_w_173_transpose_x_0 = const()[name = tensor<string, []>("mh_w_173_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_173_transpose_y_0 = const()[name = tensor<string, []>("mh_w_173_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_173_cast_fp16 = matmul(transpose_x = mh_w_173_transpose_x_0, transpose_y = mh_w_173_transpose_y_0, x = var_11525_cast_fp16, y = var_11527_cast_fp16)[name = tensor<string, []>("mh_w_173_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_405_cast_fp16 = softmax(axis = var_11248, x = mh_w_173_cast_fp16)[name = tensor<string, []>("obj_405_cast_fp16")];
            tensor<int32, [4]> var_11531 = const()[name = tensor<string, []>("op_11531"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_11532_cast_fp16 = reshape(shape = var_11531, x = value_115_cast_fp16)[name = tensor<string, []>("op_11532_cast_fp16")];
            tensor<bool, []> attn_115_transpose_x_0 = const()[name = tensor<string, []>("attn_115_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_115_transpose_y_0 = const()[name = tensor<string, []>("attn_115_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_115_cast_fp16 = matmul(transpose_x = attn_115_transpose_x_0, transpose_y = attn_115_transpose_y_0, x = var_11532_cast_fp16, y = obj_405_cast_fp16)[name = tensor<string, []>("attn_115_cast_fp16")];
            tensor<int32, [4]> var_11535 = const()[name = tensor<string, []>("op_11535"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_857_cast_fp16 = reshape(shape = var_11535, x = attn_115_cast_fp16)[name = tensor<string, []>("input_857_cast_fp16")];
            tensor<int32, [2]> var_11542 = const()[name = tensor<string, []>("op_11542"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11544 = const()[name = tensor<string, []>("op_11544"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_575_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_575_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_575_pad_0 = const()[name = tensor<string, []>("pretrained_out_575_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_28_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(540065472))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(540884736))), name = tensor<string, []>("layers_28_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_28_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_28_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(540884864)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_575_cast_fp16 = conv(bias = layers_28_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_11544, groups = var_11255, pad = pretrained_out_575_pad_0, pad_type = pretrained_out_575_pad_type_0, strides = var_11542, weight = layers_28_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_857_cast_fp16)[name = tensor<string, []>("pretrained_out_575_cast_fp16")];
            tensor<int32, [2]> var_11548 = const()[name = tensor<string, []>("op_11548"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11550 = const()[name = tensor<string, []>("op_11550"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_859_pad_type_0 = const()[name = tensor<string, []>("input_859_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_859_pad_0 = const()[name = tensor<string, []>("input_859_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_28_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_28_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(540887488)))];
            tensor<fp16, [1, 16, 1, 1]> input_859_cast_fp16 = conv(dilations = var_11550, groups = var_11255, pad = input_859_pad_0, pad_type = input_859_pad_type_0, strides = var_11548, weight = layers_28_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_857_cast_fp16)[name = tensor<string, []>("input_859_cast_fp16")];
            tensor<int32, [2]> var_11554 = const()[name = tensor<string, []>("op_11554"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11556 = const()[name = tensor<string, []>("op_11556"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1149_pad_type_0 = const()[name = tensor<string, []>("lora_out_1149_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1149_pad_0 = const()[name = tensor<string, []>("lora_out_1149_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1151_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1151_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(540928512)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1151_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_11556, groups = var_11255, pad = lora_out_1149_pad_0, pad_type = lora_out_1149_pad_type_0, strides = var_11554, weight = lora_out_1151_weight_0_to_fp16, x = input_859_cast_fp16)[name = tensor<string, []>("lora_out_1151_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_403_cast_fp16 = add(x = pretrained_out_575_cast_fp16, y = lora_out_1151_cast_fp16)[name = tensor<string, []>("obj_403_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_173_cast_fp16 = add(x = inputs_171_cast_fp16, y = obj_403_cast_fp16)[name = tensor<string, []>("inputs_173_cast_fp16")];
            tensor<int32, [1]> var_11565 = const()[name = tensor<string, []>("op_11565"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_173_cast_fp16 = reduce_mean(axes = var_11565, keep_dims = var_11256, x = inputs_173_cast_fp16)[name = tensor<string, []>("channels_mean_173_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_173_cast_fp16 = sub(x = inputs_173_cast_fp16, y = channels_mean_173_cast_fp16)[name = tensor<string, []>("zero_mean_173_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_173_cast_fp16 = mul(x = zero_mean_173_cast_fp16, y = zero_mean_173_cast_fp16)[name = tensor<string, []>("zero_mean_sq_173_cast_fp16")];
            tensor<int32, [1]> var_11569 = const()[name = tensor<string, []>("op_11569"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_11570_cast_fp16 = reduce_mean(axes = var_11569, keep_dims = var_11256, x = zero_mean_sq_173_cast_fp16)[name = tensor<string, []>("op_11570_cast_fp16")];
            tensor<fp16, []> var_11571_to_fp16 = const()[name = tensor<string, []>("op_11571_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_11572_cast_fp16 = add(x = var_11570_cast_fp16, y = var_11571_to_fp16)[name = tensor<string, []>("op_11572_cast_fp16")];
            tensor<fp32, []> denom_173_epsilon_0 = const()[name = tensor<string, []>("denom_173_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_173_cast_fp16 = rsqrt(epsilon = denom_173_epsilon_0, x = var_11572_cast_fp16)[name = tensor<string, []>("denom_173_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_173_cast_fp16 = mul(x = zero_mean_173_cast_fp16, y = denom_173_cast_fp16)[name = tensor<string, []>("out_173_cast_fp16")];
            tensor<fp16, [1280]> input_861_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_861_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(540969536)))];
            tensor<fp16, [1280]> input_861_beta_0_to_fp16 = const()[name = tensor<string, []>("input_861_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(540972160)))];
            tensor<fp16, []> input_861_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_861_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_861_cast_fp16 = batch_norm(beta = input_861_beta_0_to_fp16, epsilon = input_861_epsilon_0_to_fp16, gamma = input_861_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_173_cast_fp16)[name = tensor<string, []>("input_861_cast_fp16")];
            tensor<int32, [2]> var_11586 = const()[name = tensor<string, []>("op_11586"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11588 = const()[name = tensor<string, []>("op_11588"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_577_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_577_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_577_pad_0 = const()[name = tensor<string, []>("pretrained_out_577_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_28_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(540974784))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(544251648))), name = tensor<string, []>("layers_28_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_28_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_28_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(544251776)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_577_cast_fp16 = conv(bias = layers_28_fc1_pretrained_bias_to_fp16, dilations = var_11588, groups = var_11255, pad = pretrained_out_577_pad_0, pad_type = pretrained_out_577_pad_type_0, strides = var_11586, weight = layers_28_fc1_pretrained_weight_to_fp16_palettized, x = input_861_cast_fp16)[name = tensor<string, []>("pretrained_out_577_cast_fp16")];
            tensor<int32, [2]> var_11592 = const()[name = tensor<string, []>("op_11592"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11594 = const()[name = tensor<string, []>("op_11594"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_863_pad_type_0 = const()[name = tensor<string, []>("input_863_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_863_pad_0 = const()[name = tensor<string, []>("input_863_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_28_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_28_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(544262080)))];
            tensor<fp16, [1, 16, 1, 1]> input_863_cast_fp16 = conv(dilations = var_11594, groups = var_11255, pad = input_863_pad_0, pad_type = input_863_pad_type_0, strides = var_11592, weight = layers_28_fc1_loraA_weight_to_fp16, x = input_861_cast_fp16)[name = tensor<string, []>("input_863_cast_fp16")];
            tensor<int32, [2]> var_11598 = const()[name = tensor<string, []>("op_11598"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11600 = const()[name = tensor<string, []>("op_11600"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1153_pad_type_0 = const()[name = tensor<string, []>("lora_out_1153_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1153_pad_0 = const()[name = tensor<string, []>("lora_out_1153_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_1155_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1155_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(544303104)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_1155_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_11600, groups = var_11255, pad = lora_out_1153_pad_0, pad_type = lora_out_1153_pad_type_0, strides = var_11598, weight = lora_out_1155_weight_0_to_fp16, x = input_863_cast_fp16)[name = tensor<string, []>("lora_out_1155_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_865_cast_fp16 = add(x = pretrained_out_577_cast_fp16, y = lora_out_1155_cast_fp16)[name = tensor<string, []>("input_865_cast_fp16")];
            tensor<string, []> input_867_mode_0 = const()[name = tensor<string, []>("input_867_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_867_cast_fp16 = gelu(mode = input_867_mode_0, x = input_865_cast_fp16)[name = tensor<string, []>("input_867_cast_fp16")];
            tensor<int32, [2]> var_11612 = const()[name = tensor<string, []>("op_11612"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11614 = const()[name = tensor<string, []>("op_11614"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_579_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_579_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_579_pad_0 = const()[name = tensor<string, []>("pretrained_out_579_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_28_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(544467008))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(547743872))), name = tensor<string, []>("layers_28_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_28_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_28_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(547744000)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_579_cast_fp16 = conv(bias = layers_28_fc2_pretrained_bias_to_fp16, dilations = var_11614, groups = var_11255, pad = pretrained_out_579_pad_0, pad_type = pretrained_out_579_pad_type_0, strides = var_11612, weight = layers_28_fc2_pretrained_weight_to_fp16_palettized, x = input_867_cast_fp16)[name = tensor<string, []>("pretrained_out_579_cast_fp16")];
            tensor<int32, [2]> var_11618 = const()[name = tensor<string, []>("op_11618"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11620 = const()[name = tensor<string, []>("op_11620"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_869_pad_type_0 = const()[name = tensor<string, []>("input_869_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_869_pad_0 = const()[name = tensor<string, []>("input_869_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_28_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_28_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(547746624)))];
            tensor<fp16, [1, 16, 1, 1]> input_869_cast_fp16 = conv(dilations = var_11620, groups = var_11255, pad = input_869_pad_0, pad_type = input_869_pad_type_0, strides = var_11618, weight = layers_28_fc2_loraA_weight_to_fp16, x = input_867_cast_fp16)[name = tensor<string, []>("input_869_cast_fp16")];
            tensor<int32, [2]> var_11624 = const()[name = tensor<string, []>("op_11624"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11626 = const()[name = tensor<string, []>("op_11626"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1157_pad_type_0 = const()[name = tensor<string, []>("lora_out_1157_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1157_pad_0 = const()[name = tensor<string, []>("lora_out_1157_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1159_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1159_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(547910528)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1159_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_11626, groups = var_11255, pad = lora_out_1157_pad_0, pad_type = lora_out_1157_pad_type_0, strides = var_11624, weight = lora_out_1159_weight_0_to_fp16, x = input_869_cast_fp16)[name = tensor<string, []>("lora_out_1159_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_59_cast_fp16 = add(x = pretrained_out_579_cast_fp16, y = lora_out_1159_cast_fp16)[name = tensor<string, []>("hidden_states_59_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_175_cast_fp16 = add(x = inputs_173_cast_fp16, y = hidden_states_59_cast_fp16)[name = tensor<string, []>("inputs_175_cast_fp16")];
            tensor<int32, []> var_11642 = const()[name = tensor<string, []>("op_11642"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_11649 = const()[name = tensor<string, []>("op_11649"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_11650 = const()[name = tensor<string, []>("op_11650"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_11662 = const()[name = tensor<string, []>("op_11662"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_175_cast_fp16 = reduce_mean(axes = var_11662, keep_dims = var_11650, x = inputs_175_cast_fp16)[name = tensor<string, []>("channels_mean_175_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_175_cast_fp16 = sub(x = inputs_175_cast_fp16, y = channels_mean_175_cast_fp16)[name = tensor<string, []>("zero_mean_175_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_175_cast_fp16 = mul(x = zero_mean_175_cast_fp16, y = zero_mean_175_cast_fp16)[name = tensor<string, []>("zero_mean_sq_175_cast_fp16")];
            tensor<int32, [1]> var_11666 = const()[name = tensor<string, []>("op_11666"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_11667_cast_fp16 = reduce_mean(axes = var_11666, keep_dims = var_11650, x = zero_mean_sq_175_cast_fp16)[name = tensor<string, []>("op_11667_cast_fp16")];
            tensor<fp16, []> var_11668_to_fp16 = const()[name = tensor<string, []>("op_11668_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_11669_cast_fp16 = add(x = var_11667_cast_fp16, y = var_11668_to_fp16)[name = tensor<string, []>("op_11669_cast_fp16")];
            tensor<fp32, []> denom_175_epsilon_0 = const()[name = tensor<string, []>("denom_175_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_175_cast_fp16 = rsqrt(epsilon = denom_175_epsilon_0, x = var_11669_cast_fp16)[name = tensor<string, []>("denom_175_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_175_cast_fp16 = mul(x = zero_mean_175_cast_fp16, y = denom_175_cast_fp16)[name = tensor<string, []>("out_175_cast_fp16")];
            tensor<fp16, [1280]> obj_407_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_407_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(547951552)))];
            tensor<fp16, [1280]> obj_407_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_407_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(547954176)))];
            tensor<fp16, []> obj_407_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_407_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_407_cast_fp16 = batch_norm(beta = obj_407_beta_0_to_fp16, epsilon = obj_407_epsilon_0_to_fp16, gamma = obj_407_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_175_cast_fp16)[name = tensor<string, []>("obj_407_cast_fp16")];
            tensor<int32, [2]> var_11687 = const()[name = tensor<string, []>("op_11687"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11689 = const()[name = tensor<string, []>("op_11689"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_581_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_581_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_581_pad_0 = const()[name = tensor<string, []>("pretrained_out_581_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_29_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(547956800))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(548776064))), name = tensor<string, []>("layers_29_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_29_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_29_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(548776192)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_581_cast_fp16 = conv(bias = layers_29_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_11689, groups = var_11649, pad = pretrained_out_581_pad_0, pad_type = pretrained_out_581_pad_type_0, strides = var_11687, weight = layers_29_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_407_cast_fp16)[name = tensor<string, []>("pretrained_out_581_cast_fp16")];
            tensor<int32, [2]> var_11693 = const()[name = tensor<string, []>("op_11693"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11695 = const()[name = tensor<string, []>("op_11695"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_871_pad_type_0 = const()[name = tensor<string, []>("input_871_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_871_pad_0 = const()[name = tensor<string, []>("input_871_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_29_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_29_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(548778816)))];
            tensor<fp16, [1, 16, 1, 1]> input_871_cast_fp16 = conv(dilations = var_11695, groups = var_11649, pad = input_871_pad_0, pad_type = input_871_pad_type_0, strides = var_11693, weight = layers_29_self_attn_q_proj_loraA_weight_to_fp16, x = obj_407_cast_fp16)[name = tensor<string, []>("input_871_cast_fp16")];
            tensor<int32, [2]> var_11699 = const()[name = tensor<string, []>("op_11699"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11701 = const()[name = tensor<string, []>("op_11701"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1161_pad_type_0 = const()[name = tensor<string, []>("lora_out_1161_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1161_pad_0 = const()[name = tensor<string, []>("lora_out_1161_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1163_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1163_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(548819840)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1163_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_11701, groups = var_11649, pad = lora_out_1161_pad_0, pad_type = lora_out_1161_pad_type_0, strides = var_11699, weight = lora_out_1163_weight_0_to_fp16, x = input_871_cast_fp16)[name = tensor<string, []>("lora_out_1163_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_117_cast_fp16 = add(x = pretrained_out_581_cast_fp16, y = lora_out_1163_cast_fp16)[name = tensor<string, []>("query_117_cast_fp16")];
            tensor<int32, [2]> var_11711 = const()[name = tensor<string, []>("op_11711"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11713 = const()[name = tensor<string, []>("op_11713"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_583_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_583_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_583_pad_0 = const()[name = tensor<string, []>("pretrained_out_583_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_29_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(548860864))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(549680128))), name = tensor<string, []>("layers_29_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_583_cast_fp16 = conv(dilations = var_11713, groups = var_11649, pad = pretrained_out_583_pad_0, pad_type = pretrained_out_583_pad_type_0, strides = var_11711, weight = layers_29_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_407_cast_fp16)[name = tensor<string, []>("pretrained_out_583_cast_fp16")];
            tensor<int32, [2]> var_11717 = const()[name = tensor<string, []>("op_11717"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11719 = const()[name = tensor<string, []>("op_11719"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_873_pad_type_0 = const()[name = tensor<string, []>("input_873_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_873_pad_0 = const()[name = tensor<string, []>("input_873_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_29_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_29_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(549680256)))];
            tensor<fp16, [1, 16, 1, 1]> input_873_cast_fp16 = conv(dilations = var_11719, groups = var_11649, pad = input_873_pad_0, pad_type = input_873_pad_type_0, strides = var_11717, weight = layers_29_self_attn_k_proj_loraA_weight_to_fp16, x = obj_407_cast_fp16)[name = tensor<string, []>("input_873_cast_fp16")];
            tensor<int32, [2]> var_11723 = const()[name = tensor<string, []>("op_11723"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11725 = const()[name = tensor<string, []>("op_11725"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1165_pad_type_0 = const()[name = tensor<string, []>("lora_out_1165_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1165_pad_0 = const()[name = tensor<string, []>("lora_out_1165_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1167_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1167_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(549721280)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1167_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_11725, groups = var_11649, pad = lora_out_1165_pad_0, pad_type = lora_out_1165_pad_type_0, strides = var_11723, weight = lora_out_1167_weight_0_to_fp16, x = input_873_cast_fp16)[name = tensor<string, []>("lora_out_1167_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_59_cast_fp16 = add(x = pretrained_out_583_cast_fp16, y = lora_out_1167_cast_fp16)[name = tensor<string, []>("current_key_59_cast_fp16")];
            tensor<int32, [2]> var_11736 = const()[name = tensor<string, []>("op_11736"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11738 = const()[name = tensor<string, []>("op_11738"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_585_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_585_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_585_pad_0 = const()[name = tensor<string, []>("pretrained_out_585_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_29_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(549762304))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(550581568))), name = tensor<string, []>("layers_29_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_29_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_29_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(550581696)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_585_cast_fp16 = conv(bias = layers_29_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_11738, groups = var_11649, pad = pretrained_out_585_pad_0, pad_type = pretrained_out_585_pad_type_0, strides = var_11736, weight = layers_29_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_407_cast_fp16)[name = tensor<string, []>("pretrained_out_585_cast_fp16")];
            tensor<int32, [2]> var_11742 = const()[name = tensor<string, []>("op_11742"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11744 = const()[name = tensor<string, []>("op_11744"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_875_pad_type_0 = const()[name = tensor<string, []>("input_875_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_875_pad_0 = const()[name = tensor<string, []>("input_875_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_29_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_29_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(550584320)))];
            tensor<fp16, [1, 16, 1, 1]> input_875_cast_fp16 = conv(dilations = var_11744, groups = var_11649, pad = input_875_pad_0, pad_type = input_875_pad_type_0, strides = var_11742, weight = layers_29_self_attn_v_proj_loraA_weight_to_fp16, x = obj_407_cast_fp16)[name = tensor<string, []>("input_875_cast_fp16")];
            tensor<int32, [2]> var_11748 = const()[name = tensor<string, []>("op_11748"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11750 = const()[name = tensor<string, []>("op_11750"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1169_pad_type_0 = const()[name = tensor<string, []>("lora_out_1169_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1169_pad_0 = const()[name = tensor<string, []>("lora_out_1169_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1171_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1171_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(550625344)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1171_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_11750, groups = var_11649, pad = lora_out_1169_pad_0, pad_type = lora_out_1169_pad_type_0, strides = var_11748, weight = lora_out_1171_weight_0_to_fp16, x = input_875_cast_fp16)[name = tensor<string, []>("lora_out_1171_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_59_cast_fp16 = add(x = pretrained_out_585_cast_fp16, y = lora_out_1171_cast_fp16)[name = tensor<string, []>("current_value_59_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_11760_cast_fp16 = mul(x = current_key_59_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_11760_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_11762_cast_fp16 = mul(x = var_103_cast_fp16_29, y = var_295_cast_fp16)[name = tensor<string, []>("op_11762_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_117_cast_fp16 = add(x = var_11760_cast_fp16, y = var_11762_cast_fp16)[name = tensor<string, []>("key_117_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_11764_cast_fp16 = mul(x = current_value_59_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_11764_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_11766_cast_fp16 = mul(x = var_138_cast_fp16_29, y = var_295_cast_fp16)[name = tensor<string, []>("op_11766_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_117_cast_fp16 = add(x = var_11764_cast_fp16, y = var_11766_cast_fp16)[name = tensor<string, []>("value_117_cast_fp16")];
            tensor<int32, [4]> var_11769 = const()[name = tensor<string, []>("op_11769"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_11770_cast_fp16 = reshape(shape = var_11769, x = query_117_cast_fp16)[name = tensor<string, []>("op_11770_cast_fp16")];
            tensor<fp16, []> var_11771_to_fp16 = const()[name = tensor<string, []>("op_11771_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_11772_cast_fp16 = mul(x = var_11770_cast_fp16, y = var_11771_to_fp16)[name = tensor<string, []>("op_11772_cast_fp16")];
            tensor<int32, [4]> var_11773 = const()[name = tensor<string, []>("op_11773"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_11774_cast_fp16 = reshape(shape = var_11773, x = key_117_cast_fp16)[name = tensor<string, []>("op_11774_cast_fp16")];
            tensor<bool, []> mh_w_175_transpose_x_0 = const()[name = tensor<string, []>("mh_w_175_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_175_transpose_y_0 = const()[name = tensor<string, []>("mh_w_175_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_175_cast_fp16 = matmul(transpose_x = mh_w_175_transpose_x_0, transpose_y = mh_w_175_transpose_y_0, x = var_11772_cast_fp16, y = var_11774_cast_fp16)[name = tensor<string, []>("mh_w_175_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_177_cast_fp16 = add(x = mh_w_175_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_177_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_11782_cast_fp16 = softmax(axis = var_11642, x = mh_w_177_cast_fp16)[name = tensor<string, []>("op_11782_cast_fp16")];
            tensor<int32, [4]> var_11783 = const()[name = tensor<string, []>("op_11783"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_11784_cast_fp16 = reshape(shape = var_11783, x = value_117_cast_fp16)[name = tensor<string, []>("op_11784_cast_fp16")];
            tensor<bool, []> attn_117_transpose_x_0 = const()[name = tensor<string, []>("attn_117_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_117_transpose_y_0 = const()[name = tensor<string, []>("attn_117_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_117_cast_fp16 = matmul(transpose_x = attn_117_transpose_x_0, transpose_y = attn_117_transpose_y_0, x = var_11784_cast_fp16, y = var_11782_cast_fp16)[name = tensor<string, []>("attn_117_cast_fp16")];
            tensor<int32, [4]> var_11787 = const()[name = tensor<string, []>("op_11787"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_877_cast_fp16 = reshape(shape = var_11787, x = attn_117_cast_fp16)[name = tensor<string, []>("input_877_cast_fp16")];
            tensor<int32, [2]> var_11794 = const()[name = tensor<string, []>("op_11794"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11796 = const()[name = tensor<string, []>("op_11796"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_587_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_587_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_587_pad_0 = const()[name = tensor<string, []>("pretrained_out_587_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_29_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(550666368))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(551485632))), name = tensor<string, []>("layers_29_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_29_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_29_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(551485760)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_587_cast_fp16 = conv(bias = layers_29_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_11796, groups = var_11649, pad = pretrained_out_587_pad_0, pad_type = pretrained_out_587_pad_type_0, strides = var_11794, weight = layers_29_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_877_cast_fp16)[name = tensor<string, []>("pretrained_out_587_cast_fp16")];
            tensor<int32, [2]> var_11800 = const()[name = tensor<string, []>("op_11800"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11802 = const()[name = tensor<string, []>("op_11802"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_879_pad_type_0 = const()[name = tensor<string, []>("input_879_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_879_pad_0 = const()[name = tensor<string, []>("input_879_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_29_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_29_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(551488384)))];
            tensor<fp16, [1, 16, 1, 1]> input_879_cast_fp16 = conv(dilations = var_11802, groups = var_11649, pad = input_879_pad_0, pad_type = input_879_pad_type_0, strides = var_11800, weight = layers_29_self_attn_o_proj_loraA_weight_to_fp16, x = input_877_cast_fp16)[name = tensor<string, []>("input_879_cast_fp16")];
            tensor<int32, [2]> var_11806 = const()[name = tensor<string, []>("op_11806"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11808 = const()[name = tensor<string, []>("op_11808"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1173_pad_type_0 = const()[name = tensor<string, []>("lora_out_1173_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1173_pad_0 = const()[name = tensor<string, []>("lora_out_1173_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1175_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1175_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(551529408)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1175_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_11808, groups = var_11649, pad = lora_out_1173_pad_0, pad_type = lora_out_1173_pad_type_0, strides = var_11806, weight = lora_out_1175_weight_0_to_fp16, x = input_879_cast_fp16)[name = tensor<string, []>("lora_out_1175_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_413_cast_fp16 = add(x = pretrained_out_587_cast_fp16, y = lora_out_1175_cast_fp16)[name = tensor<string, []>("obj_413_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_177_cast_fp16 = add(x = inputs_175_cast_fp16, y = obj_413_cast_fp16)[name = tensor<string, []>("inputs_177_cast_fp16")];
            tensor<int32, [1]> var_11821 = const()[name = tensor<string, []>("op_11821"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_177_cast_fp16 = reduce_mean(axes = var_11821, keep_dims = var_11650, x = inputs_177_cast_fp16)[name = tensor<string, []>("channels_mean_177_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_177_cast_fp16 = sub(x = inputs_177_cast_fp16, y = channels_mean_177_cast_fp16)[name = tensor<string, []>("zero_mean_177_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_177_cast_fp16 = mul(x = zero_mean_177_cast_fp16, y = zero_mean_177_cast_fp16)[name = tensor<string, []>("zero_mean_sq_177_cast_fp16")];
            tensor<int32, [1]> var_11825 = const()[name = tensor<string, []>("op_11825"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_11826_cast_fp16 = reduce_mean(axes = var_11825, keep_dims = var_11650, x = zero_mean_sq_177_cast_fp16)[name = tensor<string, []>("op_11826_cast_fp16")];
            tensor<fp16, []> var_11827_to_fp16 = const()[name = tensor<string, []>("op_11827_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_11828_cast_fp16 = add(x = var_11826_cast_fp16, y = var_11827_to_fp16)[name = tensor<string, []>("op_11828_cast_fp16")];
            tensor<fp32, []> denom_177_epsilon_0 = const()[name = tensor<string, []>("denom_177_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_177_cast_fp16 = rsqrt(epsilon = denom_177_epsilon_0, x = var_11828_cast_fp16)[name = tensor<string, []>("denom_177_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_177_cast_fp16 = mul(x = zero_mean_177_cast_fp16, y = denom_177_cast_fp16)[name = tensor<string, []>("out_177_cast_fp16")];
            tensor<fp16, [1280]> obj_415_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_415_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(551570432)))];
            tensor<fp16, [1280]> obj_415_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_415_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(551573056)))];
            tensor<fp16, []> obj_415_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_415_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_415_cast_fp16 = batch_norm(beta = obj_415_beta_0_to_fp16, epsilon = obj_415_epsilon_0_to_fp16, gamma = obj_415_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_177_cast_fp16)[name = tensor<string, []>("obj_415_cast_fp16")];
            tensor<int32, [2]> var_11846 = const()[name = tensor<string, []>("op_11846"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11848 = const()[name = tensor<string, []>("op_11848"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_589_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_589_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_589_pad_0 = const()[name = tensor<string, []>("pretrained_out_589_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_29_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(551575680))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(552394944))), name = tensor<string, []>("layers_29_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_29_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_29_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(552395072)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_589_cast_fp16 = conv(bias = layers_29_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_11848, groups = var_11649, pad = pretrained_out_589_pad_0, pad_type = pretrained_out_589_pad_type_0, strides = var_11846, weight = layers_29_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_415_cast_fp16)[name = tensor<string, []>("pretrained_out_589_cast_fp16")];
            tensor<int32, [2]> var_11852 = const()[name = tensor<string, []>("op_11852"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11854 = const()[name = tensor<string, []>("op_11854"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_881_pad_type_0 = const()[name = tensor<string, []>("input_881_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_881_pad_0 = const()[name = tensor<string, []>("input_881_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_29_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_29_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(552397696)))];
            tensor<fp16, [1, 16, 1, 1]> input_881_cast_fp16 = conv(dilations = var_11854, groups = var_11649, pad = input_881_pad_0, pad_type = input_881_pad_type_0, strides = var_11852, weight = layers_29_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_415_cast_fp16)[name = tensor<string, []>("input_881_cast_fp16")];
            tensor<int32, [2]> var_11858 = const()[name = tensor<string, []>("op_11858"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11860 = const()[name = tensor<string, []>("op_11860"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1177_pad_type_0 = const()[name = tensor<string, []>("lora_out_1177_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1177_pad_0 = const()[name = tensor<string, []>("lora_out_1177_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1179_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1179_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(552438720)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1179_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_11860, groups = var_11649, pad = lora_out_1177_pad_0, pad_type = lora_out_1177_pad_type_0, strides = var_11858, weight = lora_out_1179_weight_0_to_fp16, x = input_881_cast_fp16)[name = tensor<string, []>("lora_out_1179_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_119_cast_fp16 = add(x = pretrained_out_589_cast_fp16, y = lora_out_1179_cast_fp16)[name = tensor<string, []>("query_119_cast_fp16")];
            tensor<int32, [2]> var_11870 = const()[name = tensor<string, []>("op_11870"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11872 = const()[name = tensor<string, []>("op_11872"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_591_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_591_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_591_pad_0 = const()[name = tensor<string, []>("pretrained_out_591_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_29_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(552479744))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(553299008))), name = tensor<string, []>("layers_29_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_591_cast_fp16 = conv(dilations = var_11872, groups = var_11649, pad = pretrained_out_591_pad_0, pad_type = pretrained_out_591_pad_type_0, strides = var_11870, weight = layers_29_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_591_cast_fp16")];
            tensor<int32, [2]> var_11876 = const()[name = tensor<string, []>("op_11876"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11878 = const()[name = tensor<string, []>("op_11878"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_883_pad_type_0 = const()[name = tensor<string, []>("input_883_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_883_pad_0 = const()[name = tensor<string, []>("input_883_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_29_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_29_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(553299136)))];
            tensor<fp16, [1, 16, 1, 1500]> input_883_cast_fp16 = conv(dilations = var_11878, groups = var_11649, pad = input_883_pad_0, pad_type = input_883_pad_type_0, strides = var_11876, weight = layers_29_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_883_cast_fp16")];
            tensor<int32, [2]> var_11882 = const()[name = tensor<string, []>("op_11882"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11884 = const()[name = tensor<string, []>("op_11884"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1181_pad_type_0 = const()[name = tensor<string, []>("lora_out_1181_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1181_pad_0 = const()[name = tensor<string, []>("lora_out_1181_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1183_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1183_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(553340160)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_1183_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_11884, groups = var_11649, pad = lora_out_1181_pad_0, pad_type = lora_out_1181_pad_type_0, strides = var_11882, weight = lora_out_1183_weight_0_to_fp16, x = input_883_cast_fp16)[name = tensor<string, []>("lora_out_1183_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_119_cast_fp16 = add(x = pretrained_out_591_cast_fp16, y = lora_out_1183_cast_fp16)[name = tensor<string, []>("key_119_cast_fp16")];
            tensor<int32, [2]> var_11895 = const()[name = tensor<string, []>("op_11895"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11897 = const()[name = tensor<string, []>("op_11897"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_593_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_593_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_593_pad_0 = const()[name = tensor<string, []>("pretrained_out_593_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_29_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(553381184))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(554200448))), name = tensor<string, []>("layers_29_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_29_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_29_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(554200576)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_593_cast_fp16 = conv(bias = layers_29_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_11897, groups = var_11649, pad = pretrained_out_593_pad_0, pad_type = pretrained_out_593_pad_type_0, strides = var_11895, weight = layers_29_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_593_cast_fp16")];
            tensor<int32, [2]> var_11901 = const()[name = tensor<string, []>("op_11901"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11903 = const()[name = tensor<string, []>("op_11903"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_885_pad_type_0 = const()[name = tensor<string, []>("input_885_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_885_pad_0 = const()[name = tensor<string, []>("input_885_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_29_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_29_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(554203200)))];
            tensor<fp16, [1, 16, 1, 1500]> input_885_cast_fp16 = conv(dilations = var_11903, groups = var_11649, pad = input_885_pad_0, pad_type = input_885_pad_type_0, strides = var_11901, weight = layers_29_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_885_cast_fp16")];
            tensor<int32, [2]> var_11907 = const()[name = tensor<string, []>("op_11907"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11909 = const()[name = tensor<string, []>("op_11909"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1185_pad_type_0 = const()[name = tensor<string, []>("lora_out_1185_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1185_pad_0 = const()[name = tensor<string, []>("lora_out_1185_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1187_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1187_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(554244224)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_1187_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_11909, groups = var_11649, pad = lora_out_1185_pad_0, pad_type = lora_out_1185_pad_type_0, strides = var_11907, weight = lora_out_1187_weight_0_to_fp16, x = input_885_cast_fp16)[name = tensor<string, []>("lora_out_1187_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_119_cast_fp16 = add(x = pretrained_out_593_cast_fp16, y = lora_out_1187_cast_fp16)[name = tensor<string, []>("value_119_cast_fp16")];
            tensor<int32, [4]> var_11916 = const()[name = tensor<string, []>("op_11916"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_11917_cast_fp16 = reshape(shape = var_11916, x = query_119_cast_fp16)[name = tensor<string, []>("op_11917_cast_fp16")];
            tensor<fp16, []> var_11918_to_fp16 = const()[name = tensor<string, []>("op_11918_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_11919_cast_fp16 = mul(x = var_11917_cast_fp16, y = var_11918_to_fp16)[name = tensor<string, []>("op_11919_cast_fp16")];
            tensor<int32, [4]> var_11920 = const()[name = tensor<string, []>("op_11920"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_11921_cast_fp16 = reshape(shape = var_11920, x = key_119_cast_fp16)[name = tensor<string, []>("op_11921_cast_fp16")];
            tensor<bool, []> mh_w_179_transpose_x_0 = const()[name = tensor<string, []>("mh_w_179_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_179_transpose_y_0 = const()[name = tensor<string, []>("mh_w_179_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_179_cast_fp16 = matmul(transpose_x = mh_w_179_transpose_x_0, transpose_y = mh_w_179_transpose_y_0, x = var_11919_cast_fp16, y = var_11921_cast_fp16)[name = tensor<string, []>("mh_w_179_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_419_cast_fp16 = softmax(axis = var_11642, x = mh_w_179_cast_fp16)[name = tensor<string, []>("obj_419_cast_fp16")];
            tensor<int32, [4]> var_11925 = const()[name = tensor<string, []>("op_11925"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_11926_cast_fp16 = reshape(shape = var_11925, x = value_119_cast_fp16)[name = tensor<string, []>("op_11926_cast_fp16")];
            tensor<bool, []> attn_119_transpose_x_0 = const()[name = tensor<string, []>("attn_119_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_119_transpose_y_0 = const()[name = tensor<string, []>("attn_119_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_119_cast_fp16 = matmul(transpose_x = attn_119_transpose_x_0, transpose_y = attn_119_transpose_y_0, x = var_11926_cast_fp16, y = obj_419_cast_fp16)[name = tensor<string, []>("attn_119_cast_fp16")];
            tensor<int32, [4]> var_11929 = const()[name = tensor<string, []>("op_11929"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_887_cast_fp16 = reshape(shape = var_11929, x = attn_119_cast_fp16)[name = tensor<string, []>("input_887_cast_fp16")];
            tensor<int32, [2]> var_11936 = const()[name = tensor<string, []>("op_11936"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11938 = const()[name = tensor<string, []>("op_11938"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_595_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_595_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_595_pad_0 = const()[name = tensor<string, []>("pretrained_out_595_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_29_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(554285248))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(555104512))), name = tensor<string, []>("layers_29_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_29_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_29_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(555104640)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_595_cast_fp16 = conv(bias = layers_29_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_11938, groups = var_11649, pad = pretrained_out_595_pad_0, pad_type = pretrained_out_595_pad_type_0, strides = var_11936, weight = layers_29_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_887_cast_fp16)[name = tensor<string, []>("pretrained_out_595_cast_fp16")];
            tensor<int32, [2]> var_11942 = const()[name = tensor<string, []>("op_11942"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11944 = const()[name = tensor<string, []>("op_11944"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_889_pad_type_0 = const()[name = tensor<string, []>("input_889_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_889_pad_0 = const()[name = tensor<string, []>("input_889_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_29_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_29_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(555107264)))];
            tensor<fp16, [1, 16, 1, 1]> input_889_cast_fp16 = conv(dilations = var_11944, groups = var_11649, pad = input_889_pad_0, pad_type = input_889_pad_type_0, strides = var_11942, weight = layers_29_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_887_cast_fp16)[name = tensor<string, []>("input_889_cast_fp16")];
            tensor<int32, [2]> var_11948 = const()[name = tensor<string, []>("op_11948"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11950 = const()[name = tensor<string, []>("op_11950"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1189_pad_type_0 = const()[name = tensor<string, []>("lora_out_1189_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1189_pad_0 = const()[name = tensor<string, []>("lora_out_1189_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1191_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1191_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(555148288)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1191_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_11950, groups = var_11649, pad = lora_out_1189_pad_0, pad_type = lora_out_1189_pad_type_0, strides = var_11948, weight = lora_out_1191_weight_0_to_fp16, x = input_889_cast_fp16)[name = tensor<string, []>("lora_out_1191_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_417_cast_fp16 = add(x = pretrained_out_595_cast_fp16, y = lora_out_1191_cast_fp16)[name = tensor<string, []>("obj_417_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_179_cast_fp16 = add(x = inputs_177_cast_fp16, y = obj_417_cast_fp16)[name = tensor<string, []>("inputs_179_cast_fp16")];
            tensor<int32, [1]> var_11959 = const()[name = tensor<string, []>("op_11959"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_179_cast_fp16 = reduce_mean(axes = var_11959, keep_dims = var_11650, x = inputs_179_cast_fp16)[name = tensor<string, []>("channels_mean_179_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_179_cast_fp16 = sub(x = inputs_179_cast_fp16, y = channels_mean_179_cast_fp16)[name = tensor<string, []>("zero_mean_179_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_179_cast_fp16 = mul(x = zero_mean_179_cast_fp16, y = zero_mean_179_cast_fp16)[name = tensor<string, []>("zero_mean_sq_179_cast_fp16")];
            tensor<int32, [1]> var_11963 = const()[name = tensor<string, []>("op_11963"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_11964_cast_fp16 = reduce_mean(axes = var_11963, keep_dims = var_11650, x = zero_mean_sq_179_cast_fp16)[name = tensor<string, []>("op_11964_cast_fp16")];
            tensor<fp16, []> var_11965_to_fp16 = const()[name = tensor<string, []>("op_11965_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_11966_cast_fp16 = add(x = var_11964_cast_fp16, y = var_11965_to_fp16)[name = tensor<string, []>("op_11966_cast_fp16")];
            tensor<fp32, []> denom_179_epsilon_0 = const()[name = tensor<string, []>("denom_179_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_179_cast_fp16 = rsqrt(epsilon = denom_179_epsilon_0, x = var_11966_cast_fp16)[name = tensor<string, []>("denom_179_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_179_cast_fp16 = mul(x = zero_mean_179_cast_fp16, y = denom_179_cast_fp16)[name = tensor<string, []>("out_179_cast_fp16")];
            tensor<fp16, [1280]> input_891_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_891_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(555189312)))];
            tensor<fp16, [1280]> input_891_beta_0_to_fp16 = const()[name = tensor<string, []>("input_891_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(555191936)))];
            tensor<fp16, []> input_891_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_891_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_891_cast_fp16 = batch_norm(beta = input_891_beta_0_to_fp16, epsilon = input_891_epsilon_0_to_fp16, gamma = input_891_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_179_cast_fp16)[name = tensor<string, []>("input_891_cast_fp16")];
            tensor<int32, [2]> var_11980 = const()[name = tensor<string, []>("op_11980"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11982 = const()[name = tensor<string, []>("op_11982"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_597_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_597_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_597_pad_0 = const()[name = tensor<string, []>("pretrained_out_597_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_29_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(555194560))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(558471424))), name = tensor<string, []>("layers_29_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_29_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_29_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(558471552)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_597_cast_fp16 = conv(bias = layers_29_fc1_pretrained_bias_to_fp16, dilations = var_11982, groups = var_11649, pad = pretrained_out_597_pad_0, pad_type = pretrained_out_597_pad_type_0, strides = var_11980, weight = layers_29_fc1_pretrained_weight_to_fp16_palettized, x = input_891_cast_fp16)[name = tensor<string, []>("pretrained_out_597_cast_fp16")];
            tensor<int32, [2]> var_11986 = const()[name = tensor<string, []>("op_11986"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11988 = const()[name = tensor<string, []>("op_11988"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_893_pad_type_0 = const()[name = tensor<string, []>("input_893_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_893_pad_0 = const()[name = tensor<string, []>("input_893_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_29_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_29_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(558481856)))];
            tensor<fp16, [1, 16, 1, 1]> input_893_cast_fp16 = conv(dilations = var_11988, groups = var_11649, pad = input_893_pad_0, pad_type = input_893_pad_type_0, strides = var_11986, weight = layers_29_fc1_loraA_weight_to_fp16, x = input_891_cast_fp16)[name = tensor<string, []>("input_893_cast_fp16")];
            tensor<int32, [2]> var_11992 = const()[name = tensor<string, []>("op_11992"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_11994 = const()[name = tensor<string, []>("op_11994"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1193_pad_type_0 = const()[name = tensor<string, []>("lora_out_1193_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1193_pad_0 = const()[name = tensor<string, []>("lora_out_1193_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_1195_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1195_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(558522880)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_1195_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_11994, groups = var_11649, pad = lora_out_1193_pad_0, pad_type = lora_out_1193_pad_type_0, strides = var_11992, weight = lora_out_1195_weight_0_to_fp16, x = input_893_cast_fp16)[name = tensor<string, []>("lora_out_1195_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_895_cast_fp16 = add(x = pretrained_out_597_cast_fp16, y = lora_out_1195_cast_fp16)[name = tensor<string, []>("input_895_cast_fp16")];
            tensor<string, []> input_897_mode_0 = const()[name = tensor<string, []>("input_897_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_897_cast_fp16 = gelu(mode = input_897_mode_0, x = input_895_cast_fp16)[name = tensor<string, []>("input_897_cast_fp16")];
            tensor<int32, [2]> var_12006 = const()[name = tensor<string, []>("op_12006"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12008 = const()[name = tensor<string, []>("op_12008"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_599_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_599_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_599_pad_0 = const()[name = tensor<string, []>("pretrained_out_599_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_29_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(558686784))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(561963648))), name = tensor<string, []>("layers_29_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_29_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_29_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(561963776)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_599_cast_fp16 = conv(bias = layers_29_fc2_pretrained_bias_to_fp16, dilations = var_12008, groups = var_11649, pad = pretrained_out_599_pad_0, pad_type = pretrained_out_599_pad_type_0, strides = var_12006, weight = layers_29_fc2_pretrained_weight_to_fp16_palettized, x = input_897_cast_fp16)[name = tensor<string, []>("pretrained_out_599_cast_fp16")];
            tensor<int32, [2]> var_12012 = const()[name = tensor<string, []>("op_12012"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12014 = const()[name = tensor<string, []>("op_12014"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_899_pad_type_0 = const()[name = tensor<string, []>("input_899_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_899_pad_0 = const()[name = tensor<string, []>("input_899_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_29_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_29_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(561966400)))];
            tensor<fp16, [1, 16, 1, 1]> input_899_cast_fp16 = conv(dilations = var_12014, groups = var_11649, pad = input_899_pad_0, pad_type = input_899_pad_type_0, strides = var_12012, weight = layers_29_fc2_loraA_weight_to_fp16, x = input_897_cast_fp16)[name = tensor<string, []>("input_899_cast_fp16")];
            tensor<int32, [2]> var_12018 = const()[name = tensor<string, []>("op_12018"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12020 = const()[name = tensor<string, []>("op_12020"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1197_pad_type_0 = const()[name = tensor<string, []>("lora_out_1197_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1197_pad_0 = const()[name = tensor<string, []>("lora_out_1197_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1199_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1199_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(562130304)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1199_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_12020, groups = var_11649, pad = lora_out_1197_pad_0, pad_type = lora_out_1197_pad_type_0, strides = var_12018, weight = lora_out_1199_weight_0_to_fp16, x = input_899_cast_fp16)[name = tensor<string, []>("lora_out_1199_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_61_cast_fp16 = add(x = pretrained_out_599_cast_fp16, y = lora_out_1199_cast_fp16)[name = tensor<string, []>("hidden_states_61_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_181_cast_fp16 = add(x = inputs_179_cast_fp16, y = hidden_states_61_cast_fp16)[name = tensor<string, []>("inputs_181_cast_fp16")];
            tensor<int32, []> var_12036 = const()[name = tensor<string, []>("op_12036"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_12043 = const()[name = tensor<string, []>("op_12043"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_12044 = const()[name = tensor<string, []>("op_12044"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_12056 = const()[name = tensor<string, []>("op_12056"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_181_cast_fp16 = reduce_mean(axes = var_12056, keep_dims = var_12044, x = inputs_181_cast_fp16)[name = tensor<string, []>("channels_mean_181_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_181_cast_fp16 = sub(x = inputs_181_cast_fp16, y = channels_mean_181_cast_fp16)[name = tensor<string, []>("zero_mean_181_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_181_cast_fp16 = mul(x = zero_mean_181_cast_fp16, y = zero_mean_181_cast_fp16)[name = tensor<string, []>("zero_mean_sq_181_cast_fp16")];
            tensor<int32, [1]> var_12060 = const()[name = tensor<string, []>("op_12060"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_12061_cast_fp16 = reduce_mean(axes = var_12060, keep_dims = var_12044, x = zero_mean_sq_181_cast_fp16)[name = tensor<string, []>("op_12061_cast_fp16")];
            tensor<fp16, []> var_12062_to_fp16 = const()[name = tensor<string, []>("op_12062_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_12063_cast_fp16 = add(x = var_12061_cast_fp16, y = var_12062_to_fp16)[name = tensor<string, []>("op_12063_cast_fp16")];
            tensor<fp32, []> denom_181_epsilon_0 = const()[name = tensor<string, []>("denom_181_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_181_cast_fp16 = rsqrt(epsilon = denom_181_epsilon_0, x = var_12063_cast_fp16)[name = tensor<string, []>("denom_181_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_181_cast_fp16 = mul(x = zero_mean_181_cast_fp16, y = denom_181_cast_fp16)[name = tensor<string, []>("out_181_cast_fp16")];
            tensor<fp16, [1280]> obj_421_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_421_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(562171328)))];
            tensor<fp16, [1280]> obj_421_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_421_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(562173952)))];
            tensor<fp16, []> obj_421_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_421_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_421_cast_fp16 = batch_norm(beta = obj_421_beta_0_to_fp16, epsilon = obj_421_epsilon_0_to_fp16, gamma = obj_421_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_181_cast_fp16)[name = tensor<string, []>("obj_421_cast_fp16")];
            tensor<int32, [2]> var_12081 = const()[name = tensor<string, []>("op_12081"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12083 = const()[name = tensor<string, []>("op_12083"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_601_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_601_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_601_pad_0 = const()[name = tensor<string, []>("pretrained_out_601_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_30_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(562176576))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(562995840))), name = tensor<string, []>("layers_30_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_30_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_30_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(562995968)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_601_cast_fp16 = conv(bias = layers_30_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_12083, groups = var_12043, pad = pretrained_out_601_pad_0, pad_type = pretrained_out_601_pad_type_0, strides = var_12081, weight = layers_30_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_421_cast_fp16)[name = tensor<string, []>("pretrained_out_601_cast_fp16")];
            tensor<int32, [2]> var_12087 = const()[name = tensor<string, []>("op_12087"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12089 = const()[name = tensor<string, []>("op_12089"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_901_pad_type_0 = const()[name = tensor<string, []>("input_901_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_901_pad_0 = const()[name = tensor<string, []>("input_901_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_30_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_30_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(562998592)))];
            tensor<fp16, [1, 16, 1, 1]> input_901_cast_fp16 = conv(dilations = var_12089, groups = var_12043, pad = input_901_pad_0, pad_type = input_901_pad_type_0, strides = var_12087, weight = layers_30_self_attn_q_proj_loraA_weight_to_fp16, x = obj_421_cast_fp16)[name = tensor<string, []>("input_901_cast_fp16")];
            tensor<int32, [2]> var_12093 = const()[name = tensor<string, []>("op_12093"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12095 = const()[name = tensor<string, []>("op_12095"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1201_pad_type_0 = const()[name = tensor<string, []>("lora_out_1201_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1201_pad_0 = const()[name = tensor<string, []>("lora_out_1201_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1203_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1203_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(563039616)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1203_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_12095, groups = var_12043, pad = lora_out_1201_pad_0, pad_type = lora_out_1201_pad_type_0, strides = var_12093, weight = lora_out_1203_weight_0_to_fp16, x = input_901_cast_fp16)[name = tensor<string, []>("lora_out_1203_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_121_cast_fp16 = add(x = pretrained_out_601_cast_fp16, y = lora_out_1203_cast_fp16)[name = tensor<string, []>("query_121_cast_fp16")];
            tensor<int32, [2]> var_12105 = const()[name = tensor<string, []>("op_12105"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12107 = const()[name = tensor<string, []>("op_12107"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_603_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_603_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_603_pad_0 = const()[name = tensor<string, []>("pretrained_out_603_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_30_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(563080640))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(563899904))), name = tensor<string, []>("layers_30_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_603_cast_fp16 = conv(dilations = var_12107, groups = var_12043, pad = pretrained_out_603_pad_0, pad_type = pretrained_out_603_pad_type_0, strides = var_12105, weight = layers_30_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_421_cast_fp16)[name = tensor<string, []>("pretrained_out_603_cast_fp16")];
            tensor<int32, [2]> var_12111 = const()[name = tensor<string, []>("op_12111"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12113 = const()[name = tensor<string, []>("op_12113"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_903_pad_type_0 = const()[name = tensor<string, []>("input_903_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_903_pad_0 = const()[name = tensor<string, []>("input_903_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_30_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_30_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(563900032)))];
            tensor<fp16, [1, 16, 1, 1]> input_903_cast_fp16 = conv(dilations = var_12113, groups = var_12043, pad = input_903_pad_0, pad_type = input_903_pad_type_0, strides = var_12111, weight = layers_30_self_attn_k_proj_loraA_weight_to_fp16, x = obj_421_cast_fp16)[name = tensor<string, []>("input_903_cast_fp16")];
            tensor<int32, [2]> var_12117 = const()[name = tensor<string, []>("op_12117"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12119 = const()[name = tensor<string, []>("op_12119"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1205_pad_type_0 = const()[name = tensor<string, []>("lora_out_1205_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1205_pad_0 = const()[name = tensor<string, []>("lora_out_1205_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1207_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1207_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(563941056)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1207_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_12119, groups = var_12043, pad = lora_out_1205_pad_0, pad_type = lora_out_1205_pad_type_0, strides = var_12117, weight = lora_out_1207_weight_0_to_fp16, x = input_903_cast_fp16)[name = tensor<string, []>("lora_out_1207_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_61_cast_fp16 = add(x = pretrained_out_603_cast_fp16, y = lora_out_1207_cast_fp16)[name = tensor<string, []>("current_key_61_cast_fp16")];
            tensor<int32, [2]> var_12130 = const()[name = tensor<string, []>("op_12130"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12132 = const()[name = tensor<string, []>("op_12132"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_605_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_605_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_605_pad_0 = const()[name = tensor<string, []>("pretrained_out_605_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_30_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(563982080))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(564801344))), name = tensor<string, []>("layers_30_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_30_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_30_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(564801472)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_605_cast_fp16 = conv(bias = layers_30_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_12132, groups = var_12043, pad = pretrained_out_605_pad_0, pad_type = pretrained_out_605_pad_type_0, strides = var_12130, weight = layers_30_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_421_cast_fp16)[name = tensor<string, []>("pretrained_out_605_cast_fp16")];
            tensor<int32, [2]> var_12136 = const()[name = tensor<string, []>("op_12136"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12138 = const()[name = tensor<string, []>("op_12138"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_905_pad_type_0 = const()[name = tensor<string, []>("input_905_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_905_pad_0 = const()[name = tensor<string, []>("input_905_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_30_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_30_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(564804096)))];
            tensor<fp16, [1, 16, 1, 1]> input_905_cast_fp16 = conv(dilations = var_12138, groups = var_12043, pad = input_905_pad_0, pad_type = input_905_pad_type_0, strides = var_12136, weight = layers_30_self_attn_v_proj_loraA_weight_to_fp16, x = obj_421_cast_fp16)[name = tensor<string, []>("input_905_cast_fp16")];
            tensor<int32, [2]> var_12142 = const()[name = tensor<string, []>("op_12142"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12144 = const()[name = tensor<string, []>("op_12144"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1209_pad_type_0 = const()[name = tensor<string, []>("lora_out_1209_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1209_pad_0 = const()[name = tensor<string, []>("lora_out_1209_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1211_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1211_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(564845120)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1211_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_12144, groups = var_12043, pad = lora_out_1209_pad_0, pad_type = lora_out_1209_pad_type_0, strides = var_12142, weight = lora_out_1211_weight_0_to_fp16, x = input_905_cast_fp16)[name = tensor<string, []>("lora_out_1211_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_61_cast_fp16 = add(x = pretrained_out_605_cast_fp16, y = lora_out_1211_cast_fp16)[name = tensor<string, []>("current_value_61_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_12154_cast_fp16 = mul(x = current_key_61_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_12154_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_12156_cast_fp16 = mul(x = var_103_cast_fp16_30, y = var_295_cast_fp16)[name = tensor<string, []>("op_12156_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_121_cast_fp16 = add(x = var_12154_cast_fp16, y = var_12156_cast_fp16)[name = tensor<string, []>("key_121_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_12158_cast_fp16 = mul(x = current_value_61_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_12158_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_12160_cast_fp16 = mul(x = var_138_cast_fp16_30, y = var_295_cast_fp16)[name = tensor<string, []>("op_12160_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_121_cast_fp16 = add(x = var_12158_cast_fp16, y = var_12160_cast_fp16)[name = tensor<string, []>("value_121_cast_fp16")];
            tensor<int32, [4]> var_12163 = const()[name = tensor<string, []>("op_12163"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_12164_cast_fp16 = reshape(shape = var_12163, x = query_121_cast_fp16)[name = tensor<string, []>("op_12164_cast_fp16")];
            tensor<fp16, []> var_12165_to_fp16 = const()[name = tensor<string, []>("op_12165_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_12166_cast_fp16 = mul(x = var_12164_cast_fp16, y = var_12165_to_fp16)[name = tensor<string, []>("op_12166_cast_fp16")];
            tensor<int32, [4]> var_12167 = const()[name = tensor<string, []>("op_12167"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_12168_cast_fp16 = reshape(shape = var_12167, x = key_121_cast_fp16)[name = tensor<string, []>("op_12168_cast_fp16")];
            tensor<bool, []> mh_w_181_transpose_x_0 = const()[name = tensor<string, []>("mh_w_181_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_181_transpose_y_0 = const()[name = tensor<string, []>("mh_w_181_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_181_cast_fp16 = matmul(transpose_x = mh_w_181_transpose_x_0, transpose_y = mh_w_181_transpose_y_0, x = var_12166_cast_fp16, y = var_12168_cast_fp16)[name = tensor<string, []>("mh_w_181_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_183_cast_fp16 = add(x = mh_w_181_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_183_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_12176_cast_fp16 = softmax(axis = var_12036, x = mh_w_183_cast_fp16)[name = tensor<string, []>("op_12176_cast_fp16")];
            tensor<int32, [4]> var_12177 = const()[name = tensor<string, []>("op_12177"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_12178_cast_fp16 = reshape(shape = var_12177, x = value_121_cast_fp16)[name = tensor<string, []>("op_12178_cast_fp16")];
            tensor<bool, []> attn_121_transpose_x_0 = const()[name = tensor<string, []>("attn_121_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_121_transpose_y_0 = const()[name = tensor<string, []>("attn_121_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_121_cast_fp16 = matmul(transpose_x = attn_121_transpose_x_0, transpose_y = attn_121_transpose_y_0, x = var_12178_cast_fp16, y = var_12176_cast_fp16)[name = tensor<string, []>("attn_121_cast_fp16")];
            tensor<int32, [4]> var_12181 = const()[name = tensor<string, []>("op_12181"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_907_cast_fp16 = reshape(shape = var_12181, x = attn_121_cast_fp16)[name = tensor<string, []>("input_907_cast_fp16")];
            tensor<int32, [2]> var_12188 = const()[name = tensor<string, []>("op_12188"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12190 = const()[name = tensor<string, []>("op_12190"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_607_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_607_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_607_pad_0 = const()[name = tensor<string, []>("pretrained_out_607_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_30_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(564886144))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(565705408))), name = tensor<string, []>("layers_30_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_30_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_30_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(565705536)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_607_cast_fp16 = conv(bias = layers_30_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_12190, groups = var_12043, pad = pretrained_out_607_pad_0, pad_type = pretrained_out_607_pad_type_0, strides = var_12188, weight = layers_30_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_907_cast_fp16)[name = tensor<string, []>("pretrained_out_607_cast_fp16")];
            tensor<int32, [2]> var_12194 = const()[name = tensor<string, []>("op_12194"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12196 = const()[name = tensor<string, []>("op_12196"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_909_pad_type_0 = const()[name = tensor<string, []>("input_909_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_909_pad_0 = const()[name = tensor<string, []>("input_909_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_30_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_30_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(565708160)))];
            tensor<fp16, [1, 16, 1, 1]> input_909_cast_fp16 = conv(dilations = var_12196, groups = var_12043, pad = input_909_pad_0, pad_type = input_909_pad_type_0, strides = var_12194, weight = layers_30_self_attn_o_proj_loraA_weight_to_fp16, x = input_907_cast_fp16)[name = tensor<string, []>("input_909_cast_fp16")];
            tensor<int32, [2]> var_12200 = const()[name = tensor<string, []>("op_12200"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12202 = const()[name = tensor<string, []>("op_12202"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1213_pad_type_0 = const()[name = tensor<string, []>("lora_out_1213_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1213_pad_0 = const()[name = tensor<string, []>("lora_out_1213_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1215_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1215_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(565749184)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1215_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_12202, groups = var_12043, pad = lora_out_1213_pad_0, pad_type = lora_out_1213_pad_type_0, strides = var_12200, weight = lora_out_1215_weight_0_to_fp16, x = input_909_cast_fp16)[name = tensor<string, []>("lora_out_1215_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_427_cast_fp16 = add(x = pretrained_out_607_cast_fp16, y = lora_out_1215_cast_fp16)[name = tensor<string, []>("obj_427_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_183_cast_fp16 = add(x = inputs_181_cast_fp16, y = obj_427_cast_fp16)[name = tensor<string, []>("inputs_183_cast_fp16")];
            tensor<int32, [1]> var_12215 = const()[name = tensor<string, []>("op_12215"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_183_cast_fp16 = reduce_mean(axes = var_12215, keep_dims = var_12044, x = inputs_183_cast_fp16)[name = tensor<string, []>("channels_mean_183_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_183_cast_fp16 = sub(x = inputs_183_cast_fp16, y = channels_mean_183_cast_fp16)[name = tensor<string, []>("zero_mean_183_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_183_cast_fp16 = mul(x = zero_mean_183_cast_fp16, y = zero_mean_183_cast_fp16)[name = tensor<string, []>("zero_mean_sq_183_cast_fp16")];
            tensor<int32, [1]> var_12219 = const()[name = tensor<string, []>("op_12219"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_12220_cast_fp16 = reduce_mean(axes = var_12219, keep_dims = var_12044, x = zero_mean_sq_183_cast_fp16)[name = tensor<string, []>("op_12220_cast_fp16")];
            tensor<fp16, []> var_12221_to_fp16 = const()[name = tensor<string, []>("op_12221_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_12222_cast_fp16 = add(x = var_12220_cast_fp16, y = var_12221_to_fp16)[name = tensor<string, []>("op_12222_cast_fp16")];
            tensor<fp32, []> denom_183_epsilon_0 = const()[name = tensor<string, []>("denom_183_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_183_cast_fp16 = rsqrt(epsilon = denom_183_epsilon_0, x = var_12222_cast_fp16)[name = tensor<string, []>("denom_183_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_183_cast_fp16 = mul(x = zero_mean_183_cast_fp16, y = denom_183_cast_fp16)[name = tensor<string, []>("out_183_cast_fp16")];
            tensor<fp16, [1280]> obj_429_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_429_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(565790208)))];
            tensor<fp16, [1280]> obj_429_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_429_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(565792832)))];
            tensor<fp16, []> obj_429_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_429_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_429_cast_fp16 = batch_norm(beta = obj_429_beta_0_to_fp16, epsilon = obj_429_epsilon_0_to_fp16, gamma = obj_429_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_183_cast_fp16)[name = tensor<string, []>("obj_429_cast_fp16")];
            tensor<int32, [2]> var_12240 = const()[name = tensor<string, []>("op_12240"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12242 = const()[name = tensor<string, []>("op_12242"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_609_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_609_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_609_pad_0 = const()[name = tensor<string, []>("pretrained_out_609_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_30_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(565795456))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(566614720))), name = tensor<string, []>("layers_30_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_30_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_30_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(566614848)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_609_cast_fp16 = conv(bias = layers_30_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_12242, groups = var_12043, pad = pretrained_out_609_pad_0, pad_type = pretrained_out_609_pad_type_0, strides = var_12240, weight = layers_30_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_429_cast_fp16)[name = tensor<string, []>("pretrained_out_609_cast_fp16")];
            tensor<int32, [2]> var_12246 = const()[name = tensor<string, []>("op_12246"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12248 = const()[name = tensor<string, []>("op_12248"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_911_pad_type_0 = const()[name = tensor<string, []>("input_911_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_911_pad_0 = const()[name = tensor<string, []>("input_911_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_30_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_30_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(566617472)))];
            tensor<fp16, [1, 16, 1, 1]> input_911_cast_fp16 = conv(dilations = var_12248, groups = var_12043, pad = input_911_pad_0, pad_type = input_911_pad_type_0, strides = var_12246, weight = layers_30_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_429_cast_fp16)[name = tensor<string, []>("input_911_cast_fp16")];
            tensor<int32, [2]> var_12252 = const()[name = tensor<string, []>("op_12252"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12254 = const()[name = tensor<string, []>("op_12254"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1217_pad_type_0 = const()[name = tensor<string, []>("lora_out_1217_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1217_pad_0 = const()[name = tensor<string, []>("lora_out_1217_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1219_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1219_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(566658496)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1219_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_12254, groups = var_12043, pad = lora_out_1217_pad_0, pad_type = lora_out_1217_pad_type_0, strides = var_12252, weight = lora_out_1219_weight_0_to_fp16, x = input_911_cast_fp16)[name = tensor<string, []>("lora_out_1219_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_123_cast_fp16 = add(x = pretrained_out_609_cast_fp16, y = lora_out_1219_cast_fp16)[name = tensor<string, []>("query_123_cast_fp16")];
            tensor<int32, [2]> var_12264 = const()[name = tensor<string, []>("op_12264"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12266 = const()[name = tensor<string, []>("op_12266"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_611_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_611_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_611_pad_0 = const()[name = tensor<string, []>("pretrained_out_611_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_30_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(566699520))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(567518784))), name = tensor<string, []>("layers_30_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_611_cast_fp16 = conv(dilations = var_12266, groups = var_12043, pad = pretrained_out_611_pad_0, pad_type = pretrained_out_611_pad_type_0, strides = var_12264, weight = layers_30_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_611_cast_fp16")];
            tensor<int32, [2]> var_12270 = const()[name = tensor<string, []>("op_12270"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12272 = const()[name = tensor<string, []>("op_12272"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_913_pad_type_0 = const()[name = tensor<string, []>("input_913_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_913_pad_0 = const()[name = tensor<string, []>("input_913_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_30_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_30_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(567518912)))];
            tensor<fp16, [1, 16, 1, 1500]> input_913_cast_fp16 = conv(dilations = var_12272, groups = var_12043, pad = input_913_pad_0, pad_type = input_913_pad_type_0, strides = var_12270, weight = layers_30_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_913_cast_fp16")];
            tensor<int32, [2]> var_12276 = const()[name = tensor<string, []>("op_12276"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12278 = const()[name = tensor<string, []>("op_12278"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1221_pad_type_0 = const()[name = tensor<string, []>("lora_out_1221_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1221_pad_0 = const()[name = tensor<string, []>("lora_out_1221_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1223_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1223_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(567559936)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_1223_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_12278, groups = var_12043, pad = lora_out_1221_pad_0, pad_type = lora_out_1221_pad_type_0, strides = var_12276, weight = lora_out_1223_weight_0_to_fp16, x = input_913_cast_fp16)[name = tensor<string, []>("lora_out_1223_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_123_cast_fp16 = add(x = pretrained_out_611_cast_fp16, y = lora_out_1223_cast_fp16)[name = tensor<string, []>("key_123_cast_fp16")];
            tensor<int32, [2]> var_12289 = const()[name = tensor<string, []>("op_12289"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12291 = const()[name = tensor<string, []>("op_12291"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_613_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_613_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_613_pad_0 = const()[name = tensor<string, []>("pretrained_out_613_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_30_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(567600960))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(568420224))), name = tensor<string, []>("layers_30_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_30_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_30_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(568420352)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_613_cast_fp16 = conv(bias = layers_30_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_12291, groups = var_12043, pad = pretrained_out_613_pad_0, pad_type = pretrained_out_613_pad_type_0, strides = var_12289, weight = layers_30_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_613_cast_fp16")];
            tensor<int32, [2]> var_12295 = const()[name = tensor<string, []>("op_12295"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12297 = const()[name = tensor<string, []>("op_12297"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_915_pad_type_0 = const()[name = tensor<string, []>("input_915_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_915_pad_0 = const()[name = tensor<string, []>("input_915_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_30_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_30_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(568422976)))];
            tensor<fp16, [1, 16, 1, 1500]> input_915_cast_fp16 = conv(dilations = var_12297, groups = var_12043, pad = input_915_pad_0, pad_type = input_915_pad_type_0, strides = var_12295, weight = layers_30_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_915_cast_fp16")];
            tensor<int32, [2]> var_12301 = const()[name = tensor<string, []>("op_12301"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12303 = const()[name = tensor<string, []>("op_12303"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1225_pad_type_0 = const()[name = tensor<string, []>("lora_out_1225_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1225_pad_0 = const()[name = tensor<string, []>("lora_out_1225_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1227_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1227_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(568464000)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_1227_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_12303, groups = var_12043, pad = lora_out_1225_pad_0, pad_type = lora_out_1225_pad_type_0, strides = var_12301, weight = lora_out_1227_weight_0_to_fp16, x = input_915_cast_fp16)[name = tensor<string, []>("lora_out_1227_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_123_cast_fp16 = add(x = pretrained_out_613_cast_fp16, y = lora_out_1227_cast_fp16)[name = tensor<string, []>("value_123_cast_fp16")];
            tensor<int32, [4]> var_12310 = const()[name = tensor<string, []>("op_12310"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_12311_cast_fp16 = reshape(shape = var_12310, x = query_123_cast_fp16)[name = tensor<string, []>("op_12311_cast_fp16")];
            tensor<fp16, []> var_12312_to_fp16 = const()[name = tensor<string, []>("op_12312_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_12313_cast_fp16 = mul(x = var_12311_cast_fp16, y = var_12312_to_fp16)[name = tensor<string, []>("op_12313_cast_fp16")];
            tensor<int32, [4]> var_12314 = const()[name = tensor<string, []>("op_12314"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_12315_cast_fp16 = reshape(shape = var_12314, x = key_123_cast_fp16)[name = tensor<string, []>("op_12315_cast_fp16")];
            tensor<bool, []> mh_w_185_transpose_x_0 = const()[name = tensor<string, []>("mh_w_185_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_185_transpose_y_0 = const()[name = tensor<string, []>("mh_w_185_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_185_cast_fp16 = matmul(transpose_x = mh_w_185_transpose_x_0, transpose_y = mh_w_185_transpose_y_0, x = var_12313_cast_fp16, y = var_12315_cast_fp16)[name = tensor<string, []>("mh_w_185_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_433_cast_fp16 = softmax(axis = var_12036, x = mh_w_185_cast_fp16)[name = tensor<string, []>("obj_433_cast_fp16")];
            tensor<int32, [4]> var_12319 = const()[name = tensor<string, []>("op_12319"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_12320_cast_fp16 = reshape(shape = var_12319, x = value_123_cast_fp16)[name = tensor<string, []>("op_12320_cast_fp16")];
            tensor<bool, []> attn_123_transpose_x_0 = const()[name = tensor<string, []>("attn_123_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_123_transpose_y_0 = const()[name = tensor<string, []>("attn_123_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_123_cast_fp16 = matmul(transpose_x = attn_123_transpose_x_0, transpose_y = attn_123_transpose_y_0, x = var_12320_cast_fp16, y = obj_433_cast_fp16)[name = tensor<string, []>("attn_123_cast_fp16")];
            tensor<int32, [4]> var_12323 = const()[name = tensor<string, []>("op_12323"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_917_cast_fp16 = reshape(shape = var_12323, x = attn_123_cast_fp16)[name = tensor<string, []>("input_917_cast_fp16")];
            tensor<int32, [2]> var_12330 = const()[name = tensor<string, []>("op_12330"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12332 = const()[name = tensor<string, []>("op_12332"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_615_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_615_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_615_pad_0 = const()[name = tensor<string, []>("pretrained_out_615_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_30_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(568505024))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(569324288))), name = tensor<string, []>("layers_30_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_30_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_30_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(569324416)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_615_cast_fp16 = conv(bias = layers_30_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_12332, groups = var_12043, pad = pretrained_out_615_pad_0, pad_type = pretrained_out_615_pad_type_0, strides = var_12330, weight = layers_30_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_917_cast_fp16)[name = tensor<string, []>("pretrained_out_615_cast_fp16")];
            tensor<int32, [2]> var_12336 = const()[name = tensor<string, []>("op_12336"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12338 = const()[name = tensor<string, []>("op_12338"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_919_pad_type_0 = const()[name = tensor<string, []>("input_919_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_919_pad_0 = const()[name = tensor<string, []>("input_919_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_30_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_30_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(569327040)))];
            tensor<fp16, [1, 16, 1, 1]> input_919_cast_fp16 = conv(dilations = var_12338, groups = var_12043, pad = input_919_pad_0, pad_type = input_919_pad_type_0, strides = var_12336, weight = layers_30_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_917_cast_fp16)[name = tensor<string, []>("input_919_cast_fp16")];
            tensor<int32, [2]> var_12342 = const()[name = tensor<string, []>("op_12342"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12344 = const()[name = tensor<string, []>("op_12344"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1229_pad_type_0 = const()[name = tensor<string, []>("lora_out_1229_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1229_pad_0 = const()[name = tensor<string, []>("lora_out_1229_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1231_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1231_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(569368064)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1231_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_12344, groups = var_12043, pad = lora_out_1229_pad_0, pad_type = lora_out_1229_pad_type_0, strides = var_12342, weight = lora_out_1231_weight_0_to_fp16, x = input_919_cast_fp16)[name = tensor<string, []>("lora_out_1231_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_431_cast_fp16 = add(x = pretrained_out_615_cast_fp16, y = lora_out_1231_cast_fp16)[name = tensor<string, []>("obj_431_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_185_cast_fp16 = add(x = inputs_183_cast_fp16, y = obj_431_cast_fp16)[name = tensor<string, []>("inputs_185_cast_fp16")];
            tensor<int32, [1]> var_12353 = const()[name = tensor<string, []>("op_12353"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_185_cast_fp16 = reduce_mean(axes = var_12353, keep_dims = var_12044, x = inputs_185_cast_fp16)[name = tensor<string, []>("channels_mean_185_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_185_cast_fp16 = sub(x = inputs_185_cast_fp16, y = channels_mean_185_cast_fp16)[name = tensor<string, []>("zero_mean_185_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_185_cast_fp16 = mul(x = zero_mean_185_cast_fp16, y = zero_mean_185_cast_fp16)[name = tensor<string, []>("zero_mean_sq_185_cast_fp16")];
            tensor<int32, [1]> var_12357 = const()[name = tensor<string, []>("op_12357"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_12358_cast_fp16 = reduce_mean(axes = var_12357, keep_dims = var_12044, x = zero_mean_sq_185_cast_fp16)[name = tensor<string, []>("op_12358_cast_fp16")];
            tensor<fp16, []> var_12359_to_fp16 = const()[name = tensor<string, []>("op_12359_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_12360_cast_fp16 = add(x = var_12358_cast_fp16, y = var_12359_to_fp16)[name = tensor<string, []>("op_12360_cast_fp16")];
            tensor<fp32, []> denom_185_epsilon_0 = const()[name = tensor<string, []>("denom_185_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_185_cast_fp16 = rsqrt(epsilon = denom_185_epsilon_0, x = var_12360_cast_fp16)[name = tensor<string, []>("denom_185_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_185_cast_fp16 = mul(x = zero_mean_185_cast_fp16, y = denom_185_cast_fp16)[name = tensor<string, []>("out_185_cast_fp16")];
            tensor<fp16, [1280]> input_921_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_921_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(569409088)))];
            tensor<fp16, [1280]> input_921_beta_0_to_fp16 = const()[name = tensor<string, []>("input_921_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(569411712)))];
            tensor<fp16, []> input_921_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_921_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_921_cast_fp16 = batch_norm(beta = input_921_beta_0_to_fp16, epsilon = input_921_epsilon_0_to_fp16, gamma = input_921_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_185_cast_fp16)[name = tensor<string, []>("input_921_cast_fp16")];
            tensor<int32, [2]> var_12374 = const()[name = tensor<string, []>("op_12374"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12376 = const()[name = tensor<string, []>("op_12376"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_617_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_617_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_617_pad_0 = const()[name = tensor<string, []>("pretrained_out_617_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_30_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(569414336))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(572691200))), name = tensor<string, []>("layers_30_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_30_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_30_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(572691328)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_617_cast_fp16 = conv(bias = layers_30_fc1_pretrained_bias_to_fp16, dilations = var_12376, groups = var_12043, pad = pretrained_out_617_pad_0, pad_type = pretrained_out_617_pad_type_0, strides = var_12374, weight = layers_30_fc1_pretrained_weight_to_fp16_palettized, x = input_921_cast_fp16)[name = tensor<string, []>("pretrained_out_617_cast_fp16")];
            tensor<int32, [2]> var_12380 = const()[name = tensor<string, []>("op_12380"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12382 = const()[name = tensor<string, []>("op_12382"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_923_pad_type_0 = const()[name = tensor<string, []>("input_923_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_923_pad_0 = const()[name = tensor<string, []>("input_923_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_30_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_30_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(572701632)))];
            tensor<fp16, [1, 16, 1, 1]> input_923_cast_fp16 = conv(dilations = var_12382, groups = var_12043, pad = input_923_pad_0, pad_type = input_923_pad_type_0, strides = var_12380, weight = layers_30_fc1_loraA_weight_to_fp16, x = input_921_cast_fp16)[name = tensor<string, []>("input_923_cast_fp16")];
            tensor<int32, [2]> var_12386 = const()[name = tensor<string, []>("op_12386"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12388 = const()[name = tensor<string, []>("op_12388"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1233_pad_type_0 = const()[name = tensor<string, []>("lora_out_1233_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1233_pad_0 = const()[name = tensor<string, []>("lora_out_1233_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_1235_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1235_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(572742656)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_1235_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_12388, groups = var_12043, pad = lora_out_1233_pad_0, pad_type = lora_out_1233_pad_type_0, strides = var_12386, weight = lora_out_1235_weight_0_to_fp16, x = input_923_cast_fp16)[name = tensor<string, []>("lora_out_1235_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_925_cast_fp16 = add(x = pretrained_out_617_cast_fp16, y = lora_out_1235_cast_fp16)[name = tensor<string, []>("input_925_cast_fp16")];
            tensor<string, []> input_927_mode_0 = const()[name = tensor<string, []>("input_927_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_927_cast_fp16 = gelu(mode = input_927_mode_0, x = input_925_cast_fp16)[name = tensor<string, []>("input_927_cast_fp16")];
            tensor<int32, [2]> var_12400 = const()[name = tensor<string, []>("op_12400"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12402 = const()[name = tensor<string, []>("op_12402"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_619_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_619_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_619_pad_0 = const()[name = tensor<string, []>("pretrained_out_619_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_30_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(572906560))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(576183424))), name = tensor<string, []>("layers_30_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_30_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_30_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(576183552)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_619_cast_fp16 = conv(bias = layers_30_fc2_pretrained_bias_to_fp16, dilations = var_12402, groups = var_12043, pad = pretrained_out_619_pad_0, pad_type = pretrained_out_619_pad_type_0, strides = var_12400, weight = layers_30_fc2_pretrained_weight_to_fp16_palettized, x = input_927_cast_fp16)[name = tensor<string, []>("pretrained_out_619_cast_fp16")];
            tensor<int32, [2]> var_12406 = const()[name = tensor<string, []>("op_12406"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12408 = const()[name = tensor<string, []>("op_12408"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_929_pad_type_0 = const()[name = tensor<string, []>("input_929_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_929_pad_0 = const()[name = tensor<string, []>("input_929_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_30_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_30_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(576186176)))];
            tensor<fp16, [1, 16, 1, 1]> input_929_cast_fp16 = conv(dilations = var_12408, groups = var_12043, pad = input_929_pad_0, pad_type = input_929_pad_type_0, strides = var_12406, weight = layers_30_fc2_loraA_weight_to_fp16, x = input_927_cast_fp16)[name = tensor<string, []>("input_929_cast_fp16")];
            tensor<int32, [2]> var_12412 = const()[name = tensor<string, []>("op_12412"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12414 = const()[name = tensor<string, []>("op_12414"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1237_pad_type_0 = const()[name = tensor<string, []>("lora_out_1237_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1237_pad_0 = const()[name = tensor<string, []>("lora_out_1237_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1239_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1239_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(576350080)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1239_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_12414, groups = var_12043, pad = lora_out_1237_pad_0, pad_type = lora_out_1237_pad_type_0, strides = var_12412, weight = lora_out_1239_weight_0_to_fp16, x = input_929_cast_fp16)[name = tensor<string, []>("lora_out_1239_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_63_cast_fp16 = add(x = pretrained_out_619_cast_fp16, y = lora_out_1239_cast_fp16)[name = tensor<string, []>("hidden_states_63_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_187_cast_fp16 = add(x = inputs_185_cast_fp16, y = hidden_states_63_cast_fp16)[name = tensor<string, []>("inputs_187_cast_fp16")];
            tensor<int32, []> var_12430 = const()[name = tensor<string, []>("op_12430"), val = tensor<int32, []>(3)];
            tensor<int32, []> var_12437 = const()[name = tensor<string, []>("op_12437"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_12438 = const()[name = tensor<string, []>("op_12438"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_12450 = const()[name = tensor<string, []>("op_12450"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_187_cast_fp16 = reduce_mean(axes = var_12450, keep_dims = var_12438, x = inputs_187_cast_fp16)[name = tensor<string, []>("channels_mean_187_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_187_cast_fp16 = sub(x = inputs_187_cast_fp16, y = channels_mean_187_cast_fp16)[name = tensor<string, []>("zero_mean_187_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_187_cast_fp16 = mul(x = zero_mean_187_cast_fp16, y = zero_mean_187_cast_fp16)[name = tensor<string, []>("zero_mean_sq_187_cast_fp16")];
            tensor<int32, [1]> var_12454 = const()[name = tensor<string, []>("op_12454"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_12455_cast_fp16 = reduce_mean(axes = var_12454, keep_dims = var_12438, x = zero_mean_sq_187_cast_fp16)[name = tensor<string, []>("op_12455_cast_fp16")];
            tensor<fp16, []> var_12456_to_fp16 = const()[name = tensor<string, []>("op_12456_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_12457_cast_fp16 = add(x = var_12455_cast_fp16, y = var_12456_to_fp16)[name = tensor<string, []>("op_12457_cast_fp16")];
            tensor<fp32, []> denom_187_epsilon_0 = const()[name = tensor<string, []>("denom_187_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_187_cast_fp16 = rsqrt(epsilon = denom_187_epsilon_0, x = var_12457_cast_fp16)[name = tensor<string, []>("denom_187_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_187_cast_fp16 = mul(x = zero_mean_187_cast_fp16, y = denom_187_cast_fp16)[name = tensor<string, []>("out_187_cast_fp16")];
            tensor<fp16, [1280]> obj_435_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_435_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(576391104)))];
            tensor<fp16, [1280]> obj_435_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_435_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(576393728)))];
            tensor<fp16, []> obj_435_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_435_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_435_cast_fp16 = batch_norm(beta = obj_435_beta_0_to_fp16, epsilon = obj_435_epsilon_0_to_fp16, gamma = obj_435_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_187_cast_fp16)[name = tensor<string, []>("obj_435_cast_fp16")];
            tensor<int32, [2]> var_12475 = const()[name = tensor<string, []>("op_12475"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12477 = const()[name = tensor<string, []>("op_12477"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_621_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_621_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_621_pad_0 = const()[name = tensor<string, []>("pretrained_out_621_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_31_self_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(576396352))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(577215616))), name = tensor<string, []>("layers_31_self_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_31_self_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_31_self_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(577215744)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_621_cast_fp16 = conv(bias = layers_31_self_attn_q_proj_pretrained_bias_to_fp16, dilations = var_12477, groups = var_12437, pad = pretrained_out_621_pad_0, pad_type = pretrained_out_621_pad_type_0, strides = var_12475, weight = layers_31_self_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_435_cast_fp16)[name = tensor<string, []>("pretrained_out_621_cast_fp16")];
            tensor<int32, [2]> var_12481 = const()[name = tensor<string, []>("op_12481"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12483 = const()[name = tensor<string, []>("op_12483"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_931_pad_type_0 = const()[name = tensor<string, []>("input_931_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_931_pad_0 = const()[name = tensor<string, []>("input_931_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_31_self_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_31_self_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(577218368)))];
            tensor<fp16, [1, 16, 1, 1]> input_931_cast_fp16 = conv(dilations = var_12483, groups = var_12437, pad = input_931_pad_0, pad_type = input_931_pad_type_0, strides = var_12481, weight = layers_31_self_attn_q_proj_loraA_weight_to_fp16, x = obj_435_cast_fp16)[name = tensor<string, []>("input_931_cast_fp16")];
            tensor<int32, [2]> var_12487 = const()[name = tensor<string, []>("op_12487"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12489 = const()[name = tensor<string, []>("op_12489"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1241_pad_type_0 = const()[name = tensor<string, []>("lora_out_1241_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1241_pad_0 = const()[name = tensor<string, []>("lora_out_1241_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1243_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1243_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(577259392)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1243_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_12489, groups = var_12437, pad = lora_out_1241_pad_0, pad_type = lora_out_1241_pad_type_0, strides = var_12487, weight = lora_out_1243_weight_0_to_fp16, x = input_931_cast_fp16)[name = tensor<string, []>("lora_out_1243_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_125_cast_fp16 = add(x = pretrained_out_621_cast_fp16, y = lora_out_1243_cast_fp16)[name = tensor<string, []>("query_125_cast_fp16")];
            tensor<int32, [2]> var_12499 = const()[name = tensor<string, []>("op_12499"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12501 = const()[name = tensor<string, []>("op_12501"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_623_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_623_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_623_pad_0 = const()[name = tensor<string, []>("pretrained_out_623_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_31_self_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(577300416))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(578119680))), name = tensor<string, []>("layers_31_self_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_623_cast_fp16 = conv(dilations = var_12501, groups = var_12437, pad = pretrained_out_623_pad_0, pad_type = pretrained_out_623_pad_type_0, strides = var_12499, weight = layers_31_self_attn_k_proj_pretrained_weight_to_fp16_palettized, x = obj_435_cast_fp16)[name = tensor<string, []>("pretrained_out_623_cast_fp16")];
            tensor<int32, [2]> var_12505 = const()[name = tensor<string, []>("op_12505"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12507 = const()[name = tensor<string, []>("op_12507"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_933_pad_type_0 = const()[name = tensor<string, []>("input_933_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_933_pad_0 = const()[name = tensor<string, []>("input_933_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_31_self_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_31_self_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(578119808)))];
            tensor<fp16, [1, 16, 1, 1]> input_933_cast_fp16 = conv(dilations = var_12507, groups = var_12437, pad = input_933_pad_0, pad_type = input_933_pad_type_0, strides = var_12505, weight = layers_31_self_attn_k_proj_loraA_weight_to_fp16, x = obj_435_cast_fp16)[name = tensor<string, []>("input_933_cast_fp16")];
            tensor<int32, [2]> var_12511 = const()[name = tensor<string, []>("op_12511"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12513 = const()[name = tensor<string, []>("op_12513"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1245_pad_type_0 = const()[name = tensor<string, []>("lora_out_1245_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1245_pad_0 = const()[name = tensor<string, []>("lora_out_1245_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1247_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1247_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(578160832)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1247_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_12513, groups = var_12437, pad = lora_out_1245_pad_0, pad_type = lora_out_1245_pad_type_0, strides = var_12511, weight = lora_out_1247_weight_0_to_fp16, x = input_933_cast_fp16)[name = tensor<string, []>("lora_out_1247_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_key_cast_fp16 = add(x = pretrained_out_623_cast_fp16, y = lora_out_1247_cast_fp16)[name = tensor<string, []>("current_key_cast_fp16")];
            tensor<int32, [2]> var_12524 = const()[name = tensor<string, []>("op_12524"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12526 = const()[name = tensor<string, []>("op_12526"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_625_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_625_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_625_pad_0 = const()[name = tensor<string, []>("pretrained_out_625_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_31_self_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(578201856))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(579021120))), name = tensor<string, []>("layers_31_self_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_31_self_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_31_self_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(579021248)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_625_cast_fp16 = conv(bias = layers_31_self_attn_v_proj_pretrained_bias_to_fp16, dilations = var_12526, groups = var_12437, pad = pretrained_out_625_pad_0, pad_type = pretrained_out_625_pad_type_0, strides = var_12524, weight = layers_31_self_attn_v_proj_pretrained_weight_to_fp16_palettized, x = obj_435_cast_fp16)[name = tensor<string, []>("pretrained_out_625_cast_fp16")];
            tensor<int32, [2]> var_12530 = const()[name = tensor<string, []>("op_12530"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12532 = const()[name = tensor<string, []>("op_12532"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_935_pad_type_0 = const()[name = tensor<string, []>("input_935_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_935_pad_0 = const()[name = tensor<string, []>("input_935_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_31_self_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_31_self_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(579023872)))];
            tensor<fp16, [1, 16, 1, 1]> input_935_cast_fp16 = conv(dilations = var_12532, groups = var_12437, pad = input_935_pad_0, pad_type = input_935_pad_type_0, strides = var_12530, weight = layers_31_self_attn_v_proj_loraA_weight_to_fp16, x = obj_435_cast_fp16)[name = tensor<string, []>("input_935_cast_fp16")];
            tensor<int32, [2]> var_12536 = const()[name = tensor<string, []>("op_12536"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12538 = const()[name = tensor<string, []>("op_12538"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1249_pad_type_0 = const()[name = tensor<string, []>("lora_out_1249_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1249_pad_0 = const()[name = tensor<string, []>("lora_out_1249_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1251_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1251_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(579064896)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1251_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_12538, groups = var_12437, pad = lora_out_1249_pad_0, pad_type = lora_out_1249_pad_type_0, strides = var_12536, weight = lora_out_1251_weight_0_to_fp16, x = input_935_cast_fp16)[name = tensor<string, []>("lora_out_1251_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> current_value_cast_fp16 = add(x = pretrained_out_625_cast_fp16, y = lora_out_1251_cast_fp16)[name = tensor<string, []>("current_value_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_12548_cast_fp16 = mul(x = current_key_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_12548_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_12550_cast_fp16 = mul(x = var_103_cast_fp16_31, y = var_295_cast_fp16)[name = tensor<string, []>("op_12550_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> key_125_cast_fp16 = add(x = var_12548_cast_fp16, y = var_12550_cast_fp16)[name = tensor<string, []>("key_125_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_12552_cast_fp16 = mul(x = current_value_cast_fp16, y = var_292_cast_fp16)[name = tensor<string, []>("op_12552_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> var_12554_cast_fp16 = mul(x = var_138_cast_fp16_31, y = var_295_cast_fp16)[name = tensor<string, []>("op_12554_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 448]> value_125_cast_fp16 = add(x = var_12552_cast_fp16, y = var_12554_cast_fp16)[name = tensor<string, []>("value_125_cast_fp16")];
            tensor<int32, [4]> var_12557 = const()[name = tensor<string, []>("op_12557"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_12558_cast_fp16 = reshape(shape = var_12557, x = query_125_cast_fp16)[name = tensor<string, []>("op_12558_cast_fp16")];
            tensor<fp16, []> var_12559_to_fp16 = const()[name = tensor<string, []>("op_12559_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_12560_cast_fp16 = mul(x = var_12558_cast_fp16, y = var_12559_to_fp16)[name = tensor<string, []>("op_12560_cast_fp16")];
            tensor<int32, [4]> var_12561 = const()[name = tensor<string, []>("op_12561"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_12562_cast_fp16 = reshape(shape = var_12561, x = key_125_cast_fp16)[name = tensor<string, []>("op_12562_cast_fp16")];
            tensor<bool, []> mh_w_187_transpose_x_0 = const()[name = tensor<string, []>("mh_w_187_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_187_transpose_y_0 = const()[name = tensor<string, []>("mh_w_187_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 448]> mh_w_187_cast_fp16 = matmul(transpose_x = mh_w_187_transpose_x_0, transpose_y = mh_w_187_transpose_y_0, x = var_12560_cast_fp16, y = var_12562_cast_fp16)[name = tensor<string, []>("mh_w_187_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> mh_w_189_cast_fp16 = add(x = mh_w_187_cast_fp16, y = var_313_cast_fp16)[name = tensor<string, []>("mh_w_189_cast_fp16")];
            tensor<fp16, [1, 20, 1, 448]> var_12570_cast_fp16 = softmax(axis = var_12430, x = mh_w_189_cast_fp16)[name = tensor<string, []>("op_12570_cast_fp16")];
            tensor<int32, [4]> var_12571 = const()[name = tensor<string, []>("op_12571"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 448]> var_12572_cast_fp16 = reshape(shape = var_12571, x = value_125_cast_fp16)[name = tensor<string, []>("op_12572_cast_fp16")];
            tensor<bool, []> attn_125_transpose_x_0 = const()[name = tensor<string, []>("attn_125_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_125_transpose_y_0 = const()[name = tensor<string, []>("attn_125_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_125_cast_fp16 = matmul(transpose_x = attn_125_transpose_x_0, transpose_y = attn_125_transpose_y_0, x = var_12572_cast_fp16, y = var_12570_cast_fp16)[name = tensor<string, []>("attn_125_cast_fp16")];
            tensor<int32, [4]> var_12575 = const()[name = tensor<string, []>("op_12575"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_937_cast_fp16 = reshape(shape = var_12575, x = attn_125_cast_fp16)[name = tensor<string, []>("input_937_cast_fp16")];
            tensor<int32, [2]> var_12582 = const()[name = tensor<string, []>("op_12582"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12584 = const()[name = tensor<string, []>("op_12584"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_627_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_627_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_627_pad_0 = const()[name = tensor<string, []>("pretrained_out_627_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_31_self_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(579105920))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(579925184))), name = tensor<string, []>("layers_31_self_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_31_self_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_31_self_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(579925312)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_627_cast_fp16 = conv(bias = layers_31_self_attn_o_proj_pretrained_bias_to_fp16, dilations = var_12584, groups = var_12437, pad = pretrained_out_627_pad_0, pad_type = pretrained_out_627_pad_type_0, strides = var_12582, weight = layers_31_self_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_937_cast_fp16)[name = tensor<string, []>("pretrained_out_627_cast_fp16")];
            tensor<int32, [2]> var_12588 = const()[name = tensor<string, []>("op_12588"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12590 = const()[name = tensor<string, []>("op_12590"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_939_pad_type_0 = const()[name = tensor<string, []>("input_939_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_939_pad_0 = const()[name = tensor<string, []>("input_939_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_31_self_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_31_self_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(579927936)))];
            tensor<fp16, [1, 16, 1, 1]> input_939_cast_fp16 = conv(dilations = var_12590, groups = var_12437, pad = input_939_pad_0, pad_type = input_939_pad_type_0, strides = var_12588, weight = layers_31_self_attn_o_proj_loraA_weight_to_fp16, x = input_937_cast_fp16)[name = tensor<string, []>("input_939_cast_fp16")];
            tensor<int32, [2]> var_12594 = const()[name = tensor<string, []>("op_12594"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12596 = const()[name = tensor<string, []>("op_12596"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1253_pad_type_0 = const()[name = tensor<string, []>("lora_out_1253_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1253_pad_0 = const()[name = tensor<string, []>("lora_out_1253_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1255_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1255_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(579968960)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1255_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_12596, groups = var_12437, pad = lora_out_1253_pad_0, pad_type = lora_out_1253_pad_type_0, strides = var_12594, weight = lora_out_1255_weight_0_to_fp16, x = input_939_cast_fp16)[name = tensor<string, []>("lora_out_1255_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_441_cast_fp16 = add(x = pretrained_out_627_cast_fp16, y = lora_out_1255_cast_fp16)[name = tensor<string, []>("obj_441_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_189_cast_fp16 = add(x = inputs_187_cast_fp16, y = obj_441_cast_fp16)[name = tensor<string, []>("inputs_189_cast_fp16")];
            tensor<int32, [1]> var_12609 = const()[name = tensor<string, []>("op_12609"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_189_cast_fp16 = reduce_mean(axes = var_12609, keep_dims = var_12438, x = inputs_189_cast_fp16)[name = tensor<string, []>("channels_mean_189_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_189_cast_fp16 = sub(x = inputs_189_cast_fp16, y = channels_mean_189_cast_fp16)[name = tensor<string, []>("zero_mean_189_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_189_cast_fp16 = mul(x = zero_mean_189_cast_fp16, y = zero_mean_189_cast_fp16)[name = tensor<string, []>("zero_mean_sq_189_cast_fp16")];
            tensor<int32, [1]> var_12613 = const()[name = tensor<string, []>("op_12613"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_12614_cast_fp16 = reduce_mean(axes = var_12613, keep_dims = var_12438, x = zero_mean_sq_189_cast_fp16)[name = tensor<string, []>("op_12614_cast_fp16")];
            tensor<fp16, []> var_12615_to_fp16 = const()[name = tensor<string, []>("op_12615_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_12616_cast_fp16 = add(x = var_12614_cast_fp16, y = var_12615_to_fp16)[name = tensor<string, []>("op_12616_cast_fp16")];
            tensor<fp32, []> denom_189_epsilon_0 = const()[name = tensor<string, []>("denom_189_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_189_cast_fp16 = rsqrt(epsilon = denom_189_epsilon_0, x = var_12616_cast_fp16)[name = tensor<string, []>("denom_189_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_189_cast_fp16 = mul(x = zero_mean_189_cast_fp16, y = denom_189_cast_fp16)[name = tensor<string, []>("out_189_cast_fp16")];
            tensor<fp16, [1280]> obj_443_gamma_0_to_fp16 = const()[name = tensor<string, []>("obj_443_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(580009984)))];
            tensor<fp16, [1280]> obj_443_beta_0_to_fp16 = const()[name = tensor<string, []>("obj_443_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(580012608)))];
            tensor<fp16, []> obj_443_epsilon_0_to_fp16 = const()[name = tensor<string, []>("obj_443_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> obj_443_cast_fp16 = batch_norm(beta = obj_443_beta_0_to_fp16, epsilon = obj_443_epsilon_0_to_fp16, gamma = obj_443_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_189_cast_fp16)[name = tensor<string, []>("obj_443_cast_fp16")];
            tensor<int32, [2]> var_12634 = const()[name = tensor<string, []>("op_12634"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12636 = const()[name = tensor<string, []>("op_12636"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_629_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_629_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_629_pad_0 = const()[name = tensor<string, []>("pretrained_out_629_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_31_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(580015232))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(580834496))), name = tensor<string, []>("layers_31_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_31_encoder_attn_q_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_31_encoder_attn_q_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(580834624)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_629_cast_fp16 = conv(bias = layers_31_encoder_attn_q_proj_pretrained_bias_to_fp16, dilations = var_12636, groups = var_12437, pad = pretrained_out_629_pad_0, pad_type = pretrained_out_629_pad_type_0, strides = var_12634, weight = layers_31_encoder_attn_q_proj_pretrained_weight_to_fp16_palettized, x = obj_443_cast_fp16)[name = tensor<string, []>("pretrained_out_629_cast_fp16")];
            tensor<int32, [2]> var_12640 = const()[name = tensor<string, []>("op_12640"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12642 = const()[name = tensor<string, []>("op_12642"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_941_pad_type_0 = const()[name = tensor<string, []>("input_941_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_941_pad_0 = const()[name = tensor<string, []>("input_941_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_31_encoder_attn_q_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_31_encoder_attn_q_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(580837248)))];
            tensor<fp16, [1, 16, 1, 1]> input_941_cast_fp16 = conv(dilations = var_12642, groups = var_12437, pad = input_941_pad_0, pad_type = input_941_pad_type_0, strides = var_12640, weight = layers_31_encoder_attn_q_proj_loraA_weight_to_fp16, x = obj_443_cast_fp16)[name = tensor<string, []>("input_941_cast_fp16")];
            tensor<int32, [2]> var_12646 = const()[name = tensor<string, []>("op_12646"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12648 = const()[name = tensor<string, []>("op_12648"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1257_pad_type_0 = const()[name = tensor<string, []>("lora_out_1257_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1257_pad_0 = const()[name = tensor<string, []>("lora_out_1257_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1259_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1259_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(580878272)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1259_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_12648, groups = var_12437, pad = lora_out_1257_pad_0, pad_type = lora_out_1257_pad_type_0, strides = var_12646, weight = lora_out_1259_weight_0_to_fp16, x = input_941_cast_fp16)[name = tensor<string, []>("lora_out_1259_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> query_cast_fp16 = add(x = pretrained_out_629_cast_fp16, y = lora_out_1259_cast_fp16)[name = tensor<string, []>("query_cast_fp16")];
            tensor<int32, [2]> var_12658 = const()[name = tensor<string, []>("op_12658"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12660 = const()[name = tensor<string, []>("op_12660"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_631_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_631_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_631_pad_0 = const()[name = tensor<string, []>("pretrained_out_631_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_31_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(580919296))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(581738560))), name = tensor<string, []>("layers_31_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_631_cast_fp16 = conv(dilations = var_12660, groups = var_12437, pad = pretrained_out_631_pad_0, pad_type = pretrained_out_631_pad_type_0, strides = var_12658, weight = layers_31_encoder_attn_k_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_631_cast_fp16")];
            tensor<int32, [2]> var_12664 = const()[name = tensor<string, []>("op_12664"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12666 = const()[name = tensor<string, []>("op_12666"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_943_pad_type_0 = const()[name = tensor<string, []>("input_943_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_943_pad_0 = const()[name = tensor<string, []>("input_943_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_31_encoder_attn_k_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_31_encoder_attn_k_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(581738688)))];
            tensor<fp16, [1, 16, 1, 1500]> input_943_cast_fp16 = conv(dilations = var_12666, groups = var_12437, pad = input_943_pad_0, pad_type = input_943_pad_type_0, strides = var_12664, weight = layers_31_encoder_attn_k_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_943_cast_fp16")];
            tensor<int32, [2]> var_12670 = const()[name = tensor<string, []>("op_12670"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12672 = const()[name = tensor<string, []>("op_12672"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1261_pad_type_0 = const()[name = tensor<string, []>("lora_out_1261_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1261_pad_0 = const()[name = tensor<string, []>("lora_out_1261_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1263_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1263_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(581779712)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_1263_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_12672, groups = var_12437, pad = lora_out_1261_pad_0, pad_type = lora_out_1261_pad_type_0, strides = var_12670, weight = lora_out_1263_weight_0_to_fp16, x = input_943_cast_fp16)[name = tensor<string, []>("lora_out_1263_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> key_cast_fp16 = add(x = pretrained_out_631_cast_fp16, y = lora_out_1263_cast_fp16)[name = tensor<string, []>("key_cast_fp16")];
            tensor<int32, [2]> var_12683 = const()[name = tensor<string, []>("op_12683"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12685 = const()[name = tensor<string, []>("op_12685"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_633_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_633_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_633_pad_0 = const()[name = tensor<string, []>("pretrained_out_633_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_31_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(581820736))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(582640000))), name = tensor<string, []>("layers_31_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_31_encoder_attn_v_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_31_encoder_attn_v_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(582640128)))];
            tensor<fp16, [1, 1280, 1, 1500]> pretrained_out_633_cast_fp16 = conv(bias = layers_31_encoder_attn_v_proj_pretrained_bias_to_fp16, dilations = var_12685, groups = var_12437, pad = pretrained_out_633_pad_0, pad_type = pretrained_out_633_pad_type_0, strides = var_12683, weight = layers_31_encoder_attn_v_proj_pretrained_weight_to_fp16_palettized, x = encoder_output_embeds)[name = tensor<string, []>("pretrained_out_633_cast_fp16")];
            tensor<int32, [2]> var_12689 = const()[name = tensor<string, []>("op_12689"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12691 = const()[name = tensor<string, []>("op_12691"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_945_pad_type_0 = const()[name = tensor<string, []>("input_945_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_945_pad_0 = const()[name = tensor<string, []>("input_945_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_31_encoder_attn_v_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_31_encoder_attn_v_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(582642752)))];
            tensor<fp16, [1, 16, 1, 1500]> input_945_cast_fp16 = conv(dilations = var_12691, groups = var_12437, pad = input_945_pad_0, pad_type = input_945_pad_type_0, strides = var_12689, weight = layers_31_encoder_attn_v_proj_loraA_weight_to_fp16, x = encoder_output_embeds)[name = tensor<string, []>("input_945_cast_fp16")];
            tensor<int32, [2]> var_12695 = const()[name = tensor<string, []>("op_12695"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12697 = const()[name = tensor<string, []>("op_12697"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1265_pad_type_0 = const()[name = tensor<string, []>("lora_out_1265_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1265_pad_0 = const()[name = tensor<string, []>("lora_out_1265_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1267_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1267_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(582683776)))];
            tensor<fp16, [1, 1280, 1, 1500]> lora_out_1267_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_12697, groups = var_12437, pad = lora_out_1265_pad_0, pad_type = lora_out_1265_pad_type_0, strides = var_12695, weight = lora_out_1267_weight_0_to_fp16, x = input_945_cast_fp16)[name = tensor<string, []>("lora_out_1267_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1500]> value_cast_fp16 = add(x = pretrained_out_633_cast_fp16, y = lora_out_1267_cast_fp16)[name = tensor<string, []>("value_cast_fp16")];
            tensor<int32, [4]> var_12704 = const()[name = tensor<string, []>("op_12704"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1]> var_12705_cast_fp16 = reshape(shape = var_12704, x = query_cast_fp16)[name = tensor<string, []>("op_12705_cast_fp16")];
            tensor<fp16, []> var_12706_to_fp16 = const()[name = tensor<string, []>("op_12706_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 20, 64, 1]> var_12707_cast_fp16 = mul(x = var_12705_cast_fp16, y = var_12706_to_fp16)[name = tensor<string, []>("op_12707_cast_fp16")];
            tensor<int32, [4]> var_12708 = const()[name = tensor<string, []>("op_12708"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_12709_cast_fp16 = reshape(shape = var_12708, x = key_cast_fp16)[name = tensor<string, []>("op_12709_cast_fp16")];
            tensor<bool, []> mh_w_transpose_x_0 = const()[name = tensor<string, []>("mh_w_transpose_x_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> mh_w_transpose_y_0 = const()[name = tensor<string, []>("mh_w_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 20, 1, 1500]> mh_w_cast_fp16 = matmul(transpose_x = mh_w_transpose_x_0, transpose_y = mh_w_transpose_y_0, x = var_12707_cast_fp16, y = var_12709_cast_fp16)[name = tensor<string, []>("mh_w_cast_fp16")];
            tensor<fp16, [1, 20, 1, 1500]> obj_447_cast_fp16 = softmax(axis = var_12430, x = mh_w_cast_fp16)[name = tensor<string, []>("obj_447_cast_fp16")];
            tensor<int32, [4]> var_12713 = const()[name = tensor<string, []>("op_12713"), val = tensor<int32, [4]>([1, 20, 64, -1])];
            tensor<fp16, [1, 20, 64, 1500]> var_12714_cast_fp16 = reshape(shape = var_12713, x = value_cast_fp16)[name = tensor<string, []>("op_12714_cast_fp16")];
            tensor<bool, []> attn_transpose_x_0 = const()[name = tensor<string, []>("attn_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_transpose_y_0 = const()[name = tensor<string, []>("attn_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [1, 20, 64, 1]> attn_cast_fp16 = matmul(transpose_x = attn_transpose_x_0, transpose_y = attn_transpose_y_0, x = var_12714_cast_fp16, y = obj_447_cast_fp16)[name = tensor<string, []>("attn_cast_fp16")];
            tensor<int32, [4]> var_12717 = const()[name = tensor<string, []>("op_12717"), val = tensor<int32, [4]>([1, 1280, 1, -1])];
            tensor<fp16, [1, 1280, 1, 1]> input_947_cast_fp16 = reshape(shape = var_12717, x = attn_cast_fp16)[name = tensor<string, []>("input_947_cast_fp16")];
            tensor<int32, [2]> var_12724 = const()[name = tensor<string, []>("op_12724"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12726 = const()[name = tensor<string, []>("op_12726"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_635_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_635_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_635_pad_0 = const()[name = tensor<string, []>("pretrained_out_635_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 1280, 1, 1]> layers_31_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [819200]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(582724800))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(583544064))), name = tensor<string, []>("layers_31_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 1280, 1, 1])];
            tensor<fp16, [1280]> layers_31_encoder_attn_o_proj_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_31_encoder_attn_o_proj_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(583544192)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_635_cast_fp16 = conv(bias = layers_31_encoder_attn_o_proj_pretrained_bias_to_fp16, dilations = var_12726, groups = var_12437, pad = pretrained_out_635_pad_0, pad_type = pretrained_out_635_pad_type_0, strides = var_12724, weight = layers_31_encoder_attn_o_proj_pretrained_weight_to_fp16_palettized, x = input_947_cast_fp16)[name = tensor<string, []>("pretrained_out_635_cast_fp16")];
            tensor<int32, [2]> var_12730 = const()[name = tensor<string, []>("op_12730"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12732 = const()[name = tensor<string, []>("op_12732"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_949_pad_type_0 = const()[name = tensor<string, []>("input_949_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_949_pad_0 = const()[name = tensor<string, []>("input_949_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_31_encoder_attn_o_proj_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_31_encoder_attn_o_proj_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(583546816)))];
            tensor<fp16, [1, 16, 1, 1]> input_949_cast_fp16 = conv(dilations = var_12732, groups = var_12437, pad = input_949_pad_0, pad_type = input_949_pad_type_0, strides = var_12730, weight = layers_31_encoder_attn_o_proj_loraA_weight_to_fp16, x = input_947_cast_fp16)[name = tensor<string, []>("input_949_cast_fp16")];
            tensor<int32, [2]> var_12736 = const()[name = tensor<string, []>("op_12736"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12738 = const()[name = tensor<string, []>("op_12738"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1269_pad_type_0 = const()[name = tensor<string, []>("lora_out_1269_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1269_pad_0 = const()[name = tensor<string, []>("lora_out_1269_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_1271_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1271_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(583587840)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_1271_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_12738, groups = var_12437, pad = lora_out_1269_pad_0, pad_type = lora_out_1269_pad_type_0, strides = var_12736, weight = lora_out_1271_weight_0_to_fp16, x = input_949_cast_fp16)[name = tensor<string, []>("lora_out_1271_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> obj_445_cast_fp16 = add(x = pretrained_out_635_cast_fp16, y = lora_out_1271_cast_fp16)[name = tensor<string, []>("obj_445_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_191_cast_fp16 = add(x = inputs_189_cast_fp16, y = obj_445_cast_fp16)[name = tensor<string, []>("inputs_191_cast_fp16")];
            tensor<int32, [1]> var_12747 = const()[name = tensor<string, []>("op_12747"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_191_cast_fp16 = reduce_mean(axes = var_12747, keep_dims = var_12438, x = inputs_191_cast_fp16)[name = tensor<string, []>("channels_mean_191_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_191_cast_fp16 = sub(x = inputs_191_cast_fp16, y = channels_mean_191_cast_fp16)[name = tensor<string, []>("zero_mean_191_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_191_cast_fp16 = mul(x = zero_mean_191_cast_fp16, y = zero_mean_191_cast_fp16)[name = tensor<string, []>("zero_mean_sq_191_cast_fp16")];
            tensor<int32, [1]> var_12751 = const()[name = tensor<string, []>("op_12751"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_12752_cast_fp16 = reduce_mean(axes = var_12751, keep_dims = var_12438, x = zero_mean_sq_191_cast_fp16)[name = tensor<string, []>("op_12752_cast_fp16")];
            tensor<fp16, []> var_12753_to_fp16 = const()[name = tensor<string, []>("op_12753_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_12754_cast_fp16 = add(x = var_12752_cast_fp16, y = var_12753_to_fp16)[name = tensor<string, []>("op_12754_cast_fp16")];
            tensor<fp32, []> denom_191_epsilon_0 = const()[name = tensor<string, []>("denom_191_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_191_cast_fp16 = rsqrt(epsilon = denom_191_epsilon_0, x = var_12754_cast_fp16)[name = tensor<string, []>("denom_191_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_191_cast_fp16 = mul(x = zero_mean_191_cast_fp16, y = denom_191_cast_fp16)[name = tensor<string, []>("out_191_cast_fp16")];
            tensor<fp16, [1280]> input_951_gamma_0_to_fp16 = const()[name = tensor<string, []>("input_951_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(583628864)))];
            tensor<fp16, [1280]> input_951_beta_0_to_fp16 = const()[name = tensor<string, []>("input_951_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(583631488)))];
            tensor<fp16, []> input_951_epsilon_0_to_fp16 = const()[name = tensor<string, []>("input_951_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> input_951_cast_fp16 = batch_norm(beta = input_951_beta_0_to_fp16, epsilon = input_951_epsilon_0_to_fp16, gamma = input_951_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_191_cast_fp16)[name = tensor<string, []>("input_951_cast_fp16")];
            tensor<int32, [2]> var_12768 = const()[name = tensor<string, []>("op_12768"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12770 = const()[name = tensor<string, []>("op_12770"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_637_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_637_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_637_pad_0 = const()[name = tensor<string, []>("pretrained_out_637_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 1280, 1, 1]> layers_31_fc1_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(583634112))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(586910976))), name = tensor<string, []>("layers_31_fc1_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([5120, 1280, 1, 1])];
            tensor<fp16, [5120]> layers_31_fc1_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_31_fc1_pretrained_bias_to_fp16"), val = tensor<fp16, [5120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(586911104)))];
            tensor<fp16, [1, 5120, 1, 1]> pretrained_out_637_cast_fp16 = conv(bias = layers_31_fc1_pretrained_bias_to_fp16, dilations = var_12770, groups = var_12437, pad = pretrained_out_637_pad_0, pad_type = pretrained_out_637_pad_type_0, strides = var_12768, weight = layers_31_fc1_pretrained_weight_to_fp16_palettized, x = input_951_cast_fp16)[name = tensor<string, []>("pretrained_out_637_cast_fp16")];
            tensor<int32, [2]> var_12774 = const()[name = tensor<string, []>("op_12774"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12776 = const()[name = tensor<string, []>("op_12776"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_953_pad_type_0 = const()[name = tensor<string, []>("input_953_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_953_pad_0 = const()[name = tensor<string, []>("input_953_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1280, 1, 1]> layers_31_fc1_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_31_fc1_loraA_weight_to_fp16"), val = tensor<fp16, [16, 1280, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(586921408)))];
            tensor<fp16, [1, 16, 1, 1]> input_953_cast_fp16 = conv(dilations = var_12776, groups = var_12437, pad = input_953_pad_0, pad_type = input_953_pad_type_0, strides = var_12774, weight = layers_31_fc1_loraA_weight_to_fp16, x = input_951_cast_fp16)[name = tensor<string, []>("input_953_cast_fp16")];
            tensor<int32, [2]> var_12780 = const()[name = tensor<string, []>("op_12780"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12782 = const()[name = tensor<string, []>("op_12782"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1273_pad_type_0 = const()[name = tensor<string, []>("lora_out_1273_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1273_pad_0 = const()[name = tensor<string, []>("lora_out_1273_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [5120, 16, 1, 1]> lora_out_1275_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_1275_weight_0_to_fp16"), val = tensor<fp16, [5120, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(586962432)))];
            tensor<fp16, [1, 5120, 1, 1]> lora_out_1275_cast_fp16 = conv(bias = lora_out_35_bias_0_to_fp16, dilations = var_12782, groups = var_12437, pad = lora_out_1273_pad_0, pad_type = lora_out_1273_pad_type_0, strides = var_12780, weight = lora_out_1275_weight_0_to_fp16, x = input_953_cast_fp16)[name = tensor<string, []>("lora_out_1275_cast_fp16")];
            tensor<fp16, [1, 5120, 1, 1]> input_955_cast_fp16 = add(x = pretrained_out_637_cast_fp16, y = lora_out_1275_cast_fp16)[name = tensor<string, []>("input_955_cast_fp16")];
            tensor<string, []> input_957_mode_0 = const()[name = tensor<string, []>("input_957_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 5120, 1, 1]> input_957_cast_fp16 = gelu(mode = input_957_mode_0, x = input_955_cast_fp16)[name = tensor<string, []>("input_957_cast_fp16")];
            tensor<int32, [2]> var_12794 = const()[name = tensor<string, []>("op_12794"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12796 = const()[name = tensor<string, []>("op_12796"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> pretrained_out_pad_type_0 = const()[name = tensor<string, []>("pretrained_out_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> pretrained_out_pad_0 = const()[name = tensor<string, []>("pretrained_out_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 5120, 1, 1]> layers_31_fc2_pretrained_weight_to_fp16_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [3276800]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(587126336))), lut = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(590403200))), name = tensor<string, []>("layers_31_fc2_pretrained_weight_to_fp16_palettized"), shape = tensor<uint32, [4]>([1280, 5120, 1, 1])];
            tensor<fp16, [1280]> layers_31_fc2_pretrained_bias_to_fp16 = const()[name = tensor<string, []>("layers_31_fc2_pretrained_bias_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(590403328)))];
            tensor<fp16, [1, 1280, 1, 1]> pretrained_out_cast_fp16 = conv(bias = layers_31_fc2_pretrained_bias_to_fp16, dilations = var_12796, groups = var_12437, pad = pretrained_out_pad_0, pad_type = pretrained_out_pad_type_0, strides = var_12794, weight = layers_31_fc2_pretrained_weight_to_fp16_palettized, x = input_957_cast_fp16)[name = tensor<string, []>("pretrained_out_cast_fp16")];
            tensor<int32, [2]> var_12800 = const()[name = tensor<string, []>("op_12800"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12802 = const()[name = tensor<string, []>("op_12802"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> input_pad_type_0 = const()[name = tensor<string, []>("input_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> input_pad_0 = const()[name = tensor<string, []>("input_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 5120, 1, 1]> layers_31_fc2_loraA_weight_to_fp16 = const()[name = tensor<string, []>("layers_31_fc2_loraA_weight_to_fp16"), val = tensor<fp16, [16, 5120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(590405952)))];
            tensor<fp16, [1, 16, 1, 1]> input_cast_fp16 = conv(dilations = var_12802, groups = var_12437, pad = input_pad_0, pad_type = input_pad_type_0, strides = var_12800, weight = layers_31_fc2_loraA_weight_to_fp16, x = input_957_cast_fp16)[name = tensor<string, []>("input_cast_fp16")];
            tensor<int32, [2]> var_12806 = const()[name = tensor<string, []>("op_12806"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> var_12808 = const()[name = tensor<string, []>("op_12808"), val = tensor<int32, [2]>([1, 1])];
            tensor<string, []> lora_out_1277_pad_type_0 = const()[name = tensor<string, []>("lora_out_1277_pad_type_0"), val = tensor<string, []>("custom")];
            tensor<int32, [4]> lora_out_1277_pad_0 = const()[name = tensor<string, []>("lora_out_1277_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [1280, 16, 1, 1]> lora_out_weight_0_to_fp16 = const()[name = tensor<string, []>("lora_out_weight_0_to_fp16"), val = tensor<fp16, [1280, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(590569856)))];
            tensor<fp16, [1, 1280, 1, 1]> lora_out_cast_fp16 = conv(bias = obj_1_mean_0_to_fp16, dilations = var_12808, groups = var_12437, pad = lora_out_1277_pad_0, pad_type = lora_out_1277_pad_type_0, strides = var_12806, weight = lora_out_weight_0_to_fp16, x = input_cast_fp16)[name = tensor<string, []>("lora_out_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_65_cast_fp16 = add(x = pretrained_out_cast_fp16, y = lora_out_cast_fp16)[name = tensor<string, []>("hidden_states_65_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> inputs_cast_fp16 = add(x = inputs_191_cast_fp16, y = hidden_states_65_cast_fp16)[name = tensor<string, []>("inputs_cast_fp16")];
            tensor<bool, []> var_12821 = const()[name = tensor<string, []>("op_12821"), val = tensor<bool, []>(true)];
            tensor<int32, [1]> var_12825 = const()[name = tensor<string, []>("op_12825"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> channels_mean_cast_fp16 = reduce_mean(axes = var_12825, keep_dims = var_12821, x = inputs_cast_fp16)[name = tensor<string, []>("channels_mean_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_cast_fp16 = sub(x = inputs_cast_fp16, y = channels_mean_cast_fp16)[name = tensor<string, []>("zero_mean_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> zero_mean_sq_cast_fp16 = mul(x = zero_mean_cast_fp16, y = zero_mean_cast_fp16)[name = tensor<string, []>("zero_mean_sq_cast_fp16")];
            tensor<int32, [1]> var_12829 = const()[name = tensor<string, []>("op_12829"), val = tensor<int32, [1]>([1])];
            tensor<fp16, [1, 1, 1, 1]> var_12830_cast_fp16 = reduce_mean(axes = var_12829, keep_dims = var_12821, x = zero_mean_sq_cast_fp16)[name = tensor<string, []>("op_12830_cast_fp16")];
            tensor<fp16, []> var_12831_to_fp16 = const()[name = tensor<string, []>("op_12831_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1, 1, 1]> var_12832_cast_fp16 = add(x = var_12830_cast_fp16, y = var_12831_to_fp16)[name = tensor<string, []>("op_12832_cast_fp16")];
            tensor<fp32, []> denom_epsilon_0 = const()[name = tensor<string, []>("denom_epsilon_0"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp16, [1, 1, 1, 1]> denom_cast_fp16 = rsqrt(epsilon = denom_epsilon_0, x = var_12832_cast_fp16)[name = tensor<string, []>("denom_cast_fp16")];
            tensor<fp16, [1, 1280, 1, 1]> out_cast_fp16 = mul(x = zero_mean_cast_fp16, y = denom_cast_fp16)[name = tensor<string, []>("out_cast_fp16")];
            tensor<fp16, [1280]> hidden_states_gamma_0_to_fp16 = const()[name = tensor<string, []>("hidden_states_gamma_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(590610880)))];
            tensor<fp16, [1280]> hidden_states_beta_0_to_fp16 = const()[name = tensor<string, []>("hidden_states_beta_0_to_fp16"), val = tensor<fp16, [1280]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(590613504)))];
            tensor<fp16, []> hidden_states_epsilon_0_to_fp16 = const()[name = tensor<string, []>("hidden_states_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.5p-17)];
            tensor<fp16, [1, 1280, 1, 1]> hidden_states_cast_fp16 = batch_norm(beta = hidden_states_beta_0_to_fp16, epsilon = hidden_states_epsilon_0_to_fp16, gamma = hidden_states_gamma_0_to_fp16, mean = obj_1_mean_0_to_fp16, variance = obj_1_variance_0_to_fp16, x = out_cast_fp16)[name = tensor<string, []>("hidden_states_cast_fp16")];
            tensor<int32, [1]> var_12842_axes_0 = const()[name = tensor<string, []>("op_12842_axes_0"), val = tensor<int32, [1]>([2])];
            tensor<fp16, [1, 1280, 1]> var_12842_cast_fp16 = squeeze(axes = var_12842_axes_0, x = hidden_states_cast_fp16)[name = tensor<string, []>("op_12842_cast_fp16")];
            tensor<int32, [3]> var_12845_perm_0 = const()[name = tensor<string, []>("op_12845_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<fp16, [51866]> linear_0_bias_0_to_fp16 = const()[name = tensor<string, []>("linear_0_bias_0_to_fp16"), val = tensor<fp16, [51866]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(590616128)))];
            tensor<fp16, [1, 1, 1280]> transpose_0 = transpose(perm = var_12845_perm_0, x = var_12842_cast_fp16)[name = tensor<string, []>("transpose_0")];
            tensor<fp16, [1, 1, 51866]> logits = linear(bias = linear_0_bias_0_to_fp16, weight = embed_tokens_weight_to_fp16, x = transpose_0)[name = tensor<string, []>("linear_0_cast_fp16")];
            tensor<int32, []> var_12849 = const()[name = tensor<string, []>("op_12849"), val = tensor<int32, []>(1)];
            tensor<bool, []> obj_451_interleave_0 = const()[name = tensor<string, []>("obj_451_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 40960, 1, 1]> key_cache_updates = concat(axis = var_12849, interleave = obj_451_interleave_0, values = (current_key_1_cast_fp16, current_key_3_cast_fp16, current_key_5_cast_fp16, current_key_7_cast_fp16, current_key_9_cast_fp16, current_key_11_cast_fp16, current_key_13_cast_fp16, current_key_15_cast_fp16, current_key_17_cast_fp16, current_key_19_cast_fp16, current_key_21_cast_fp16, current_key_23_cast_fp16, current_key_25_cast_fp16, current_key_27_cast_fp16, current_key_29_cast_fp16, current_key_31_cast_fp16, current_key_33_cast_fp16, current_key_35_cast_fp16, current_key_37_cast_fp16, current_key_39_cast_fp16, current_key_41_cast_fp16, current_key_43_cast_fp16, current_key_45_cast_fp16, current_key_47_cast_fp16, current_key_49_cast_fp16, current_key_51_cast_fp16, current_key_53_cast_fp16, current_key_55_cast_fp16, current_key_57_cast_fp16, current_key_59_cast_fp16, current_key_61_cast_fp16, current_key_cast_fp16))[name = tensor<string, []>("obj_451_cast_fp16")];
            tensor<int32, []> var_12852 = const()[name = tensor<string, []>("op_12852"), val = tensor<int32, []>(1)];
            tensor<bool, []> obj_453_interleave_0 = const()[name = tensor<string, []>("obj_453_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 40960, 1, 1]> value_cache_updates = concat(axis = var_12852, interleave = obj_453_interleave_0, values = (current_value_1_cast_fp16, current_value_3_cast_fp16, current_value_5_cast_fp16, current_value_7_cast_fp16, current_value_9_cast_fp16, current_value_11_cast_fp16, current_value_13_cast_fp16, current_value_15_cast_fp16, current_value_17_cast_fp16, current_value_19_cast_fp16, current_value_21_cast_fp16, current_value_23_cast_fp16, current_value_25_cast_fp16, current_value_27_cast_fp16, current_value_29_cast_fp16, current_value_31_cast_fp16, current_value_33_cast_fp16, current_value_35_cast_fp16, current_value_37_cast_fp16, current_value_39_cast_fp16, current_value_41_cast_fp16, current_value_43_cast_fp16, current_value_45_cast_fp16, current_value_47_cast_fp16, current_value_49_cast_fp16, current_value_51_cast_fp16, current_value_53_cast_fp16, current_value_55_cast_fp16, current_value_57_cast_fp16, current_value_59_cast_fp16, current_value_61_cast_fp16, current_value_cast_fp16))[name = tensor<string, []>("obj_453_cast_fp16")];
            tensor<int32, [4]> var_12863_begin_0 = const()[name = tensor<string, []>("op_12863_begin_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [4]> var_12863_end_0 = const()[name = tensor<string, []>("op_12863_end_0"), val = tensor<int32, [4]>([1, 1, 1, 1500])];
            tensor<bool, [4]> var_12863_end_mask_0 = const()[name = tensor<string, []>("op_12863_end_mask_0"), val = tensor<bool, [4]>([true, false, true, true])];
            tensor<fp16, [1, 1, 1, 1500]> var_12863_cast_fp16 = slice_by_index(begin = var_12863_begin_0, end = var_12863_end_0, end_mask = var_12863_end_mask_0, x = obj_111_cast_fp16)[name = tensor<string, []>("op_12863_cast_fp16")];
            tensor<int32, [4]> var_12866_begin_0 = const()[name = tensor<string, []>("op_12866_begin_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [4]> var_12866_end_0 = const()[name = tensor<string, []>("op_12866_end_0"), val = tensor<int32, [4]>([1, 1, 1, 1500])];
            tensor<bool, [4]> var_12866_end_mask_0 = const()[name = tensor<string, []>("op_12866_end_mask_0"), val = tensor<bool, [4]>([true, true, false, true])];
            tensor<bool, [4]> var_12866_squeeze_mask_0 = const()[name = tensor<string, []>("op_12866_squeeze_mask_0"), val = tensor<bool, [4]>([false, false, true, false])];
            tensor<fp16, [1, 1, 1500]> var_12866_cast_fp16 = slice_by_index(begin = var_12866_begin_0, end = var_12866_end_0, end_mask = var_12866_end_mask_0, squeeze_mask = var_12866_squeeze_mask_0, x = var_12863_cast_fp16)[name = tensor<string, []>("op_12866_cast_fp16")];
            tensor<int32, [4]> var_12881_begin_0 = const()[name = tensor<string, []>("op_12881_begin_0"), val = tensor<int32, [4]>([0, 17, 0, 0])];
            tensor<int32, [4]> var_12881_end_0 = const()[name = tensor<string, []>("op_12881_end_0"), val = tensor<int32, [4]>([1, 18, 1, 1500])];
            tensor<bool, [4]> var_12881_end_mask_0 = const()[name = tensor<string, []>("op_12881_end_mask_0"), val = tensor<bool, [4]>([true, false, true, true])];
            tensor<fp16, [1, 1, 1, 1500]> var_12881_cast_fp16 = slice_by_index(begin = var_12881_begin_0, end = var_12881_end_0, end_mask = var_12881_end_mask_0, x = obj_153_cast_fp16)[name = tensor<string, []>("op_12881_cast_fp16")];
            tensor<int32, [4]> var_12884_begin_0 = const()[name = tensor<string, []>("op_12884_begin_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [4]> var_12884_end_0 = const()[name = tensor<string, []>("op_12884_end_0"), val = tensor<int32, [4]>([1, 1, 1, 1500])];
            tensor<bool, [4]> var_12884_end_mask_0 = const()[name = tensor<string, []>("op_12884_end_mask_0"), val = tensor<bool, [4]>([true, true, false, true])];
            tensor<bool, [4]> var_12884_squeeze_mask_0 = const()[name = tensor<string, []>("op_12884_squeeze_mask_0"), val = tensor<bool, [4]>([false, false, true, false])];
            tensor<fp16, [1, 1, 1500]> var_12884_cast_fp16 = slice_by_index(begin = var_12884_begin_0, end = var_12884_end_0, end_mask = var_12884_end_mask_0, squeeze_mask = var_12884_squeeze_mask_0, x = var_12881_cast_fp16)[name = tensor<string, []>("op_12884_cast_fp16")];
            tensor<int32, [4]> var_12899_begin_0 = const()[name = tensor<string, []>("op_12899_begin_0"), val = tensor<int32, [4]>([0, 18, 0, 0])];
            tensor<int32, [4]> var_12899_end_0 = const()[name = tensor<string, []>("op_12899_end_0"), val = tensor<int32, [4]>([1, 19, 1, 1500])];
            tensor<bool, [4]> var_12899_end_mask_0 = const()[name = tensor<string, []>("op_12899_end_mask_0"), val = tensor<bool, [4]>([true, false, true, true])];
            tensor<fp16, [1, 1, 1, 1500]> var_12899_cast_fp16 = slice_by_index(begin = var_12899_begin_0, end = var_12899_end_0, end_mask = var_12899_end_mask_0, x = obj_181_cast_fp16)[name = tensor<string, []>("op_12899_cast_fp16")];
            tensor<int32, [4]> var_12902_begin_0 = const()[name = tensor<string, []>("op_12902_begin_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [4]> var_12902_end_0 = const()[name = tensor<string, []>("op_12902_end_0"), val = tensor<int32, [4]>([1, 1, 1, 1500])];
            tensor<bool, [4]> var_12902_end_mask_0 = const()[name = tensor<string, []>("op_12902_end_mask_0"), val = tensor<bool, [4]>([true, true, false, true])];
            tensor<bool, [4]> var_12902_squeeze_mask_0 = const()[name = tensor<string, []>("op_12902_squeeze_mask_0"), val = tensor<bool, [4]>([false, false, true, false])];
            tensor<fp16, [1, 1, 1500]> var_12902_cast_fp16 = slice_by_index(begin = var_12902_begin_0, end = var_12902_end_0, end_mask = var_12902_end_mask_0, squeeze_mask = var_12902_squeeze_mask_0, x = var_12899_cast_fp16)[name = tensor<string, []>("op_12902_cast_fp16")];
            tensor<int32, [4]> var_12917_begin_0 = const()[name = tensor<string, []>("op_12917_begin_0"), val = tensor<int32, [4]>([0, 12, 0, 0])];
            tensor<int32, [4]> var_12917_end_0 = const()[name = tensor<string, []>("op_12917_end_0"), val = tensor<int32, [4]>([1, 13, 1, 1500])];
            tensor<bool, [4]> var_12917_end_mask_0 = const()[name = tensor<string, []>("op_12917_end_mask_0"), val = tensor<bool, [4]>([true, false, true, true])];
            tensor<fp16, [1, 1, 1, 1500]> var_12917_cast_fp16 = slice_by_index(begin = var_12917_begin_0, end = var_12917_end_0, end_mask = var_12917_end_mask_0, x = obj_195_cast_fp16)[name = tensor<string, []>("op_12917_cast_fp16")];
            tensor<int32, [4]> var_12920_begin_0 = const()[name = tensor<string, []>("op_12920_begin_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [4]> var_12920_end_0 = const()[name = tensor<string, []>("op_12920_end_0"), val = tensor<int32, [4]>([1, 1, 1, 1500])];
            tensor<bool, [4]> var_12920_end_mask_0 = const()[name = tensor<string, []>("op_12920_end_mask_0"), val = tensor<bool, [4]>([true, true, false, true])];
            tensor<bool, [4]> var_12920_squeeze_mask_0 = const()[name = tensor<string, []>("op_12920_squeeze_mask_0"), val = tensor<bool, [4]>([false, false, true, false])];
            tensor<fp16, [1, 1, 1500]> var_12920_cast_fp16 = slice_by_index(begin = var_12920_begin_0, end = var_12920_end_0, end_mask = var_12920_end_mask_0, squeeze_mask = var_12920_squeeze_mask_0, x = var_12917_cast_fp16)[name = tensor<string, []>("op_12920_cast_fp16")];
            tensor<int32, [4]> var_12935_begin_0 = const()[name = tensor<string, []>("op_12935_begin_0"), val = tensor<int32, [4]>([0, 1, 0, 0])];
            tensor<int32, [4]> var_12935_end_0 = const()[name = tensor<string, []>("op_12935_end_0"), val = tensor<int32, [4]>([1, 2, 1, 1500])];
            tensor<bool, [4]> var_12935_end_mask_0 = const()[name = tensor<string, []>("op_12935_end_mask_0"), val = tensor<bool, [4]>([true, false, true, true])];
            tensor<fp16, [1, 1, 1, 1500]> var_12935_cast_fp16 = slice_by_index(begin = var_12935_begin_0, end = var_12935_end_0, end_mask = var_12935_end_mask_0, x = obj_237_cast_fp16)[name = tensor<string, []>("op_12935_cast_fp16")];
            tensor<int32, [4]> var_12938_begin_0 = const()[name = tensor<string, []>("op_12938_begin_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [4]> var_12938_end_0 = const()[name = tensor<string, []>("op_12938_end_0"), val = tensor<int32, [4]>([1, 1, 1, 1500])];
            tensor<bool, [4]> var_12938_end_mask_0 = const()[name = tensor<string, []>("op_12938_end_mask_0"), val = tensor<bool, [4]>([true, true, false, true])];
            tensor<bool, [4]> var_12938_squeeze_mask_0 = const()[name = tensor<string, []>("op_12938_squeeze_mask_0"), val = tensor<bool, [4]>([false, false, true, false])];
            tensor<fp16, [1, 1, 1500]> var_12938_cast_fp16 = slice_by_index(begin = var_12938_begin_0, end = var_12938_end_0, end_mask = var_12938_end_mask_0, squeeze_mask = var_12938_squeeze_mask_0, x = var_12935_cast_fp16)[name = tensor<string, []>("op_12938_cast_fp16")];
            tensor<int32, [4]> var_12953_begin_0 = const()[name = tensor<string, []>("op_12953_begin_0"), val = tensor<int32, [4]>([0, 14, 0, 0])];
            tensor<int32, [4]> var_12953_end_0 = const()[name = tensor<string, []>("op_12953_end_0"), val = tensor<int32, [4]>([1, 15, 1, 1500])];
            tensor<bool, [4]> var_12953_end_mask_0 = const()[name = tensor<string, []>("op_12953_end_mask_0"), val = tensor<bool, [4]>([true, false, true, true])];
            tensor<fp16, [1, 1, 1, 1500]> var_12953_cast_fp16 = slice_by_index(begin = var_12953_begin_0, end = var_12953_end_0, end_mask = var_12953_end_mask_0, x = obj_251_cast_fp16)[name = tensor<string, []>("op_12953_cast_fp16")];
            tensor<int32, [4]> var_12956_begin_0 = const()[name = tensor<string, []>("op_12956_begin_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [4]> var_12956_end_0 = const()[name = tensor<string, []>("op_12956_end_0"), val = tensor<int32, [4]>([1, 1, 1, 1500])];
            tensor<bool, [4]> var_12956_end_mask_0 = const()[name = tensor<string, []>("op_12956_end_mask_0"), val = tensor<bool, [4]>([true, true, false, true])];
            tensor<bool, [4]> var_12956_squeeze_mask_0 = const()[name = tensor<string, []>("op_12956_squeeze_mask_0"), val = tensor<bool, [4]>([false, false, true, false])];
            tensor<fp16, [1, 1, 1500]> var_12956_cast_fp16 = slice_by_index(begin = var_12956_begin_0, end = var_12956_end_0, end_mask = var_12956_end_mask_0, squeeze_mask = var_12956_squeeze_mask_0, x = var_12953_cast_fp16)[name = tensor<string, []>("op_12956_cast_fp16")];
            tensor<int32, [4]> var_12971_begin_0 = const()[name = tensor<string, []>("op_12971_begin_0"), val = tensor<int32, [4]>([0, 11, 0, 0])];
            tensor<int32, [4]> var_12971_end_0 = const()[name = tensor<string, []>("op_12971_end_0"), val = tensor<int32, [4]>([1, 12, 1, 1500])];
            tensor<bool, [4]> var_12971_end_mask_0 = const()[name = tensor<string, []>("op_12971_end_mask_0"), val = tensor<bool, [4]>([true, false, true, true])];
            tensor<fp16, [1, 1, 1, 1500]> var_12971_cast_fp16 = slice_by_index(begin = var_12971_begin_0, end = var_12971_end_0, end_mask = var_12971_end_mask_0, x = obj_279_cast_fp16)[name = tensor<string, []>("op_12971_cast_fp16")];
            tensor<int32, [4]> var_12974_begin_0 = const()[name = tensor<string, []>("op_12974_begin_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [4]> var_12974_end_0 = const()[name = tensor<string, []>("op_12974_end_0"), val = tensor<int32, [4]>([1, 1, 1, 1500])];
            tensor<bool, [4]> var_12974_end_mask_0 = const()[name = tensor<string, []>("op_12974_end_mask_0"), val = tensor<bool, [4]>([true, true, false, true])];
            tensor<bool, [4]> var_12974_squeeze_mask_0 = const()[name = tensor<string, []>("op_12974_squeeze_mask_0"), val = tensor<bool, [4]>([false, false, true, false])];
            tensor<fp16, [1, 1, 1500]> var_12974_cast_fp16 = slice_by_index(begin = var_12974_begin_0, end = var_12974_end_0, end_mask = var_12974_end_mask_0, squeeze_mask = var_12974_squeeze_mask_0, x = var_12971_cast_fp16)[name = tensor<string, []>("op_12974_cast_fp16")];
            tensor<int32, [4]> var_12989_begin_0 = const()[name = tensor<string, []>("op_12989_begin_0"), val = tensor<int32, [4]>([0, 4, 0, 0])];
            tensor<int32, [4]> var_12989_end_0 = const()[name = tensor<string, []>("op_12989_end_0"), val = tensor<int32, [4]>([1, 5, 1, 1500])];
            tensor<bool, [4]> var_12989_end_mask_0 = const()[name = tensor<string, []>("op_12989_end_mask_0"), val = tensor<bool, [4]>([true, false, true, true])];
            tensor<fp16, [1, 1, 1, 1500]> var_12989_cast_fp16 = slice_by_index(begin = var_12989_begin_0, end = var_12989_end_0, end_mask = var_12989_end_mask_0, x = obj_307_cast_fp16)[name = tensor<string, []>("op_12989_cast_fp16")];
            tensor<int32, [4]> var_12992_begin_0 = const()[name = tensor<string, []>("op_12992_begin_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [4]> var_12992_end_0 = const()[name = tensor<string, []>("op_12992_end_0"), val = tensor<int32, [4]>([1, 1, 1, 1500])];
            tensor<bool, [4]> var_12992_end_mask_0 = const()[name = tensor<string, []>("op_12992_end_mask_0"), val = tensor<bool, [4]>([true, true, false, true])];
            tensor<bool, [4]> var_12992_squeeze_mask_0 = const()[name = tensor<string, []>("op_12992_squeeze_mask_0"), val = tensor<bool, [4]>([false, false, true, false])];
            tensor<fp16, [1, 1, 1500]> var_12992_cast_fp16 = slice_by_index(begin = var_12992_begin_0, end = var_12992_end_0, end_mask = var_12992_end_mask_0, squeeze_mask = var_12992_squeeze_mask_0, x = var_12989_cast_fp16)[name = tensor<string, []>("op_12992_cast_fp16")];
            tensor<int32, [4]> var_13007_begin_0 = const()[name = tensor<string, []>("op_13007_begin_0"), val = tensor<int32, [4]>([0, 1, 0, 0])];
            tensor<int32, [4]> var_13007_end_0 = const()[name = tensor<string, []>("op_13007_end_0"), val = tensor<int32, [4]>([1, 2, 1, 1500])];
            tensor<bool, [4]> var_13007_end_mask_0 = const()[name = tensor<string, []>("op_13007_end_mask_0"), val = tensor<bool, [4]>([true, false, true, true])];
            tensor<fp16, [1, 1, 1, 1500]> var_13007_cast_fp16 = slice_by_index(begin = var_13007_begin_0, end = var_13007_end_0, end_mask = var_13007_end_mask_0, x = obj_349_cast_fp16)[name = tensor<string, []>("op_13007_cast_fp16")];
            tensor<int32, [4]> var_13010_begin_0 = const()[name = tensor<string, []>("op_13010_begin_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [4]> var_13010_end_0 = const()[name = tensor<string, []>("op_13010_end_0"), val = tensor<int32, [4]>([1, 1, 1, 1500])];
            tensor<bool, [4]> var_13010_end_mask_0 = const()[name = tensor<string, []>("op_13010_end_mask_0"), val = tensor<bool, [4]>([true, true, false, true])];
            tensor<bool, [4]> var_13010_squeeze_mask_0 = const()[name = tensor<string, []>("op_13010_squeeze_mask_0"), val = tensor<bool, [4]>([false, false, true, false])];
            tensor<fp16, [1, 1, 1500]> var_13010_cast_fp16 = slice_by_index(begin = var_13010_begin_0, end = var_13010_end_0, end_mask = var_13010_end_mask_0, squeeze_mask = var_13010_squeeze_mask_0, x = var_13007_cast_fp16)[name = tensor<string, []>("op_13010_cast_fp16")];
            tensor<int32, [4]> var_13025_begin_0 = const()[name = tensor<string, []>("op_13025_begin_0"), val = tensor<int32, [4]>([0, 6, 0, 0])];
            tensor<int32, [4]> var_13025_end_0 = const()[name = tensor<string, []>("op_13025_end_0"), val = tensor<int32, [4]>([1, 7, 1, 1500])];
            tensor<bool, [4]> var_13025_end_mask_0 = const()[name = tensor<string, []>("op_13025_end_mask_0"), val = tensor<bool, [4]>([true, false, true, true])];
            tensor<fp16, [1, 1, 1, 1500]> var_13025_cast_fp16 = slice_by_index(begin = var_13025_begin_0, end = var_13025_end_0, end_mask = var_13025_end_mask_0, x = obj_363_cast_fp16)[name = tensor<string, []>("op_13025_cast_fp16")];
            tensor<int32, [4]> var_13028_begin_0 = const()[name = tensor<string, []>("op_13028_begin_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [4]> var_13028_end_0 = const()[name = tensor<string, []>("op_13028_end_0"), val = tensor<int32, [4]>([1, 1, 1, 1500])];
            tensor<bool, [4]> var_13028_end_mask_0 = const()[name = tensor<string, []>("op_13028_end_mask_0"), val = tensor<bool, [4]>([true, true, false, true])];
            tensor<bool, [4]> var_13028_squeeze_mask_0 = const()[name = tensor<string, []>("op_13028_squeeze_mask_0"), val = tensor<bool, [4]>([false, false, true, false])];
            tensor<fp16, [1, 1, 1500]> var_13028_cast_fp16 = slice_by_index(begin = var_13028_begin_0, end = var_13028_end_0, end_mask = var_13028_end_mask_0, squeeze_mask = var_13028_squeeze_mask_0, x = var_13025_cast_fp16)[name = tensor<string, []>("op_13028_cast_fp16")];
            tensor<int32, []> var_13035 = const()[name = tensor<string, []>("op_13035"), val = tensor<int32, []>(1)];
            tensor<bool, []> var_13036_interleave_0 = const()[name = tensor<string, []>("op_13036_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 10, 1500]> var_13036_cast_fp16 = concat(axis = var_13035, interleave = var_13036_interleave_0, values = (var_12866_cast_fp16, var_12884_cast_fp16, var_12902_cast_fp16, var_12920_cast_fp16, var_12938_cast_fp16, var_12956_cast_fp16, var_12974_cast_fp16, var_12992_cast_fp16, var_13010_cast_fp16, var_13028_cast_fp16))[name = tensor<string, []>("op_13036_cast_fp16")];
            tensor<int32, [1]> var_13038 = const()[name = tensor<string, []>("op_13038"), val = tensor<int32, [1]>([1])];
            tensor<bool, []> var_13039 = const()[name = tensor<string, []>("op_13039"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 1500]> alignment_heads_weights = reduce_mean(axes = var_13038, keep_dims = var_13039, x = var_13036_cast_fp16)[name = tensor<string, []>("obj_cast_fp16")];
        } -> (logits, key_cache_updates, value_cache_updates, alignment_heads_weights);
}